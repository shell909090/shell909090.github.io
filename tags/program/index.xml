<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>program on Shell&#39;s Home</title>
    <link>//blog.shell909090.org/tags/program/</link>
    <description>Recent content in program on Shell&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>CC-BY-SA4.0</copyright>
    <lastBuildDate>Tue, 27 Jan 2015 22:19:37 +0800</lastBuildDate>
    
	<atom:link href="//blog.shell909090.org/tags/program/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Charlie and Dave</title>
      <link>//blog.shell909090.org/blog/archives/2720/</link>
      <pubDate>Tue, 27 Jan 2015 22:19:37 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2720/</guid>
      <description> 公司希望弄一套双授权的安全系统，老大提供了一套算法，求大家review。如果这个方案确实可行，那么我们会做完然后开源出来给大家用。
Author and License Author: 韩拓 保留所有权利 All Rights Reserved
以下内容不以cc-by-sa3.0发布。(因为根本不是我的创作)
场景  Alice希望登录到Bob上执行操作。 两者的基本控制协议为ssh。  假定  攻击者名叫Mallory。 如果Alice的私钥泄漏，管理者必须有权停止Alice到Bob的访问而不需要更换所有Bob的公钥。 除去Alice和Bob外，参与通讯过程的所有机器(即下文中的Charlie和Dave)中可能随机被攻破一台。 服务都在内网，但是如果网关和被攻破的机器是同类系统，Mallory即可具有内网监听和伪造数据报文的权限。 Alice不会利用获得的Bob的权限故意执行危害性指令(但是可能被诱骗)。 Alice和Bob不会被攻破。  方案 假定有两台机器，Charlie和Dave，Dave和网关不得是同类系统。根据假定4，两台机器不会同时被攻破。
 Alice通过SSL和Dave建立连接，上报自己的用户名，需要访问的设备和帐号，并提交一个临时生成的ssh pubkey(username, account, host, pubkey)。 Dave根据预先设的IP-username-sslkey验证用户身份为Alice，并且根据ACL确认其具有访问权限。 如果通过验证，那么Dave用自己的key，通过SSL联系Bob上的某个程序，将Alice的pubkey提交到Bob的合适帐号上(account, pubkey)。 Bob通过sslkey验证提交者确系Dave，将pubkey临时加入account中。 Bob完成此事后，通过Dave向Alice返回成功。 Alice通过SSL和Charlie联系，上报自己的(username, account, host)。 Charlie根据预设的IP-username-sslkey验证用户身份为Alice，并且根据ACL确认其具有访问权限。 如果通过验证，那么Charlie用自己的key，通过SSL联系Bob上某个程序，为Alice开通到Bob的22端口的tcp盲转发。 Alice利用开启的tcp通道，和自己的临时ssh private key验证登录Bob。 在Alice连接Bob上的程序后，删除alice留在Bob上的临时pubkey。  验证 假定Charlie被攻破。
 方案1-5没有影响。 Charlie拥有能够在任意一台机器上开启盲转发的权限。 但是Charlie并不能影响Dave去添加pubkey。  假定Dave被攻破。
 Dave拥有在任意一台机器上添加pubkey的权限。 但是Dave并不具有打开到任意一台机器ssh端口的权限。  </description>
    </item>
    
    <item>
      <title>手机上app的权限对比和分析</title>
      <link>//blog.shell909090.org/blog/archives/2698/</link>
      <pubDate>Fri, 07 Nov 2014 16:16:04 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2698/</guid>
      <description>简述 今天看到这篇文章，勾起了我的好奇。我的手机里有多少app有安全隐患呢？当然，我知道很多有安全问题的app我不能删——例如企鹅家。但是如果某个app没有必然需要，或者有替代品。我不介意换一个用。所以我写了这篇blog，对比了各种同类或近似app的权限要求。
先说明一点，这篇文章所列出的app权限，是根据当前(2014-11-07)google play上的应用权限数据，截取我感兴趣的部分权限汇总的。既不是完全的敏感权限列表，也不可能不变化。如果有什么补充，欢迎你联系我。
同时你需要知道，app需要某个权限，并不一定表示要用来做坏事。很多时候是因为功能确实需要。因此我也在下面点评了部分我知道的功能需要对应权限。即便我们在app里面找不到权限对应功能，也不能绝对断言app正在作恶——只是相比起来我更信任不需要提供这个权限的app而已。这也是为什么我做的是分类对比——方便你来比较和替换。
IM类 telegram  read SMS 照相 录音 location read/modify contacts run at startup  talkback  change audio setting  我太感动了。
QQ  read SMS read/modify contacts 照相 录音 location read/write call log read/write calendar disable screen lock NFC bluetooth run at startup change audio setting  流氓权限大集合啊。你说要contacts我还能理解，要call log干嘛？还要write？而且功能里也找不到为什么需要NFC和蓝牙。
微信  read SMS 照相 录音 location read/modify contacts bluetooth run at startup change audio setting  基本同QQ，不过权限少了很多。</description>
    </item>
    
    <item>
      <title>context切换测试——C语言协程有关部分请求review</title>
      <link>//blog.shell909090.org/blog/archives/2696/</link>
      <pubDate>Thu, 06 Nov 2014 17:08:18 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2696/</guid>
      <description>setjmp/longjmp测试 使用s_jmp程序来测试setjmp的性能。1G次循环。下面是结论：
5.77,0.00,29,0,0,0,99% 5.70,0.00,30,0,0,0,99% 5.71,0.00,22,0,0,0,99% 5.71,0.00,23,0,0,0,99% 5.70,0.00,30,0,0,0,100% 5.70,0.00,23,0,0,0,99%  统计结果如下：
 time mean = 5.715 time var = 0.000625  单次调度开销只有5.7ns，在所有测试中性能最优。(glibc-2.19/sysdeps/x86_64/setjmp.S)
getcontext/setcontext测试 使用s_context程序来测试setcontext的性能。100M次循环。下面是结论：
12.96,5.88,79,0,0,0,99% 13.13,5.94,105,0,0,0,99% 12.95,6.18,57,0,0,0,99% 13.13,5.90,64,0,0,0,99% 12.95,5.88,82,0,0,0,99% 12.96,5.80,51,0,0,0,99%  统计结果如下：
 time mean = 13.01 time var = 0.0068  单次调度开销高达130ns，仅比系统的sched在高线程下略快。这事很奇怪，因为根据我看到的源码(glibc-2.19/sysdeps/unix/sysv/linux/x86_64/setcontext.S)，getcontext/setcontext在glibc中是用汇编实现的。其中陷入内核只是为了设定signal mask。</description>
    </item>
    
    <item>
      <title>context切换测试——python有关部分请求review</title>
      <link>//blog.shell909090.org/blog/archives/2684/</link>
      <pubDate>Wed, 29 Oct 2014 10:30:23 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2684/</guid>
      <description>python yield模式性能测试 python下的测试就不用time了，我们改用python的timeit，循环100M次。具体可以看py_yield.py。数据结果如下：
7.64262938499 9.2919304393e-06 5.41777145863 4.94284924931e-06  从结果来看，100M次循环的平均时间是5.4s，平均每次大约54ns。使用yield后变为76ns，增加了22ns。
python greenlet模式性能测试 这次代码在py_greenlet.py，循环10M次。数据结果如下：
5.35270996888 7.44085846125e-05 5.31448976199 5.82336765673e-05  单次循环时间消耗为535ns。比最初的54ns，增加了481ns。基本来说，时间增长了10倍率。
这是预料中的，因为greenlet早就声明自己通过堆栈拷贝来实现上下文切换。这会消耗大量CPU时间。从原理上说，栈越深，消耗越大。但是测试结果表明两者几乎没有差异，栈深反而性能更加优异(TODO: why?)。</description>
    </item>
    
    <item>
      <title>goproxy和msocks简介</title>
      <link>//blog.shell909090.org/blog/archives/2627/</link>
      <pubDate>Thu, 08 May 2014 16:41:25 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2627/</guid>
      <description>goproxy是我个人写的，和shadowsocks同类的软件。当然，在设计之初我完全不知道shadowsocks的存在，goproxy的最初目标也不是成为shadowsocks的同类。只是我一直无法实现一个可靠的，能够达成目标的系统。最后想，那这样吧，我找一个跳一跳能够够到的苹果。大幅简化的结果就是goproxy——后来我才知道shadowsocks。
shadowsocks的基本原理 shadowsocks的基本概念，就是利用某种不同于SSL的协议，将本地的socks数据流转发到远程。这个协议，在默认版本中是一个凯撒变换，后来有了aes等加密算法。goproxy也采用了类似的做法，同样支持aes等加密算法。在每次连接时，客户端先用加密通道连接服务器端，然后完成整个连接通路。这样的设计鲁棒性相当好，但是作为代价的，也有不少缺陷。
首先，goproxy和shadowsocks不约而同的采用了自己的协议，而非将socks5透明的转发到远程的服务器端。为什么？因为socksv5协议中，握手过程是三次交互。客户发送握手包，服务器响应允许的握手验证方法。客户发送验证报文，服务器端返回是否成功，客户发送要连接的目标，服务器端返回是否成功。细节我记得不是很清楚，但是2-3次往返是必须的。
这种工作机制需要client -&amp;gt; proxy-client -&amp;gt; proxy-server -&amp;gt; server的一个链条，本身就比直连多了两次TCP握手。加上上述的往返过程，更加耗时。而且这个消耗在每次建立链接时都要来一次，而HTTP是一种短连接协议——这就更加无法容忍了。因此改用自有协议，一次交互完成握手，就会更加快速。
更根本的原因在于，这两个系统都需要越过IDS，而三次交互的报文大小是几乎固定的——就算加密也无法改变报文大小。不但大小一样，而且由于用户名密码相同，起始加密过程和IV一致，因此采用socks协议的话，每个链接开始都有相同的来返数据。
我不知道shadowsocks怎么处理的这个问题。qsocks协议（msocks）的前身规定，每次握手时客户端提供一组IV，然后发送一个头部变长的字符串（256字符以内），在远程丢弃同样长度的随机字符。经过这样的处理，每次链接时的报文长度和内容序列都不一样，增加了破译难度。至于多出来的几十个字节，和验证报文在一个报文内，开销相比一次RTO几乎可以忽略不计。
但是还是有一点无法避免的问题。如果你看到某个服务器上有一个端口，频繁的被一个或多个IP链接。每个链接都不长，每次都是客户端吐一堆数据，服务器返回一堆，然后关闭链接。尽管协议无法破解，但是基本可以肯定这就是shadowsocks。根据这个特性，可以有效的阻挡服务——这也是我最近碰到的问题。
而且每个链接都需要验证和TCP握手太慢了。
msocks的改进 所以，我参考SPDY协议，做了msocks。msocks的核心思路和qsocks很类似，主要修改是以下两点：
 使用一个可靠链接（这里是经过加密的TCP），在这个链接里面封装多对传输。 每个链接只要一次验证。  这样做，首先减少了一次TCP握手和一次身份验证，工作速度更加快。其次多个传输叠加在一个流里面，流特征更加变化莫测。最后，无论是服务器端还是客户端的开销都小了很多。
当然，这也带来不少问题。例如TCP原本的拥塞控制窗口是为了一对传输序列设计的。当很多传输序列在一对TCP上传递的时候，丢报文造成的影响会作用作用在全体传输序列上。包括丢了一个报文重传的时候，所有序列都必须阻塞。还有基础的TCP被施加了丢包，导致全体序列共享5k带宽。当然，经过评估后，我觉得这些问题比频繁握手更加轻，所以就设计了msocks协议。
协议设计的时候，有几个细节问题。
多对复用 我采用了一个map，来记录某个id是否对应到了一个控制结构。这个映射只能被客户端更改，并且有个专门的函数负责查找空闲的id，每次生成的id都是递增的，如果碰到最大值则绕回。
id的大小是16位，足够容纳65536对同时链接。其实不修改内核的话，500对代理就会导致too many files。
实际上一般到id达到400后，单一的tcp就断线重连了。目前我还没见过上千的数字呢。
连接状态 连接一般情况下可以看到5种状态，连接请求发送，连接请求接收，连接建立，主动关闭连接中，被动关闭连接中。
当客户端请求代理连接一个远程服务器时，进入连接请求发送。代理远程端接受后在连接目标服务器的过程中，进入连接请求接收。当成功后，双方进入连接建立。
当关闭时，主动发起关闭一端进入主动关闭，另一端进入被动关闭。当被动关闭端调用close，或者主动关闭端收到对方关闭，整个链接就销毁。
由于tcp是可靠传输，因此三次握手和四次关闭都是不必须的。
简单吧。
拥塞控制 TCP原本是带有拥塞控制的——借助SSN双序列和窗口机制。但是在多路复用的时候，我们需要自行控制拥塞——而且不能采用会和机制。会和会导致后续已经到达的其他链接的报文被一个没人接收的报文阻挡。所以必须采用带拥塞控制的缓存队列机制。
不过幸好，TCP本身是可靠传输协议，所以我不用担心丢包重发之类的问题。我需要做的，就是把对方读取的字节数传递回来，减在控制器上，即可。
不过，我没有做对应于silly window syndrome的优化，在每次读取小数据量后，这个读取造成的window扩张都会被传回。当然，这么设计是有原因的。我默认采用了8K的buffer进行fd间拷贝，所以一般碰不到SWS。
为了解决tcp链接复用造成的单连接带宽问题，我强烈的建议你做以下的设定：
net.ipv4.tcp_congestion_control = htcp net.core.rmem_default = 2621440 net.core.rmem_max = 16777216 net.core.wmem_default = 655360 net.core.wmem_max = 16777216 net.ipv4.tcp_rmem = 4096 2621440 16777216 net.ipv4.tcp_wmem = 4096 655360 16777216  ip选择算法和DNS 在goproxy中，我沿用了一个做法。通过DNS获得请求的目标IP，和中国IP范围核对。如果在国内则直接访问，否则透过代理。这个方法能够极快的加速访问，而且几乎不依赖于需要更新的列表（中国IP列表相对来说固定）。</description>
    </item>
    
    <item>
      <title>一种新的python局部调试手法</title>
      <link>//blog.shell909090.org/blog/archives/2450/</link>
      <pubDate>Fri, 19 Jul 2013 14:33:14 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2450/</guid>
      <description>我们都知道，python里面可以用pdb来调试代码。但是pdb往往不大好用。有时候调试代码往往在多重条件里面，直接用pdb需要下条件断点，设定复杂的条件。
一个简单的办法就是这么干。
 __import__(&#39;pdb&#39;).set_trace()  但是有的时候，连这个出现的条件都不满足。例如，代码必须在一个受限环境中运行，很难拿到console，或者其他林林总总的毛病。这时候，我们还有一招秘技。
 import pdb, socket s = socket.socket() s.connect((&#39;127.0.0.1&#39;, 8888)) f = s.makefile() pdb.Pdb(stdin=f, stdout=f).set_trace()  在连接到的目标端口上，提前用nc做好监听，就可以在触发断点的时候直接连接上来调试。</description>
    </item>
    
    <item>
      <title>git log的一个吐血问题</title>
      <link>//blog.shell909090.org/blog/archives/2397/</link>
      <pubDate>Sun, 28 Apr 2013 16:26:34 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2397/</guid>
      <description>刚刚在公司里查了半个多小时，记一下笔记。
不知道你们有没有这种吐血经历。在git上有两个分支，莫名其妙合并到一起了。这可能是某个人的误操作。你检查log的时候，只看到他不停的把主分支merge到支线上去，却从没有把支线合并到主线上去。但是最终两个线却合并了，主线指向了支线。这是为什么？
要理解这个问题，我们要搞明白，merge在git里是怎么工作的。当两个分支，来自同一个祖先，但是提交了不同修改，又要合并的时候，就需要进行merge。能够自动merge的，多一个merge commit，被合并分支的HEAD不变，合并入的分支的HEAD加一，指向merge commit。不能够自动merge的，手工处理冲突，其余和自动相同。
注意这点，“被合并分支的HEAD不变，合并入的分支的HEAD加一”。由于两者在不同的点上，因此修改和提交会形成不同的分支。合并后的两个分支不会发生交汇。
如果在一次正向的merge后，立刻进行了一次反向merge呢？事情就麻烦了。两个branch的HEAD指向了同一个commit。因此你可以认为支线分支合并到了主线，却没有merge记录。这是当然，因为这只是指针移动，属于fast forward。没有commit，没有log。
不幸的是，这种操作还经常发生。当我们把支线向主线合并的时候，合并难度可能非常大。此时我们可以将主线向支线合并，然后反向合并。这样的合并难度就小很多了。然而这会使得合并记录不可查。
所以，当碰到类似问题的时候，考虑两次合并的可能性。</description>
    </item>
    
    <item>
      <title>python插件技巧</title>
      <link>//blog.shell909090.org/blog/archives/2344/</link>
      <pubDate>Wed, 20 Mar 2013 11:18:03 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2344/</guid>
      <description>简述和通则 何谓插件。
在实现某个功能时，经常需要对一个功能提供多种实现。例如短信网关接口各异，但是对系统而言，发送代码是一样的。 通过一套特定的机制，在成型的产品中，增加一个独立的文件，即可实现定制化实现。这套机制被称为插件机制。插件必须满足下面几个要求。
 对于已经发出去的产品，插件机制可以通过增加文件，并少量修改（一般1-3行）产品源码，即可为产品添加新的功能。 对于产品主分支，带有插件不会影响主分支的正常工作。  插件机制的以上两个特性对产品定制非常有帮助。因为使用插件进行定制开发的项目，不需要独立建立分支。只需要在主分支上添加几个文件即可。分发补丁时也格外容易。
 禁止在python主目录下直接放置插件，所有插件必须在python下级目录下存放。 插件的命名必须使用前缀师命名规则，所有同类型插件，要么在一个目录下独立存放（目录下没有其他代码），要么在一个目录下拥有同样的前缀（其他代码不得使用这个前缀）。  替换型插件 最简单的插件手法，就是某个文件提供提供某些函数，在变更功能时用另一个同样实现这些函数的文件替换掉原始文件。这甚至称不上一个插件手法，只能算打补丁。
替换型插件的提升，就是在文件中不直接提供函数，而是从某个其他文件载入这些函数。例如以下代码：
from abc import *  原始是从abc文件中取得所有符号。当有新的文件abc2提供时，将原始文件替换为abc2，补上去，即可改变代码。注意这行代码一般不在一个大的文件中的某一行，而一般存放于一个独立文件。因为大文件相对容易修改，不能用新的代码替换。而独立文件相对固定，在打补丁时可以用新的代码直接替换。
替换型插件适用于，对于某个客户而言，只需要在多组实现中静态的选择一组的情况。替换型插件的优点是工作原理简单直观，排查容易。缺点是对于一个功能不能提供复数组实现。
配置型插件 另一种插件手法基于文件或配置。在某个目录中，放置某个功能的多个实现。在加载时，载入全部插件。在使用时，根据配置动态选择。这种手法被称为配置型插件。
配置型插件是一种非常重要的编程技巧，他为程序提供了非常优良的可扩展性。
例如下面的例子，简述了一种配置型插件的实现：
funcmap = {} def register_func(name): def _inner(func): funcmap[name] = func return func return _inner 在具体实现中 @register_func(name) def func1(....): pass  在__init__.py中，import一下新的文件。在原本的funcmap中，即可出现新的name和func的对应。
配置型插件适用于大多数场景，其优点是工作原理简单，可以为一个功能提供复数组实现。缺点是使用上限制比较大，必须和逻辑结合，思考困难。
动态加载 动态加载插件是一种插件技巧，并不特定用于替换型或配置型插件。
当需要加载插件时，通过python代码访问文件系统，枚举出特定文件并加载的技巧，称为动态加载。以下代码是配合上面的配置型插件的例子，实现动态加载的例子。
def load_plugins(): for filename in os.listdir(&#39;plugins&#39;): if filename.endswith(&#39;py&#39;): __import__(filename[:-3]) if filename.endswith(&#39;pyc&#39;): __import__(filename[:-4])  动态加载的优点是，可以通过放置文件来增加/修改功能，而不需要修改代码。缺点是，由于需要访问文件系统，因此效率并不高。如果每次加载都需要动态查询，那么系统效率会大幅下降。
热加载插件 热加载是一种比较高级的技巧。在程序执行中，不退出进程而动态的将最新的组件加载进来的能力，被称为热加载。
简单的热加载就是在每次执行功能的时候，检查是否有新的组件。由于这样会带来很高的系统负载，因此除非必要，否则不要滥用热加载。</description>
    </item>
    
    <item>
      <title>异常和错误的几条军规</title>
      <link>//blog.shell909090.org/blog/archives/2282/</link>
      <pubDate>Tue, 27 Nov 2012 17:27:54 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2282/</guid>
      <description> 如果处理不了，就地崩溃，留尸不埋，供后人评价。
 偷偷埋尸，100军棍。处理不了偷偷埋尸，拉出去先轮后杀。  忽略错误只有两种合法情况。
 逻辑上可以忽略，记log，忽略。 逻辑上期待异常，不记log，忽略。 逻辑上不可以忽略的忽略，100军棍。 逻辑上可以忽略，没有记log，50军棍。  错误在函数间传递的唯一理由，是可以期待别人那里有个错误处理函数，能够对的上这个错误。
 没人处理错误的乱传递，20军棍。  该你处理的，处理，不该你处理的，别乱处理。
 乱处理错误的，先轮后杀。   </description>
    </item>
    
    <item>
      <title>python环境部署</title>
      <link>//blog.shell909090.org/blog/archives/2278/</link>
      <pubDate>Thu, 22 Nov 2012 14:19:46 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2278/</guid>
      <description>abstract 本文的目的，在于教授使用virtualenv创立python环境，对环境的管理和使用，以及代码和部署的用法范例。在阅读完本文后，你应当可以。
 创立，部署，管理virtualenv环境 使用virtualenv环境进行编码  virtualenv环境建立 virtualenv是python的虚环境管理包，他的主要目的是为了隔离环境。其中包含以下两个范畴。
 在虚环境中安装包，不需要对系统进行修改，不会对系统造成污染。 在系统中安装的包，不会对虚环境造成污染。这主要是出于版本安全考虑。  因此，virtualenv默认会阻止你使用系统中安装的包。要解决这个问题，需要在建立虚拟环境时指定参数&amp;ndash;system-site-packages。 virtualenv的环境可以通过执行virtualenv path加以建立。当建立完成后不可移动，需要一些特殊调整，使用参数&amp;ndash;relocatable对此没有帮助。
virtualenv环境的激活和反激活 virtualenv环境是通过替换系统环境变量工作的。在激活后会替换系统的提示符，提示你进入环境。一般我们使用source \$VIRTUALENVPATH/bin/activate来激活。激活后直接执行deactivate反激活。 virtualenv替换系统环境变量的方式是在path前加入virtualenv的bin路径，使自己的python优于系统python执行。同时替换pythonhome，变更lib查找路径。因此，对于某些可以指定pythonhome的应用（例如网络部署），直接指定pythonpath为virtualenv路径即可。 注意，由于virtualenv的工作方式，因此当你执行su/sudo bash后，virtualenv环境都有可能消失，但是提示符仍旧生效。建议通过sudo执行脚本，脚本内进行source比较安全。或者直接sudo目标程序也可以，不要新建上下文。 如果需要保持持续的环境激活，可以将source \$VIRTUALENVPATH/bin/activate加入~/.bashrc。 当virtualenv激活后，后续的pip安装和python使用都会使用virtualenv内的版本。因此下文未经特殊说明，都是指在激活环境后进行操作。
virtualenv环境的管理 主要包括两种手段，安装和删除。一般使用pip install package name进行安装。pip uninstall package name进行删除。
virtualenv环境的保存和恢复 virtualenv环境可以保存和恢复。所谓保存和恢复，是指在安装过包的环境中保存包列表（和具体版本），在未安装（或版本错误）的环境中启用。 一般通过pip freeze &amp;gt; filename进行保存。在目标机器上执行pip install -r filename进行恢复。</description>
    </item>
    
    <item>
      <title>python入门指引</title>
      <link>//blog.shell909090.org/blog/archives/2272/</link>
      <pubDate>Mon, 19 Nov 2012 10:11:49 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2272/</guid>
      <description>前言 其实我也不知道python怎么入门，由我来写这个真的不是很合适。我学python是直接找了dive into python来看。然后照着写了几个例子。大概两天后，就能磕磕绊绊的上路了。就好像拿筷子，都不记得怎么学会的拿筷子，怎么来教人呢？
不过最近在python-cn的列表里面，我大概连续数周都持续看到“python入门看哪本教程比较好”，实在是不堪其扰。干脆就写个简单的guide，有心的人自己看。没心的——那我也没办法了。
基本知识 首先，你要了解一个事情。很多你不会的东西并不属于python。例如你不知道网络通讯的流程，你不知道文件的权限和打开标志用法，你不知道fork和stdin/stdout的关系。这些python教不会你。如果你缺乏这些和语言/库无关的相关知识，请自行补课。如果你缺乏计算机基础理论，请自行补课。
因此不要随便给我发邮件/留言/咨询，为什么这个问题在python里无法解决。为什么python无法所见即所得，为什么python无法热部署，为什么python无法用于嵌入式开发。在问这个问题之前，请先确认“这是一个python的问题”。例如GIL，或者脑残lambda。如果你不确定，请自己搜索一下相关的文章，确认一下。在提问前，看看“提问的智慧”。如果你确实搜过了，找不到，那就问吧，没办法。
入门 在网络上，python入门的两大基础书籍分别是(后面有朋友补充了一本，我也加上)：
 A Byte of Python 中文版 Dive Into Python 中文版 Learn Python The Hard Way, 2nd Edition 中文版  后面基本就是看python-doc，我推荐你跳过一堆有的没的，直接看Library Reference。python本身就是易读性极强的代码，文档又相当漂亮，内置库又全。大部分情况下，python-doc都应当能解决你的问题。
web web是程序员的一大去向。python程序员入门必须要过的一个框架就是django。不要纠结了，django在python社区中名气太大，用的人太多。因此入门材料是最多的，社区最大，门槛最低。如果你要入门web，必然从django开始。在不熟悉python的情况下，我不推荐你贸然从其他框架开始入门。
当然，如果你已经熟悉python了，考虑入门web框架，可以参考专精一节。
爬虫 python下说到爬虫开发，入门首选Scrapy。原因和上面一样，社区最大，用的人最多。好不好用就见仁见智了。反正我的所有爬虫框架都是用自己基于gevent写的库。
ui python的ui框架也很多，很复杂。同样，如果是入门，我建议从qt的两个框架，pyqt和pyside开始入门。关于这两家的恩怨我就不多废话了。
专精 所谓专精，是指使用python在特定工作上。我们基本分为几个领域。
系统和部署  virtualenv：基本凡是在商用环境中部署的，建议都用这个。可以将python自带在源码里面，避免迁移/集成问题。 python-daemon：写daemon的时候比较方便。  网络 说到网络，基本就是除web外。
 twisted：非常强大的网络库，各种协议支持全面，不过reactor模式真是纠结。 gevent：异步协程模式的网络库。 Scapy：强大的网络库，基本啥都能干。 pyzmq：我一直不觉得zeromq是一个mq。我觉得他是一个抽象网络层。  web容器 python web框架的一大特点，是容器/框架/ORM/template可以分开自己玩。
注意，容器和框架是两码事情。容器是python web运行的环境，框架是解析环境的玩意。两者间一般都使用wsgi接口进行连接。这是python的标准做法，fastcgi/scgi也会被转换为wsgi进行连接。但是也不是没有其他选择。一般我们有以下模式：
 cgi：python-doc中自带了cgi模块。 mod_python：embed in apache。  下面是wsgi接口的容器。wsgi的优点在于我们可以在这些容器上运行任意一款支持wsgi的框架。
 flup：支持提供fastcgi, scgi, AJP接口，web server可以用这三种协议进行连接。 Google App Engine：PaaS服务。 Gunicorn：直接提供http服务。 mod_wsgi：使用内部协议和apache集成。 twisted：直接提供http服务。 tornado：直接提供http服务。 uWSGI：使用内部协议和nginx集成。 werkzeug：直接提供http服务。  建议的部署模式是，用apache的，去mode_wsgi。用nginx的，去uwsgi。用GAE的，直接可用。其他，通通转发。</description>
    </item>
    
    <item>
      <title>异常之殇</title>
      <link>//blog.shell909090.org/blog/archives/2266/</link>
      <pubDate>Tue, 30 Oct 2012 16:42:25 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2266/</guid>
      <description>异常之殇 辗转开解 辗转开解(stack unwinding)说的其实是这么一个现象。当执行流从深层向浅层转移时，深层调用所产生的栈上对象(stack object)需要销毁，资源需要释放。对于面对对象语言而言，往往就会执行到析构函数。
辗转开解中的异常 辗转开解真正令人迷惑之处在于，如果在析构函数中发生错误怎么办？在异常处理中发生异常，我们可以继续向上抛出。但是在辗转开解代码中出现异常，上层应当收到两个异常呢？还是一个？
无论是哪种可能，都没有完美自恰的符合直觉，因此这一般是一个未定义的行为。在C++中，进程会整个彻底崩溃掉的。因此，千万不要在析构函数内抛出(或者可能抛出)异常。
如果分离析构和资源销毁 一种做法是，在析构时不做资源销毁，转而提供专门的函数来执行资源销毁过程。析构只处理简单的delete等操作。然而这种做法的杯具在于，你在任何时候，一旦使用对象，都必须使用finally来保证销毁函数的调用。在发生异常时，栈上对象的辗转开解是自动的，析构函数的调用也是自动的，但是销毁函数的调用就是手工的了。
拷贝构造和隐式转换 和构造相反，对于构造函数，我们不能限制异常使用。你必须捕获构造函数的异常。
假如构造函数出了错 普通函数出错，你有两种选择。1. 异常。2. 返回值。构造函数出错，是没有选项2的。因此构造函数凡是出错必定异常。
而如果构造函数可能出错，而你期望捕获他，你就不能栈上构造一个对象出来。因为这会导致栈上对象的作用域被限定在捕获他所用的try块之内。
分离构造的尝试 和析构函数类似，我们可以尝试在构造函数外，提供一个构造函数，来替代构造的初始化过程。这样可以很大程度上保证构造函数不出错。
然而，首先，这样的代码就会变的复杂。每次构造函数完成调用后，都必须调用初始化函数。而且，有两种特殊的构造函数你不可能使用这种方法来解决。
拷贝构造和隐式转换 是的，这两种构造函数分别叫做拷贝构造(copy construct)和隐式转换(implicit casting)。我们举例来说。如果你在函数内建立了一个对象，你希望返回这个对象，怎么做呢？第一个思路是引用返回。不幸的是，要做引用返回，这个对象必须是堆上对象，而非栈上对象。因为栈上对象在返回后会销毁掉。如果要返回栈上对象，唯一靠谱的方案是先将对象复制到堆上，然后再复制到调用者的栈里。
C++中有一类特殊的优化，叫做对象返回优化。当编译器察觉到你需要返回栈上对象时，那么编译器会直接获得调用者栈里的对象地址。这样可以避免两次的拷贝过程。然而，如果没有对象返回优化（或者没有识别出来），那么就需要两次复制以保证正确性。而C++里，默认的复制过程是内存拷贝。
对于很多对象，内存拷贝是错误的行为。例如字符串，一种字符串的加速方法叫做共享内存字符串。两个字符串对象会共享一个内存块，以避免重复内容的开销。直到其中一块需要修改时，复制才真的继续。对于这种情况，直接拷贝会明显的导致错误。因此C++有一种特殊的构造函数，叫做拷贝构造。
在拷贝构造的时候，调用是由C++隐式发生的，你根本没有先构造，再调用的机会和权力。因此，试图分离构造在技术上不可行。
隐式转换是另一种情况。当你传递的参数和实际被赋值对象的类型不一致时（例如调用了某个函数，其参数类型不一致），C++会试图将你的对象转换为目标对象。如果是内部类型，这个被称为内部隐式转换。unsigned char可以被无错的转换为unsigned long，这个大家都知道。但是如果是对象，转换行为就需要由构造函数定义，这个叫做隐式转换构造函数。
另外，隐式转换也是OO中的一大问题。我强烈建议你用explicit禁用所有隐式转换，改为显式转换。这会费一点事，但是却可以避免很多问题。
分离构造/析构的邪恶之处 ZMQ的作者曾经吐槽过这种在构造/析构之外再定义初始化/清除代码的努力。他的观点是，如果万一在构造函数中加入了代码，会引起半构造现象。为了解决这个问题，会使得整个类带上状态。我在上面已经假定这件事情不会发生了，否则代码会更加复杂，问题也更加严重。
二次异常 是的，你不应当在异常处理代码中抛出异常。当然，这里的异常指的是你的异常处理代码不应当发生异常。经过逻辑判定，当前的异常应当由更上层处理的情况不在此列。
如果在异常处理中抛出异常，很可能导致的结果就是异常处理没有完成。而未完成的异常处理会发生什么问题，那只有天晓得。这个在任何带有异常系统的语言中都是成立的。</description>
    </item>
    
    <item>
      <title>面对对象的吐槽——类型之殇</title>
      <link>//blog.shell909090.org/blog/archives/2265/</link>
      <pubDate>Mon, 29 Oct 2012 14:26:30 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2265/</guid>
      <description>继承之殇 讲继承问题，我们首先得定义什么是继承(inherit)，他是用来干吗的。
所谓继承，就是当两种实体，满足其中一种必然全部都满足另一种的定义(is a)。一旦构成继承，可以带来以下好处（简单起见，我们直接就管这俩实体一个叫派生类一个叫父类）：
 派生类具备父类所有已经实现的方法，毋须再实现一遍——除非需要重写(override)。 派生类可以当作父类使用，凡是使用父类的地方给与派生类也对。  继承的最主要作用，是用于复用(reuse)。
内涵和外延 形式逻辑里面有一句话，内涵越大，外延越小。在继承上，如果我们严格按照定义来做，会发生很反人类的事情。因为类的定义是依赖于内涵的，
我们还是看平行四边形，长方形和正方形的例子。我们用两边长度，夹角来定义平行四边形。然后如何定义长方形？夹角为pi/2。然后如何定义正方形？两边长度相当。
不知道你是否看出了问题。是的，按照正统来定义，数据的约束只会越来越多。因为派生类必须是(ISA)父类，因此父类的约束必须全部满足。我们接着上面的例子，我们为平行四边形定义一个方法，设定夹角大小。那么在长方形中，这个方法如何处理？一旦用户调用方法设定夹角大小，必然会破坏长方形定义，因此这个方法只能重写抛错。
为什么？从逻辑的本源来说，平行四边形是“两组对边分别平行”，并没有说夹角的事情。到长方形的时候才说，长方形是夹角为90度的平行四边形。显然，长方形是不能设定夹角的。因此，我们要么承认，不是每个平行四边形都可以设定夹角的，例如长方形不行。要么承认，每个平行四边形都可以设定夹角，长方形不是平行四边形。显然，后者违背逻辑，我们只能得出结论，不是每个平行四边形都可以设定夹角。
同样，正方形的例子也说明，不是每个平行四边形都可以设定两个分离的边长。如果以此标准来定义类，那么必然得到的是正确而无用的逻辑玩具。平行四边形没有夹角，我们就不能定义面积计算的函数，也不能——基本什么都不可以。更过分的是，我们还不能定义两个分离的边长，因为定义并没有告诉我们，边长一定不等。照此下去，我们除了一个空空荡荡的“平行四边形”这个名字外，什么都定义不下去。
为了解决这个问题，实践中，我们采取的都是，平行四边形是可以设定夹角的，然后对特例做抛错处理。这其实在本质上就违背了继承的原初意义。
继承和聚合 继承的另一个容易混淆的地方，就是分不清继承和聚合。
其实从逻辑上说。继承和聚合根本就不是一回事情。例如你有(have a)一条狗，你可以让狗做任何狗可以做的事情，例如追猎物。我们可以说，你可以做的事情和狗没有区别，所以——你就是(ISA)一条狗？！
傻子都不会弄错其中的区别！
我们说，如果一个东西看起来像鸭子，叫起来像鸭子，走起路来像鸭子，我们就可以当他是一只鸭子，说的是弱类型语言。而且我们只能认为，我们不知道那个东西是什么(这是弱类型的特点)，总之可以当他是一只鸭子用。但是这不代表那个东西就是一只鸭子，他也可以是鸭子的代理人，或者拥有一只鸭子。在静态类型语言中，为了复用就不管三七二十一，直接声明PNG图像是一种BMP图像的——这绝对是逻辑上错误的行为。
然而，你自己数数你在代码里面犯过多少次错？
多重继承 继承本身的问题我们先不说，我们再说一个很常见的问题——多重继承。
既然我们说，只要一种满足ISA谓词判定，就可以认为是继承。那么理论上，我们就不能否决双重继承。例如我们定义了平行四边形，又定义了中心对称图形。那么长方形就同时是(ISA)这两者。从逻辑关系上，我们说长方形可以合法的继承两者。
但是如果我们真的在程序内设定将长方形继承两者，马上会引起一连串的问题。
当多重继承发生冲突时 首先第一个是继承冲突。即当两个父类都具备同一个方法的时候，对派生类做方法调用会发生什么行为？
 肯定不能只调用一个，这会因此另一个父类的方法间发生内在不一致。这违背了继承的好处2。 也不能两个都调用。两者的先后次序可能引发逻辑问题，因此先调用谁都是错误的。而且函数还有返回值问题——你返回谁的返回值呢？如果多值返回合并，这和函数原始的定义又发生了悖离，从而又违背了继承的好处2。 因此，我们只能宣布这是个错误。 既然是个错误，鉴于类间函数可能存在的内在联系，其他继承的函数也未必能够正常使用。  你看，明明是合法的多重继承，居然造成了不可复用的结果。这就是继承冲突。
菱形继承 如果说继承冲突还是一个比较好考虑的问题的话，菱形继承就是一个让人吐血的东西了。
所谓菱形继承，就是两个父类继承同一个基类。在这种情况下，对父类的调用会间接转到基类上。那么，基类的函数会调用几次呢？
继承冲突的几种解法  所有冲突的函数，父类必须都无实现。 不得多重继承。这是很扯淡的，不过也是大多数时候的做法。我的编程指南之一就是——在C++中，任何时候都不要使用多重继承。 使用其中一者。python是个典型的使用其中一者的例子，具体使用的按照继承编写顺序展开成MRO次序决定。然而这直接违背了继承类是(ISA)父类的定义。因此不要以为在python中，继承后总是没问题的。有的时候可能会出现继承后不能正常工作的情况。 强制用户解决。要求用户必须人工定义函数，解决继承冲突的问题。从逻辑上说，如果用户定义的函数可以同时兼容于两个父类，就可以彻底化解多重继承冲突问题。然而杯具的是，很多时候在逻辑上，继承冲突是无解的。  区分接口和继承 父类没有实现冲突的函数，那么派生类中就不必纠结于调用谁的问题了。但是这引发了另一个问题——这就无法复用了。作为这一解法的极限，java不允许多重继承——除非继承的父类都是没有实现的类。这其实不是继承，而是实现(implement)接口(interface)。
接口编程是一个很有道理的东西，COM里面大量着重于接口。但是接口也有自己扯淡的地方——接口是一个编写期的东西，他最大的用途就是编译期类型检查。接口并不能复用(reuse)代码。如果你有一个接口，叫做平行四边形。里面有个方法，用于计算平行四边形面积。然后你实现了长方形和正方形——那么杯具来了，你需要在两个里面通通实现一遍这个方法，即使他们基本没区别。
当然，接口本身的好坏各有评价。你看，接口的唯一作用，就是声明类提供了某些函数。当我们对方法传入一个新的类的时候，我们必须将新的类也实现一下接口——哪怕这个类其实已经实现了这些方法。只要不实现接口，方法就不认可。这是强制编译器类型检查(静态类型语言)的基础。因此一般来说，静态类型语言，使用接口。动态类型语言，duck typing。</description>
    </item>
    
    <item>
      <title>cython编译细节</title>
      <link>//blog.shell909090.org/blog/archives/2259/</link>
      <pubDate>Thu, 25 Oct 2012 11:12:09 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2259/</guid>
      <description>两点简述：
 可以使用cython &amp;ndash;embed来编译一个pyx，生成带main的代码，然后用gcc直接编译过去。大概样例是这样的：
cython &amp;ndash;embed $^ gcc $(shell python-config &amp;ndash;includes) $(shell python-config &amp;ndash;libs) -O2 -o $@ $^
 pyx的文件名会被转换为变量，所以所有在变量中不应当出现的符号也别出现，例如-。
  </description>
    </item>
    
    <item>
      <title>pycon2012</title>
      <link>//blog.shell909090.org/blog/archives/2257/</link>
      <pubDate>Tue, 23 Oct 2012 14:27:34 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2257/</guid>
      <description>今天第一天在大型会议上演讲，其实挺紧张的。不过还不错，虽然临场反应并不热烈，但是至少不冷场。下面是我今天看到内容的回忆，有些印象不神，记得不清楚了。
第一天上午 视频播放 上来先是sting先给我们放了一堆视频，我基本啥都没记住。就记住一个在日本的pythoner说教孩子编程时大家的评语了——python穷三代，编程毁一生。我后面接的是，用scheme子子孙孙都完了。
python产品构建和发布指南 沈游侠的主题，彻底干货。基本要点就是利用cython和pypy来编译类python语言，变成C语言代码。这样不但速度快，而且C代码都是可以跨平台的。后面又列举了如何用cython和pypy来编译库。这样基本可以完成python到多数平台的移植。
我做了一下简单测试。cython对速度的增加主要是静态类型编译，如果保持代码不动，速度反而会略微下降。因此在速度提升上，作用并不如想像中那么明显。但是在跨平台上，效果就非常好。rpython则完全相反，经过rpython编译的代码，在基本不修改的情况下（当然，前提是你需要符合rpython），执行比C还快。
不过游侠在后面的答疑中也说了，pypy的rpython编译把握难度比较高，不建议在产品中使用。
另外，他后面也提了溜宝的例子，在python和js之间可以远过程调用，还可以回调。熟悉http的应该可以听出来，这个在现在浏览器中必然是要用到long pull技术的。因此底层框架不肖说，必然是Eurasia。
让程序运行更快 我们几个都在说，土豆的一贯风格是分享内容是和技术有关的干货，但是都和python不搭边。最多在最后说一句，这个技术在我们这里是利用python做的。上次黄东的演讲就是，讲如何算流量带宽费，最后来一句，这个是python实现的。这次李小红的分享也是，很技术，但是和python没啥关系。讲到一半还来了一句，“我对python不熟悉，前几天特意看了一下，dict是利用开放地址法实现而不是开链实现的，这让我对python顿时有了信心”。微薄上无数吐槽高级黑啊。
土豆的分享其实很简单，核心就是如何通过代理让网站的响应速度更快。干货是干货，但是不是非常熟悉http协议，能够将http本身优化到相当程度的，听了等于白听。因为上面讲的大部分，都是内存命中和交换，磁盘写出，cpu调度，poll和epoll内核模式差异之类的话题。在python下面，poll和epoll基本都看不出差别，大部分优化都围绕着模式打转。研究这种命中技巧不是南辕北辙么？
但是这不表示这个主题没用，只是如果你不把其他方面的问题解决的很彻底，先没头没脑在CPU和内存缓存命中上下功夫，多半是做不过别人的。
第一天下午 OpenERP 即将推出的第 7 版的功能和新的编程框架介绍 演讲者是个法国人，中文相当不错。不过和Thomas比起来还是差点。旁边的老外哥们说，那是因为Thomas有个好中国老婆。
基本是广告。除了让我们体验了一把openerp的风格外，啥都没看着。不过openerp看起来确实够屌的，直接去下一个插件，应用，然后就直接换掉了语言。这基本和php差不多。还有一堆的良好的交互特性，看起来非常像应用。此外，啥技术都没有。
元编程在 Redis ORM 中的应用 我自己的题目，会场反应并不很热烈。总共两个选项，我问认为是1的举手，几个。认为2的举手，几个。剩下的是啥？
其实元编程本身就不好讲，这个题目我写完文档算了一下，大概1个小时到一个半小时。问题是我问sting多要点时间，没有。好容易给我加到45分钟。我对着文档左砍右砍，还是紧紧张张的25分钟讲完。要在30分钟出头讲完整个题目，也难怪听众反应不良。
具体我也就不展开了，希望看到的可以看我的slide。另外我说一下，这个slide也是我用python做的。
用 Tornado 开发 RESTful API 应用 其实以这个应用而言，是适合GAE的项目。不过飞龙只是借这个题目讲Tornado而已。
阿里云之移动开发者上云 纯粹广告。不过既然是lighting topic，也不算太难受。我也顺便看了一下阿里云的架构。不过主讲完全没讲到要点，他们到底是卖IaaS业务，还是卖PaaS业务，还是云存储，还是三者都有？另外，用IaaS来做PaaS的可伸缩？我还真不觉得这是个好主意。。。
Python如何帮助「逆转三国」获得成功 广告中的广告。今天唯一一个妹纸上场的主题，我还在想，终于有妹纸上去做分享了，还是个美女。结果介绍完了心里就凉了半截——市场总监，这姐们是个非技术的角色。演讲的主要内容是，python很好，python没出过乱子。完了，总共15分钟不到，我连拍第二张照片的机会都没有。其余时间全在说游戏是如何成功，左右还有海报助阵。最后还出来一个美女发传单。
最后主办方出来道歉，他们也以为这个topic是正规演讲，没想到讲成了lighting topic。
网页游戏的跨界开发 董诣的题目，主要讲他如何训练公司的策划使用python。他用的方法基本就是元编程的路数。
策划将配置写入excel，然后他们的程序读取excel，写出一个python的文件，再由服务器加载。这是典型的字符处理型元编程的例子。早知道他们这么用，我满可以顺手拿来举例的。
最后他的例子倒是让我们吐槽了一把。print后面可以不加空格，这是他们公司美工教的。
实战游戏客户端 林伟每年来都是带来大量干货。今年他是特别从北京飞过来，在演讲前刚刚到场。
他的题目是用python做客户端，并不是很好讲。因为python做游戏客户端不是很多。他举了一个pygame的例子，超级玛丽的企鹅复刻版，玩的挺欢乐的。
后面他大概讲解了一下游戏界面编程的几代模式变化。不过我印象最深的还是说到flash在苹果上。后面他运行flash的那个模拟的时候，我彻底吓一跳。我偷偷和沈游侠说，林伟说的完全没错，乔帮主抹黑flash完全是为了抢app的地位。
大家可以想象一下，如果flash拿到了硬件驱动加速会如何？Apple Store上的程序还有谁会花钱？都直接用网页跑一个Flash游戏就直接玩了。PC上能跑的，在苹果上自然也能跑，效果还不差。那还用Objective C做什么？只有性能要求特别高的才会用到。如果不需要Objective C，那Apple Store还怎么赚钱？从Flash能够做到这点，还有Adobe的战略布局，以及Apple Store目前的情况。我们多半可以得出这么个结论，苹果抹黑Flash的主要目地是将Flash踢出移动平台。而只有将Flash踢出了移动平台，才能保护移动设备开发市场的封闭性，从而从中牟利。
另外，他讲到的FlashCC也很有意思。在一个语言内调用其他语言，这非常有利于Flash的开发。不过后面林伟的一句口误让全场都笑了。他说：“我今天来就是告诉大家，从今以后，大家可以用Flash开发python程序了。”得，又是一堆高级黑评价。
第二天上午 网游开发中的 Python 组件 赖总的topic，基本讲的其实是模式。
对我来说其实也挺有用的，尤其是关于对象可调用方法的那个idea。写程序到了一定程度，实现已经不是问题。只要有明确的实现方法，你给足够的时间干，肯定是干的出的。问题是思路，也就是idea。一个好的思路往往是经过很久的总结，在实践中不停摔倒，才能真正用上去。
另外，最后的吐槽，其实是自行实现语法，或者至少是语法糖。我和赖总说，scheme其实很容易嵌入，而且很容易实现这样的要求——lisp类语言的宏天下闻名。赖总在研究的是基于python自己的Parser的方案，我回头有空也看一下。
Python in Gentoo Linux Patrick Lauer的主题，主要是讲了Gentoo下面如何使用python，每个版本的python在gentoo下面的支持情况如何。按照数据来看，python3的支持接近完成了。而pypy大概只有2/3的支持比例。</description>
    </item>
    
    <item>
      <title>铁道部的扯淡排队系统</title>
      <link>//blog.shell909090.org/blog/archives/2241/</link>
      <pubDate>Wed, 19 Sep 2012 16:08:57 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2241/</guid>
      <description>缘起 这两天同事都在讨论12306的订票机制，据说要排队了。我不买火车票，所以只是大概听同事讲解了一下机制。如果不正确，希望大家告知我。我听到的机制大概是这样的。
首先，是每个人进去，正常购票。当碰到热门线路，在提交时进入不定时的排队。等排队结束，成功与否给与提示。铁道部称，这是为了能够减轻并发压力。
问题 如同老板说的那样，这个机制P都没解决。问题的关键在于系统的每秒负载能力，即每秒能够完成多少个transaction。只要来的人比能完成的transaction多。那只有几个结局：
 刷爆网站，这是原来的结局。 堆在队列上，有人买不到票。  如果铁道部宣称的目的是真的的话，那他们一定用错了机制。
原因 铁道部这个系统的核心想法，是将并发的业务改为串行业务。即，前置一个订单系统，减轻核心的交易数据库的压力。实话说，这一定是没在互联网上混过的领导想出来的馊主意。
在通常业务系统里面，如果我们说一个核心交易组件有压力，那么最常用的办法就是排队。然而在互联网上却不能这么干，尤其是很多“非买不可”的系统里面，更不能让用户玩“排队”。因为对于互联网上的人，“分身”是再容易不过的事情了。使用多个浏览器，甚至开多虚拟机，普通人可以轻易的做到4-5个不同的会话。就算普通人做不到，看网络教程学是可以学出来的。每个会话订不同班次的火车。多开会话的结果，就是让队列的长度比原本会长上很多。这是一种级联效应。由于购票组件的处理速度有限，所以压力向前堆积，最终前面的排队系统也会被汹涌的客户（比原来大N倍）玩死。
机制 对此其实我很难想明白，为什么铁道部的核心交易系统有这么差的效率。有网友曾经说，系统要检查很多东西，要上锁——这都是假的。作为铁道部的核心交易系统，和铁道部内部的资讯检查有什么关系？他唯一要做的事情，就是检查是否真的有票，座位多少，有的话锁定一张（这个过程要排他）。
也许你会觉得，既然要排他，那么就需要用事务型数据库。目前数据库平均性能都是1k/s（我们就按照我们在普通台式机上的数据计算好了），而全国每秒成交的数量远大于这个值。这里出的问题？
这是不可能的。傻想也知道，每趟车和另一趟车没有耦合关系。按照车次做哈希，分布在多台服务器上交易就行了。这是典型的可并行系统，效率可以直接用单台机器性能乘以服务器数。在交换机允许的范围内，根本不会有交易性能压力。我们仔细审查铁路系统的结构，会发现，这东西天生就是分布交易的好材料。
 部署一组服务器，每一台都部署同一套东西，接口按照REST开放。 将车次哈希后映射到具体的服务器上，所有的余票查询/订购，都向这台机器做请求。而核心服务器只要返回静态页面和车次信息就好。 单个服务器上的每秒transaction要求就不可能太高。  阴谋论 也许有些人会想，这个系统莫非是铁道部给内部留票做的？这又错了。要做内部留票，最简单的方法就是开打内部提前售票限制。只要这个限制一开，他们想留多少留多少，你一点脾气都没有。
结论 我只能归因于国有垄断企业在解决这类问题上的扯淡了，和私有企业没法比阿。建议对铁道部实行拆分。</description>
    </item>
    
    <item>
      <title>snappy的性能测定</title>
      <link>//blog.shell909090.org/blog/archives/2206/</link>
      <pubDate>Mon, 23 Jul 2012 08:03:45 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2206/</guid>
      <description>要去马尔代夫渡蜜月了，闪人前最后一贴。
方法是用python准备数据，然后用timeit进行测试。虽然因为python框架的干扰，具体时值不是很准。但是用来做数量级对比和计算足够了。原生数据是一个屏幕截图，4M的数据块。
zlib.compress: 0.054105230093 snappy.compress: 0.00374100804329 zlib.decompress: 0.0157685602903 snappy.decompress: 0.0051297039032  从结果分析，zlib是典型的非对称压缩算法，压缩/解压速度比大约是3.5:1。而snappy的压缩和解压速度在同一个数量级上，甚至在具体的数值上，压缩比解压还要快那么一点。以解压速度为基础的对比，snappy大概比zlib快了3倍。而压缩速度上，则是快了14.5倍。
由于python的干扰是在每个的时间上面增加了一定开销，通常会使得速度比更接近1。也就是说，实际上snappy和zlib的速度比比这个还要大。
另外说一句题外话。按照我们测试下来的数值计算，snappy和zlib的压缩比大概在1:2之间。zlib压缩图形资料时的典型比例是0.05，而snappy则是0.1左右。对于熵比较高的数据，zlib大约是0.33左右的时候，snappy是0.5。都是比2倍大小略小。</description>
    </item>
    
    <item>
      <title>快速深入一门语言的几个问题</title>
      <link>//blog.shell909090.org/blog/archives/2194/</link>
      <pubDate>Fri, 15 Jun 2012 07:19:45 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2194/</guid>
      <description>劳资明天要结婚了，今天婚前最后一个blog。
1.hello, world
目标：屏幕上打印出hello, world。
原因：不解释。
进阶：当命令行给与不同参数的时候，打印hello,
名字。给与开关的时候，打印hello, 123。
2.正则提取
目标：写一个正则表达式(或者类似的东西)，从一段网页源码中找到某个标签的内容，去掉前后空格，显示。
原因：测试字符串处理能力。
进阶：支持正则扩展
3.扫描排重
目标：将某个目录和子目录下的所有文件扫描，排除重复的文件。
原因：测试文件系统操作能力。
进阶：多线程处理，注意吞吐颠簸。
4.做24点自动计算程序
目标：写一个程序，能够计算24点。要求能够自定义扩展算符。
原因：检查深度优先搜索，栈，结构设计，抽象处理能力等等。
进阶：做并发处理。有数种语言可能无法实现并发，或并发实现难度大，不美观，例如python。
5.做一个计算器
目标：做一个计算器，要求能计算1+2*3=7，并支持()。
原因：表达式解析和处理需要用到程序的方方面面，字符串处理等等。
进阶：做一个本语言的eval函数出来。
7.抓网页
目标：实现一个服务，定期下载符合规则的一批网页，解析，获得格式化的数据，并存入数据库。
原因：测试系统开发能力，基础网络库，字符串处理能力。
进阶：分布化抓取。
8.留言板
目标：设计一个留言板，将所有人提交的话保存起来，能一并展示。提交不需验证，展示不需分页。
原因：测试网络服务能力，数据库支持和多国语言支持。
进阶：防止XSS攻击。
9.异步大并发服务器
目标：设计一个异步http服务器，能对请求做出响应，添加，删除，修改数据库中的数据。不得使用现有的http框架和容器。
原因：集成性测试
进阶：不使用现有数据库，自己写一个。。。</description>
    </item>
    
    <item>
      <title>一个超微模板系统</title>
      <link>//blog.shell909090.org/blog/archives/2188/</link>
      <pubDate>Wed, 06 Jun 2012 03:29:57 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2188/</guid>
      <description>re_tmpl = re.compile(&#39;&amp;lt;%(.*?)%&amp;gt;&#39;) def template(s, d): return re_tmpl.sub(lambda m: str(eval(m.group(1), globals(), d)), s) template(&#39;&amp;lt;%&amp;quot;ddd&amp;quot; if abc else &amp;quot;eee&amp;quot;%&amp;gt;&#39;, {&#39;abc&#39;: 1})  限制挺多，只能在&amp;lt;%%&amp;gt;中写一行代码，不能多行。不能用跨区块的if for等控制结构。但是对于功能需求不复杂，需要可变性强，又不希望引入额外库的地方还是非常实用的。</description>
    </item>
    
    <item>
      <title>语言的效率差异3</title>
      <link>//blog.shell909090.org/blog/archives/2182/</link>
      <pubDate>Mon, 28 May 2012 02:13:32 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2182/</guid>
      <description>在总结前，我们首先搞明白三个问题的差异“效率的决定因素”，“语言效率差异”和“日常使用中造成运行效率差异的因素”。
代码的效率最根本因素绝对不是语言的效率，我一直这么确信。代码效率的决定因素必然是算法的正确选择和实现的优秀程度。这里面包括了正确评估问题，选择合适的数据结构，使用合适的算法等。例如对给定数据的高速查询，用红黑树去跑查询肯定跑不过预编译的哈希算法和哈希表。即使前者使用汇编实现，而后者只是python实现。(对于这点，我对比过一个大规模数据的查询，数据是固定的。数据库效率最差，C++用红黑树的map次之，效率最好的是python的dict，底层是hashtable。当然，为了防止某些人补充，我自己先说了——我最后用了stlport的hash_map)
语言效率的差异，有很多因素。例如编译型/解释型语言，动态语言和静态语言，是否带jit优化等，都会造成很大的性能差异。甚至同样是C，不同的编译和优化参数也会造成很大规模的差异，做优化的朋友一定心里有数。然而大多数情况下，决定语言效率的关键因素都不在语言自身的效率上，而是在于底层库实现的效率上。当然，如果底层库使用该种语言直接写成(我也比较喜欢这种风格)，那么归根结底还是考验语言本身的效率问题的。以正则测试为例，实际上python是一种性能很差的语言，但是在测试上并不很低。因为python的库实现是直接引用了C库，其效率仅仅是C加上一个不高的值。而lua得分不足只能说是库的实现比python差。
最后一个问题相信大家最关心，即日常使用中造成运行效率差异的关键。到底是什么，决定了我们每天写的代码的效率？
可能要出乎大家的意料，从实际测试来看，实际上是测试能力和可变性。我们能够大致预料某些性能特别差的情况，然而对于性能在50%-200%以内变化的细节，实际上是很难提前预测的。也许我们会“猜测”某种情况性能比较优秀，但是实现下来情况可能完全不是这么回事。例如我曾经就一个C代码进行优化，预期应当能提高4倍性能，当时测试的结果是性能提高3-5倍，但是实际生产环境跑下来觉得没区别。后来发现，我自己测试用的是-O0，而生产系统是-O2。我的优化实际上在-O2的时候就全部被自动优化掉了。如果你觉得你的经验够丰富，能够预测-O2会优化你的哪些代码。那么你可以考虑一下，CPU的指令流水优化呢？系统上所安装版本的libc的实现细节和内核细节呢？如果都能精通，您可以忽略我这篇文章。但是对于我自己而言，我只能预计某个做法可能优化，而不能确定。
这时候，对于这个优化的实现难易程度，和实现完成后进行测量的难度就成为了关键。尤其是精确测量耗费时间的代码，执行时的瓶颈，这些能力才是优化代码的关键所在。我曾经写过为什么python效率不比C低，有人不服。我说了，并且反复强调了，这个仅限于“两者的生产速度一致”这个前提下。实际上如果真满足这个前提，大部分情况下C这边都输的没法测试的。因为完成同样任务，python的编码时间大约只有C的一半到1/4。即使算上优化，python完成项目的时间，C都不一定能写的完代码。更不提后面还要进行泄漏测试，复查，复杂的调试。等全部通过，开始关注效率问题，生产时间早超了。
作为日常生产，我想大部分程序员都有这么个经验。决定代码质量的实际上是项目的时间是否充裕，程序员是否用心严谨，生产流程管理是否到位。除非程序员太差劲，否则技术性代码质量差异并不特别多——一般都是远远小于赶代码造成的严重问题的。如果您那里不是这样，我建议您更换一批靠谱的程序员。同样，在真实的日常生产中，大部分项目都没有那个机会对代码进行多次的复查，深层次优化所有问题。基本是写，写完了查，没有什么表面问题。然后检查一下，用户体验效率是不是很差，找最差的地方优化一下，然后直接交货。很少有像理论代码那样，反复优化和测试，甚至受到来自不同程序员的交叉检测和沟通。如果有这种级别的反复优化，毫无疑问的，C会是常用语言中的效率之王。在shootout&amp;gt;给出的速度评测上，仅有Intel自己实现的fortran超越了C。当然，我相信汇编会更加优秀。
然而杯具的是，日常生产中恰恰相反，至少我是没什么时间去优化每行代码的。大部分时候，为了处理一个排序问题，我不会去网络上找一个vector库，而是直接开一个100的数组，然后qsort。前方报错了，改1000的数组。在写python的时候，也不会精细的考虑每个地方是否都用了合适的方法，某点是生成器好还是list好。大不了觉得某个程序慢了，cProfile一把，然后对着花时间最长的几个点看看是否有问题。自我感觉而言，python项目在做完之余，我还能泡个茶聊会天，自然也有功夫去看两眼代码，是否有哪里写的太难看了。而C代码就是不停的debug，即使我好容易喘口气，也绝对不会想去再看了。
最后说一下sbcl，在自身性能测试中，是当之无愧的语言之王。速度是python的一倍不到，代码量是python的一半。常规来说，出错概率，维护难度，都是和代码行数直接相关。一半的代码量基本就意味着维护成本削减一半，而一倍的速度基本和java持平，在C后面紧追不舍。但是，以上常理对lisp均不适用。lisp的学习难度惊人不说，维护难度和代码行数没有直接关系，而是取决于写作者的水平。水平越好的写作者，代码越容易维护，反之，初心者写出来的玩意那是看都看不懂的。冰河在博客上说他找了个职业lisp程序员的工作，人家视若珍宝。我不知道是哪年的blog，但是从老板的角度来说，这才是程序员的悲哀。老板喜欢什么语言？最好有个点子，跑去人才市场插个牌子，上书“我要人”。然后就会有一堆人云集过来，脖子上面都套着“五行一元”，“精通XXX”的草标。抓一只大个的，给个项目经理的头衔，让他管着别人。每个月扔一麻袋饲料下去，过两个月就能收程序了。
看起来和农场有点像，不是么？遗憾的是，lisp看来是达不到这个要求了。全国能用的python程序员不会超过5000，lisp程序员大概连500都不到。如果哪个老板不幸脑残，用了lisp来做项目，那么在招人这个问题上会比python更难执行。从这个意义上说，这才是lisp程序员不流行的关键——不好找工作。即使运行效率再高，语言本身再好，也没法过老板那关。</description>
    </item>
    
    <item>
      <title>几个小技巧</title>
      <link>//blog.shell909090.org/blog/archives/2178/</link>
      <pubDate>Wed, 23 May 2012 03:17:34 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2178/</guid>
      <description> virtualbox中使用物理硬盘 省略权限，物理硬盘分区结构基础知识，最核心只有一句话：
VBoxManage internalcommands createrawvmdk -filename sdc -rawdisk /dev/sdc -relative  在不重启的情况下调试awesome的方法 省去安装和man，也只有一句：
Xephyr -ac -screen 1024x768 -br :1  </description>
    </item>
    
    <item>
      <title>python中调用C的几种方法</title>
      <link>//blog.shell909090.org/blog/archives/2176/</link>
      <pubDate>Tue, 22 May 2012 03:12:44 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2176/</guid>
      <description>引言 别废话了，我觉得这都应当是常识的。除去最后几种包装框架，剩下都是基本知识问题。即使不知道怎么做，也应该知道有这种方法。所谓经验，很多时候不是把知识装脑子里，而是把索引装内存，数据丢硬盘。
C模块 最基本的方法，直接写个C模块。具体很长，你去找python-doc，看“Extending
and Embedding”这章，全看完就差不多了。如果没空，看几个例子就上也可以。
优点：基本没有，写起来很麻烦，要维护额外的C代码，还有交叉版本固定，跟随C升级等等麻烦。唯一的优点，就是这是唯一一个“绝对没有问题”的方法，而且没有额外依赖。如果下面几个路子全出了问题，就用C模块吧。
ctypes 去看python-doc的ctypes模块。本质上是提供一个C模块，去载入和使用其他模块。
优点：写起来很方便，修改便捷，而且跨各个python实现。
缺点：只能调用动态库，对静态库没啥办法。某些复杂数据类型的转换很麻烦，据说有时还有效率问题。
swig 自己找，一个叫做swig的项目，目标是制作C语言的各种平台包装。实现上看，会生成一个动态库和一个py。
优点：跨平台多。如果你的C代码不仅是python需要调用，还有其他语言（例如php），那么swig用起来很舒服。
缺点：编译时引入额外依赖，而且调用范式也是受限的。不过别担心，一般你也用不到范围以外的范式。
boost.python boost的自带库，只能用于C++。
优点：对C++的支持是极好的。
缺点：要依赖boost这么个坑爹玩意，摔。
Pyrex 我知道douban的python-libmemcached是使用这个来包装的，不过没用过，不是很清楚。</description>
    </item>
    
    <item>
      <title>语言的效率差异2</title>
      <link>//blog.shell909090.org/blog/archives/2174/</link>
      <pubDate>Fri, 18 May 2012 07:14:24 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2174/</guid>
      <description>问题 为了更深入的测试语言，我做了一个经典问题——24点。
这个问题主要是测试递归，循环效率，还有数组和树的复制性能。
为了简化问题，方便测试，我的问题是这样描述的：
有一个数组，里面有多个正整数。有一个操作数组，其中每个都是双目操作符。找出以两者构成算式，其值等于给定值的所有表达式组合。 要求不得遗漏，可以有少量重复。例如可交换算符的交换同构暂不做排重。  实际运行的时候，取+-*/和3 4 6 8，运行100次，查看时间消耗。正确的单次输出结果应当是这样的。
(((8 + 4) / 3) * 6) = 24 (6 / (3 / (8 + 4))) = 24 (((8 + 4) * 6) / 3) = 24 (((8 / 4) + 6) * 3) = 24 (((8 - 6) * 3) * 4) = 24 (((8 - 6) * 4) * 3) = 24 (((3 * 4) - 8) * 6) = 24 ((8 - (6 / 3)) * 4) = 24 (((4 + 8) / 3) * 6) = 24 (6 / (3 / (4 + 8))) = 24 (((4 + 8) * 6) / 3) = 24 (((8 / 4) + 6) * 3) = 24 (((4 * 3) - 8) * 6) = 24 (((8 - 6) * 3) * 4) = 24 (((8 - 6) * 4) * 3) = 24 ((8 - (6 / 3)) * 4) = 24  python python的解很复杂，长达31行，以下是我写的解。当然，还有更简单的版本，我可以用eval来干这个事情，代码只有24行，但是确实给人很evil的感觉。</description>
    </item>
    
    <item>
      <title>语言的效率差异1</title>
      <link>//blog.shell909090.org/blog/archives/2172/</link>
      <pubDate>Mon, 14 May 2012 02:52:27 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2172/</guid>
      <description>问题 为了测试语言的效率，做一个正则解析。
预先说好，正则解析的问题是老板正在做的一个实际问题，我把其他和效率无关的部分去了。因此我接受“用法不正确”这样的反驳理由，但是不接受“这不是典型用例”的理由。我欢迎你指正我的用法错误，或者对语言不了解导致的效率低下，但是别来和我吵吵这种例子太特殊。另外，在调整代码和评估速度的时候，顺便注意一下代码行数。我知道用汇编逐行写和优化会很优秀，但是这对实际工作基本没有帮助。
问题是这样的：
 有一个文本文件，每行两个数，要求解析出来这两个数。
 我用python生成了数据，代码是这样的
with open(sys.argv[1], &#39;w&#39;) as fo: for i in xrange(500000): fo.write(&#39;%d %dn&#39; % (i, random.randint(0, 10000)))  正则分析速率，是个典型的CPU密集操作。对于非编译型语言而言(这里的编译是指正则表达式的解析预编译，实际上除了lisp还真没有编译型的，即使是go也是现场拿到正则进行解析的)，这主要是看正则库的实现效率。很多时候，语言的效率问题并不取决于语言本身，还取决于语言的库的实现。大部分情况下我们都不可能砍掉系统的库重新来一个，那还不如换一门语言。
python 我首先贴出python语言的解答。
reline = re.compile(&#39;(d+) (d+)&#39;) def main(): with open(sys.argv[1], &#39;r&#39;) as fi: for line in fi: reline.match(line).groups()  这是性能
real 0m0.466s user 0m0.436s sys 0m0.012s  common lisp 我找了N个正则包，实际能用的只有ppcre。有些包号称很快，实际测试下来还不如ppcre。
(require :cl-ppcre) (defun grepfile (filename) (let* ((cl-ppcre:*use-bmh-matchers* t) (cl-ppcre:*regex-char-code-limit* 256) (scanner (cl-ppcre:create-scanner &amp;quot;d+ d+&amp;quot;))) (with-open-file (in filename) (loop for line = (read-line in nil) while line do (cl-ppcre:split scanner line)))))  代码在slime里面测试(time (grepfile &amp;ldquo;data.</description>
    </item>
    
    <item>
      <title>dvc和vc简评</title>
      <link>//blog.shell909090.org/blog/archives/2160/</link>
      <pubDate>Thu, 03 May 2012 03:28:18 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2160/</guid>
      <description>我有必要换git么 实话说，这得分干吗。目前的推荐是，如果是企业级项目，对权限要求比较严格，你必须用svn。如果是普通项目，你可以尝试使用git，但是这并不表示git是最适合你项目的。有的时候svn比git合用的多。
svn是什么模式 svn的核心思路是，取出，修改，提交，合并。即，你从核心库中取得数据，修改，然后提交上去。如果有两个一样的修改，那么要求你进行合并。当然，svn工具会首先尝试自动合并，然后再让你手工干。但即使如此，合并的时候还是很费力。
svn的模式很容易理解，然而在使用中却有两个实际缺陷。
 保存数据的唯一方式就是提交，而提交是不可撤销的。 必须连接核心库使用。  第一点问题，就是说，如果你希望暂时保存一下当前的修改状态，然后进行某个测试性修改。如果失败，退回当前。抱歉，做不到。你的提交一定会进入svn库。虽然你可以退回到你提交前的版本，但是很麻烦，而且版本记录不会消失。而第二个问题更加致命。如果在网络不稳定/没网络的时候，还干不干活了？
因此，svn的设计模式并不鼓励你提交。当你有修改的时候，你必须保持修改的状态，直到某个稳定的状态。你需要检查代码是基本可用的，然后才应当提交。svn提交有个基础原则，不能塞住head，讲的就是这个。
所以有了hg hg正是为了解决上述问题而出现的。hg实际上是用python实现的，解决上两个问题的svn。
hg拥有本地版本库，这解决了离线模式。至于暂存性提交，你可以在本地随便提交。只要不提交到核心库上，就不会导致塞住。如果你觉得本地库不行，可以直接重新co，而不进行push。
git和hg哪个好 锤子和扳手哪个好？我永远无法回答你这个问题，因为这两个的目标根本不同，因此根本没有可比性。同样，git和hg的工作流程和模式完全是两回事，因此不要问这个问题，没意义。
哦，那么git是 git的设计核心思路，是取出，分支，修改，提交，合并分支。git的分支是处理工作的利器。
要彻底理解git，你必须接受平行世界假定。假设世界并不是顺序发展的，由于你的选择不同，而会变成不同的几个分支。git可以让你在分支间自由穿越，并且让世界变成某个分支上的某个点的状态。你可以重新选择，产生一个不同的分支。当你需要时，可以对两个分支进行合并。如果两个分支从源头分开后，对世界的影响各自不同，那么合并就是自动的。
git的同步就是在同步这颗世界树。树扩展成什么样子和你在树的什么位置没有关系，因此fetch后如果不chechout，那么就不会应用最新的修改。
我没看出多大区别 实际是非常大的。有了平行世界假定，我可以正交的对一个源码做两件以上不同的事情。而在hg中，虽然也可以做两个不同的分支，然而却很难在两个分支间切换，从而使得切换到做另一件事情非常困难。这也导致了一个人实际上只能做一件事情，否则就无法将过程同时纳入vc管理，又满足正交。</description>
    </item>
    
    <item>
      <title>语义的精密表达</title>
      <link>//blog.shell909090.org/blog/archives/2148/</link>
      <pubDate>Thu, 19 Apr 2012 03:25:34 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2148/</guid>
      <description>辨析语言的微妙差异，使得语言精密的符合目的语义，此为程序员基本功的最高要求。对精密语义的追求，应当凌驾于排版美观，代码美感，代码简化之上，也凌驾于运行时效率之上。除非为特定目的小幅的修正，否则不应破坏此原则。
以此为指导，我们看几个if。
if a in python 以下代码的目标语义是，如果a不为None，就运行代码。
if a: do something  有什么问题？
有没有考虑a=0的情况？a=[]呢？
if a is not None: do something  这样才是严密表达。
if a in C 以下代码的目标语义是，a是一个int数，对a!=0的情况下，执行代码。
if (a) do something  有什么问题？
没问题，因为C是静态语言，这限定了a的使用。除了代码并没有体现a!=0的条件，没有太大问题。但是鉴于语言表达语义，最好改为以下代码。
if (a != 0)  相对的，如果a是bool型，就可以直接用了。
if (a)  如果a是char*形，那么合适的语义表达应当是。
if (a != NULL)  他们生成的汇编代码都没有差异。
if a in C++ 概念上同C，不过a是一个复杂对象。
if (a) do something  有什么问题？
问题大了去了，和python一样，C++可以重载行为。谁知道type(a)::opreator bool(const type(a) &amp;amp;a)函数被定义为什么鬼逻辑。这就是为什么我憎恨默认行为重载的原因——因为他们对精密语义表达有破坏作用。</description>
    </item>
    
    <item>
      <title>值返回和指针返回简说</title>
      <link>//blog.shell909090.org/blog/archives/2146/</link>
      <pubDate>Wed, 18 Apr 2012 01:53:48 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2146/</guid>
      <description>好吧，这是常识，我说快点。
C * c = get_c();  这是指针返回。
C c = get_c():  这是值返回。
指针返回的缺点是，你必须检测返回指针的有效性，也就是NULL。并且，你需要手工管理指针释放。而优点则是避免了值拷贝，还有可以返回空值，即通过返回NULL表示没有值的情况。
而引用返回最大的优势在于，变量的生存周期和作用域相同，你无需管理释放问题。然而缺陷就是庞大的拷贝开销。
在get_c返回的时候，会return一个对象。这个对象是子函数作用域对象(sub function scope)，会随着子函数退出而失效。因此，在返回值的时候会引发拷贝。这种拷贝有两种可能。
 拷贝构造  当返回值被用于某个对象的声明时，会触发拷贝构造函数。被返回的对象会作为拷贝构造参数传递(引用传递)，而拷贝出的对象就是被生成对象。
 赋值算子  即operator =。当对某个已经声明对象进行赋值时，会发生这种现象。
当然，近代编译器对于“在返回时进行构造用于返回后的构造”这种情况做了优化，通称RVO优化。例如上文，如果get_c中使用return C(a, b);进行返回，实际上只有C::C(a, b)的调用，而没有C::C(const C &amp;amp;
c)的调用。</description>
    </item>
    
    <item>
      <title>segment的核心数据结构空间和时间效率估量</title>
      <link>//blog.shell909090.org/blog/archives/2138/</link>
      <pubDate>Thu, 12 Apr 2012 01:55:37 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2138/</guid>
      <description>首先我们简述核心词典的目标。词典最主要的目标是，给定一句句子S，匹配出所有和句子开始拥有完整匹配的词语。所谓完整匹配，就是句子开始的一定长度的连续序列和词语相等。例如，中华，中华人民，中华人民共和国，都是句子：中华人民共和国今天成立了，的完整匹配。
要解决这个问题，直观方式是使用tied tree。但是中文的tied tree非常不好实现。英文的tied tree在一个节点上最多拥有不超过26个子节点，而中文的在根上面会拥有6000个以上的子节点，使用同样的结构在子节点上会浪费大量内存。
我们先跳过tied树本身的细节，来讨论如何使用python内置数据结构高效简洁的完成这一工作。作为一个读比写高频很多的结构，无疑hash table是一个非常适合的结构。我在hash table的性能分析中说过，hash table的查询性能是O(1)量级的。无疑，可以使用hash tree来高速完成查找。同时注意一点，词语的最小长度是2，因此不存在只有一级的结构。所以，hash tree的第一级结构可以从2开始，而不是1。
实现效果如何？我们正式给出的词典拥有127K的词汇量，平均第二级宽度为6.8，因此大致可以推算出，第一级的词典含有元素19K个左右。python源码解析中说过，当表项小于50000个时，扩张大小为当前活跃表项的4倍，最高填充率不超过2/3，即填充率最低25%，最高66%。平均来说，填充率应当在45%上下波动，我们以0.5计算，实际上一级词典的Entry个数应当是40K个上下。在源码Include/dictobject.h:50有给出Entry的结构，这应当是三个平台相关的数据结构，以贝壳的64位系统而言，长度应当是24字节。忽略掉辅助结构，一级词典的大小应当是960K，即约1M。而词典指向的数据，即2字长的str对象本身头部长度24字节，辅助数据长度12字节，数据长度4字节（utf-16编码的两个unicode），null term1字节，共计41字节。由于python对象是8字节对齐，因此实际占用48字节。19K个数据总计占用912K。
二级表项平均长度6.8，这个长度很难估量。因为5的话总表项刚好是8，而6就会增长到24，我们取中间数20做一个估量值（因为6.8毕竟大大偏离了5），一个词典的大小应当是480字节，加上头部大约是512字节（算的粗糙点吧），19K个词典就是8.5M左右。指向的对象长度更加难估量，我们粗糙点按照96字节一个对象（别忘记了，unicode对象不但成员多，而且超出了BOM，一个字占4字节），127K个对象大约是12M内存。而float内部使用C的double类型，一个对象占据32字节，127K个对象占据4M内存。
以上总计，初级词典本身占用1M，关键字占1M。二级索引占据10M，关键字占12M，频率数据占4M。总计28M内存，基本上一个12.7W词的词典，大小2.5M，占据30M内存，这就是dict核心词典的空间效率估量。
时间复杂度估量更加复杂，不过我们可以简化来说。初级索引需要多少时间？O(1)量级，毋庸置疑。问题是二级词典的复杂度，异常难算。凑合一下，按照比较6.8次计算（因为必须通过遍历才能知道全部的匹配）索引出一个句子所有的完整匹配的时间复杂度O应当为O(n)，其中n是平均二级索引宽度。目前而言，实际测量结果，平均6.8。当词汇量大于一定值后，随着词典的加大，这个值基本是线性增加的，我们粗略的可以认为O(n)即是正比于词典大小。
而后我们顺便给出分词核心算法在处理一句话时的效率估量吧，证明太长，这里写不下。假定句子长度S，词典大小N，匹配数目M，分词算法的时间复杂度量级为O(N*M*S)，有兴趣的可以帮我复核一下，这个证明颇为困难，不知道有没有证错。在实际运行的时候，匹配数目会跟着词典的增长而增长，而句子长度则相对固定。当然，明眼人一眼就可以看出，所谓匹配数据随着词典增长而增长，其中并不是正比的。而是O(1)&amp;lt;O&amp;lt;O(n)。因此我们可以看作时间复杂度为O(N)&amp;lt;O&amp;lt;O(N\^2)，具体是什么，做不出来。
然后是纯粹的tied tree的性能估量。讲到tied tree，我们就必须要提到如何实现一个有效的tied tree。实际上纯粹用区域哈希映射太浪费内存了，而顺序查找太浪费时间。比较折衷的办法还是只有——dynamic hash table。
不过这次我们就可以控制一下哈希表的大小了。对于大小不超过6W的哈希，我建议采用crc32，虽然离散度并不高，但是作为一个近似填满的hash table的hash key足矣（这点需要实际考察一下）。如果是自己实现，表项直接存字符串，连指针都不需要，采用开链法。总计大小1M即可以保存所有的一级数据。
二级数据就无法这么偷懒了，因为二级结构中字符串长度不定。但是以数据展开大小只有2.4M来看，无论这一级别如何扩张，字符串本身大小不应当超过3M。开链法一个节点24字节，平均填充率0.5计算，14个表项一个词典（这个也可以自行控制了），336个字节一个词典，乘以19K个dict。大约6.23M。127K个频率数据1M，这是常规占用。
以上总计，初级词典本身占用1M，二级结构本身占用10M，不超过20M应当就可以构建起一个高效的核心数据结构。由于实现类似，时间复杂度也类似，就不详细推论了。
以上还有一点可改进之处，dict作为二级存储的绝对劣势在于，必须要对比全部词典才能确定完全匹配数量，于是时间复杂度正比于词典大小。严格的tied树只需要沿着顺序进行几次索引即可，复杂度取决于词语长度——基本来说和词典大小无关。按照这个推论，实现一个紧凑的，高效的二级小结构，可能比较有利于减小总体大小，增加工作速度。</description>
    </item>
    
    <item>
      <title>每个程序员都是铁蹄下的尘埃</title>
      <link>//blog.shell909090.org/blog/archives/2106/</link>
      <pubDate>Tue, 06 Mar 2012 06:01:08 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2106/</guid>
      <description>这个标题很文艺，我知道。实际上我想说的问题是，未来的计算机会是什么样子。在讲正题前，我们先得说说一个我相当成功也是相当失败的项目。
在很久很久以前——好吧，其实大概就是八九年前——我还在上大学，学习机械工程。当时我对电脑很感兴趣，所以父母给我装了一台电脑。这台电脑有512M内存，PIII800MHZ的CPU，120G硬盘，是当时比较新的配置，相当好。实际上，我是用考入大学时的配置升级来的，而且花了不小的一笔钱。当时我迷上了看动漫，交大有一套系统叫做comic，用过的人都有印象吧？这套系统开始是为了动漫而设计的，上面保存了相当多的动漫，而且有管理员定期更新。后来上面更是放上了其他的影像资料，做了视频点播系统，并且为全校师生服务。交大的网络滥用警告（例如国际流量超标）并不直接张贴在校务栏上，那样没多少人能看到。这些警告张贴在comic上，并且会ban掉你对comic服务器的访问。我们哪天看不了comic了，就会去看看上面是否有警告，然后去网络中心处理掉。
好吧，扯远了。在毕业的年代，我担心自己将来不能访问comic了，所以打算带走一批我觉得有价值的数据。我毕业时新增了一块硬盘，组成了双硬盘系统，但是没有组成磁盘阵列(Raid或者动态磁盘[1])。除去系统中的80G左右的程序和数据使用空间，我还可以使用300G左右的空间。但是comic上我喜欢的数据远远超过了1T。为了解决这个问题，我就设计了volcpy系统。这个系统是这样设计的，将硬盘上的数据保存在光盘上，而将他的元数据——包括文件名，大小，光盘卷标等——留在磁盘上。这样我可以以1M的空间存储上T的数据。当时250G的磁盘大约700元，平均2.8元/G。而光盘4.3G大约1元，合0.23元/G，大约相差10倍。动漫数据是不会经常更新的，事实上应当是几乎不更新。volcpy系统负责将光盘上的文件在硬盘上生成描述文件，在将来需要的时候也可以进行数据还原。
这个设计还是挺成功的，时至今日这个系统还在工作。我手头有接近2T的光盘，也不可能不使用这个系统。不过这个系统设计的时候，我还没接触linux，因此系统在设计上有一点缺陷——他的内部结构直接照抄了windows的卷描述和文件描述数据结构[2]，这对于windows下的存储很方便。要拼装存储数据，我只需要memcpy[3]就可以了。但是这也导致linux下想读取这个数据就必须进行解析，然后对照windows文档（电脑诸神阿），将内容解析和转换。如果是今天，也许我会使用基于文本的格式，例如json，yaml，或者xml。文件大小会膨胀2-4倍，但是也只有2-4M而已。
但是我最近正在试图将数据拷贝回硬盘，并且废弃这个系统。为什么？我们再来看看刚刚计算的账单。目前光盘还在1元左右——除非你只打算保存几天的数据，否则廉价光盘的损坏率太高了。但是硬盘的价格却下降到了2T600元，合0.3元/G。有0.3元/G的可变数据存储，谁还会想要0.23元/G的光盘呢？更不提每次使用都需要启动volcpy，插入光盘，然后以7M/s的速度读取。硬盘的速度从50M/s提升到了接近100M/s，大约是光盘速度的10倍，而且还不用找到底是哪张光盘。
可写光盘存储已经死了，除非大容量固定数据的短期分发，例如软件发行，或者盗版电影，否则没人会用光盘。我在拷贝东西给别人的时候，都使用U盘——拿回来重新格式化过就不必担心中毒（windows用户不要学，没用的）。8G的usb存储只要80元，还可以重复使用。U盘还遇到了更加强劲的对手——云存储。1G网络空间基本不要钱。以现在我的带宽，我需要3小时填满，9分钟下载。主要麻烦还在于3小时缓慢的上传速度。如果上传和下载对称的话，我也没道理会使用8G80的U盘，而且花费不少时间去拿给别人。我只需要将1G数据（大概8部动漫），花费10分钟多点上传到我的云端存储，然后把地址和密码（如果需要保密的话）传给对方，让对方再用10分钟下载。我甚至不需要自己保存数据，只需要问云存储机构购买40G的空间和一定数额的带宽（这个应当比自己的硬盘便宜），然后直接使用就好，就像一块只有2.5M/s工作速度的本地磁盘一样。我可以在家里和公司使用一样的存储，把数据共享给别人，在不开启电脑的情况下下载。这简直是价廉物美的无敌方案。
但是这也是为什么我痛恨低上传网络的原因。
OK，我们说回来，未来的电脑是什么样子。本质上说，上面一个题外话（而且是相当长的题外话）正是说明这个问题的关键——软件技术受制于硬件体系的发展，在高速时代使用低速技术是不可能的。我们现在不会满足于使用光盘的廉价存储系统，也不会满足于只能传输文字的聊天系统。同样，当硬件快速发展的时候，我们更没道理满足于快速但不可变的程序。
在我大学的时候，那台老电脑（现在是老电脑了，当时可是新鲜货咧）是相当强劲的编译机，我也是个不错的程序员。经常有同学过来问一些程序问题。我一般会听一下大致问题，看看是否需要开机。如果需要，我坐下，打开vs6[4]（那还是盗版，不过当时我也是学生）和合适的项目，然后拉过一把椅子让同学坐下，然后扯一些题外话，讨论一下问题。大概15-20s后，vs6那个难看的界面打开了，插件也初始化完毕，lazy eval和swap[5]也完成了，我可以很自由的操作电脑了，才会和他说。不好意思久等了。一般人都会说，没关系，你这个相当快。我觉得他们不是在恭维。
今天，我已经不用vs了，不过很偶尔还是会用到。vs已经从6升级到了2008，更复杂，界面也更漂亮了，没有什么可比性。但是我们做一个不伤脑筋的计算。目前我的电脑是3.0GHz4核，8G内存，1T硬盘的货色。CPU的线性速度增长了4倍不到，速度已经不能更快了。但是相应的，核心多了4倍，所以计算能力大概增长了16倍。内存大了16倍，硬盘大了4倍，硬盘速度快了一倍。单从集成电路的角度说，这个很符合摩尔定律。不过四个摩尔周期花费了不止6年，而是9年。也许这和设备价格下降了不止一倍有一定关系。实际上今天的瓶颈已经更进一步的向磁盘转移了。如果硬盘速度也增加了4倍或者4倍以上，我大概猜测，vs6的打开速度也许只需要1-2s，编译速度也至少应当增加了10倍。
这种速度下，我当年做了很长时间的一些修改，使得计算速度可以增加30%的努力，顿时变得黯然失色。固然，这些修改今天依然有效，1-2s的时间会加速0.3s。但是这0.3s绝对不是我如此长久努力所期待的结果。如果这个事情重演，我们在10年后，反观今天一些能够让速度加速1倍的决定，会觉得无比的愚蠢。当时为什么我不决定使用一种简单的方法呢？虽然响应时间从0.3s变成了0.6s，但是易变性很好，对未来的兼容也很好，谁在乎0.3s呢？
原因在于，你不知道什么时候会发生什么事情。我刚刚说了，我们今天的瓶颈在于硬盘吞吐。那么你怎么知道什么时候这个问题会有突破性的新技术出现呢？也许是明天，也许是10年后。难道你先去做别的，10年后再继续你的程序员生涯？我们必须基于我们当前的硬件假定编程，然后再把这个假定放在时间面前评判。而这个假定当出现新的硬件技术体系的时候，就会变得无比愚蠢。
如果要我预期将来的计算机系统，我首先就会猜测他无比的快，而且小巧省电。足够快，代表我们不需要把code载入内存中再运行，而是可以直接从外存（或者外存缓存）中直接运行代码。或者直接从网络（或者网络缓存，下同）中直接运行。足够小巧省电，代表我们可以带着计算机到处走，就像今天我们带着手机一样。然后在工作地点，或者其他地方，把机器接入一个输入输出设备上。所以？我估计好多人已经在泪流满面了，是不是呢？做磁盘检测和恢复的孩子们？当然，不是说这个行业会消失。但是他会变成一个相当小众的行业。小众到如同TBBT的笑话一样——25个人已经是一个嘉年华了。专家会通吃所有人，而普通程序员则根本进不去。然后——Bang，硬件又升级了，专家瞬间变成了转家。
每个程序员，或多或少，都生存在硬件升级这只巨兽脚下。你一不小心猜错了他会抬起左脚还是右脚，就会直接化为尘埃。如果猜对了，没事，你只是比别人多生存了一会而已。
1.两者都是将多块硬盘逻辑上变成一块硬盘的方案。
2.描述结构指属性存储格式和顺序，例如卷描述结构就是光盘的大小，卷标等等数据和他们的顺序。
3.指直接在内存中复制数据，不做任何其他操作。
4.visual stdio，Microsoft公司上世纪出品的编程工具，一般用于C/C++语言。
5.lazy eval指程序在加载一段时间后才会执行的一些工作。把这些工作分开有助于加快程序的启动速度，但是在操作时会感觉到速度变慢。swap也有类似效果。</description>
    </item>
    
    <item>
      <title>外包和派遣的一些问题和顾虑</title>
      <link>//blog.shell909090.org/blog/archives/2090/</link>
      <pubDate>Fri, 10 Feb 2012 07:01:39 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2090/</guid>
      <description>很多公司老总很头痛的一个问题是外包。相比自己生产程序，外包有一定的优势，也有劣势。
优势
1.外包便宜，从实现角度，比自己养程序员便宜很多。毕竟自己养程序员还要交三金所得税，外包程序员需要自己管理自己的三金所得税——通常都不会交。所以比自己养的要便宜的多。
2.在安全性上，外包并不一定比自己养程序员差。毕竟自己养程序员也没法杜绝跳槽，也没法杜绝恶意的underhand代码。
劣势
1.不稳定，极度不稳定。能不能完成并不像自己养的程序员那样有一个项目经理在跟踪，搞不好就是到期了，基本什么都没有。虽然可以不付钱，但是被耽误的时间更麻烦。
2.逼良为娼。如果你的需求类似一个论坛，他们就会诱使你做一个论坛。论坛可以用开源的项目经过定制和修改来完成，看起来工程浩大牛逼XX，实际上没花多少时间，实现小开销大收入的目的。如果你真的没被说动，他们会先答应你的一切需求，等期限快到了再告诉你，论坛做起来很快的，改一点需求吧。如果再说不动，参考问题1。
3.良莠不齐。多年筛选下来，很多优秀的，可靠的外包团队真的很厉害。但是混事的团队混事能力也很厉害，很多问题说的头头是道，价钱也比正儿八经做的便宜不少。你觉得便宜的就是混子？错，有时混事的团队比正经外包公司还贵。万一一个没看准，那就又参考问题2了。
4.外包没法解决资金来源。很多老板对这个问题只会哈哈一笑，不过有的时候这确实是个问题。不是每个外包团队都能提供发票的，很多团队没有挂靠公司，或者挂靠公司但是发票加税点。这时候你开出来的外包费用就无法按照服务费计算，只能当作其他费用处理。要么你自己找发票填上，要么就扣税。
我看下来，愿意做外包的老板，大概不足一成，而且大多都是逼上梁山没办法了（要么人力来不及按时完成了，要么没人会做了），才外包一部分。
相比起来，人力资源派遣是个新行当。这行当和外包差不多，只是他们不分离做，他们找人去你公司做。
优势
1.你的项目经理可以盯着他们了。
2.派遣多数都是从公司来的，大半有发票。
3.你让干吗就干吗，不行滚蛋。
劣势
1.可没比自己养程序员便宜，搞不好还贵。
所以很多公司对人力派遣也不是很喜欢。不过我说句实话，要是需要一个特殊类型的人才，预计时间不长，或者想试用一下，不妨考虑考虑。
目前很多外包也参考了HR派遣的做法，他们的做法是这样的。谈项目。达成协议。派团队去你的公司，该干吗干吗。验收。撤回团队。
你的项目经理可以随时验证他们的工作，因此也不会出现逼良为娼的情况。
但是无论如何，请自己找一个项目经理！不要让你的程序员来做项目经理的事情，更不要指望什么都不管丢钱下去程序就会自动长出来！</description>
    </item>
    
    <item>
      <title>python的字符串相加效率</title>
      <link>//blog.shell909090.org/blog/archives/2070/</link>
      <pubDate>Wed, 18 Jan 2012 01:51:37 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2070/</guid>
      <description>今天文章被人纠了错，就跑去人家主页上逛。结果看到有篇文章说字符串相加速度的，看看结论很奇怪。就做了一下实验。原文可以看这里。我们只讨论python部分的行为。首先是论证我观点的测试，无关部分就跳过了，大家应当可以自行补上。
def f(): s = &#39;&#39; for i in range(3): s += &#39;123&#39; print id(s) return s f() f()  输出：
138190216 138276992 138276992 138190216 138276992 138276992  至少在几十的规模，这个结论还是成立的。说明对象确实被缓存了，这导致了字符串相加的多次测试中，后续次数都没有实际的执行字符串分配动作。召dis来问之。
14 0 LOAD_CONST 1 (u&#39;&#39;) 3 STORE_FAST 0 (s) 15 6 SETUP_LOOP 46 (to 55) 9 LOAD_GLOBAL 0 (range) 12 LOAD_CONST 2 (3) 15 CALL_FUNCTION 1 18 GET_ITER &amp;gt;&amp;gt; 19 FOR_ITER 32 (to 54) 22 STORE_FAST 1 (i) 16 25 LOAD_FAST 0 (s) 28 LOAD_CONST 3 (u&#39;123&#39;) 31 INPLACE_ADD 32 STORE_FAST 0 (s) 17 35 LOAD_GLOBAL 1 (print) 38 LOAD_GLOBAL 2 (id) 41 LOAD_FAST 0 (s) 44 CALL_FUNCTION 1 47 CALL_FUNCTION 1 50 POP_TOP 51 JUMP_ABSOLUTE 19 &amp;gt;&amp;gt; 54 POP_BLOCK 18 &amp;gt;&amp;gt; 55 LOAD_FAST 0 (s) 58 RETURN_VALUE  我们看到s是local变量，这个符合我们的预期。但是后续确实发生了add，而string的+算法，我们可以参考Objects/stringobject.</description>
    </item>
    
    <item>
      <title>加密学中一个规定的来历</title>
      <link>//blog.shell909090.org/blog/archives/2066/</link>
      <pubDate>Mon, 16 Jan 2012 03:24:54 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2066/</guid>
      <description>为什么密码学中总有个假定，算法是对方已知的，密钥是可以更改的？
因为在很久以前，密码算法是靠人工运算的，更改算法每次都需要培训一堆人，很麻烦。所以变态的需求催生了变态的解法——算法彻底公开，靠密钥保密。
还记得很多谍战片中的“密码本”么？如果在现代，那就只一个记载着256个字符的纸条。因为整个过程其实地球人都知道，双方只是相差一个纸条上的256个字符而已。
觉得这点东西不靠谱，随便记忆一下就搞定了？你想想，以前的密码本也可以照相阿。是重建一个密码本，并且分发给各处安全，还是重建一个纸条并分发方便？
现代？其实还是很有意义的。因为很多遗留系统/硬件模块中的算法会长达10多年不变，如果依靠算法保密来保护安全性，哪天泄露了不是开玩笑的。上千万的硬件模块，没有人维护的遗留系统，都要整死人的。
而且算法本身也必须足够强，如果没有公开算法，“足够强”这个事情本身就是含糊不清的。没有人见过你这个算法，没有人讨论，谁知道是不是“够”安全呢？md5以前一直作为哈希的标准，我们都觉得够安全了，但是哈希碰撞的研究使得现在基本都推荐sha256了。同样，DES也不要再用了，换成AES吧。</description>
    </item>
    
    <item>
      <title>最牛电商</title>
      <link>//blog.shell909090.org/blog/archives/2060/</link>
      <pubDate>Wed, 11 Jan 2012 07:25:56 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2060/</guid>
      <description>昨天聊天，聊到最牛电商的问题，大家都笑了。
frank订票45分钟花了45分钟，还没搞定。先是从chrome换到IE，因为前面的部分chrome能用，付款不行。然后从工商付款，上限500，不行，必须一次付款800，而且不能用支付宝。问我借卡，我的也不行。最后借到卡了，结果过45分钟了，重排，没票了。
淘宝买东西要是需要超过5分钟，喵喵就会少买好多东西。
还有个朋友说，他的卡能支付5000，买票，扣款后没票。人家说钱能拿回来的——钱能回来可是票回不来阿。好，再买，又扣钱没票。再买——没钱了。
我去阿，这TMD不是坑爹么？
这种网站，转化率还是100%，广告成本0，绝对最牛电商阿——没有之一。
关于顶不住这个问题呢，大家都懂的。我自己也做过类似的事情——甲方设法让自己的厂家中标，也不管人家有没有能力做。厂家领导是先中标再说，不中标自己就完蛋了。下面的人没能力，要么是不知道自己没能力，要么是知道也不敢说。做着做着问题一堆，也不敢和甲方沟通。不沟通问题就越来越多，交货的时候一看，甲方吐血。然后厂家领导就和甲方领导搞协调，厂家要去修一些问题的，甲方延一点时间，最终还是会让这个系统上去的——否则领导也麻烦阿。
最后只要这个烂摊子不被揭出来，大家皆大欢喜。中国政府领域的IT，大多都是这个样子。
比较大的烂摊子揭出来的，一个是绿坝。没办法，太烂了，还要所有机器供应商都来做支持。索尼干脆发了个文，这是中国政府让我们装的，出了问题不要找索尼，谢谢。结果这样还被告上美国法庭了。最后领导实在顶不住压力，撤了。另一个就是这个，最牛电商，估计回头也会撤的。因为后面订票压力越来越大，搞事情的人也越来越多，烂摊子搞到后来领导也会怕的。
其实昨天gary说了一句比较实在的话，这个系统不应该做成这个样子的。一切说中国买票的人太多，瞬间交易压力大，刷不出票的人持续刷的，都是借口。知道压力大，搞分时销售和抽签制分散压力。前端做负载均衡和CDN负担压力，后端真到订票的时候转换成MQ去操作。大型机再怎么做的差，每秒1000个transactions是出的来的。一小时就能完成360W的交易，一天八小时，3000W的票就出来了。中国有多少人需要订票的？3亿？就算做瞬时压力，铁道部车票成交比纽约股市买卖还快，要求还高？技术做不到根本是扯淡，最多是钱的问题——现在还是花钱没解决问题。
为了见证奇葩，我特地上去看了一下，结果第一眼就晕倒了——铁道部需要你自行下载根证书。我去阿，堂堂铁道部，一个多少万的项目，连TM买一张证书的钱都没有？！
其他细节就不多写了，相信用过的人比我都清楚的多。需要多次点击才能买到一张票，访问过程长导致压力大。定时开票，时间集中导致压力大。需要注册，导致注册过程冗长，也是增加压力。这些都不是技术问题。
整个过程中耗时最长的（抱歉我懒得注册，只去看了余票查询），一个是http://dynamic.12306.cn/TrainQuery/leftTicketByStation.jsp。这个的服务器响应表明是来自Apache-Coyote/1.1，由squid/3.1.18缓存，未命中。另一个是http://dynamic.12306.cn/TrainQuery/passCodeAction.do?rand=rrand。这个的服务器响应表明来自Apache-Coyote/1.1，是一张image（验证码），同样未命中。基本squid命中的都在ms级别返回了，出问题的都是dynamic.12306.cn这个域名没有命中的页面。这个表明前端的缓存还行，压力都压到了后端。至于造成这个现象的原因是前端缓存策略错误，还是后端性能相对不足，就不知道了。
我注意到，至少有一个页面https://dynamic.12306.cn/otsweb/css/contact.css。Server字符串是asfep/2.3.0 svn:3075。asfep是什么我不知道，google了一下也没出来。不过svn？这文件是从svn服务器上出来的么？！如果是，这就有点奇葩的味道了。
然后我点了一下查询，这下大奇葩出现了。一个query居然执行了30s以上。在验证码故意输错的情况下，返回速度在10s这个量级，而输入正确就天长地久了。由此可见系统是分成多个部分的，最外面是dynamic.12306.cn和12306.cn两个域名，上面用squid做了缓存。后面是一堆应用服务器。其中有一些Coyote服务器的响应特别慢，大概在1-10s这个量级。而这些服务器当访问数据库的时候，就彻底变成访问无望了。按照网络上说法，铁道部用的是Oracle数据库，估计已经半瘫痪了。
说是Coyote，其实如果没什么意外，这个就是Tomcat。那么铁道部的架构底子基本也就出来了，是J2EE的架构。估计是一帮ERP工程师照猫画虎做出来的。J2EE不是不能用来做电子商务，有些网站还做的很成功。但是不做任何优化，直接就敢拿J2EE做ERP的架构去做大规模电商的，这就是找死了。尤其是某些ERP严重依赖于Oracle，业务逻辑根本就是用Oralce写的，用J2EE封装了一个壳子。这种就更麻烦。
目前还不能确定铁道部订票网站到底是什么情况，不过可以确定的是，这个网站的状态在未来几天内还会继续恶化。搞不好到一定程度就直接没法用，或者被铁道部直接关闭网站一段时间了，需要订票的同学最好尽早想办法。</description>
    </item>
    
    <item>
      <title>语言的继承和历史包袱</title>
      <link>//blog.shell909090.org/blog/archives/2048/</link>
      <pubDate>Sun, 01 Jan 2012 02:03:01 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2048/</guid>
      <description>出去玩，在阳朔过的新年，随便发点吧。
我们知道，C++继承了C语言的语法，并且号称完全兼容。实际玩下来，C标准自己也不怎么统一，说基本兼容大家是没异议的。这个给C++带来了无限的好处，从一开始，C++的用户数量和其他语言就不在一个数量级上。《C++语言的设计和演化》一书中说，作者设计出来后没多久，基本没有做宣传，就有无数人给他打电话，用户数量飙升。作为一个新出的语言，即使是Go也没有如此的待遇，这就是继承了C的好处。
有好处就有包袱，C++兼容C，出现的包袱也很大。想做GC？想使用智能指针？那就没法兼容C（具体不细说）。此外里面有无数的问题是因为“需要兼容C”而变成一个四不像的。再后来，为了在语言上更进一步，Java继承和吸收了C++的部分语法。这给Java带来好处，也带来问题。
继承一个东西的好处，就会带来一定的包袱。这个也同时体现在Zope社区和Python社区里面。Zope3把2直接推倒重来，导致了用户纷纷出走（当然还有别的原因）。从而出现目前Python
Web框架满天飞，各自为战的局面。而Python3则是不完全兼容Python2，导致目前上面的可用库依然不足。在Python3.2的时候，几乎是被迫的做了一些前向兼容，来换取用户可接受的过渡。同样，前几天我在说Django的演进的时候，也说过。如果我要做一个jinja版本的Django出来，大家接受度如何？当然，这不代表你无法在Django中使用jinja，不过发行版中不会作为标配。
还有什么语言继承和革新的事情？大家不妨想想。自己做的时候，对照一下，谨慎取舍。</description>
    </item>
    
    <item>
      <title>Py 有什么缺点?!</title>
      <link>//blog.shell909090.org/blog/archives/2029/</link>
      <pubDate>Wed, 21 Dec 2011 22:06:20 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2029/</guid>
      <description>在 2011年12月21日 下午2:24，Zoom.Quiet 写道： &amp;gt;
在昨天内部分享交流中,俺回顾了 PyCon2011China 中透露出的 Py
最新使用/发展和体验; &amp;gt; 最后有同学问: &amp;gt; Python 有什么缺点!? &amp;gt;
 直接HOLD 住了俺的思路&amp;hellip; &amp;gt; - 是也乎!? &amp;gt; -
 世界上没有完美的语言 &amp;gt; - Python 相比各种开发语言也有缺点,当然的!
 可是,是什么呢?! &amp;gt; &amp;gt; - 没有 {} ? &amp;gt; - 不支持多CPU ? &amp;gt;
大家在学习使用过程中,对 Python 有什么失望的地方?! &amp;gt; - 兼听则明
 现在不满意的,就是我们努力的方向.. &amp;gt; &amp;gt; PS: &amp;gt; -   俺现场憋出的回答是: &amp;gt; - 由于 Py
历史上积累的好用模块太多，会导致开发人员更加懒惰，不思进取，不论什么都可以直接搜出可用的现成模块来!
  &amp;ndash; &amp;gt; 人生苦短, Pythonic!</description>
    </item>
    
    <item>
      <title>python为什么叫好不叫座</title>
      <link>//blog.shell909090.org/blog/archives/2008/</link>
      <pubDate>Thu, 08 Dec 2011 10:15:31 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/2008/</guid>
      <description>python的招聘，看似火爆，各家都在抢人，还抢不到。但是实际操作一下，发现实际上还是较好不叫座。八成以上的人去应聘，都找不到心仪的工作。当然这个原因很多，我只说我听闻的几个。
1.python的快速开发名气
这是中枪最多的原因，这个传说是从阿北开始的。想当年他一人做豆瓣，几个月就出活了。后来一帮做系统的一听这名声，都投靠了python，而且无一例外的都是django。他们的希望，就是超越阿北的传奇。一个人三个月出个系统，那我们找三个人，加班加班，一个月也能出个系统了。好，后来的事情大家都懂了。
当然这个故事纯属虚构，很多公司在计划上还是半年出系统的。但是实际执行上，老板要求能多快就多快，工资能多低多低。这种公司你指望他开多少薪水？15K？别傻了。偏偏python这东西学的贼快，有三个月就能出来混事了，你和他们比工资低，傻了吧。
这帮人也许接触过网络开发，也许没有，不过他们应当都没看过“人月传说”。即使没看过，傻子也应该想到，阿北当时的工作状态和水准，要给自己发工资该发多少？找一帮接触电脑都没满一年的人来搞人海战术，那铁定是找虐的。
2.在找第二主程
我和thomas说过一个观点，一家IT公司永远也不应当停止招聘，他们只有提高标准和降低标准两个情况而已。在公司里面缺人的时候，标准低一点。在不缺人的时候，标准高一点。一旦停止招聘，停止HR相关的工作，有些大牛刚好出来你就抢不到。
去这样的招聘是很容易被鄙视的，因为标准很高。他们也不担心招不到人，反正只是碰碰运气而已么。有一些大公司发招聘你去了什么消息都没有，就是这种情况。
所以，对一些已经成熟的团队，你还是认识一下里面的人，多接触多聊聊比较好。一方面可以学一些东西，另一方面搞清楚里面现在是缺人还是爆仓。也许一家靠谱的公司，本来处于爆仓状态。讨论决定做一个产品，一下子就缺人了呢。
3.其实我们在找披着python皮的其他工种
python用途很广，所以老耿说过，我们不招python程序员。他的本意大概是，你是个好程序员，又刚好会点python，那就是我们找的人。如果不会python，学一下就是我们找的人。很多公司在表达的时候，其实反了过来。他们要找一个sa，会一些python，能够写程序，于是HR的需求出炉就是——python程序员。系统程序员，抓取分析，报表统计，凡是需要你会一些python，但是主要是其他工作的时候，这其实都是一样的。他们找的是披着python皮的其他工种。
你要是个程序，去了一准被鄙视。</description>
    </item>
    
    <item>
      <title>正好聊到django——论他的模板问题</title>
      <link>//blog.shell909090.org/blog/archives/1994/</link>
      <pubDate>Thu, 24 Nov 2011 16:54:56 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1994/</guid>
      <description>首先先广播一个纠错，我那篇《几个模板的性能对比》，对cheetah模板没有做渲染处理，只生成了对象。因此性能出现严重误差，在此向所有被误导的朋友致歉。
——不过这并不影响django慢到渣的结果。
Shell: 他们用了django的orm，映射到了mysql
我一点办法都没有 mysql唯一能做的，就是一写多读 或者可以加入handlesocket
Bill: 为什么facebook以前好像用mysql能处理那么NB.
Shell: 多久以前的事情啊？
而且你得想，他们以前还用php呢 他们自己开发了hiphop，把php编译为了C 同样，我估计mysql他们也做了手脚 那玩意我学不来 而且，即使学的来，也不可能在django固定了范式的前提下 ——起码得给我修改范式的机会吧
Bill: 你可以改django嘛.
Shell: 太麻烦了
django已经积重难返了
这个问题，并不来自于django本身，而是来自于所有学django的人 Bill: 为什么这么说?
Shell: 由于他们的努力，django变成了一个固定的商业标准
试图对django进行修改的行为，哪怕是正面的努力，都会受到已经存在于上面的系统的抵制 例如，我开发一个django的分支，允许使用其他模板，你觉得会如何？
压根不会有人理我 因为大家都使用现有的模板系统，并且在上面做了无数的代码 很多人甚至无法升级django的版本 很多app也已经使用了现有的模板 如果我对django整合cheetah，那只能限于自用的范畴
Bill: 这么说还真是一条不归路了..
Shell: 除非他们的维护者作出很大的努力
说白了，就是官方强推
Bill: 不过到时候遇到瓶颈了,怎么办..
Shell: 但是，这样一来，很多人就根本不会升级了
怎么办？
要是有办法，他们还会找我么？
Bill: 靠硬件..
Shell: 他的页面就是3-5秒的打开时间
硬件上再增加，一个花钱，另一方面，也不可能增速啊 只能增加并发访问量
Bill: 也有点增速效果吧..处理速度快乐 快了
Shell: 怎么会呢？
你想，靠硬件是怎么靠的？
换更高频率的机器，还是加同样的机器？</description>
    </item>
    
    <item>
      <title>python-segment使用示例</title>
      <link>//blog.shell909090.org/blog/archives/1990/</link>
      <pubDate>Tue, 22 Nov 2011 10:18:15 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1990/</guid>
      <description>项目的主页是http://code.google.com/p/python-segment/，如果有问题，可以在上面提交issue，我会收到邮件（google code会么？应该会吧）。如果你希望协助开发，可以加入项目。一些简单问题可以直接看项目的WIKI，Wiki中有的一些内容我不会进一步解释，只会告诉你在那里可以看到。
1.如何获得源码
你可以使用以下代码，直接从版本库中复制一个可用版本出来。
hg clone https://shell909090@code.google.com/p/python-segment/  或者可以从这里下载一个最新版本的包。
2.如何准备环境
你可以看INSTALL，里面讲解的比较详细了。如果你不准备进行安装部署，可以跳过安装和打包这两步。但是如果你打算使用cutter工具，请安装chardet。如果你打算使用spider工具，请安装html2text。
首先按照如下方式生成词典。
gunzip dict.tar.gz ./ps_dbmgr create dict.txt  然后，你可以看到生成了frq.db，这是词典的默认文件名。注意，词典文件的格式和具体的版本有关，换用版本后最好重新生成词典。
3.试验分词
假定有一个文本文件，test.txt，里面内容是中文平文本，编码任意。
./ps_cutter cutshow test.txt  cutter会自动推测编码。
4.代码使用
假如当前有一个frq.db词库。
import segment cut = segment.get_cutter(&#39;frq.db&#39;) print list(cut.parse(u&#39;工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作&#39;))  注意，仅仅使用parse是不会进行分词的，因为parse返回的是一个生成器。</description>
    </item>
    
    <item>
      <title>关于网站架构的几封邮件摘抄</title>
      <link>//blog.shell909090.org/blog/archives/1978/</link>
      <pubDate>Fri, 11 Nov 2011 16:18:45 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1978/</guid>
      <description>Shell.Xu &amp;lt;shell909090@gmail.com&amp;gt;:
我知道，我自己写过一个greenlet + epoll的实验性框架。
http://code.google.com/p/py-web-server
最主要的问题是，写到后来我发现，这东西对用户的要求太高了。要用好这种框架，用户必须具备系统经验，知道阻塞操作实际上是由非阻塞操作和上下文调度去模拟的，知道代码处处无阻塞（其实是不能有无调度的阻塞），能够想像系统是如何运行的。
这种人不会太多。在cpyug里面不算少，抓10个20个肯定能抓出来，抓上100个也不是没希望。但是实际在操作的时候，平摊到上海这么个地方，会python的也就见过那么不到100人，有这种要求的几乎可以一个个数出来。而且大多数已经在一个不错的公司里面有个不错的职位，你没法指望招个人来做事。
这也是为什么很多公司凡python必django的原因，毕竟用了django，虽然罕见，但是可以招人。用了tornado，能招的范围就少了很多。我自己做的这个实验性的玩意，风险大不说，HR角度来说，可选程序员只有一个。一旦在上面做了系统，不废弃系统的前提下，你压根没法谈判工资。。。
从语言角度来说，我更倾向于lisp，那个比较优美一些，而且也有编译成C的选项，速度不慢，天然的fp。问题是lisp从语义的自然可理解性来说非常差劲，那个传说中某AI实验室源码最后一页全是)并非空穴来风。对于新手入门而言，lisp成本更加高，使用lisp做系统，HR执行的难度也更高。haskell我并不懂，不过从语言理解来说，大概介于lisp和python之间吧。
协程型框架和进程/线程型框架相比，最大的好处就是减少了锁的问题。因为上下文切换的位置都是已知的，是否需要锁很容易考虑。很多时候甚至不需要严格锁定，只要置标志位就好，速度很快。使用fp，也可以大幅减少锁的问题，但绝对不是避免。目前的系统架构设计，已经越来越多的把锁的问题扔到了数据库层。
例如，我在操作一条记录的时候，一定会发生行级锁，否则就是不安全的。而在添加一条记录的时候，必然会修改这个表上关联的索引。而修改索引的瞬间，就会发生瞬时的锁定和解锁，否则也是不安全的。这个过程虽然对用户不可见，但是并非不存在。诚然，数据库访问是基于网络的，而基于网络的read是一个阻塞操作，在架构级别一定会调度到别的上下文执行。但是没意义阿，大规模的用户访问，除掉可以缓存的部分外，都被压到了数据库上进行读写。这些访问，在表级频繁的发生冲突，被各种锁序列化成顺序访问。到最后，我们不断的向系统中添加机器，来换取性能增长的时候，应用服务器实际上变成了问题最小的一个——小到用也许bash去写cgi都可以满足。与此同时，我们的数据库问题越来越大，还没法拆分——你没办法像应用服务器负载均衡那样把数据库拆到多个机器上去，然后让他们的写入性能成倍数增加。
无论是mongo，redis，还是mysql，都没有本质上的解决锁，尤其是写入锁的问题。mongo的读取性能可以上到15kreq/s，但是写入只有5kreq/s，而且好像还不能由sheding做加速——至少不是成倍级别的加速。mysql目前比较成熟的方案还是单写多读。当然，还有所谓水平拆分和垂直拆分的方法。垂直拆分对业务有要求，水平拆分只解决了大规模数据吞吐分布到多个存储媒体的问题，不解决索引访问的问题。redis压根没有自己的分布方案，你必须自己来做。
k-v受到热捧的原因之一，在它给了你一个从某个层面绕过这个问题的方法。目前写入锁最严重的点在于索引。无论是插入还是修改记录都需要在数据库上变更索引，而索引的变更就必然会发生锁。K-V的要点在于不允许在记录上做索引——所以mongo不是k-v数据库——从而允许用户将庞大的写操作分布到数十乃至数百台机器上的同时，获得倍数级别的性能增长。我们先不考虑添加/删除——这个是一致性哈希的目标，也不考虑可用性——这个是冗余的目标。仅从这点来说，k-v数据库受到热捧是有原因的。
问题是，这也不是解决问题，这只是绕过问题。相信使用k-v的人应该有所感受，这玩意根本没法替代常规数据库来用。没有事务，没有一致性隔离就算了。连索引都没有，这TMD的怎么用阿。目前来说，更加实际的使用还是用k-v来存储一些确实没必要进行索引的东西——例如大量小规模图片，用户的属性数据。
Zoom.Quiet &amp;lt;zoom.quiet@gmail.com&amp;gt;:
 那么这样的话,可以考虑用 Erlang ,这货天然就是为了大分布高迸发服务发明的
 而且从语义行文角度看也很好理解
 更加要命的是 erl
  提供了丰富到变态的动态调试工具,风骚无比的热部署无缝回滚&amp;hellip;
 只是,摧悲的是 erl 对于计算无爱&amp;hellip;
 不过,反过来想一下:
 现在 web2.0
  的世界,以及在爆发中的移动互联应用中,有什么是非要复杂关系查询的?!
 通过业务的良好统计,可以从业务角度就异步化
 那么,不论什么语言来开发,都没有阻塞问题存在了哈&amp;hellip;
 这也是为毛 K/V 数据库得以商业应用的主要原因
 另外,前述有人说 git 作存儲的思路也是个方向:
 既然分布式写入锁是个难题
 那么就直接只进行本地操作好了
 仅在必要时,进行分布式合并,这方面,各种版本控制系统都作得很好
 如果 redis 的bilog 文本对 git
  合并是可耐受的,那不就是个山寨的分布异步安全锁了?
Shell.Xu &amp;lt;shell909090@gmail.com&amp;gt;:</description>
    </item>
    
    <item>
      <title>几个模板系统的性能对比</title>
      <link>//blog.shell909090.org/blog/archives/1975/</link>
      <pubDate>Wed, 09 Nov 2011 14:52:47 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1975/</guid>
      <description>对比目标，jinja2，cheetah，mako，webpy，bottle，tornado，django的性能。 
 方法，随机生成一个二维数组，第一列是自增数据，第二列是长度为100的随机字符串，然后生成html，比较一次生成的时间。

 说明，如果模板有编译缓存，打开。有其他方法加速，打开。生成缓存，关闭。不计算随机数据生成时间，一次生成后一直使用。   以下是文件有效内容，没用的都略去了。最后的顺序是因为我根据结果整理了一下调用次序。   -----testcheetah.tmpl-----    &amp;lt;table&amp;gt;   \#for \$i in \$l   &amp;lt;tr&amp;gt;   &amp;lt;td&amp;gt;\$i\[0\]&amp;lt;/td&amp;gt;   &amp;lt;td&amp;gt;\$i\[1\]&amp;lt;/td&amp;gt;   &amp;lt;/tr&amp;gt;   \#end for   &amp;lt;/table&amp;gt;  
 -----testdjango.html-----    &amp;lt;table&amp;gt;   {% for i in l %}   &amp;lt;tr&amp;gt;   &amp;lt;td&amp;gt;{{ i.0 }}&amp;lt;/td&amp;gt;   &amp;lt;td&amp;gt;{{ i.</description>
    </item>
    
    <item>
      <title>ApacheBench在性能分析时的一点注意</title>
      <link>//blog.shell909090.org/blog/archives/1961/</link>
      <pubDate>Thu, 27 Oct 2011 16:47:36 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1961/</guid>
      <description>废话不多说，上干货。
http://blog.miniasp.com/post/2009/10/07/Explain-ApacheBench-ab-for-the-Failed-request-field.aspx http://stackoverflow.com/questions/579450/load-testing-with-ab-fake-failed-requests-length 简单来说，如果你用ab压网站，发现很多Failed requests。只要这些都是Length，就不算数。</description>
    </item>
    
    <item>
      <title>python内存不释放原理</title>
      <link>//blog.shell909090.org/blog/archives/1921/</link>
      <pubDate>Wed, 28 Sep 2011 09:57:04 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1921/</guid>
      <description>在maillist里面看到无数次的有人问，python速度为什么这么慢，python内存管理很差。实话说，我前面已经说过了。如果你在意内存/CPU，不要用python，改用C吧。就算C不行，起码也用个go或者java。不过今天还是说说，python的内存为什么不释放。
首先，python的初始内存消耗比C大，而且大很多。这个主要来自python解释器的开销，没什么好解释的。用解释器，就得承担解释器运行开销。然后，python中的每个对象，都有一定的对象描述成本。因此一个long为例，在C下面一般是4个字节（不用int是因为int在不同平台下是变长的），而python下面至少是16个字节。如果你生成100W个对象，那么C的内存消耗是4M，python的是16M。这些都是常规内存消耗，搞不明白的就别问了，不再解释。
下面解释一下python的内存释放情况。
如果是C，通常是用long array[1024 * 1024]的方法来生成1M个对象空间。当然，实际这样是不一定能运行的。因为linux的默认栈空间是8M，而Windows默认栈空间只有1M。所以代码在linux下可以通过，而windows下会跑爆掉。怎么办？下面说。当这个函数执行完毕后，当RET的时候，会自动退栈，空间就会自动释放掉（虽然在逻辑上这部分空间还是保留没有释放的，然而空间不活跃了，不过统计的时候还是占用的）。当然，更好的办法是使用malloc。malloc会从系统中自动提取和管理空间，free自动释放。这样无论是linux还是windows，都没有栈空间不足的问题。free后就会自动交还系统（4M已经超过了交还的最大阀值，一般glibc不会自己闷掉不交给系统的）。如果你忘记free，这部分内存就会一直占用，直到进程退出未知，这就是很有名的内存泄露。
python下的情况更加复杂一些，python没有直接使用malloc为对象分配细粒度内存，而是使用了三层堆结构，加上三色标记进行回收。所谓三层堆，细节我们不说了，在源码阅读笔记里面写的比较详细。但是有一点需要我们记住的——当我们分配某个大小的内存的时候，内存管理器实际上是向上对齐到8字节，然后去对应的内存池中切一块出来用的。也就是说，如果我们运气比较差，申请了10个对象，偏偏每个对象大小差8字节。这样系统就要给我们分配10个堆，而不是刚刚好。如果你的对象粒度都比较散，那么内存开销比较大也不奇怪。
python下还有一个更坑爹的事情，也是大部分内存不释放的根本原因。在int/str等对象的模块中，有个模块级别的对象缓存链表，static PyObject * free_list。当对象释放的时候，压根不会还到池中，而是直接在free_list中缓存。根据我的搜索，python内部没有地方对此进行干预。就是说，一旦你真的生成了1M个数字对象，然后释放。这1M个对象会在free_list链表中等待重用，直到天荒地老，这16M内存压根不会返还。而且，int的对象缓存链表和str的还不通用。如果你又做了1M个str对象，他的开销还是会继续上涨。几乎所有的内建对象都有这种机制，因此对于大规模对象同时生成，python会消耗大量内存，并且永不释放。
解决的机制，基本只有用yield来将列表对象转换为生成器对象。列表对象会同时生成所有元素，从而直接分配所有内存。而生成器则是一次生成一个元素，比较节约内存。</description>
    </item>
    
    <item>
      <title>uwsgi under debian</title>
      <link>//blog.shell909090.org/blog/archives/1919/</link>
      <pubDate>Tue, 27 Sep 2011 10:28:02 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1919/</guid>
      <description>好了，debian官方的uwsgi总算出来了。包已经到了testing，stable暂时别指望了，等下一次release吧。这次打的包，比贝壳打的复杂多了。贝壳自己只打了python专用的包，debian官方的包将多个语言分别打成了plugins。
下面说说，使用debian官方的包如何做uwsgi发布，还是vhost模式哦。
首先安装uwsgi，uwsgi-plugin-python这两个包。uwsgi-plugin-greenlet-python也可以考虑，装不装看你的需求。
然后在/etc/uwsgi/apps-available/sites.xml下面写一个文本文件，内容如下：
&amp;lt;uwsgi&amp;gt; &amp;lt;vhost/&amp;gt; &amp;lt;no-site/&amp;gt; &amp;lt;/uwsgi&amp;gt;  再从/etc/uwsgi/apps-enabled/sites.xml链接过去，重启uwsgi服务，事情就搞定了。
默认的配置在/usr/share/uwsgi/conf/default.ini，可以看看是否都满意了。一般来说，master和no-orphans都建议打开，chmod-socket最高660，改成600应该也可以工作。贝壳的机器负载小，只用一个worker就够了，所以完整的配置是这样的：
&amp;lt;uwsgi&amp;gt; &amp;lt;plugins&amp;gt;greenlet,ugreen&amp;lt;/plugins&amp;gt; &amp;lt;workers&amp;gt;1&amp;lt;/workers&amp;gt; &amp;lt;reload-on-as&amp;gt;128&amp;lt;/reload-on-as&amp;gt; &amp;lt;vhost/&amp;gt; &amp;lt;no-site/&amp;gt; &amp;lt;/uwsgi&amp;gt;  nginx里面如此设定：
location /asdf { include uwsgi\_params; uwsgi\_param UWSGI\_PYHOME /usr; uwsgi\_param UWSGI\_CHDIR /var/web/hosts; uwsgi\_param UWSGI\_SCRIPT main; uwsgi\_pass unix:/run/uwsgi/sites/socket; }  其中，我的程序放在/var/web/hosts底下，使用系统环境来运行（而不是virtualenv），主脚本（带applications那个）是main.py。unix
socket和上文default.ini里面的socket正好对应上。
同理，我们其实还可以开多个uwsgi应用，只要放置多个xml配置就好。不过既然都采用了vhost模式，何必还开多个呢？这毕竟不是虚拟网站，要给其他人使用的。</description>
    </item>
    
    <item>
      <title>除虫故事（三）</title>
      <link>//blog.shell909090.org/blog/archives/1887/</link>
      <pubDate>Wed, 17 Aug 2011 16:03:11 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1887/</guid>
      <description>第三个bug是刚出的，贝壳刚刚从现场回来，提交了bug系统关闭申请。
问题是这样的，我们有一套系统，为客户提供从web访问某台windows的能力，作为管理系统使用。这个系统的后台使用了三四个不同的程序，通过管道通讯。目标设备上有一个组件，要适应2000/2003/2008的32位和64位环境，非常复杂。最近，贝壳将这套系统的目标设备的组件进行了重编译，提供了64位版本。然后测试发现，32位系统不工作了，64位系统正常。
第一反应是什么？一定是组件有问题？贝壳在服务器上，直接使用连接程序去连接，结果是成功的。这个表明组件应当是正常的，或者部分正常。问题就在web页面到连接程序的过程中某处。
负责web界面到连接程序的工程师同事接手了下一步排查，他也是一头雾水。系统看来一切正常，连接程序明明可以工作，为什么从web页面调用就会失败呢？而且只有32位会失败。web页面对CPU字长（而且是目标设备的CPU字长）并不敏感阿，这个听起来不合理。
测试过程中，测试部门的同事偶然的看了一下日志系统，发现了问题。我们的连接程序会写出日志，默认情况下这个日志的属主应当是web.web的，而当时的日志是root.root的，而且权限是644。所以当连接程序被直接调用，当前id是root，就可以连接成功。而连接程序被web调用，当前id是apache，日志写出就会失败，程序就挂了，目标设备会失去反应。
出现这个错误的原因也很直观，在某次调试后，有人删除了原始的日志，并且直接执行了连接程序。但奇怪的是，同样是连接程序挂掉，为什么64位就可以继续执行呢？我们讨论不出为什么，只有基本猜测，64位设备是2008，rdp服务版本比较高，所以相对健壮。
所以，实际的错误是两个。一个是日志权限导致的连接程序不工作。另一个是64位下不正常的连接程序依旧可以工作。
好吧，总结一下这个奇怪的问题中的教训。
1.隔离最小差异。要验证是否是组件升级导致问题，一定要进行旧组件测试，然后再测试新组件。万不可假定旧组件可以正常运行，直接测试新组件，从而将非组件问题带入排查。
2.单元测试隔离。每个部分都要做单元测试，如果测试通过却无法连接，那就是环境问题。再查不出，再检查通讯/调用记录。
3.通讯系统关联错误。当两个程序通过通讯工作，其中一个程序死亡时。另一个程序应当能够检测并且报错退出，而不是出现各种异常反应。
4.日志底线设计。程序一定要写日志，如果日志写不出，就写系统日志，再写不出，设法报全局错误。</description>
    </item>
    
    <item>
      <title>从C&#43;&#43;的一个特性到设计原则再到哲学</title>
      <link>//blog.shell909090.org/blog/archives/1875/</link>
      <pubDate>Mon, 08 Aug 2011 09:59:46 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1875/</guid>
      <description>最近在看C++的设计和演化，里面讲到算符重载。关于这个，Effactive C++里面明确说明，不要试图重载&amp;amp;&amp;amp;和||算符。因为这个重载造成的结果和默认不符(Not same with the default)。
&amp;amp;&amp;amp;和||有什么特殊？熟悉C的朋友考虑这么一个问题。if(i &amp;amp;&amp;amp; ++i)的作用是什么？基本来说，这个语句是判断i是否为0或者-1的，并且有个额外效果就是对i进行自增。但是，如果i == 0，则不进行自增，这就是&amp;amp;&amp;amp;的短路求值原则。这个原则产生了一系列写法，例如sh中常见的[ -z &amp;ldquo;\$ABC&amp;rdquo; ] &amp;amp;&amp;amp; { &amp;hellip; }。
不过当重载了&amp;amp;&amp;amp;或者||后，就破坏了短路求值原则。因为C系列语言是应用序语言，参数先求值。所以后参数*一定*会被求值，无论前参数的值是多少。
更加悲崔的是，这个破坏了最小惊讶原则，或者叫做知识内隐原则。当你使用一个知识的时候，你会根据自己的经验对这个知识做内隐的预期。例如，虽然螺丝有左螺纹也有右螺纹，然而你在拧螺丝的时候，多数预期是顺时针拧紧。不论其理由，这个已经成为常态。同样，有下压把手的门是扇页门，画着杯子的店家是咖啡店和茶馆，画着裙子的厕所是女厕，这些都是你对知识内隐的预期。破坏这个预期，相当于把螺丝改为反向，下压把手的门改成移门，画着杯子的店家是古董店，男厕画裙子一样，会让人感到不知所措。大家会莫名其妙的绕出去，确认门上画的确实是裙子，走进去再看到男厕，感到世界莫名其妙。
同样的道理，如果一个对象使用了&amp;amp;&amp;amp;重载，程序员唯一能够快速发现的机会就是在调试时单步了&amp;amp;&amp;amp;的语句。如果他运气不好，可能在数个小时内都找不到理由，直到反汇编目标代码为止。
那C++为什么设计算符重载？那是设计给需要的算符用的。其实C++一直是一个矛盾的设计，一方面他认为，程序员是不可信的，所以C++里面有隔离保护系统，例如私有成员函数和变量。另一方面，他又认为程序员应当对自己的行为负责，因此他设计了复杂的算符重载，复杂的继承系统，并期待程序员能够按照正确的方法使用。这是一个奇妙的，矛盾的设计思路，反映设计者自身的冲突（例如多人设计），或者C++设计者的实用主义倾向（选择最实用的设计）。python语言的思路相对统一，他认为程序员应当为自己的行为负责，所以python的隔离系统都是伪系统。而java的思路也相对统一，他认为程序员是不可信的，所以java才会搞出复杂的架构哲学。</description>
    </item>
    
    <item>
      <title>如果你的python项目一定要源码保密，你一定用错语言了</title>
      <link>//blog.shell909090.org/blog/archives/1871/</link>
      <pubDate>Wed, 03 Aug 2011 14:13:37 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1871/</guid>
      <description>python的特征在于快速编写代码，快速运行得到结果。通常而言，就是高开发速度。
如果你的项目需要源码保密，那通常不会是高速开发的项目。因为能够高速开发的，就能够高速复制。别人在看到你的概念和基本逻辑后，可以非常快的抄一份出来。代码什么的根本是浮云。</description>
    </item>
    
    <item>
      <title>除虫故事（二）</title>
      <link>//blog.shell909090.org/blog/archives/1869/</link>
      <pubDate>Tue, 02 Aug 2011 15:16:56 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1869/</guid>
      <description>第二个故事，是一次oracle数据库的紧急损坏抢修问题。
当时客户紧急保修，系统无法继续工作，重启后无效。我们就找了DBA赶快飞去客户那里。客户有两台应用服务器和两台数据库，应用服务器组成热备的态势，数据库组成RAC。数据保存在一个SAN盘阵上，LogFile放本地，ArchivedLog使用备份脚本复制到备份服务器后删除。听起来是挺靠谱的方案，没想到就坏了。
去了后，客户说暂时恢复了运作。然而我们还是要出具详细的报告，因此赶快去了机房。贝壳第一眼看的东西，就是/var/log。里面的报告是err9，也就是文件读写错误。oracle一切正常，应用发布服务器一切正常。
这下有点抓瞎了，难不成要出具一份报告说SAN盘阵损坏？可是损坏也得有厂商来维修，说坏得有真凭实据阿。现在SAN一切正常，这个报告怎么写呢？
说来算巧合，贝壳检查磁盘的时候，顺手打了一句df -h进去，看到磁盘空间已经用掉了80%以上，顺口问了句DBA，如果空间耗尽会如何。DBA说会挂起，和目前状况一致。贝壳顿觉狐疑，是不是空间耗尽呢？是的话，为什么会神秘的恢复呢？
Oralce的运作非常精巧，也非常复杂。当一条SQL语句执行的时候，先写LOG，然后操作数据，最后再将结果写入LOG。当出现问题需要复原的时候，根据某个时间点的数据备份，和整个运作过程中的所有Log，就可以复原。但是LOG写出的时候量非常大，没有无限的空间给他写阿。所以LogFile的设计是文件循环，当写满一个文件，切换下一个文件。一个文件写满后，就会有一个服务，趁着磁盘空闲，将Log压缩备份为ArchivedLog，然后再将这个文件的状态变为Empty。
我们的设计，是通过脚本备份ArchivedLog，除去最后一个文件外，复制到备份服务器上，然后删除。但是我们对ArchivedLog的量估计不足，一天清理一次，分配空间只有20G出头。系统开始的时候压力不高，因此绰绰有余。后来压力逐渐升高，这天的操作比较多，ArchivedLog量大了点，导致空间写满。当ArchivedLog空间满之后，备份进程就会报告错误，这就是/var/log下面err9的来历，因此LogFile无法备份出来。当所有的LogFile被循环写满后，SQL执行前试图写入LogFile失败，执行就会失败，然后挂起在那里。这导致了所有应用发布服务器的失效。
备份脚本的设计是定时和开机结合的，在客户第一次重启设备的时候，已经执行了备份脚本。然而备份动作需要执行相当久，中间客户又重启了几次，导致备份工作进展缓慢。直到半个小时后，第一份ArchivedLog才备份出去。然后清理文件，开始LogFile的备份，大约执行了一个小时多。此时服务就突然恢复了，因为空间问题已经暂时解决。而后是不断的ArchivedLog备份和LogFile的备份的平衡，直到我们到的时候，LogFile已经全部空了，ArchivedLog还没有完成备份。因此我们才能抓到最后的尾巴。
反过去检查备份脚本的执行记录，基本验证了这个想法，客户也接受了我们的报告，不过还是要责令修改系统——这是后话不提了。
这个故事里面，至少有几个教训。
 对于所有编程时无关紧要的假定值，在开发时可以胡给一个差不多就行，但是上线的时候必须重新分配合理的值。因此必须将这些假定值记录出来，否则从程序中找出假定值来本身就是一个非常困难的事情。
 确实运作一下，搞清楚运作方方面面的问题，不要想当然，觉得没问题。就算运作了没问题，在时间的考验前都没人敢保证没事。
 一套系统，尤其是大型复杂系统，必须有懂得运维的人员接手管理。检查磁盘IO，CPU压力，内存和磁盘用量，数据量，网络响应速度等等问题。
 废物Log不要乱出，太多的Log和没有无异。如果早关注备份脚本的执行记录，就能早找到问题。可是由于量太大，我都是过滤掉了看的。
  </description>
    </item>
    
    <item>
      <title>除虫故事（一）</title>
      <link>//blog.shell909090.org/blog/archives/1867/</link>
      <pubDate>Mon, 01 Aug 2011 14:46:25 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1867/</guid>
      <description>汽车对冰淇淋过敏的传说都听说过吧，贝壳也说几件故事。寓意什么的就别提了，当个故事听吧。
第一个故事，是一个传奇的问题。贝壳早在02年的时候，就在家里弄了两台电脑。互相用网线一连，组成局域网打游戏。当时流行的游戏还是Diablo II，当然，这东西的III已经叫了10年，还没出来，接近永远的毁灭公爵。两台机器之间的游戏打的很流畅，一点异常都没有。
当年文件共享还是有很多问题的，尤其是连续的几个蠕虫，有志一同的使用了windows的samba系统。所以安全上说，贝壳舍弃了windows文件共享，使用ftp方案。当年还流行用ftp开自己的文件资料共享站，贝壳就用雷电自己开了一个。现在基本看不到了，基本都是用网盘或者p2p。问题就出现在这个文件传输上。
文件传输的速度常常限制在1-3K之间，速度死活上不去。结合Diablo II可以正常工作的事实，贝壳的初步结论是ftp系统问题。然而从外网测试的结果，ftp站点一切正常。那么ftp客户端呢？经过测试，这个客户端软件和配置在外网上访问贝壳自己的站点是正常的。
那么从表象上看，问题就在客户端所在的机器上了。贝壳检查了机器的网卡和系统驱动，又重装了系统，问题仍旧没有消除——似乎有点奇怪吧。而且推理上说，如果机器有问题，Diablo II也不会运行的如此流畅的。
好吧，我们揭晓谜底。问题出在两台机器相连的一根网线上。这根网线质量不好，有一根线时通时断。结果导致ip数据包概率性不一致。ip是不管peyload一致性的，但是tcp管阿，结果导致大量的tcp重传。tcp是一种慢启动协议，因此速度死活上不去。
至于Diablo II可用的问题，则是因为游戏的数据量少，包也小。因此即使慢启动，数据也可以很快重传，导致虽然有问题，却不能很直观的被发现。
这个问题，直到贝壳无意中更换网线才被发现。但是细究推理，却是合情合理。算是一场灯下黑吧。</description>
    </item>
    
    <item>
      <title>纯C和纯C&#43;&#43;都不是好选择</title>
      <link>//blog.shell909090.org/blog/archives/1824/</link>
      <pubDate>Wed, 08 Jun 2011 17:30:54 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1824/</guid>
      <description>其实严格说来，纯C是门好语言，我很欣赏纯C。但是作为程序设计，C用起来让人觉得很不方便。
 在标准C规范中，变量必须在块的头部声明。当然，在近代C编译器中已经取消了这个限制。
 我提到过的，C中缺乏高级数据结构支持，导致一些简单问题的实现变得异常复杂。例如我需要解析表达式，生成lisp样子的前缀表达式。这在很多高级语言中是个很简答的事情，但是C中，你不得不自行管理内存和结构，虽然这并不算复杂。
  还有一些缺点不能尽述，但是经过时间的考验，C无疑是强大而具有生命力的一种语言。
C++就比较搞笑了，纯C++是一个非常糟糕的东西。我们列举其缺点：
 函数指针是C中常用的概念，在C++中应当使用抽象接口-实现的方式，或者使用仿函。从技术上说，在C++中使用函数指针是一个落后而没有C++特色的行为。然而无论使用哪种，生成一个新的函数就必须生成一个新的类。你当自己是java么？
 太多internal操作，导致代码隐性错误和思考心智负荷大幅上升。例如某个类可以定义一个单参的构造函数，constructor(int c);这等于定义了一个隐性转换函数，允许将int转换为类。或者使用T operator T();算符函数，将类转换到T。如果此时错误的将类实例当作int来操作，就会产生编译通过但是运行时出错的问题。更严重的是，转换函数严重的消耗性能。在这种情况下，编译和运行都不会出错，只是莫名其妙的性能很差。要避免这个问题，可以用explicit关键字。具体可以看这里（http://www.cnblogs.com/cutepig/archive/2009/01/14/1375917.html）。但是这就需要额外的知识，和随时关心自己是否会犯下这个错误的小心。
 强大到啰嗦的模板系统。那位有信心看懂所有stl编译时报错的？反正effactive C++的作者举过一个缺陷，打印了1500个左右的字符。大部分都是符号，望之犹如天书。
 为了支持多重继承，导致指针类型转换可能导致指针地址变换。这是一个很扯淡的缺陷，转换指针类型不会引发指针的地址转换是一个C中的基础常识。然而C++为了支持多重继承，导致这个常识被破坏。
 thiscall和non-thiscall指针无法转换。类成员函数和普通函数指针是无法转换的。这个破坏了所有代码都可获得地址的常识。
  其实C++的致命缺陷，就是过度设计。每一步都是很必要很有道理的改进，在最后就组合成了让人望之生畏的复杂系统。
要使用C++，关键就是克制自己的过度设计欲望。C++可以很容易的使用类，模板，友元系统写的很强大，而且看起来很自然。例如你可以定义自己的BioTree，使用+做合并，可以使用|运算符做输出等。然而到最后，就会变成另一种语法。并且，如果合并上大数运算库之类的库，做一个BioTree，其中元素是大数的结构。当这个结构内发生错误的时候，你觉得你能够在里面找到正确的调试方向么？
要克制自己觉得很自然的想法，使用传统C中的一些做法，哪怕他们看起来很古怪，但是这是有道理的。</description>
    </item>
    
    <item>
      <title>使用uwsgi搭建python应用</title>
      <link>//blog.shell909090.org/blog/archives/1811/</link>
      <pubDate>Wed, 25 May 2011 11:08:38 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1811/</guid>
      <description>wsgi是python的一个标准web服务接口，具体去google pep文档，不解释。在李木头的忽悠下，贝壳试用了一下uwsgi搭建python服务器，感觉还不错。 首先，贝壳将uwsgi打包成deb包，因为这东西和python基本没什么关系，就是一个标准的系统守护服务程序。其中贝壳测试了一下，uwsgi编译的时候是依赖版本的。所以请教了一下thomas，打了uwsgi2.6和uwsgi2.7两个包。没办法，mercurial对python2.7的支持不是很好，每次都出问题。具体的可以加贝壳的repos: https://home.shell909090.org/debian/ testing，然后通过一下贝壳的key，就可以直接安装uwsgi2.6了。当然，不通过key也可以，只是每次安装升级都有警告。 贝壳写了一个很简单的init.d，使用&amp;ndash;vhost来启动uwsgi为服务模式。这种模式的好处是，uwsgi的具体执行的应用都是由nginx来确定的，因此所有的映射只需要修改nginx配置就好。uwsgi参数很多，包括可以指定内存限制，工作进程/线程，定时重启工作进程，多解释器等等。是一个高效的，功能强大的服务器。具体可以自己参考调整。最好的的地方是，uwsgi还支持virtualenv，你可以给不同的应用建立不同的工作环境，从而在环境中使用指定的包，而不是系统包。 下面是一个nginx配置的例子。 location /ticket { include uwsgi_params; uwsgi_param UWSGI_PYHOME /usr; uwsgi_param UWSGI_CHDIR /home/shell/workspace/hg/thost; uwsgi_param UWSGI_SCRIPT main; uwsgi_pass unix:/var/run/uwsgi.socket; } location /mlocate { include uwsgi_params; uwsgi_param UWSGI_PYHOME /usr; uwsgi_param UWSGI_CHDIR /home/shell/workspace/hg/thost; uwsgi_param UWSGI_SCRIPT main; uwsgi_pass unix:/var/run/uwsgi.socket; } location /hg { include uwsgi_params; uwsgi_param UWSGI_PYHOME /usr; uwsgi_param UWSGI_CHDIR /home/shell/workspace/hg; uwsgi_param UWSGI_SCRIPT hgweb; uwsgi_param SCRIPT_NAME /; uwsgi_param SERVER_NAME hgweb; uwsgi_pass unix:/var/run/uwsgi.socket; } 这里面设定了三个应用。由于贝壳不需要virtualenv，所以PYHOME设定了/usr。第一二个应用的基础路径在/home/shell/workspace/hg/thost，脚本叫做main.py。第三个应用的基础路径在/home/shell/workspace/hg，脚本叫做hgweb.py。需要注意的是，uwsgi会以模块方式导入这些脚本，然后使用其中的application对象作为wsgi处理函数。所以不要把application对象赋值放在if __name__ == &amp;lsquo;__main__&amp;lsquo;里面，那没用的。第三个应用指定了SCRIPT_NAME和SERVER_NAME，是因为hg的wsgi模块没有SCRIPT_NAME不工作，而这个应用和前两个不在一起，所以如果不指定SERVER_NAME会导致覆盖冲突。 这种部署模式的好处是，我可以使用一个宿主来管理所有的应用，而不必每个应用启动一个宿主，省去了多个宿主管理的麻烦。而多进程，压力分布等等问题都被uwsgi的配置系统搞定了。于是应用程序宿主做到了彻底的免管理，即装即用，只用调节性能匹配即可。具体程序配置下放到nginx中，要修改映射关系只用管理一个位置。</description>
    </item>
    
    <item>
      <title>组合翻墙方法——细节</title>
      <link>//blog.shell909090.org/blog/archives/1804/</link>
      <pubDate>Wed, 18 May 2011 09:53:48 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1804/</guid>
      <description>中国这网络，越来越没法上了。现在你访问国外禁网，就会中断连接10分钟。问题是我也不知道哪个网是禁止的&amp;hellip;
现在教大家一招，基本能够永久套上翻墙。理论上你就没有中招的可能，尤其适用于公司使用。
首先是squid，这个是流量分离和缓存的关键部件。你可以用pac替代，但是这只局限于某台具体的机器，并且代理用户支持pac。squid的好处是，任何http访问都可以分流，而且无须客户端支持。甚至如果你精通squid配置，你可以配置成透明代理（cache拦截），从而避免在每台机器上修改代理配置。当然，cache拦截是有技术问题的，具体请参考这篇（http://home.arcor.de/pangj/squid/chap09.html#a6）。
squid的配置如下：
include /etc/squid3/gfw.conf acl localnet src [192.168.0.0/16](http://192.168.0.0/16) http\_access allow localnet http\_access allow localhost cache\_peer 127.0.0.1 parent 8123 0 no-delay no-query cache\_peer\_access 127.0.0.1 allow gfw always\_direct deny gfw never\_direct allow gfw  以上配置是允许192.168.0.0的C类内部子网访问本机，所有gfw规则的域名必须通过8123端口的上层代理，而其他的直接访问。注意以上不是完整配置，不保证可以独立运行，只保证在debian的标准配置文件的基础上，修改以上内容就可以工作。独立配置你可能还需要加入以下两句。
http\_access deny all http\_port 3128  配置中的gfw.conf是gfw这个规则的定义文件，这个文件是由程序生成的，程序如下。注意，你系统上的python版本应当在2.5以上。
#!/usr/bin/python from \_\_future\_\_ import with\_statement with open(&#39;gfw&#39;, &#39;r&#39;) as fi: for line in fi: print &#39;acl gfw dstdomain .%s&#39; % line.strip()  以上内容，保存为平文本，赋予执行权限后，直接执行即可。同目录下必须有一个gfw文件，平文本，里面一行保存一个域名。域名不以.开头，可以使用泛域名（例如google.com匹配www.google.com）。执行后打印出内容，所以你还需要重定向。./gfw2squid &amp;gt; /etc/squid3/gfw.conf。当每次gfw文件升级时，你都需要重新生成，并且迫使squid加载。方法是squid -k reconfigure。
OK，现在你有一台配置了分流的squid，然后你需要一个可以翻墙的代理。由于我的目标是看youtube，所以我采取了一个非常复杂而高性能高可靠的方案。</description>
    </item>
    
    <item>
      <title>说说x509证书链</title>
      <link>//blog.shell909090.org/blog/archives/1772/</link>
      <pubDate>Mon, 11 Apr 2011 11:03:47 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1772/</guid>
      <description>x509证书一般会用到三类文件，key，csr，crt。key是私用密钥，openssl格式，通常是rsa算法，爱咋用咋用的。csr是证书请求文件，用于申请证书。在申请的时候，必须使用自己的私钥来签署申请，还可以设定一个密钥。crt是证书文件（windows下面的csr，其实是crt），是签署人用自己的key给你签署的凭证。通常签名证书的时候都需要一个序列号，避免两个证书重复，当指明序列文件后，被签名证书会使用这个文件，并且文件会发生变化。另外一个额外说明的东西是dh参数，做openvpn的时候需要这个东西，大致是什么算法的初始参数，在下面有生成方法。
key的生成方法：
openssl genrsa -des3 -out in.key 2048  这样是生成rsa私钥，des3算法，openssl格式，2048位强度。ca.key是文件名。为了生成这样的密钥，需要一个至少四位的密码。可以通过以下方法去除。
openssl rsa -in in.key -out out.key  输入密钥后，out.key就是没有密码的版本了。
csr的生成方法：
openssl req -new -key server.key -out server.csr  需要依次输入国家，地区，组织，email。最重要的是，有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。
crt生成方法：
openssl x509 -md5 -days 3560 -req -CA ca.crt -CAkey ca.key -CAcreateserial -CAserial ca.srl -in server.csr -out server.crt  输入key的密钥后，完成证书生成。-CA选项指明用于签名的ca证书，-CAkey选项指明用于签名的密钥。-CAserial指明序列号文件，而-CAcreateserial指明文件不存在时自动生成。
openssl req -new -x509 -days 3650 -key ca.key -out ca.crt  这个是用于生成自签名证书的。
dh参数生成方法：
openssl dhparam -out dh1024.pem  1024是位数，一般1024已经够了。
x509的证书链是这样的。crt上有证书持有人的信息，持有人的公钥，签署者的签名。当你安装了一个证书后，就信任了这份证书。证书上会说明用途，例如服务器认证，客户端认证，或者签署其他证书。当系统收到一份新的证书的时候，证书会说明，是由谁签署的。如果这个签署者确实可以签署其他证书，并且收到证书上的签名和签署者的公钥可以对上的时候，系统就自动信任新的证书。
在系统开始的时候，会自动安装信任一些证书机构，这些被称为根证书机构（CA）。根证书机构会为其他公司颁发证书，用于各种用途。当然，被签署的证书也可能是一份“可签署证书”，这样就要检查对方的资质。这样逐层签署，就会形成一个叫做“证书链”的东西。从拓扑结构上来说，其实应该是森林结构。</description>
    </item>
    
    <item>
      <title>python源码解析读书笔记（四）——杂项</title>
      <link>//blog.shell909090.org/blog/archives/1760/</link>
      <pubDate>Thu, 31 Mar 2011 11:04:43 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1760/</guid>
      <description>1.GIL的影响
很多人讨论python性能的时候都提到一个概念，GIL。我在python源码中搜了一下，这个函数调用并不多，但是位置很要命。每个线程，生成的时候请求一下，退出的时候释放一下。在每次运行字节码前也会短暂的释放一下，让其他线程有获得运行的机会。说白了，除非程序显式的调用release_lock去释放资源，否则python是没有任何多线程能力的。这种机会并不很多，通常只发生在阻塞的时候。
而python原子化的粒度也比较清晰，就是每个字节码内部一定是原子的，字节码和字节码之间是非原子的。当我们操作l.append的时候，不用担心线程竞争导致数据结构损坏。但是如果我们操作del l[len(l)]的时候，存在发生异常的概率。
2.对象缓存池
python对小内存对象（碎片对象）提供了小内存对象缓存池。默认情况下，256字节以下的内存由小内存缓存池管理，以上的直接向系统申请，申请大小每8字节对齐。
对象缓存池的分配和收集技术采用了自由资源链表，在2.5之后，当某个尺度的资源不再需要时，会整体释放。
3.python的GC机制
python的GC机制是基于引用计数的，因此当引用计数归零，对象一定会被释放（如果是碎片对象，内存不一定直接释放，可能归对象缓存池）。
python的辅助垃圾收集算法是三色标记法和分代垃圾收集模型（generation），由于要跟踪所有的容器对象，因此容器对象上有跟踪链表。
4.字符编码处理方案
无论从何种来源，只要是字符串，并可能交给一个和当前代码并不紧密耦合的代码处理，就应当被转换为unicode。或者换一个更简洁的说法，应当使用unicode作为接口数据类型。
str对象是很难猜测编码的，当离开了数据源代码后，再分析编码是个不靠谱的方案。</description>
    </item>
    
    <item>
      <title>python源码解析读书笔记（三）——对象和函数</title>
      <link>//blog.shell909090.org/blog/archives/1759/</link>
      <pubDate>Wed, 30 Mar 2011 10:19:16 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1759/</guid>
      <description>1.mro
算法，自身先入栈，而后按声明顺序继承每个父类的mro，内部对象在最后。简单来说，深度优先，从左向右。
当类对象创建时，会将父类所有函数全部复制过来（很明显，应当是符号复制）。
2.super规则
&amp;gt;&amp;gt;&amp;gt; class A(object):
&amp;hellip; def f(self): print &amp;lsquo;A&amp;rsquo;
&amp;hellip;
&amp;gt;&amp;gt;&amp;gt; class B(object):
&amp;hellip; def f(self): print &amp;lsquo;B&amp;rsquo;
&amp;hellip;
&amp;gt;&amp;gt;&amp;gt; class C(A):
&amp;hellip; def f(self): print &amp;lsquo;C&amp;rsquo;
&amp;hellip;
&amp;gt;&amp;gt;&amp;gt; class D(C, B):
&amp;hellip; def f(self): super(D, self).f()
&amp;hellip;
&amp;gt;&amp;gt;&amp;gt; d = D()
&amp;gt;&amp;gt;&amp;gt; d.f()
C
&amp;gt;&amp;gt;&amp;gt; D.__base__
&amp;lt;class &amp;lsquo;__main__.C&amp;rsquo;&amp;gt;
&amp;gt;&amp;gt;&amp;gt; D.__bases__
(&amp;lt;class &amp;lsquo;__main__.C&amp;rsquo;&amp;gt;, &amp;lt;class &amp;lsquo;__main__.B&amp;rsquo;&amp;gt;)
&amp;gt;&amp;gt;&amp;gt; class A(object):
&amp;hellip; def f(self): print &amp;lsquo;A&amp;rsquo;
&amp;hellip;
&amp;gt;&amp;gt;&amp;gt; class B(object):</description>
    </item>
    
    <item>
      <title>python源码解析读书笔记（二）——函数特性</title>
      <link>//blog.shell909090.org/blog/archives/1757/</link>
      <pubDate>Tue, 29 Mar 2011 10:55:21 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1757/</guid>
      <description>1.函数的性质    &amp;gt;&amp;gt;&amp;gt; def outer(o1, o2):   ... def inner(i1 = 10, i2 = \[\]):   ... return i1+o1+o2   ... return inner   ...   &amp;gt;&amp;gt;&amp;gt; a1 = outer(50, 30)   &amp;gt;&amp;gt;&amp;gt; a2 = outer(50, 30)   &amp;gt;&amp;gt;&amp;gt; a1.func\_closure   (&amp;lt;cell at 0xb75454f4: int object at 0x8455ddc&amp;gt;, &amp;lt;cell at 0xb7545524: int object at 0x8455cec&amp;gt;)   &amp;gt;&amp;gt;&amp;gt; a2.func\_closure   (&amp;lt;cell at 0xb754541c: int object at 0x8455ddc&amp;gt;, &amp;lt;cell at 0xb75453a4: int object at 0x8455cec&amp;gt;)   两次生成的函数对象拥有不同的闭包空间。    &amp;gt;&amp;gt;&amp;gt; a1.</description>
    </item>
    
    <item>
      <title>python源码解析读书笔记（一）——内置对象</title>
      <link>//blog.shell909090.org/blog/archives/1756/</link>
      <pubDate>Sun, 27 Mar 2011 22:48:11 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1756/</guid>
      <description>1.类型的类型  
 obj int(10).ob_type -&amp;gt; PyInt_Type

 PyInt\_Type.ob\_type -&amp;gt; PyType\_Type   PyInt\_Type.tp\_base -&amp;gt; PyBaseObject\_Type   PyBaseObject\_Type.ob\_type -&amp;gt; PyType\_Type   PyType\_Type.ob\_type -&amp;gt; PyType\_Type   更精确的参考源码解析262页图。   \   2.小整数对象   if (-NSMALLNEGINTS &amp;lt;= ival &amp;&amp; ival &amp;lt; NSMALLPOSINTS) {   v = small\_ints\[ival + NSMALLNEGINTS\];   Py\_INCREF(v);   }   \   3.大整数对象，空对象池，对象缓存    &amp;gt;&amp;gt;&amp;gt; a = 1000000   &amp;gt;&amp;gt;&amp;gt; b = 2000000   &amp;gt;&amp;gt;&amp;gt; id(a) == id(1000000)   False    &amp;gt;&amp;gt;&amp;gt; id(100000) == id(100000)   True   最后一个是因为python解析器在解析对象的时候，对前后生成的对象进行了缓存。经过测试，对文件也有效。   \   4.</description>
    </item>
    
    <item>
      <title>nginx使用fastcgi连接django时的细节</title>
      <link>//blog.shell909090.org/blog/archives/1694/</link>
      <pubDate>Tue, 15 Feb 2011 11:10:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1694/</guid>
      <description>django使用PATH_INFO和SCRIPT_NAME来计算urls.py中的匹配路径，当两者都设定时，会出现URL计算结果为空，导致无法访问的问题。具体看这里。
http://aftnn.org/2009/jan/23/nginx-django-fastcgi/</description>
    </item>
    
    <item>
      <title>从快递说非对称密码学</title>
      <link>//blog.shell909090.org/blog/archives/1686/</link>
      <pubDate>Tue, 25 Jan 2011 11:07:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1686/</guid>
      <description>这两年快递评价很差，听说有基层员工冒充客户签名偷货物的。今天我们不说快递的问题，只是简单的讨论一下，如果快递公司管理层有心改变这种局面，他们有什么办法。
首先采用的方案是要求基层员工送货到门，必须本人签名，核对签名等。不过这对冒充客户签名没有任何帮助。因为基层员工一旦参与此事，什么送货到门的规矩，本人签名的规定，都是一句废话。核对签名是个废话中的废话，因为在仲裁的时候，基层员工得到的签名不对，并不能作为他故意将货物交给别人的证据。还不明白？如果客户不提前留下签名，最后的送货员可以辩解说，我又不知道收货人签名张啥样，给签就给收呗。如果客户提前留下签名，那么送货员可以仿冒一个。
同样，密码也有一样的困境。如果给送货员密码，等于没有防护。如果不给，等于没设定。
对于这种现象，可行的解决方案有二。
一种是让每个送货人携带一个终端，当客户取货的时候，必须输入预先设定的密码。如果密码持续试错，则该件锁定，交由收货人重新设定密码。这种做法的好处是原理简单明了，又能达成目标。送货人如果想要冒充收获，就必须反复尝试密码。多数情况下都是无法试出的，于是收件人收到一个警告，要求重设。这样的密码试出机率几乎是0。而收件人自己设定一个密码就可以收件，如果忘记可以重设。
但这种方法弊端也很明显，送货人要多携带一个终端，并且收件时必须保证终端通畅。不说终端部署的费用，在很多地方，指望通讯通畅是一件非常奢侈的事情。
第二种方法，就是让收货人提供一个问题，自行保留一个答案。这个问题和答案必须有几个特征。1.知道问题，是无法推出答案的。2.可以很简单的验证答案是否解答了问题。3.评判标准简单，不存在模棱两可的答案。4.问题和答案都便于生成和操作。
我们来看一下，为什么这样可以阻止送货人冒充客户收货。如果送货人要冒充收件人收货，就必须知道问题的答案。但是根据1，他是推不出答案的。而当收件人收货的时候，他给出的答案是很容易验证的。当然，其实这样就满足了要求。但是如果没有4条件，这个过程只能做一次，对于大量重复的快递工作是没有任何帮助的。
如果忽略去第四点，我们可以提供这么个问题和答案。一个1000位的质数和1000位的质数相乘，大概能得到一个1999-2001位的合数。这个合数能唯一的分解因数，求两个因数。问题很简单，但是根据目前的水平，要解出这个问题需要大量的计算资源。至少一个计算中心跑个几年是跑不出结果的。很明显一个送货的不可能随随便便解出这个问题的答案。但是如果收件人提供了两个质数，我们不说输入难度，要验证两个数相乘是否得到合数只需要一台手机一两秒的时间。至于一个数是不是质数，有一个概率算法叫做Robin-Miller算法能够解决（当然，实际用的都是略有变形的），验证起来也不过是几秒的时间。
这个方案无疑是很不错的，但是有一个致命的问题。要进行答案验证，就必须输入两个质数和合数。加起来大概有4000位的数据，输入起来会让人绝望的。在实际的快递中，这种方法没有任何应用价值。
但是对于类似快递的电子邮件系统，电子商务交易，在实际操作的时候数据交换和计算设备都绝对不是问题。因此，这类方法在电子商务上有非常重大的用途，说是电子商务的基石也毫不为过。
这类算法就叫做非对称密码算法，所谓非对称，指的是加密和解密过程使用的两个密钥不相等，又互相关联。其原理是当今世界最顶尖数学问题之一的“P和NP问题”，位列希尔伯特23问题和千禧年八大数学问题之中。能同时列入的都是对世界产生深远影响的重要数学问题，例如黎曼猜想。其实从理论物理角度，有一样东西更容易满足非对称验证的特性，就是两个处于纠缠态的基础粒子。如果我们忽略两个纠缠态量子怎么传递的问题，理论的想象，其中一个基础粒子跟随箱子，而另一个基础粒子在收件人手里。验证就是非常简单的问题了。干涉一个基础粒子到某个特定偏振态，使用一束光同时通过两个粒子。如果两个粒子处于纠缠态，那么光子在通过两个粒子的时候，粒子一定处于同一偏振状态。如果是非纠缠态的两个粒子，则光子输出的时候会比纠缠态量子有更大的吸收幅度。这个系统最完美的一点是，纠缠态的量子是绝对无法复制的东西，除非违背量子力学。不过从实际角度考虑，不说我们尚未成功在实验室里做到这一系列事情。单是让箱子携带一个基础粒子就是一个扯淡到不能再扯淡的事情。
当然，在快递中没有采用非对称算法的主要原因并不是因为实现困难，而是管理层根本无心改变这种局面。关于这个问题，我们在另一篇“快递战争”中讨论。</description>
    </item>
    
    <item>
      <title>python试题</title>
      <link>//blog.shell909090.org/blog/archives/1668/</link>
      <pubDate>Tue, 04 Jan 2011 14:27:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1668/</guid>
      <description>前两年在公司用过的试题，不知道发过没有。在我的blog上搜了搜，没找着。大家可以看看玩。
1.py文件在运行时会产生pyc文件，用于缓存编译后代码(3分)：
a.正确
b.错误
c.不完全正确
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-
c
2.python支持多线程，能够单进程无缝发挥多路CPU的优势(4分)：
a.支持，能够
b.支持，不能够
c.不支持，能够
d.不支持，不能够
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-
b
3.在python中，使用for从列表中删除元素是错误的做法，会导致___________。
正确的做法是使用python内置的____________函数(4分)。
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-
漏删元素，filter。(一空2分)
4.请改正以下程序中的错误，并写出结果(12分，本题禁止使用python运行):
a=10
def test (*b):
print (a,type(b));
a = 20;
print a;
print b[0](b[0])
if __name__ == &amp;ldquo;__main__&amp;ldquo;:
print test (*[test]);
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-
答对一处错误给3分，答对结果给6分，结果其他部分对但type(b)错误给4分。
答其他错误倒扣2分，扣完为止。
a = 10;
def test (*b):
global a;
print (a, type(b));
a = 20;
print a;
if __name__ == &amp;ldquo;__main__&amp;ldquo;:
print test (*[test]);
以下是结果。
(10, &amp;lt;type &amp;lsquo;tuple&amp;rsquo;&amp;gt;)
20</description>
    </item>
    
    <item>
      <title>为什么C语言并不适合语言入门教学</title>
      <link>//blog.shell909090.org/blog/archives/1666/</link>
      <pubDate>Sun, 02 Jan 2011 20:21:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1666/</guid>
      <description>国内学校基本都用C语言作为入门语言教学，某本C语言教材大卖，这TMD是我看到的最蛋疼外加胡扯的事情了。你们打算把全校学生包括传媒系都培养成职业程序员么？感谢上帝，中国已经有部分学校用了java乃至python，让我不至于太绝望。
C语言作为语言之王，有着与生俱来的优势和原罪。你可以不用，但你不能无视。python的os模块基本都是底层封装，封装的是什么呢？linux下是libstdc或者是linux c api，windows下是SDK API，都是C接口而不是C++接口。因为C是一层对底层数据结构的高层抽象，主要解决兼容性问题。例如ARM/x86平台不兼容之类的问题。用C写代码的时候，就是在直观的操作底层的数据，包括内存结构，指针。正是因为这个特点，因此几乎所有平台都用C作为底层语言，并且提供C的API接口。然而也是因为同一个理由，C中缺乏高级对象支持，写一个稍稍复杂点的结构就必须动用数据结构的知识。例如你需要模拟一个园区的物流运作，因此需要写个程序。很明显，运作是以时间为顺序触发的，因此需要一个时间队列。熟悉数据结构的同学应该想到，最适合的结构应当是堆排序中的堆结构。如果没有，那么链表结构也能凑合。但是在C语言里面呢？抱歉，你需要自己实现一个链表。
纳尼？我它喵的为了做一个园区运作的模拟，它喵的先要啃数据结构书，然后写链表代码。你当我是计算机系的学生阿，老子是管院的。
C++比C更适合这个问题，C++中可以使用STL，而STL中的list算是凑合的解决了这个问题。哪怕用vector，也算一种可以接受的方案了。C下面为了绕过这个问题，我用了65536长度的数组，于是程序一开就是10+M的内存。这还是我能找到的最优雅的解决方案——总比自己去写一个或者用第三方链表好。java就很明显更加适合解决这个问题，它内置了list数据结构。python虽然没有list结构，但是可以用array模拟，也可以用堆结构。
无论如何，总好过去找第三方库吧，真当老子是IT民工啦。
C++比C好点，但是使用C++的原罪是C++复杂的语法结构。光是类的问题上，就有静态，成员，虚三种。每种配合上public protected private，再继承一下public protected private。大约有27种情况需要记忆，它喵的这是写程序还是玩大家来找碴阿。而且还有重载，算符重载，隐性类别转换，强制类别识别这些绕死程序员的问题，我怎么看都不觉得适合给啥都不懂的非计算机系学生解决问题用。
非计算机系的学生，需要的是这样一门语言。好用，强大，建模和解决数学问题的能力要强，速度和安全性可以无视。很明显，C根本不合格，连边都够不上。因此在国内高校中，实际是matlab和java承担起了这个任务——然而这两门都是非必修选修课，或者压根没地方教。
有用的知识不算分，甚至没地方学，没用的垃圾要考试——这个，我真——无语了。。。</description>
    </item>
    
    <item>
      <title>为什么我说框架和工具不是解决安全性的良好方案</title>
      <link>//blog.shell909090.org/blog/archives/1663/</link>
      <pubDate>Thu, 30 Dec 2010 16:24:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1663/</guid>
      <description>在python-cn的maillist上，刚刚爆发了一场关于动态语言合并出错的争论。问题的起源，来自于这样一个问题。
一个程序员A，写了一个函数，function1。程序员B对函数进行了调用。现在两个人分别在svn上工作，A修改了function1，而b修改了其他内容。
由于python并不在编译时检查类别问题，因此当两人的svn merge后，运行并没有出错。现在，问题只有等上线后客户提出来了。
几乎所有的人都同意，这问题的根源不是一个语言的问题。本质上说，这是一个工作流程问题。即使是C，也只检查参数的个数和类别，对于行为的变化和参数意义的变化还是无能为力的。
1.当你公开了一个函数，并要修改这个函数的外观行为的时候，必须向其他人通告。 2.python代码要通过unittest和黑盒检查覆盖。 3.代码应当cross review。
争论的焦点主要是在python下如何避免这个问题。楼主Zhang Jiawei的观点是使用pydev，加上工具来检查。我，沈崴，ZQ的意见是通过行为来避免这个问题。所谓行为，主要包括以下几个。
1.互相review代码。 2.修改通告。 3.编写无检查和无处理的代码，并大量运行。如果代码中有错，程序会持续崩溃。因此当大量运行程序不崩溃时，代码就无错了。
为什么我们并不推荐使用自动化工具来检测错误呢？主要是因为自动化工具可以*找到*问题，但是却不能*保证*是找到问题最彻底的一种。我举个最简单的例子：
网络工程师A，用了pylint，找到了自己code中的15个低级bug。他很高兴，因为工具使用起来很方便。
A向领导汇报了自己的心得，建议全公司推行这个工具。假定他的领导是项目经理B。
A：这个工具太好了，一下就找出了我15个bug，我发现用这个工具很方便，blahblahblah。
B：恩，很好，过两天你在公司里面讲讲这个工具。对了，你的code review做了么？
A：我用工具查过拉。
B：你确定他找出了你的*所有*bug么？
问题的关键，就是*所有*。我们当然不可能找出程序中的所有bug。我所知的bug最少的程序是TeX，据说在数年的时间内只有数个bug。但是其版本号仍旧是3.1415926——正好是祖率的密率——而不是pi。我们毕竟不敢——高伯伯也不敢——保证没有bug。但是通过cross review，不处理加覆盖性检测，我们可以保证bug出现的概率在某个水平以下。
自动化工具寻找出的bug，是在这个水准以上的。就是说，自动化工具看的出的，人应该看的出。人看的出的，自动化工具不一定看的出。如果做不到这点，说明你的水准还不足。
所以，当我们需要一个尽量无错的code时，当你pydev/pylint，或者其他工具做了检测，问题是否解决了呢？没有，你仍旧需要review来保证没有bug。这样一来，工具的意义在哪里呢？
当然，这并非说在做code review之前，你*不能*去做一遍代码扫描。只是说这样做并*不能替代*对错误的人工控制行为。
除非你的目标是使用最低的成本，将错误减少到一个可接受的规模——而不是最低。就像我们在外包中常做的那样。这种情况下使用工具是比较合适的。
而且一旦使用工具，很多程序员会产生依赖。所谓依赖，并不是讲从逻辑上他们不清楚在代码扫描外还需要独立的人工检测。但是在检测时，心里就会抱有一种放松的心态。尤其是其中某些虫族程序员让人无语叹息的行为。在中国的程序员界，有着诸多非常有创造力的bug提供者。例如擅长用str+=的java网页程序员很常见，这属于常见问题。但是自己写一套字典映射规则以完成数字到字符转换的（就是c下面的itoa）.net程序员真的让我大开眼界——而且他同时犯下了str+=错误。要指望工具修正+=是可以的，要指望工具找出这类极品代码，估计下面会有更极品的人犯下更极品的错误。。。</description>
    </item>
    
    <item>
      <title>elisp的简单介绍</title>
      <link>//blog.shell909090.org/blog/archives/1661/</link>
      <pubDate>Sat, 25 Dec 2010 20:16:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1661/</guid>
      <description>emacs是利用elisp写成的，而elisp是lisp的一个方言。lisp语言是出名的优美和晦涩，当然，更出名的是括号。。。
emacs利用elisp作为上层抽象。首先，emacs提供了基本的编辑器框架，包括文件操作函数API，buffer，frame，windows的API。而后，emacs附带了很多函数实现，并且和按键一一绑定。例如Ctrl+N（简写为C-N）就被绑定到“换到下一行”这个API上。于是，我们按下Ctrl+N的时候，就会触发“换到下一行”这个函数的执行。dired等插件也是基于类似的原理写成。
我们可以用类似的方法，来编写自己的函数，扩充emacs的功能。下面我们看一个例子：
(defun popup-term () (interactive) (apply &#39;start-process &amp;quot;terminal&amp;quot; nil popup-terminal-command))  首先先说明一下，elisp的基于规则是利用括号匹配的s表达式，通过特定规则计算表达式。每个表达式由多个原子构成，一个原子可以是符号，对象（数字或者字符串），序对，表（包括空表），树，以及他们的嵌套。求值的时候，第一个原子做动词，先求值第一个原子，直到得到一个对象，再根据第一个原子的特性决定正则序和应用序。应用序的先对每个后续原子求值，再调用第一个原子对应的对象。正则序直接交给第一个原子对应对象处理。上文那个表达式，最外层的是(defun)列表，defun是函数定义函数，popup-term是符号。这部分混合起来，就是定义(interactive) (apply &amp;lsquo;start-process &amp;ldquo;terminal&amp;rdquo; nil popup-terminal-command)为一个函数，并在上层框架空间内把内容赋值给popup-term这个符号。说的更直白一点，就是定义函数。
当我们执行popup-term这个函数的时候（M-x加上函数名就可以手工调用），首先执行interactive过程。这个函数可以在这里（http://www.gnu.org/software/emacs/manual/html_node/elisp/index.html）查到，基本上，可以认为执行了这个函数，才能够和前台交互。而后是apply函数，这个函数将后面的几个值作用于紧跟着的那个符号所对应的函数。用python语言来描述，大概是这个样子。
def apply(func, \*param): return globals()\[func\](\*param)  这个函数真正的部分，是从start-process到括号结束。其意义是启动一个子进程，名为terminal，没有对应的buffer（熟悉emacs的应该知道这是什么），命令为popup-terminal-command。这个命令在windows下和linux下有不同定义，所以我将这个定义放在了emacs-win.el和emacs-linux.el里面。在linux下，他是这么定义的。
(setq popup-terminal-command &#39;(&amp;quot;x-terminal-emulator&amp;quot;))  setq是设定一个全局变量。整句合起来的意思是，在执行popup-term的时候，启动一个子进程，执行x-terminal-emulator。最后，将popup-term绑定到keymap上。
(global-set-key \[(control c) (s)\] &#39;popup-term)  现在，在任何一个buffer中按下C-c s，就可以弹出当前目录对应的term了。
我们在emacs中所做的所有配置，插件安装，其实本质上是写代码控制其他代码的载入，变更环境变量。只要有合适的文档，或者有时间阅读源码，我们就可以对其他程序进行扩充。下面介绍一个对dired进行扩充的例子，我们向dired中加入copy-from和rename-from，还有dired-open功能。dired的copy和rename必须在源目录中，选择文件，按C，输入目标路径。有的时候我们在某个目录工作到一半，突然需要从另外一个目录复制一个文件过来。这时候打开对方目录进行复制动作太繁琐，因此我编写了两个函数，分别绑定到r和c上。dired-open则是另外一个文件，有时我们需要通过其他程序打开某个文件，例如播放电影。在dired中直接用&amp;amp;可以实现这个目标，但是需要自行输入播放命令，而且会新开一个buffer。以下是代码。
(defun dired-open-file (&amp;amp;optional arg) (interactive) (apply &#39;start-process &amp;quot;dired-open&amp;quot; nil (append (split-string (read-shell-command &amp;quot;command: &amp;quot; (dired-guess-cmd (dired-get-filename)))) (list (dired-get-filename))))) (defun dired-copy-from (&amp;amp;optional arg) (interactive) (let ((source-path (read-file-name &amp;quot;filepath: &amp;quot;))) (copy-file source-path (file-name-nondirectory source-path)))) (defun dired-rename-from (&amp;amp;optional arg) (interactive) (let ((source-path (read-file-name &amp;quot;filepath: &amp;quot;))) (rename-file source-path (file-name-nondirectory source-path)))) (add-hook &#39;dired-mode-hook (lambda () (define-key dired-mode-map &amp;quot;b&amp;quot; &#39;dired-open-file) (define-key dired-mode-map &amp;quot;c&amp;quot; &#39;dired-copy-from) (define-key dired-mode-map &amp;quot;r&amp;quot; &#39;dired-rename-from) (define-key dired-mode-map \[(control c) (g)\] &#39;dired-etags-tables)))  如上文一样，我们定义了dired-open-file函数，这个函数的核心部分是start-process，但是在命令上，我们的命令是这个。</description>
    </item>
    
    <item>
      <title>空间，VPS和独立主机的对比</title>
      <link>//blog.shell909090.org/blog/archives/1659/</link>
      <pubDate>Tue, 21 Dec 2010 09:52:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1659/</guid>
      <description>空间和VPS的差异最主要在支持的压力和配置的自由度上。通常而言，空间支持的压力比VPS要小，配置也更加不灵活，当然，也可以叫更加简单。两者都可以通过加钱来升级到更加性能优异的程度，因此很难说什么情况下该用什么。简单的做法是，如果空间能满足你的要求，就不要折腾VPS。通常折腾VPS的都起码是专业公司了，通常都有自己的网管。一般公司的误区是，希望自己拥有对机器的完整权限，因此更倾向于托管机器。然而托管机器的成本并不像你所想像的那样低廉。
首先，同样的硬件，在你手里的利用率一定比在VPS商手里的利用率低。这是理所当然的，VPS商就是通过组合不同的性能组合，精细调整压力，来赚钱的公司。在VPS商手里，基本每字节内存，每个CPU时间片都是充分利用的。而一旦你买进托管主机，用的掉不用掉这都是你的事情了。当然，与此对应的，当高压力到来的时候，VPS比自己托管机器的响应更快。基本只要信用卡刷下去，性能就立刻上去了。
同样，这个特性也比较适合那些资源的峰谷比特别夸张的公司，尤其是一些几个月内会受到超大压力，过后肯定会被放弃的项目。VPS方案可以允许你短期内租用一些机器来工作，过后没有扫尾工作。
其次，由小公司运作的设备，其平均无故障时间远低于专业VPS商，也低于主机托管商。道理也很简单，硬件的物理损坏会降低平均无故障时间。而虚拟主机和VPS都是通过无单点故障的均衡系统来解决这个问题的，这个方案对于只有几台设备的小公司不适用。更进一步说，如果万一出问题，非专业人员的恢复时间无论如何比专家来的慢。
最后，最主要的是，如果使用空间或者VPS，你无需关心硬件淘汰问题。通常网络公司很少碰到多年后使用寿命满导致的机器淘汰，通常都是性能不足而进行的机器替换。汰换下来的机器用起来不方便，卖掉不合算，是个很鸡肋的东西。VPS商会自行处理这些事情，并且在机房升级后，通常还会给用户一些自动升级。
我们现在来算一个实际问题，一个比较典型的小网站，平均同时在线人数大约是400人，峰谷比大约是1:5。页面滞留时间按照20s计算，每页面流量10K，每session内存消耗0.5M。为了支持峰值在线，大约需要1G内存，瞬时带宽消耗大概是1M/s，一个月的数据流量大约是600G。一台中等的1U小型服务器大概是2W，分摊到3年折旧，每个月就是600。1U的托管最低是6000（我怀疑现在哪里还能弄到这个价格），最高的有10W的。按照1.2W计算，一个月是1000。加上少量的中间费用，直接管理硬件的成本大约是1800-2000RMB/mo。dreamhost的不限空间不限带宽服务一个月费用是9美元，折合60RMB/mo不到。gplhost上的Xen服务器，60G硬盘1.2G内存360G带宽是70美元，折合450RMB/mo。其他厂家也有200-350RMB/mo不等的类似服务方案，不过有可能是基于OpenVZ的，有超卖的可能。
为了支持这个小网站，如果使用小型服务器托管方案，那就是一台服务器搞定，1800-2000RMB/mo。如果是Xen服务器，大约是900RMB/mo。如果是空间，性能顶得住就是60RMB/mo，顶不住就当场崩溃。
基本结论是，如果你的程序并不特别重要，那么用空间。如果应用的峰值内存消耗小于2G，那么用VPS。如果峰值内存消耗奇高，或者月流量超大，还是自己托管服务器稍微省点钱。</description>
    </item>
    
    <item>
      <title>公司的网络服务选择</title>
      <link>//blog.shell909090.org/blog/archives/1652/</link>
      <pubDate>Thu, 16 Dec 2010 14:20:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1652/</guid>
      <description>最近碰到不少朋友需要做网站，或者做一些网络产品对外服务。下面统一解答一些基础概念问题，程序员或者本行的人士可以不用继续往下看了，都是常识。
1.网站/产品都包括什么东西？
从最简单的来说，你做了几个页面，放在网络上，让其他人看，这个就属于网站的范畴了。更复杂的，论坛，wiki，产品目录，公司主页，都属于互联网网站/产品。
2.为了让别人可以访问你的产品/网站，你要做什么。
我们有个术语来描述“让所有人可以访问你的产品/网站”这个定义，叫做上线。作为基础，你需要一个服务器，和一个域名（这两个名字我们下面解释）。也许你需要一些其他东西来让网站上线，但是至少一个服务器和一个域名是必须的。域名是你对外宣传的基础，其他人通过域名来访问你的网站。服务器则是支持别人访问的系统。
如果你打算对使用中国的服务器，或者说在中国经营，那么你需要在中国的网络管理部门进行备案。
如果你打算使用现有的程序，或者不需要开发程序，那么你可以忽略程序开发过程。但是大多数人都需要一些经过修改的程序，乃至于编写一些程序来让网站运行。
无论你在上面作出了何种选择，最终，你需要维护你的网站。如果你不熟悉这个过程，可能还需要一个人来管理这部分。
3.听起来很复杂的样子，那么，怎么做？
我们先解释怎么弄到服务器和域名，还有备案，程序开发和维护后面再说。
如果你对上面这一切完完全全一点点都无法理解，那么你可以不用继续阅读了。找一个信得过的专业人员，或者让信得过的人推荐一个，然后让他搞定这一切吧。
如果你还基本能听的明白，那么可以自己试着去买一个服务器和域名。我建议你从购买空间开始。
空间：多人合用 多人共享一个IP 只提供网页和邮件服务 很难安装系统软件
VPS：多人合用 一台机器一个IP 提供所有服务 除了部分内核组件外，都很容易安装和更换
独立主机：一人独用 一台机器一个IP 提供所有服务 可以任意管理
通常，大多数空间服务商都提供域名购买服务。域名和空间都是要每年付费的。注意，由于空间很难安装系统软件，因此空间支持的语言通常都是限定的，现在大多数都是支持asp或者php，偶尔有支持其他语言的，不多。在进行程序开发或安装时，必须确定空间可以支持这种语言。
如果你面向中国的群众提供服务，或者机器在中国，就必须进行备案。一般的空间服务商也提供备案业务，不过备案的情况非常复杂而且随时都在变化，因此请询问清楚现在的情况再做决定。如果可以的话，我建议尽量不要将服务器托管在中国，或者购买cn域名。
4.我买了一个空间/VPS，还有域名，然后呢？
那么你需要把合适的程序开发出来，并且放上去。通常来说，你能想到的东西一般都有良好的开源实现。你可以咨询一下专业人士，并且尽量听从他们的建议。大多数个人和公司的需求，都可以通过在开源的论坛/blog/wiki/CMS系统/ERP系统上进行简单的配置/混合/定制开发来解决（很绕？简单来说，肯定有现成的）。千万不要低估开发的成本，也许你觉得程序员很便宜，想自己动手，找一些人做一个出来。但是就我的经验，在IT业没有经验的公司要进入这个领域，几乎没有成功的经历。主要问题在于不熟悉流程和管理，导致开发总是在莫名其妙的地方停顿，并且产品的质量很难控制。（简单来说，你会掉到泥潭里）
如果你真的需要进行开发，外包是一个方案，但是也很容易失败，问题的核心也是无法控制进度和质量。对于小规模的东西，找信得过的人单人开发或者推荐人开发是个可靠性很高的方案。
5.我有程序/我找到了合适的程序
恭喜你，现在离上线只有一步了。你需要将你的程序放到你的服务器上，并且将域名指到服务器上，这一步可以请一个专业人员来做一下。然后你的产品就上线了，我们管这个过程叫做部署。
但是，且慢高兴。除了第一次的部署，你还需要定期做例行维护。例如你运行了一个论坛，总不能让人上来全看到广告吧。你运行了wiki，上面全是骂你的话。你的产品目录需要经常更新，邮箱更是天天要看。通常你需要至少一个人，来盯着你的产品。如果不复杂，叫个行政兼职看看就好，如果比较复杂，还是请职业网管的好。如果你要将这个产品的名气打响，还需要进行产品的推广/营销工作。这部分就更加复杂了。
6.让我总结一下
你最好找一个专门的咨询人员，咨询一下有没有适合你的产品，能不能简单定制一下搞定。如果可以，你需要支持哪种语言的空间（如果你用空间的话），压力大概多大，能否支持。自己去购买合适的空间或者服务器，还有域名。然后让人（通常一事不烦二主，咨询人员也兼职部署）部署上去，并且找个人盯着。大概就是这样。</description>
    </item>
    
    <item>
      <title>程序员的路线和培养</title>
      <link>//blog.shell909090.org/blog/archives/1648/</link>
      <pubDate>Tue, 14 Dec 2010 10:07:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1648/</guid>
      <description>也许我说过这话了，再说一遍也不嫌多。程序员不要什么都学，什么都吃。不但要吃好的，而且要能穿起来。先学什么，后学什么，学成是什么，大概要有个数。不在这个范围附近的东西尽量别碰，活也尽量别接——除非钱贼多。
很多新手程序员和我以前一样，看到好的技术就去学，看到大牛就去拜。结果php程序员同时还会汇编，又玩过过图形识别——这种技术组合想干嘛？joel on software表达过类似的意思，程序员的时间很值钱，最主要是前面做过的东西会变成后面的财富。前面做了个项目赚1000，后面做有关项目的时候就可以以一半的成本做1000。这样下去，只要项目足够——或者有人请你——做到三年以后工资往往是前面的几倍。反过来，前面两千三千挑值钱的做，往往到了后面还是这个值不变。用另一句话描述，“我要找的是五年经验的程序员，不是一年经验乘以五的程序员”。
差不多就是这么回事了。</description>
    </item>
    
    <item>
      <title>重载造成的隐蔽错误</title>
      <link>//blog.shell909090.org/blog/archives/1626/</link>
      <pubDate>Wed, 01 Dec 2010 10:03:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1626/</guid>
      <description>大家看看下面的代码在什么情况下才会出错？情况很特殊，想自己思考的不要先看第二段。
if ton in self.ftol: self.ftol.remove(ton)  ftol是一个list，报出的错误是ValueError。经过上文的打印，赫然发现——self.ftol中真的没有ton！
好吧，我们揭秘谜底。
ton是TimeoutObject类型，这种类型的对象通常放在一个list中进行堆排序，来确定最早的一个timeout对象。为了实现堆排序，我使用了heapq。而为了heapq是没有key或者是cmp参数的，因此我重载了TimeoutObject.__cmp__对象。然而根据python源码，list对象在进行in计算，以及基于in的remove计算的时候，__cmp__先于内置算法，内置算法先于id相同。因此，in函数在进行对象是否在列表中的计算的时候，实际上使用的是一个比较函数&amp;hellip;这肯定无疑的会导致乱糟糟的结果。
为了解决这个问题，我又重载了__eq__函数，定义为self is o。问题立刻解决了。
之所以python内置的算法，会定义__cmp__先于内置算法，内置算法先于id相同，是因为有很多对象需要人工定义比较算法。如果id相同优先，那么这种自定义的能力将无法实现。然而为了in算符中为何会调用__cmp__，只能说是一个不解之谜。</description>
    </item>
    
    <item>
      <title>为什么高性能框架都是http的</title>
      <link>//blog.shell909090.org/blog/archives/1613/</link>
      <pubDate>Tue, 16 Nov 2010 10:18:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1613/</guid>
      <description>很多高性能的web框架，例如沈崴的euraisa，fackbook的tornado（这两个都是python）框架，都是http的。这和我们的印象相反，python，或者其他高级语言不是都很慢么？为什么都用这个来做http服务器呢？
这个我们得从服务器架构开始说起。最初的时候，没得说，所有的都在同一个机器上，甚至可能使用cgi模式。在访问压力上去后，为了增强性能，首先被拆出去的应该是数据库服务器。而后会考虑使用fastcgi或者scgi进行部署，前面使用apache或者nginx做前端。在这个时候，fastcgi是有道理的。因为apache在静态文件处理的性能上远高于python框架（而且快数倍），而nginx在大规模静止长连接的情况下性能更优异。而且，更进一步说，在性能压力加大的时候，应用服务器会被拆分，这时候apache/nginx做反向代理很容易做到负载均衡集群。
然而，如果压力再上去呢？在这种情况下，通常考虑的两件事情是静态文件拆分单独的服务器和应用服务器的硬件负载均衡（没钱的话也得考虑LVS了）。道理很简单，即使服务器性能能无限提升，网络接口的性能也不会无限制的上升的。完成这两步后，我们再来看整个架构，会发现反向代理变成了一个鸡肋。静态文件处理？不在这些服务器上了。负载均衡，系统级有了。apache/nginx有什么用呢？难道就是把http协议转换为fastcgi协议？
所以说，要达到高性能，框架应当是直接处理http的，并且支持大量的客户进行长连接。当压力小的时候，使用nginx的反向代理模式进行工作（而不是fastcgi协议）。当压力大的时候，拆开静态文件，直接上去服务全社会。</description>
    </item>
    
    <item>
      <title>小公司的架构选择</title>
      <link>//blog.shell909090.org/blog/archives/1610/</link>
      <pubDate>Tue, 09 Nov 2010 11:09:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1610/</guid>
      <description>很多大公司都是从小公司起步的，往大做的时候，往往会受到很多制约因素。架构选择不对造成的问题很多，所以很多小公司都在架构选择上精打细算。其实架构问题，在公司规模小的时候，更大程度上是一个行政问题而不是一个技术问题。
小公司的特点是人少，往往就那么几个人。这种情况下，与其说是你选架构，不如说你看看有什么可用的架构。通常来说，你要考虑的问题是。
1.你有没有可以信任的核心工程师？
2.能不能找到足够的人手做大部分的事情？
3.能不能在你要求的时间范围内把事情做掉？
4.这个架构有没有成功的例子，能不能支持大规模的访问？
当这些问题都没问题的时候，你才应该考虑，这个架构性能够高么？容易扩展么？
如果你没有可信的人作为核心工程师，项目管理和控制根本无法进行。就算要评估一下手下这些人是不是真的需要这些时间来做事，得到的结果都是不可靠和不可信的。如果找不到足够的人手做事，那除非你的核心团队能够一个人或者几个人把网站整个做出来，例如豆瓣的阿北，否则项目做做就没人，就玩不下去了。如果架构很好，但是无法在要求的时间内做出事情来，等于没用。满足了上述几点，你还得兼顾考虑一下，这个架构如果没有成功案例，是否存在隐性的风险。如果不支持大规模访问，将来的扩展问题。
好吧，作为一家小公司，我相信你考虑完以上几点后，能凑出一个框架来已经很不错了。往往是你的核心团队没有一个核心工程师，大家会几种不同的架构，而且没人能保证评估结果。
这时候，不要废话，先找个核心工程师，然后用最土的，被无数人验证过的技术来把你想做的事情做掉。
除非你的核心团队有且仅有一个核心工程师，并且这个工程师的技术能力很强，管理者和投资人也支持他冒风险。否则大部分使用激进架构选择都会带来不良的结果，毕竟大部分公司都不是以开发框架和研发技术为最终目地的公司。</description>
    </item>
    
    <item>
      <title>不靠谱</title>
      <link>//blog.shell909090.org/blog/archives/1506/</link>
      <pubDate>Mon, 18 Oct 2010 10:51:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1506/</guid>
      <description>在公司中，有这么几种不靠谱行为，粘上就容易身败名裂，具体程度和人品以及不靠谱程度有关。以下排名分先后。
1.自以为是的客户需求。主要是说由程序员来搞的需求，以为搞的挺好，其实客户完全不鸟你。
2.老板定的开发周期。不用说，就像色狼为美女挑的泳装，肯定太紧。
3.废物员工。不怕神一样的对手，就怕猪一样的队友。不但没有贡献，只会拖后腿。
4.迫于压力不写文档，延后文档或者仓促写。都是废品产生的先兆。
5.过于激进的架构设计/技术选择。听起来挺好，问题是，您能玩的转么？
6.指手划脚的客户。神一样的对手。
7.钱不是问题。问题是没钱。</description>
    </item>
    
    <item>
      <title>专业程序员需要掌握的几种语言</title>
      <link>//blog.shell909090.org/blog/archives/116/</link>
      <pubDate>Thu, 20 May 2010 18:03:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/116/</guid>
      <description>受到这篇文章（http://blog.youxu.info/fyi/21-days/）的启发，我突然想起对我所会的和要学的语言做个分类。确定一下专业的程序员到底需要会多少种语言。
1.系统类。只有C一个，必须学，而且需要在几个系统上编程就要学几次。学习系统类语言需要的是对系统结构和运行原理的了解，因此抽离系统的学习语法/抽象库/代码结构是没有任何意义的。
2.面对对象类。C#,Java等，推荐Java。构架方法优美大气，代码容易修改容易阅读，复用性好。然而做事上架梁叠屋，吃个馒头洗三遍手。可以学习构架方法，千万别学做事方法。
3.一门快速的脚本语言。Python, Php, Perl, Bash，各有特色。实际上如果你有空可以统统学一遍，非常有好处。快速脚本语言的特色就是整合其他代码和已经存在的东西，快速的构建出一个可用的程序。
4.一门语法抽象语言。目前只有Lisp和Scheme，推荐Scheme。这两种语言是在人工智能和符号推理的发展过程中产生的，因此对理解“机器是如何思考的”很有帮助。注意这两种语言的本质就是有限图灵机。
5.汇编。汇编语言种类太多，推荐80x86汇编。熟悉汇编语言对了解硬件和系统如何工作很有帮助，并且为查找系统内部(internal)的错误提供了便利。
按照上面的分类，程序员最少要会五种语言，我假定是C/Java/Python/Scheme/Asm80x86。C++不要学，那个是万恶之源。那么下面列举了我推荐的一些书单，可以由浅而深的学习这些语言。
1.入门，《21天学习C语言》《Dive Into Python》《80x86汇编基础教程》等等，这类书的目地是快速的教会是使用语言和语法。完成这个阶段的程序员可以找一些简单的题目做一下，但还不能独立完成普通程序的编写。
2.简单，《Think In Java》《数据结构与算法（Java语言版）》《设计模式》。这个层面基本涉及了数据结构，设计模式和编程方法。完成这个阶段后，可以找几个实际项目玩一玩了。
3.普通，《操作系统：设计和实现》《Unix系统编程》《windows核心编程》《TCP-IP详解》《Effective C》。这个层面涉及了系统运作原理和细节。完成这个阶段就可以写一些系统工具了。
4.阅读，《Python源码剖析》《深入浅出MFC》《Linux内核完全注释》。这个阶段注重阅读和积累各种代码经验。
5.专家，《计算机程序的构造和解释》《计算机程序设计艺术》《MIT算法导论》《数值算法》。通过前面的学习，普通程序编写应当已经不成问题。这个阶段面对的是将实际问题抽象成数学问题后，试图从数学上进行解决的过程。从此以上，就是数学的领域了。</description>
    </item>
    
    <item>
      <title>关于人力资源的一些话</title>
      <link>//blog.shell909090.org/blog/archives/112/</link>
      <pubDate>Tue, 27 Apr 2010 12:50:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/112/</guid>
      <description>上周被猎头了，虽然没兴趣去，但是还是很高兴。算是对自己能力的一种认可吧。顺便联系了老董，得知原来公司的近况，又看了老赵的一篇文章。觉得有些话犹如骨鲠在喉不吐不快。
1.程序员是什么人，他们能干嘛
程序员当然是写程序的人，但是不是所有写程序的人都叫程序员。（耳熟？不是所有特仑苏都叫牛奶）一个程序员，必须能够完整的了解需求，设计系统，构架系统，完成代码，并且测试通过。当然按照现代软件工程，程序员不必亲自做这些事情。甚至更严格来说，要求这些事情不能都由程序员来完成，然而一个程序员是可以做到这些的。在这以下，基本都叫代码工人。
如果按照以上的标准来衡量，老赵的这篇文章（http://blog.zhaojie.me/2010/04/why-i-say-no-to-aptech.html）里面说到的问题是不言自明的。很多培训机构培训学员使用快速工具，例如eclipse或者vs，基于可视化系统编写项目。这些学员有能力很快的完成一个项目，然而，却无法反转数组。这些“准程序员”所能做的项目，不会超出在培训中所教授的范围。例如如何完成一个论坛，或者如何编写一个博客。问题是，这些教授的内容，都是延续多年的，被反复验证的问题。这些问题，有着最优秀程序员们做出的成熟解答，根本不用这些菜鸟多此一举。
2.精英和普通程序员
昨天和猎头说到程序员和精英的区别。现在所有的老板都希望自己的队伍中能有几个精英程序员，然而joel on software里面谈到过，你很难找到一个精英（http://www.ruanyifeng.com/blog/2008/11/finding_great_developers.html）。我的问题是，什么是精英，什么是普通人。
一个人，要成为精英，需要具备什么条件呢？不是快速产生代码，也不是良好的算法能力。要成为精英，编程能力和算法能力是必要的。然而更必要的是时间-事务管理，沟通和领导能力，名气和知名度，对行业的深刻认识和远见，以及人品。精英最大的价值并不在于写程序，而是能够激活公司内其他人员的能力。例如你可以方便的招聘到其他的程序员，让风投觉得你的团队靠谱，因为他在行业内的知名度很高，有相当的号召力。他可以培育新人，和其他程序员合作，稳定可靠的完成项目，因为他拥有良好的沟通和领导能力。最顶尖的精英可以产生新颖的创意和想法，让你规避可能的风险，让顶尖粉丝围着你转，因为他们在行业内领导性的认识和远见。当然，最重要的是，他是可靠的。
3.精英一旦聚集，精英就密集
昨天和猎头谈的另一个问题就是，他们需要精英还是普通程序员。可以想象，他们的标准答案是两个都要。然而我要说的是，精英和普通人在大多数情况下互相排斥。一旦公司或部门中多数都是精英，很神奇的，很快里面全都是精英了。而一旦一个公务或部门中多数都是普通人，那么很难留住精英——很多情况下都变质了。所以最好选择一者，或者为精英们专门成立个部门。
为什么精英和普通程序员互相排斥？这个问题要分开说。精英程序员信仰简洁的人生，他们一般不屑与笨蛋说话。很多时候你向他们寻求解答，他们往往用一两句话点明这个问题的原因和机理。多数情况下这一两句话相当受用，值得你用几个小时来消化。然而多数普通程序员的问题是根本听不懂他们在说什么。曾仕强说过，一个能干的领导只有一个作用，就是证明你的手下都是白痴。在这种环境下，没有成为顶尖高手资质的，对技术没有狂热热爱的程序员会迅速离开，而有这些资质的程序员会快速的进化成另一个精英。而反过来，让一个技术高手来领导一群普通程序员是一件很痛苦的事情。要么他受尽折磨后离开了这里，要么他就变成了一个领导者。这种情况下他不再和其他程序员沟通技术细节。反之，他利用自己的技术能力建立解决问题的框架，分解问题为一些普通程序员能解决的问题，并丢给他们——而不管他们完成的细节。
4.为什么要来你们公司
如果你的公司需要招聘一个精英，那么你需要问这么一个问题。他们为什么要来你们公司，你们公司能给他带来什么？
程序员工作的最低理由是收入。从收入层次上说，基本有工资，分红，股份三种激励方式，分别对应了短，中，长期合作关系的激励。高工资的激励效果最显著，然而由于你对高级程序员缺乏有效的监控手段（谁来实施？总不能他们监控自己或者互相监控），所以员工很快会怠惰。分红将程序员的收入和一年内或一个项目挂钩，所以能够保证他们采取一切措施，保护自己的收入——同时也保护了你这一年或一个项目的收入。而股份则是将程序员的收入和公司的成长挂钩。然而这些并不是精英们愿意去你们公司的全部理由。
程序员做到一定程度后，对于非物质条件的要求是很挑剔的。往往我们能听说一个高手谢绝了大公司的工作，或者一些优厚的报酬，其原因往往如此。这些条件包括，部门中的人水准相近可以沟通（我们所说的3），工作自由安排，有自己的时间进行研究（隐含的就是加班很少），良好的工作环境，宽松的制度，等等。通常而言，这些人都喜欢去小公司或者自己创业了，其原因就是因为大公司很难给他们需要的东西。如果你打算招揽一个真正的高手，搞清楚他真的在意什么比一味的开高薪水更加有效。
5.愿不愿意要培训生或应届生
昨天谈到的另外一个问题就是，愿不愿意招收培训生或者应届生。这个问题的“标准”答案通常是，我们愿意接受新鲜血液，这些人的薪水具体要视能力而定，如果能力真的出众后期还可以调整。实际上，除非特殊情况，否则听到这这句话，你就应当了解到几个隐含的事实，这些东西往往和你的期望背道而驰。1.公司的压力很高，严重缺人，所以进去后可能会严重加班。2.新人工资很低，而且也没有什么晋升的空间。3.基本学不到什么东西。
为什么会这样？通常而言，公司不喜欢培训生或者应届生。更准确的说，是不喜欢培训生或者应届生应聘。真正靠谱的应届生或培训生，是靠HR去校园里面抢的。记得上面那个joel on software的文章？他们在校园期间就会脱颖而出，成为佼佼者，很少有校园里默默无名的人出校园后表现出惊人实力的（虽然并非没有）。通常HR会虎视眈眈紧盯这些真正有才能的人，要抢到一个都困难，怎么可能沦落到人力市场上应聘呢？因此如果你真的有才能，请在校园期间就表现出来。否则就需要等费尽周折进入一家公司后才能表现出来，而且很晚才能反应到你的收入上。
那么，一家公司愿意接受培训生或是应届生的真正原因是什么？多半只有人手不足，而且其中大多数是短期内的人手不足。因此不但可能要加班，而且一旦当人力问题缓解（更加不幸的是在你的试用期内缓解），能力不足的人还可能遭到遣退。是的，无赔偿的，虽然不是你的责任。即使留下来，也是作为一个基础的消耗品。主要的目的是承担大量的杂务工作，并且拉低工程师的薪水。为什么？当有大量廉价工程师存在的时候，工程师的薪水比他们应得的更低。一方面因为劳动力充足，导致自己是否会失业的竞争威胁。另一方面也因为比较性的从众心理，别人的薪水比自己更低，于是就心安理得了。此谓杀价妙方。在这种指导思想下，你的晋升和学习都无法顺利展开的。
6.做项目，做产品，做团队
这是整篇文章最大的一个问题。低端做项目，中端做产品，高端做团队。怎么解释？
最低端的软件产业，依靠的是软件项目实现来获取利润。实际上他们做的事情，某种程度上也可以叫人力资源外包，他们主要通过外包价格和人力资源之间的差获得利润。因此，这类公司的主要特征是拥有发达的渠道和关系网络，拼命寻找高价的，大规模的外包项目。同时借助大量低端程序员，压低人力成本。这类公司永远处于人力缺乏状态，除非公司快倒闭了。
中端的，大量的软件公司，是依靠对客户的了解，设计创新方案或者增强通用方案，改变原始流程，从而为客户带来好处。他们最大的利润来源是创造性的改变客户的原始流程，如果是互联网公司就是新的互动模式。这类公司的主要特征，是拥有一个强力的营销团队，和良好的售后体系。三流的公司往往试图改变团队来跻身其中，然而由于糟糕的流程设计或互动模式设计，或者用更流行的说法“商业模式”，因此无论其商业团队多么努力，都无法成功进入这类市场。这类公司对技术人员的成本并不很关心，只要小于产品的总收入就好。事实上通常来说，越是代价高昂的精英，往往能越好的完成改善流程，创新，设计，快速完成的过程，从而带来更高的收益。因此这类公司往往都有些牛人，少则一两个，多则一大群。
这样的公司，从业务来说是完整的，稳健的。然而从公司角度来说却是缺失的，也不是投资者喜欢的。问题在于，公司的成败依赖于少数几个人的激情和努力。包括公司的决策层，主设计师，等等。例如苹果公司的股价就强烈的受到jobs的影响。通常而言，投资者更喜欢稳健的，风险可控的公司。通过一个固定的制度，和可迁移的管理团队，来发现和聚集人才。这类公司才是我们所说的“大公司”，并非规模大，而是构架方式大气，做事方法正规，拥有着成为行业顶尖的可能性（虽然并不一定保证）。一家从外包和产品做起的公司，如果一开始就采用了粗放型管理模式，而没有妥善解决团队打造和管理上的问题。到后期往往是版权纠纷，禁业纠纷层出不穷。或者高级程序员来一个走一个，来的薪水一个比一个高，走的速度一个比一个快。或者干脆树倒猢狲散，公司一拍两散的也有。
因此，如果一家公司有意做大，请记得在一开始的时候就设计一个良好的团队打造计划和团队保持制度。否则当碰到问题的时候再做转换，往往已经太迟了。</description>
    </item>
    
    <item>
      <title>用python实现webserver(二)――Thread</title>
      <link>//blog.shell909090.org/blog/archives/82/</link>
      <pubDate>Mon, 07 Dec 2009 09:58:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/82/</guid>
      <description>我们上面说过，Prefork模式有着先天的缺陷。针对http这种大量短请求的应用(当然，http1.1以来，有不少客户端使用了长连接)，Prefork的最高并发很让人不满。并且，无论是否高并发，Prefork的性能都非常不好。现在我们介绍一下Thread模式。 和Prefork非常类似，每Thread模式通过新建的线程来控制对象的传输。和Prefork模式不同的是，一个用户能够建立多少个线程并没有限制。在系统上似乎有限制，65535个，但是同样，文件句柄最高也就能打开65535个，因此通常而言一个服务器最高也就能顶50000并发，无法再高了(nginx就能够支撑5W并发，再高要使用一些特殊手法来均衡负载)。而且线程的建立和销毁的开销非常小——没有独立的空间，不用复制句柄，只要复制一份栈和上下文对象就可以。但是，由于所有线程运行在同一个进程空间中，因此每线程模式有几个非常麻烦的瓶颈。 首先是对象锁定和同步，在每进程模式中，由于进程空间独立，因此一个对象被两个进程使用的时候，他们使用了两个完全不同的对象。而线程模式下，他们访问的是同一个对象。如果两个线程需要进行排他性访问，就必须使用锁，或者其他线程同步工具来进行线程同步。其次，由于使用同一个进程空间，因此一旦有一个连接处理的时候发生错误，整个程序就会崩溃。对于这一问题，可以通过watchdog方式来进行部分规避。原理是通过一个父进程启动子进程，子进程使用每线程处理请求。如果子进程崩溃，父进程的wait就会返回结果。此时父进程重启子进程。使用了watchdog后，服务不会中断，但是程序崩溃时正在处理的连接会全部丢失。最后，是python特有的问题——GIL。由于GIL的存在，因此无论多少线程，实际上只有一个线程可以处理请求，这无形中降低了效率。下面我们看一下Thread模式的测试结果： 测试指令： ab -n 1000 -c 100 http://localhost:8000/py-web-server 返回结果： Document Path: /py-web-server Document Length: 1682 bytes Concurrency Level: 100 Time taken for tests: 3.834 seconds Complete requests: 1000 Failed requests: 0 Write errors: 0 Total transferred: 1723000 bytes HTML transferred: 1682000 bytes Requests per second: 260.85 [#/sec] (mean) Time per request: 383.362 [ms] (mean) Time per request: 3.834 [ms] (mean, across all concurrent requests) Transfer rate: 438.91 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 75 468.</description>
    </item>
    
    <item>
      <title>用python实现webserver(一)――Prefork</title>
      <link>//blog.shell909090.org/blog/archives/80/</link>
      <pubDate>Wed, 21 Oct 2009 10:31:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/80/</guid>
      <description>要实现webserver，首先需要一个tcp server。作为python的设计原则，最好是使用SocketServer或者封装更好的BaseHTTPServer来复用。不过既然我们的目的是为了学习，那么就不能用这两个内置对象。我们先实现一个最古典的每进程模式实现。而我们标题上的Prefork，则是apache服务器对这个模式的称呼。
每进程模式，顾名思义，就是每个新连接开启一个进程进行处理。首先创建一个socket，bind到一个套接字上。当有请求时，accept。(好多英文，不是我有意cheglish，全是api的名称)accept会返回一个通讯用的socket，这时fork出一个新的进程，处理这个socket。
主进程在每次进入accept后阻塞，子进程在每次进入recv后阻塞。这样会带来几方面的好处。首先是模型分离，即使一个子进程崩溃，也不会影响到其他子进程。其次是身份分离，当你需要让http server以高于常规运行(常规都是以apache, www-data, nobody运行的)用户的权限进行工作时，每进程模式是唯一安全的模式。其他模式都会造成同一进程内的其他session也暂时获得这个权限的问题。但是同样，这样有几方面的问题，主要就是性能问题。
由于每个连接都需要fork出一个新进程去处理。因此针对大量小连接的时候，fork和exit消耗了大量CPU。问题更严重的是，由于用户进程总数是有限的(PEM或者ulimit都会限制这个数量)，因此压力大到一定程度时(通常是1024或者2048)，就会出现无法创建连接的情况。而对小型服务器而言，在压力还没大道这个程度以前，服务器就会由于性能达到限制而造成段错误。以下是实际试验指令和结果：
测试指令：
ab -n 10000 -c 100 &amp;lt;http://localhost:8000/py-web-server&amp;gt;  服务器报错：
20090924 05:51:18: Traceback (most recent call last): 20090924 05:51:18: File &amp;ldquo;main.py&amp;rdquo;, line 19, in  20090924 05:51:18: 20090924 05:51:18: sock.run (); 20090924 05:51:18: File &amp;ldquo;/home/shell/py-web-server/server.py&amp;rdquo;, line 30, in run 20090924 05:51:18: 20090924 05:51:18: while loop_func (): pass 20090924 05:51:18: File &amp;ldquo;/home/shell/py-web-server/server.py&amp;rdquo;, line 56, in do_loop 20090924 05:51:18: 20090924 05:51:18: if os.fork () == 0:</description>
    </item>
    
    <item>
      <title>用python实现webserver(零)――导言</title>
      <link>//blog.shell909090.org/blog/archives/79/</link>
      <pubDate>Fri, 09 Oct 2009 16:01:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/79/</guid>
      <description>本系列文章的所有代码，都发布在http://code.google.com/p/py-web-server/。项目的目的，是通过写作一个可用的http web server，学习服务器程序编写中的一些方法，以及http协议的细节。
如同我在项目介绍中说的，项目遵循以下几个设计原则。
 []() []() []() []() []()  有兴趣的，可以也通过本文的介绍，不看代码写一个类似的东西。而后对比代码，找出设计上的异同和优劣。如果您也设计了一个，请告诉我，我很高兴能够得到大家的指正。</description>
    </item>
    
    <item>
      <title>计算机中的海森堡效应和罗素悖论</title>
      <link>//blog.shell909090.org/blog/archives/77/</link>
      <pubDate>Tue, 08 Sep 2009 17:58:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/77/</guid>
      <description>有点标题党，海森堡测不准原理大家都知道吧，你观测一个东西以获得他精确的描述，然而你测量行为本身就会干扰这个东西的存在，从而永远无法准确测量。
近日贝壳碰到一个计算机中的海森堡效应，因为工作需要，贝壳需要获得/proc/loadavg中的load参数。这个参数在uptime时会显示，大致意义是这一秒内平均的活跃进程数。(对电脑无爱者请自行跳过以下内容到下一段)准确的计算方法是在一秒内的所有tick上，累加当前的待运行线程列表长度，而后除以一秒内的所有tick。当tick趋于无穷小时，相当于对活跃进程的定积分除以横轴长度，即平均值。
同个文件内有另外一个值，活跃进程数，是当前的待运行队列长度。从理论上说，如果贝壳要计算一个小时(或者其他大尺度时间)的loadavg，可以高速取样该值，在一小时内求平均，即复现load参数的意义？
想法很好，不过实际上差很多。开发服务器上的loadavg大约是0.01-0.05，但是贝壳按照后者算出来的load总大于1。问题在哪里？
记住一点，当你去获得loadavg的时候，你当前的线程永远是在运行的。因此你获取的行为会增长活跃进程的值，哪怕其他时间什么都不做，这样会将取值的瞬间的load提高至少1。而内核的计算的时候，是不会把自己的行为计算为活跃进程的。
那么将值减去1对不对？也未必。在知道上述问题的同时，我们可以想象。在高压力下，你的线程什么时候会获得运行的机会？只有在最高优先级的任务空闲的时候。因此，你取得的值会严格的小于真实的压力。
因此，不要相信当前活跃进程数，那个值永远大于1，并且不总正确。如果那个值是0，那逻辑上讲，你就碰到了罗素悖论。
咳咳，又来一个问题，什么是罗素悖论？
很简单。如果说真话的人永远说真话，说假话的人永远说假话。有人对你说：“我在说谎”。你就听到了罗素悖论。同理，如果理发师只给不给理发师理发的人理发，而所有理发师的头发都有人理，那你也碰到了罗素悖论。同样，如果有程序告诉你，我读取了当前的活跃进程数，但是这个数表明我不活跃。
同样，你也碰到了罗素悖论。</description>
    </item>
    
    <item>
      <title>IT市场统计分析</title>
      <link>//blog.shell909090.org/blog/archives/69/</link>
      <pubDate>Fri, 19 Jun 2009 00:40:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/69/</guid>
      <description>最近在看简历，根据简历和自己的经验总结一些东西出来。管窥蠡测一家之言，权给新手做个参考吧。
1.行业分类
从统计上看，web开发是人数最多的行业，占大约56%。其次是嵌入式市场，大约占18%。erp市场也差不多，18%。剩余的不足8%。
2.性别分布
众所周知，程序员是男性的职业，但是出乎大家意料的，程序员中有14%是女性(纯程序员，不包括美工)。不过根据贝壳的人工观察，其中只有一人的工作时间超过5年，多数都是3年不到的新人。看来女性程序员怀孕后转业的情况非常严重啊。
3.年龄分布
以大学毕业为基准水准计算，当前程序员的最低出生日期应当是1987。贝壳按照这个进行了统计，得出结果如下。
1983年17%，1984年8%，1985年14%，1986年16%，是人数最多的4年。低于1987年的占11%，1980到1982年间的人数占20%，高于1979年的占14%。
4.水准分类
水准是一个很难界定的指标，贝壳采用五级分类法，简单对其分类。大多数情况下，级和级之间没有明确的定界。
0.是完全没有任何技术背景和资历的人士，说白了就根本不是IT人。大约占8%。
1.初步具备IT行业人员的背景知识，能够做一些简单的软件产品，有跟随1-2个项目的经验。但是无法承担独立的项目，无法解决比较复杂的问题。在这个层次上，程序员大多数时候根本不知道怎么做，以及该做什么，始终处于知识缺乏的状态。业界俗称，小白。大约占50%。
2.具有标准职业从业人员所需要的知识(当然，具体是什么知识视行业和语言而定)，跟随过多个项目，其中有2-3个大型项目。可能领导过1-2个项目，但是不清楚项目管理的概念和专业知识。这个级别的人在总体人数中最多，大多数人在工作1-3年后都可以达到这个水准。可以独立的解决问题，和客户交流，完成软件生产的整个流程。在这个层次上，程序员大多数时候都知道怎么做。主要的问题在于多数人还不知道如何将这个过程简约成自己的标准过程。一般来说，这就是标准程序员的典范。大约占32%。
3.精通C++，熟悉windows和linux系统管理和系统底层，掌握至少一门高级语言。熟悉项目流程和项目管理的概念和专业知识，能够带领团队协作完成大型项目。能够独立建模，抽象问题，并通过算法解决问题。具备独立和客户沟通，协调解决问题的能力。一般有多个项目经验，曾经领导团队完成2-3个大型项目。如果你天分不错，运气不错，又够勤奋，大概在工作3-5年后会达到这个水准。在这个层面上，算法和标准化过程这些书本上的东西首次超过了如何做，做什么，成为程序员的首要问题。这个层级的人数也比较多，能够胜任项目经理的职位。大约占8%。
4.精通专属领域的多项核心技术，有广泛的业界联系，专属领域有一定的知名度。研发过一项或几项领域中的关键技术，对领域的发展做出过一定贡献。要到到这个层次无法依靠时间的积累，很大程度是天分，运气。在这个层次上，解决问题已经不是一个问题。由于基本能解决领域内的多数问题，因此发现需要解决什么，和创造性的解决这些问题成为这个层次最主要的问题。这个层次的人基本很少，一个子领域中全国不会超过百人。大约占2%。
5.曾经研发过改变世界的技术。这种人多数你听过，运气好这辈子能见到一个。大约占1%不到。贝壳当前的水准在3上下浮动，估计奋斗一下，这辈子能够达到4的层次。至于5，这辈子不指望了。
5.工资分布 大多数情况下，工资和工龄都是挂钩的。根据贝壳的统计，工资和年龄线性拟合后得到的一阶近似方程为：y=-1.089*(x-1990.50)。带入贝壳的年龄，y=8.16。恩，贝壳当前的工资还是不错的，比平均值高。
6.语言分类
由于简历是python的职位，因此python的比例异乎寻常的高，无法作为可用结果。贝壳按照经验比例适当缩小了python所占比重，得到一个估计值。作为统计数据的修正，并列于下。根据贝壳的统计，使用java的人人数最多，占了38%，修正大约是40%。使用微软系列开发语言/工具的人其次，28%上下，修正大约是30%。使用php的人再次之，12%，修正大约15%。最后是使用C++的，8%，修正10%。真正使用python和其他动态语言的人，修正后大约是5%。由于职位不涉及前台，因此前台语言/技能不计入统计。
最后谈几个感想。
1.队伍水准不成比例
根据贝壳的经验，在多数的项目团队中，推荐的岗位配比是：1位项目经理，2位程序员，1位前台工程师，1位DBA，2位测试。如果可以，最好还有一个专门的文档和行政。这个人数配置适用于6-12人的团队管理，如果人数不足，可以减少文档和程序员。如果人数有多，可以增加2位程序员，1位前台工程师，1位测试。其中程序员、前台工程师的配比要基本保持2:1不变，程序员、前台加DBA对测试的比例要基本保持2:1不变。这可以说是项目团队的黄金比例，比例失调往往容易造成窝工或工作不完整，质量有瑕疵。
但是需要看到，这样的话要求2位达到3这个层级的程序员(PM和DBA)，但是最高只能带4名2这个层级的程序员。这个和当前的2,3层次的程序员的比例4:1严重不匹配。因此造成一个现象，3这个级别的程序员不足，1这个级别的程序员太多。
根据孟岩的blog，07-08年的IT从业人员大约是500-600万人，其中程序员大约100-130万。每年的IT行业毕业生大约是70-100万，其中能进入程序员领域工作的大约20万人。当然，他的blog是一年多前的，而且说的是毕业生就业问题。但是根据全球IT形势，我估计这几年里面程序员队伍规模即使增长也有限，不会超过150万人。也就是说，大约一年之内就要淘汰10%-20%的从业人员。根据上面的分布，贝壳猜想多数人都是倒在了2到3的路上。
2.小白丛生，项目倒霉
上面一个问题带来的麻烦是，由于小白的人数太高，因此价格太低。其中不免一些人有非常好的测试表现。这要一分为二的看，部分人是真有这个水准的，以小白的价格雇用到这些人是非常合算的(当然最多一年，不会太久)。但是多数人仅仅是表现不错而已，这些人工资低测试表现高，很容易进入项目。而进入项目后，一旦担任关键职务，后患无穷。实际上，整个团队中，水准1的小白可以担任的职位只有测试(而且必须至少要有一个是真的专业测试)和文档。但是仅这两个职位而言，远远达不到培养新人的目地。这也是很多小白倒在了达到普通程序员水准路上的原因。
更麻烦的是，如果突然招聘，很容易发生招到的程序员价格都偏高，而且很多都没定下来就先和其他公司签约了。这时候往往只有小白可以用，项目情况可想而知。
理论上可以开放一些职位旁观项目，实际上也有人这么做的。但是旁观项目是一个非常麻烦的事情。首先项目的旁观者不但对项目没有正面贡献，反而会拖慢进度(因为要占用其他人时间进行沟通)，因此旁观职位的工资应当是负数。而且多数公司项目第一，赶都来不及的时候谁会开放旁观职位。更不说光在项目中旁观是很难确实体会到那个职位上要面对的问题的。
3.项目经理的条件就是要做过项目
项目经理是一个非常专业的角色，这个职位和技术总监(或者叫核心程序员，高级程序员)、DBA并称是一个团队的三大核心。核心程序员和DBA可以慢慢学，但是项目经理是学不出来的。实际上，合格项目经理的必要条件就是带过一两个大型项目。问题是，如果想成为项目经理，你找谁让你带项目呢？
一种方法是跟随一两个项目，带一两个小项目，学整套的项目管理方法论，最后由一个成熟的项目经理指导你完成首个项目。但是实话说，这种方法只有对大公司有效，而且还的看你的运气。小公司里面哪里弄那么多人开两个团队？(原本的项目经理一个，你一个，这要35人以上的公司规模呢)大公司则是牛人太多，轮也不一定轮到你头上。
另一种方法是赶鸭子上架，等你毁过一两个项目后，也就学的差不多了。
实际上，国内由于PM(真正的PM，而不是挂这个名头的程序员或者其他捣浆糊人士)不足，而公司规模又不足，足了也没有培养人才的兴趣。因此大部分PM都是通过后一个途径培养出来的——
4.语言生态扎堆
我们开放的职位叫做python程序员，可我的邮箱里面有一半上下的人都是java和C#的资历(我不看他会的语言，而是看他资历的)，其中真正有python资历的人十不足一。实际上国内大部分的人都在学java和C#，做web和erp程序开发，大部分的小白其实扎堆在这里。真正成为3，4这个层级人才的，java/C#/C++/python的比例其实差不多，很接近。
实际上这和当前的语言生态有关。到也不是说这个生态有问题，而是这是当前现状市场化配置的必然结果。大量的小白(6成以上)集中到6成上下的低端web、erp和嵌入市场。这些市场的目标需求不复杂，没有重大的技术问题，服务器压力不大，因此小白足以应付。既然是小白，那就需要选择一种使用人数最多的语言(因为最好找人)。于是两大语言集团，java和ms系列的asp，asp.net就成为必然选择。
web行业和erp行业的几乎全是ms系列和java系列的语言，而嵌入式里面则大多数是C++(当然，也有j2me，不过那不完全输入嵌入式开发的领域，很多应当属于游戏领域)，这个是受限于嵌入式本身的技术特点。C++本身也有写的好和写的差之分，但是由于程序员要控制更多的东西，因此差的程序员很容易被识别出来，也更难在行业中生存。因此嵌入式行业的总体开发成本比web行业要高。
在我的行业中，缺少游戏行业的分析。这主要是因为我的简历里面几乎没有游戏行业的从业人员。我无法解释这个现象的成因，也许游戏正在从软件行业中独立出去，成为一门独立的体系。</description>
    </item>
    
    <item>
      <title>24点计算原理和程序</title>
      <link>//blog.shell909090.org/blog/archives/50/</link>
      <pubDate>Tue, 20 Jan 2009 14:49:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/50/</guid>
      <description>最近开心上狂算24点，于是贝壳搞了一个24点计算程序，并且说明原理。
我们将24点问题一般化，变成一个搜索问题。假定从一个初始表开始，里面有一些原子。我们定义一个操作，结合。每次操作任意从中选择出两个(或者以上)原子，使用算符连接，成为一个新的原子。那么，一般来说，24点就是计算所有可能的路径，从初始表开始，持续进行结合，直到只剩下一个原子，并且对这个原子求值得24。
有人可能在算符优先级上想不开，其实不用考虑这个问题，每次求值的时候，按照求值顺序优先就可以。你想到的另外一种优先级可能，会在穷举的时候被列举出来算掉，不用担心遗漏。
同时，算子必须是两目以上算子，因为单目算子可以持续作用于同一个对象，因此原子表中的原子个数并不严格单调减少，造成无法肯定路径收敛于有限步骤上。并且，如果允许单目算子，那么我只需要求导和阶乘就可以对任何数字求24点。
((a&#39;)!+(b&#39;)!+(c&#39;)!+(d&#39;)!)!=24  因此，单目算符是没有意义的。
另外，注意算符分可交换和非可交换的。例如：a+b=b+a，但是a-b!=b-a。如果不注意这点，倒是不会漏算，但是会造成搜索空间增大，并且有重复结果。
以下是24点计算程序，python版本的。有兴趣的朋友可以用scheme重写，相信会更简洁有效。回头会用django封装一下，做成网页给大家玩玩。
#!/usr/bin/python import sys symbol_list = [ (&amp;quot;%s+%s&amp;quot;, True), (&amp;quot;%s-%s&amp;quot;, False), (&amp;quot;%s*%s&amp;quot;, True), (&amp;quot;%s/%s&amp;quot;, False), (&amp;quot;%s**%s&amp;quot;, False), ] def diff_seq(length): for i in range(0, length): for j in range(i + 1, length): yield (i, j) def get_less_state(input_state): for i, j in diff_seq(len(input_state)): temp = input_state[:] del temp[j] del temp[i] for s in symbol_list: rslt = s[0] % (input_state[i], input_state[j]) rslt = &amp;quot;(%s)&amp;quot; % rslt temp.</description>
    </item>
    
    <item>
      <title>SCIP,lambda,Church</title>
      <link>//blog.shell909090.org/blog/archives/45/</link>
      <pubDate>Mon, 10 Nov 2008 14:08:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/45/</guid>
      <description>贝壳最近在看SCIP，感觉受益匪浅。其中有一个2.6，使用函数表达数字，很难理解。贝壳查了查资料，这篇（http://blogs.sun.com/yongsun/entry/lambda%E6%BC%94%E7%AE%97%E4%B8%8Echurch%E8%AE%A1%E6%95%B0 ）写的很好，贝壳就不多说了。贝壳把自己写的内容贴上来，作为一个借鉴。
(define zero (lambda (f) (lambda (x) x))) (define one (lambda (f) (lambda (x) (f x)))) (define two (lambda (f) (lambda (x) (f (f x))))) (define three (lambda (f) (lambda (x) (f (f (f x)))))) (define (add-1 n) (lambda (f) (lambda (x) (f ((n f) x))))) (define (add m n) (lambda (f) (lambda (x) ((m f) ((n f) x))))) (define (mult m n) (lambda (f) (m (n f)))) (define (show-func-number n) (define (inc x) (+ x 1)) ((n inc) 0)) (display (show-func-number zero)) (newline) (display (show-func-number one)) (newline) (display (show-func-number (add-1 one))) (newline) (display (show-func-number (add one two))) (newline) (display (show-func-number (mult two three))) (newline)  结果：</description>
    </item>
    
    <item>
      <title>程序生产流程管理的一些想法</title>
      <link>//blog.shell909090.org/blog/archives/42/</link>
      <pubDate>Tue, 21 Oct 2008 13:12:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/42/</guid>
      <description>程序的生产管理本质上说应当可以纳入生产管理中，然而程序毕竟是一种特殊的产品，因此程序的生产管理也有其特殊性。下面贝壳从小到大阐述一下个人对生产管理的一些想法。当然，30人以上的团队规模贝壳根本没有碰到过，因此就不予置评。
首先我们从软件的生产流程开始论述，当然你可以没有流程，然而你不能没有过程。没有流程叫做不正规，低成本和高效率，没有过程……没有过程我也不知道你怎么做的，直觉？
管理的头一步是计划，软件生产的头一步是调研和需求分析，然后是紧密关联的系统构架，包括构架选择和结构设计。调研的典型情况是回答以下问题，软件为了谁而做(Who)，设计周期和维护周期是多长(When)，软件的适用范围(When)，软件的意义和核心价值(Why)，软件要达成什么目的 (What)，如何设计达成这些目的(How)。这些问题中，要达成的目的和如何达成是核心。而后通过详细的讨论，得出到底要做什么东西，具备什么功能，以及一些细节问题。这时期形成的是软件需求分析报告和软件需求说明书。需求说明书的尺度是一个很难把握的问题，一般来说，需要灵活对应市场反馈的软件，需求说明书不用过早细化，反之则可以早细化一些。开发人员多，结构复杂的系统，设计说明书必须详尽，反之则可以简单一点。不过如果忽视甚至无视需求说明书，或者将需求说明书仅仅作为一个官样手续的团队，必定会在后面吃大苦头。如果要规避需求说明书，也并非不可以。贝壳会在最后描述一个原型系统方法，来规避灵活和不确定的需求对需求说明书的挑战。然而注意，这只是需求说明书的形成手段，本质上是以程序员和最终用户的互动来清晰需求，同时潜在的让程序员熟悉需求。并非真的不用讨论和细化需求，更不是提倡做项目不出需求说明。
项目的构架选择是在基本明确需求后做的事情，这个阶段主要明确以下问题。是单机软件还是群体软件，C/S还是B/S，.net还是java还是 C，Windows还是Linux。中间是否使用ORM，使用的话怎么设计细粒度表，不使用的话怎么使用冗余设计。结构设计和构架选择互相分离又紧密结合，结构理论上是脱离构架的，然而某些结构就必须适用某些构架(例如如果用了事务明显就不能用mysql，性能会差死)，某些构架则要求你特殊设计结构。结构设计是系统一个非常广阔专业而复杂的问题，有兴趣的可以看系统结构和构架的一些书，还有设计模式和UML的，这里就不细说了。
在系统完成结构设计后，就开始系统的编码过程了。而项目时间确定，到这个时候才有依据。粗说是编码过程，其实又细分为构架实现，技术研发，编码，自测试，系统整合几个部分。结构设计完成后，抽象的结构必须经过严格定义才能进行使用，其中进行严格定义并且文档化的过程绝对不要轻率处理。如果是大型团队，应当指定一个人负责结构定义的维护，并指定几个技术骨干来讨论定义，讨论修改。这个人需要处理每一个对结构修改的请求，分辨是否应当修改结构，并且交给骨干团队讨论。讨论确定后，对定义进行修改，修改定义文档，并且通知所有部门进行修改。
当结构定义后，系统的框架模型已经清晰可见了，剩下的就是编码了。可是否能进行顺利编码呢？未必可行。因为实际上会在过程中碰到很多技术问题。例如需要使用以前没有接触过的框架和组件，需要对抽象数学模型提出可行算法等等。这些问题如果不先行解决，后面的编码无法顺利进行，技术骨干的最主要作用就在这里。在他们解决技术问题后(或者，更经常的，在中间提出的问题被他们解决后)，系统就进入了编码阶段。编码阶段的代码一般来说会有不同级别的自测试，从最简单的写个小程序到最复杂的单元测试+冒烟测试，按照项目的级别具体分析。不过即使是再小的项目再小的模块，一般写一点代码就写个小片断测试下是否可行是最基本的常识，除非你能保证所有程序不论大小一次写对。在完成自测试后，还需要整合入系统，并可能伴随冒烟测试。如果结构设计良好，这个阶段会非常顺利，甚至不出现什么大的问题。反之，如果结构散乱，不用到客户那里，在这步就会碰到非常大的阻力。
在完成主程序的编码和整合后，项目进入收尾阶段。一般是漫长的测试和后续工作，主要包括叠代测试，性能分析，编写使用手册和编码手册，编写项目的技术分析，系统分析报告和各种材料。在这个阶段最主要是要通过测试，先于客户找出错误，并且逐步修改掉。良好的测试结果应当是逐步收敛的，当你看到一个逐步发散或者不稳定，根本没有规律的测试修改结果时，你的麻烦就大了。这通常是因为没有构架，构架错误，中间有不适应构架的修改，构架变化，核心算法错误，需求浮动太大等根本问题所导致的。当然，在测试的同时还要进行全面的文档化过程。
在测试和交付后项目是否结束呢？恐怕还没有。下面是漫长的客户服务期，需要收集和分析客户反馈，进行持续改进。不过那就是后面的问题了。下面我们按照团队的大小来逐步讨论团队的分配和任务。
首先是从一人团队开始，当然，如果也能叫团队的话。作为一人团队，也就没有什么分工问题。文档化要以轻量为主，方便自己日后理解，除非是客户特别需求。
而后是典型的一个团队，一个PM带几个技术，可能还有外面的美工支援什么的。人数不超过五人，不分组。这里前期的需求/后期文档都要由PM完成，程序员主要注重编码和测试(尤其是单元测试)。如果时间充裕，建议一些专门编码一些专门测试，这样可以有效保证代码质量。互相的沟通以开会为主，信息的沟通要诀是让每个人都知道别人的事情，尽量多的向别人传递信息。
再下面是一个典型的“大”团队，两个PM带四个程序员四个测试，其中有两个以上技术骨干，再加上一个专职美工和专职的UI Design(或者两个美工，基本差不多)，8-16人的“大型”团队。说大型是因为这个团队开始内部就要分工协作了，加引号是因为……即使10个人，基本也就刚够分工的底线而已。
贝壳个人建议，除开美工等支持岗位，将这种团队分成三个部分。一个是PM组，负责和用户沟通协调，产生需求文档，盯项目进度，调度程序员，产生用户文档，产生其他材料。这组PM不要求高技术，对于技术建议会用，但不用精通(最好也别精通，业务骨干做PM是非常浪费的)。但是对于沟通技巧，协调能力和领导能力要求非常高，也要求有相当的文字功底。毕竟他们是要和客户沟通的人，要是鸡同鸭讲就麻烦了。和客户产生矛盾，文档写不好，更是麻烦中的大麻烦。由于协调要求非常高，因此PM组强烈建议至少两人，手机24小时开机！建议设立正副职，采取正职负责，副职挂钩的方式。
第二个团队是研发组(Dev)，至少一个技术骨干带队。这组需要负责编码，自测试，系统整合，出开发文档，出技术文档。对于他们要求是沟通能力过关，程序编码效率高。对于系统经验，思考方式的全面和独特没有特殊要求。一般经过培训的新程序员就可以在研发组中担任工作。他们年轻力壮精力旺盛，相对编码效率比较高。不过如果有条件，还是用比较有经验的程序员比较好。在系统的整合测试，返工引发的效率低下控制方面会有相当的好处。
第三个团队是测试组(Test)，至少一个技术骨干带队。这组要求负责系统的叠代测试和性能测试，可能还要帮助编写用户文档，进行项目实施，培训和售后支持。这组人的要求是工作勤奋(叠代测试的工作量是非常高的)，技术过关(否则无法发现一些问题)，系统经验丰富，思考问题全面而独特。因此强列建议由最强的技术骨干和一帮能吃苦的年轻人组成。一般来说测试组和研发组的人员比例在1:2到1:1之间。如果小于1:2，那么会发生测试不充分的情况。如果大于 1:1，只要成本允许，到是强烈支持。
最后一个团队(有人算了算……怎么还有)，是系统的管理组。负责项目的构架选择，结构设计，时间节点认定，人事事务，开发成本控制，技术研发。这个团队有非常高的技术能力，管理能力和执行权限，一般由主PM，研发组和测试组骨干，客户代表，公司代表(多数和主PM是一个人)组成。主要是要对项目过程的监控，项目中人员权限的分配，核心技术的研究和管理进行处理。这个团队等若公司和客户的联合代表，对项目负全部责任。
对于30人以下的团队，估计可以按照比例放大组规模来使用同样的组织结构。不过如果再大，同样结构就不合适了。这主要是因为同一个组中的信息是互相完全流通的，超过10人的组会造成非常高的沟通成本。这时候一般是分解系统结构，分解研发组和测试组。将一个大型系统分解为两个或者多个独立的部分，让每个组分别研发和测试。这样可以避免每组内的信息沟通成本过高，可对文档的严密性和规范性提出了更高要求。通常来说，拆分方法有按照功能和按照构架。即按照功能划分出一个一个的业务模块，每个组开发一个完整的业务模块。和按照构架层次分为数据库组，业务逻辑层组和客户层组。通常来说，我支持以业务为主的拆分方法。因为此时组已经够大，让一个组精通所有层次不难。但是让所有组全部完整了解需求可就很难了。
对于这种成规模的开发，注重的主要是两点，文档和测试。最高的要求(也是我认为最好的褒奖)是及时的文档和全面的测试。此时的难点在于，研发过程中程序员经常为了修补问题而修改代码，但是忘记修改程序文档。或者需求变更后PM改了需求说明，通知了Dev，但是忘记通知Test。又或者通知了Test，但是忘记修改用户手册。因为诸多文档其实是对同一内容的不同描述，所以相互具有关联性。其中之一变化经常导致其他文档落后陈旧，而且版本不统一。
测试应当贯穿正规研发过程。从程序员实现一个个功能起就应当开始叠代，直到项目完成后。并且bug的管理应当和需求管理合并，成为几个组沟通的核心。测试的时候一定要注意充分测试和叠代测试，不要象微软一样弄出新的补丁补出老Bug的状况。
下面贝壳讲以下系统原型法，其实这个就是业界常说的敏捷开发。系统原型方法是指以构建非常简单的系统，实现非常核心功能的原型系统为基础，逐步推导出正规系统的功能和需求的系统分析方法。主要适用于系统需求不清晰，分析困难，开发周期短，程序员数量适中的项目。如果上述条件不成立，那么建议不要使用原型方法。
原型法的头一步是分析需求，不用说不确定的，就说为了实现业务目的(至少这个应该知道吧？)需要哪些功能。然后实现一个可用的，不用很美观，不用性能优化的系统。有了这个系统后，客户可以逐步分析使用这个系统哪里不方便，而后交给程序员改进。逐步反复，直到客户满意为止。使用这个方法，客户和程序员间，程序员互相之间要保证充分沟通，文档可以容后再写(前期还不确定呢，怎么写？)。主要是注意逐个的需求管理和Bug管理，这正好和我上面说的合并管理对应。使用这个方法的好处是当不清楚需求的时候可以马上做，逐步清晰。过程比较直观，做出来东西比较实用，也节约时间。坏处就是会浪费一定的程序员人力，而且一个没控制好就一直改一直改不知道哪里是头了……
当前国内软件业企业的几个问题就是，不注重需求，不注重测试，不尊重专业，不尊重规范，不培养人才，不积累技术，不重视信誉，不打算做事。下面贝壳逐个细说。
不尊重需求，一般来说，老板讲的时候都是需求为重的，可当客户需要变的时候，老板很容易同意需求变更(虽然我可以理解，做生意也不容易)。不尊重测试，做程序的非常理解测试的重要性，然而老板却认为那个岗位可以随便找个人来做。实际上，测试是一个非常专业非常流程化非常严密的东西，测试的主管最好是公司里面最有经验的人。同时，还有不尊重专业的问题。并不是说老板干预程序员的决策，而是很多时候老板根本不了解技术骨干和PM，测试的区别。让技术骨干来做策划，或是负责、或者主导和客户沟通，这都是超级缺乏效率的做法。至于不尊重规范，事先划定的流程，在遇到重大问题的时候，往往就变成了废纸一张。到不是说在重大问题前非要坚持僵硬的步伐，可一个项目一半时间都是重大问题，这就过分了把？先说了项目过程中要推进知识积累，推进技术交流，推进这个推进那个，等项目一忙就全飞了。
同时由于程序员的超高流动率，当前中国的程序界有一个非常不良好的风气，公司基本不培养自己的程序员。都不知道公司是否能开到明年呢，培养了做什么呢？这点在大型公司就比较好，无论什么情况，基础的内部交流总是保证的。只要签长约，多数可以弄到一些培训。中小公司不培养人才一方面是没有必要，另外一方面就是没有能力。于是程序员就被迫自我培训，自学或者脱产参加培训。付出了成本，自然要赶快跳到能实现价值(能把钱赚回来)的公司里面去。中小公司为人员流动付出巨额成本，而且很多都根本无知觉。
举贝壳公司的例子吧。因为发展需要，今年年初公司曾大型招人，C#程序员，结果可用者寥寥无几，很多都是浮夸碰运气的。以至于一天面试十多个人，竟然一个备选都没有的情况经常发生。一个人过来投简历，硕士，要价10K多。不说公司能否负担，看了看做的题目，算法题还不错，C#技术，解决实际问题都一塌糊涂。这种人招进来差不多就是研究算法写Paper的主，要做程序还得培训一下。还有一个人，我前周刚刚送走，转眼又回来，估计是批量投简历的时候忘记筛公司了。还有一个项目经理真的是不错，讲起问题来很深入，经验丰富，可老板认为用不到，贝壳一点办法都没有。由于人员仓促到位，我们在开发后期付出惨烈代价！有一个程序员从到岗到离开公司，最大的贡献就是拖了三个多月的进度，因为他连static函数干吗用的都不知道。还有一些人，很适应岗位，可做不到多久就走了(当然，这是有各种原因的，试用和刚满期的人走是比较正常的事情)。问题是，其他人就要重新接手他的事情，等来了人再换手。这样的直接结果是什么呢？如果说项目拖延有一半是因为我们需求没做到位，另外一半就是团队的人才损失。如果在普通项目上碰到类似问题，来的人不能做事情，人员替换率高。那么本来能按时完成的任务就一定会延后，而且分析的时候很难直接表现出来，多数会被认为是工作效率不够高，工作态度不认真之类的(某种意义上也没错，毕竟不能做事的人，不是因为效率不高就是因为做事不认真)。不能留住人才造成的后果，是通过项目拖延表现出来的，使得公司往往失去了隐性可能的良好口碑。这种软性杀伤是非常致命的但是又是难以直接表现的。
如果说不注重人才，还怎么能积累技术呢？人是技术最主要的载体。尽管我们可以通过互相培训，技术交流，技术文档化来积累技术。但是如果没有老员工的指点，那么新员工是很难吸收企业的原有技术体系的。无法积累技术的直接表现有两个，一个是中国企业没有核心技术，另外一个就是掌握技术的人就卡了公司的脖子。可能有人会举出中国有多少专利多少成果。贝壳告诉你，按照贝壳做项目的经验，那个多数都是项目做好了用来表功的牌坊。很多技术都是公司不敢给个人，个人不敢给公司，因为浮动率太高。许多真正有价值的核心技术往往是因为缺乏大公司(或者缺乏人)作为后台，而无法正式的走向商业化运作，更无法走向系统化理论化。因此中国不但缺乏真正的核心技术(我指能解决问题，有实现难度的技术)，更缺乏(这点可以确认)系统化理论化的技术体系。而掌握公司核心技术的人往往就能卡公司的脖子，尤其是技术都掌握在一个人手中的时候。并非说程序员都有坏心或者什么的，而是程序员有很多和老板不一样的想法(例如要重视测试，要重视专业等等)。当程序员觉得他是对的时候，为了和老板争辩，往往会使出走人的杀手锏。固然，公司是对产品拥有产权的。可是掌握核心技术的人不在，没有人能继续改进，研发新的产品系列，这不是要公司的命么？这时候老板就处于弱势的一方。从某个事情来说程序员往往是对的，可是从企业发展来说却绝非好事。
最后两个问题则是中国软件业更深层次的问题，不重视信誉，不打算做事。整天就想着前辈一夜暴富的事情，或者谁谁风投成功吃喝不愁的事情。根本不打算花心思将事业做好，而是设法请客招待人拉风投，找人做假买点击量买排名，花钱黑掉对手的网站，盘剥底层员工，炒作一些无聊的事情增加知名度。某种意义上说，这个才是中国软件业最大的毒瘤。</description>
    </item>
    
    <item>
      <title>分词算法的具体实践</title>
      <link>//blog.shell909090.org/blog/archives/40/</link>
      <pubDate>Sun, 12 Oct 2008 09:27:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/40/</guid>
      <description>说到分词算法，可能很多人都很陌生，然而说起百度，google，很多人却是耳熟能详。google，百度在搜索的时候，输入关键词后瞬间就可以得到结果，如果用通用数据库是无法做到的。实行这个加速的关键就是分词算法。例如&amp;rdquo;项羽是萝莉控&amp;rdquo;这句句子，我们一般搜索都是搜索项羽，或者萝莉控，萝莉。你见过有去搜&amp;rdquo;是萝&amp;rdquo;这个关键字的么？因此系统通过分词，将句子分解为&amp;rdquo;项羽/是/萝莉控&amp;rdquo;，去处单字常见词&amp;rdquo;是&amp;rdquo;(如果要索引&amp;rdquo;是&amp;rdquo;，可以想像有多少文章没有&amp;rdquo;是&amp;rdquo;的)，我们就得到了项羽和萝莉控两个词。再通过反向关联，建立项羽，萝莉控指向文章的连接，就可以完成瞬间的搜索了(具体原理不说了，只要有一定数据库基础的人都应当能想明白原理)。并且通过关联性，某种程度上也可以提供&amp;rdquo;是萝&amp;rdquo;的搜索(带&amp;rdquo;是&amp;rdquo;的词，带&amp;rdquo;萝&amp;rdquo;的词，相关度最高)。
那么，如何来计算分词呢？方法很多，大家可以在网络上搜索下，贝壳就不赘述了。贝壳现在要说的是这次贝壳主要试验的方向，基于词典的机械分词中的最大分词算法。
机械分词算法是当今的主流，关键原因在于速度问题。虽然正确的分词很有价值，然而如果速度太慢，一样没有什么用处。机械分词一般可以保证 98%-99.5%以上的正确率，同时提供极高的分词速度。而机械分词一般来说，都是基于词典的。主要有正向分词算法，逆向分词算法，最大匹配分词算法。其中最大匹配分词算法具备最高的灵活性，只要你能评价一个切分的优秀程度，算法能把所有可能算出来让你评价。然而大家可以想像，这个是非常耗费CPU的。贝壳在这个基础上，做了一个具体的实现和细化加速。并且有准备做为一个开源项目来长期运作(只要有人有意向接手合作)。
首先我们先说贝壳这个算法的评价原则。贝壳认为，评价原则应当有以下几点。同时也必须要说明，以下原则是无法正确评价所有情况的。不过以下原则在原则正确的基础上比较便于优化。一、无法分析的词最少(这是全局最大匹配的理论核心)。二、匹配出的原子最少(这是保证分词优秀性的指标)。三、匹配出原子的出现概率和最高(这是纯粹没有办法了从概率上提高匹配正确的可能)。
当我们分析一句话的时候，我们可以想像，这句话应当是正常的，可被理解的。换句话说，句子中应当都是有意义的词。那么，在匹配后无法理解的词是什么呢？一种是匹配错误，一种是新单词，一种是单字成词和无意义助词。单字成词的例子有上面的&amp;rdquo;是&amp;rdquo;，我们可以通过一个比较小的词典去除。那么，假定词典够大的情况下，无法理解和分析的词越少的组合越正确。而同样一句话，匹配出的原子越少，在搜索的时候效率越高。因此我们有规定了原子最少原则。至于最后一个，在无法分析词一致，原子个数一致的情况下，我们只能通过出现概率来猜测可能性。
然后，现在让我们分析一下分词的特点，并且做一定的优化。首先就从最著名的例子，&amp;rdquo;长春/市长/春节/致辞&amp;rdquo;开始。
长春市长春节致辞  首先，匹配算法一定要先搜索到一个出现的词，有词才有匹配优化问题。没有词的话，你试试看分词&amp;rdquo;嗡嘛呢呗咪吽&amp;rdquo;。根本无法可分。因此首先我们要计算出一个出现的单词。贝壳是从正向开始计算的(主要是因为词典的加速方法是头索引的)。
*长春*{市长春节致辞} *长春市*{长春节致辞}  好的，我们匹配到了两个，不过这就是全部可能么？不是，否则就变成了正向最大搜索。你可以看看&amp;rdquo;有意见分歧&amp;rdquo;。如果从头一个匹配到开始计算，无论如何都是&amp;rdquo;有意/见/分歧&amp;rdquo;，而事实是&amp;rdquo;有/意见/分歧&amp;rdquo;。因此我们还有一种可能，在头一个匹配到的位置，其实并不匹配。不匹配多长呢？最大长度不会超过最短的匹配词。为什么？我们来看下面一个例子。
*长春*{市长春节致辞} *长/春/(这两个字不是词，而是两个无法理解的字){市长春节致辞}  很明显，后一种分法违背了我们的第一原则，无法分析的词最少。无论后面怎么计算，其最优结果是相同的。在后续结果相同的情况下，头一次匹配到词后，所有可能的跳空(搜索可能的不匹配)最大长度严格小于最短匹配词的长度。
那么是否所有跳空都要搜索呢？也不，我们可以继续剪枝。对于情况&amp;rdquo;有意见分歧&amp;rdquo;来说，这个路径是必须搜索的。但是对于我们的例子来说，是无需搜索的。为什么呢？我们看以下计算。
*长/{春市长春节致辞}(下一个匹配是什么？总不会是春市吧，所以应当是&amp;quot;市长&amp;quot;) *长/春/市长*{春节致辞} *长春*{市长春节致辞}  大家可以看到，其实这个路径是无需计算的。那什么情况下需要计算呢？
一旦跳空，其跳空后寻找到的下个词的位置必须严格小于最短词的词尾位置。否则就没有搜索价值。具体可以看以下示例。
XXXXXXXNNNNNNNNNNN(X是词，N是无关紧要的)
SSSSSSSXXNNNNNNNNN(S是跳空或者跳空后形成的无法理解字，X是词，在这种情况下，无论后面怎么评价，都不影响该匹配被剔除)
OK，我们回到例子，刚刚我们说了，有&amp;rdquo;长&amp;rdquo;的匹配。但是通过刚刚的剪枝，又被剪了出去。我们下面分别计算两个情况。
市长春节致辞 *市/{长春节致辞} *市长*{春节致辞} 长春节致辞  好，我们先不计算下去了。通过上面的计算，我们发现，在计算过程中经常需要计算同一内容的结果。我们可以想一下，同样的分词，同样的算法，出现的应当是同样的结果。就是说，分词函数是状态无关的算法。通过分解一个单词，得到一个最优结果。那么，我们对于同样的数据，何必需要计算两次呢？贝壳上文中提到过记忆函数，这次就用上了。根据贝壳的试验结果，如果记忆全部词的分解结果，会造成大量的记忆-释放，而内容基本没有用到，造成效率下降。如果只记忆长词的分解结果，往往又会因为太长，大多数句子无法达到长度而根本没用。这中间有个平衡值，具体多少贝壳就不说了。我们可以按照上文的方法计算以下两个过程，得到结果。大家可以自行验证。
春节致辞 *春节*致辞* 长春节致辞 *长/春节*致辞* *长春*节/致辞*  结合上面的过程，我们推算得到结果。
*长春*{市长春节致辞} *长春*市长*春节*致辞* *长春市*{长春节致辞} *长春市*长/春节*致辞* *长春市*长春*节/致辞*  按照上面的评价原则，我们得到了正确的结果。
大家可以看看其他例子，这里着重说一下&amp;rdquo;有意见分歧&amp;rdquo;。
有意见分歧 *有*意见*分歧* *有意*见/分歧*  注意，有是单字成词，见可不是。如果见单字成词，做看见讲，那这句话就彻底成歧义句了。可以理解为，有意的要看到(或者让其表现出)分歧。这一般是古文语法。由此也可以看出上述原则在理解古文的时候往往会出现问题。同时还要指出的是，在匹配&amp;rdquo;长春市长春药店&amp;rdquo;的时候，会出现以下结果。
长春市长春药店 *长春*市长*春药店* *长春市*长春*药店*  两者的无法理解词都没有，切分数一致，最后硬是因为春药店出现概率低而被筛掉。可见系统有的时候是依赖概率和人品在工作的。
经过上面的原则和算法，贝壳实现了一个python的分词程序，1000行代码，原型系统。90W条词情况下，在AMD MK36上(2G主频)分词效率66K/s上下，具体看分词的选项(例如顺序分词就比较节约资源，分词排除重复就比较慢，启用多线程后在单CPU 机器上更慢)，内存使用114M。使用C++写的核心词典后，90W条词的情况下分词速度80K/s，比python的核心词典快了20%，内存70M，节约内存40%。不过可惜，这个核心词典是公司产权，贝壳无权公布。并且贝壳做了一些工作，准备使用分词程序来生成分词词表。这个么贝壳就不准备讲了。前面讲的内容贝壳准备放到试验型站点 http://shell909090.3322.org/split_word/split_show/ 上面去，08年内有效。有兴趣联系我的可以发 mail给我，shell909090+split@gmail.com，欢迎大家试验并提出意见。</description>
    </item>
    
    <item>
      <title>苏博婚礼回来暨python2.6发布</title>
      <link>//blog.shell909090.org/blog/archives/39/</link>
      <pubDate>Mon, 06 Oct 2008 15:50:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/39/</guid>
      <description>这次10.1算是个大日子，因为我们可爱的苏博终于和他美丽的新娘结婚了。据说两个人相识10年拍拖7年，找的高中班主任做证婚人。实在有点为难人家，到底说高中就好上了呢？还是高中没好上？不过总而言之，他们总算结婚了。具体苏博是怎么被我们蹂躏的，以及婚礼的起因经过什么的就不写了，毕竟我不是新闻记者。这次就写一些有趣的事情和感想。
首先是去震泽的车子，因为10.1的关系，并不怎么好去。不过坐在车上晃晃悠悠两个小时，看旁边的河跟路一起走，感觉还是很不错的。江南不愧是水乡，有条河就在我们的路旁跟了10多分钟，还有条船跟我们并排跑。震泽古镇也很灵的，宝塔街古香古色，保证没有现代元素，除了大头发现的几个公共厕所外。建议大家有空可以去看看，苏博的家乡。
而后是新郎和新娘的一个让我比较震撼的问题。婚礼上，主持人问新娘的大学同学，是否在校园里面经常看到新郎。人家说，一直以为苏於良是南大学生。我吓一跳，南大啊，我一直以为王苏瑾在上海念大学。由此我得到一个结论，远距离恋爱是否会失败，和双方爱对方的程度无关，而和双方把爱付诸行动的程度有关。其实不光远距离恋爱，婚姻也是一样。认识我的人都知道我的两个总结。夫妻双方性格相近或相反，价值观一致。今天看来还要加一条，愿意将爱付诸行动。
然后是婚礼前一天，阿丁同学打过来跟我哭诉她和她男友的情况。实话说，虽然被哭诉半天，但是我还是搞不清楚她和她男友的状态，总之是非常复杂一团浆糊。因为隐私关系，我不打算说她和她男友的具体状况。不过大致就是她很喜欢他男友，喜欢到没有自我没有尊严。他男友呢，则是有点——不知道怎么说。说有问题吧，说不出来，说没有问题吧，情况确实——不怎么好。而且她本人处理事情上也不是没有问题，我觉得这个应当叫孽缘吧。不过无论如何，我的建议是——分手。
然后我就建议阿丁同学到震泽来玩一天，反正黄禹同学正好没来。然后她跑来玩了一天，回去和我说了一句雷晕人的话。我彻底无语了——
无论如何，那是她的家事。
再后面就是苏州到上海的车，同样也不怎么好弄。我问今天又没有去上海的车，最好是动车。回答说有，动车。我说来两张票（帮人代买一张），售票员说，晚上11点半的哦～～
我彻底无语。
后面一个朋友则更悲惨。他问，今天到南京的车票还有么？没了。明天的呢？也没了。后天的呢？我们只发售今明两天的～～
最后我们坐大巴回来的。
最后的最后，说一下，python2.6发布了，虽然我不打算用。比以前在构架上有了不少进步，不过很多东西暂时没有这么快迁移过去。我打算等3.0出了后直接用3.0，反正程序是一样写的。</description>
    </item>
    
    <item>
      <title>语言的对比</title>
      <link>//blog.shell909090.org/blog/archives/34/</link>
      <pubDate>Wed, 10 Sep 2008 20:36:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/34/</guid>
      <description>最近贝壳在学(或者准备学)三门语言，python，ruby，scheme。全部都是高级抽象语言，都是脚本语言。加上贝壳本身已经非常熟悉的几门语言，C/C++，Java，Asm，bash，贝壳这次是正宗的要&amp;rdquo;精通&amp;rdquo;七门语言了。当然，如果加上勉强会用如vb这些，十多种也不成问题。做为一个学了多种语言用了多种语言的程序员，我想写一下自己多这些语言的认识，作为后来者的参考。
首先是C，当然，是不包含C++特性的C。这门语言可以说是贝壳所见的语言中，最强大最广泛最具备生命力的语言。其他任何一种语言说到混编接口，基本就是C语言接口。C语言也可以模拟非常多的特性，COM，C++，都可以用C模拟。当然，模拟的复杂程度是另外回事情。并且可以编写其他语言的解析器/虚拟机，而这点来说其他语言很难做到。其实本质上说，C语言就是跨机器跨平台的万能汇编语言，所以才具备这些强大特性。C的核心思想是指针，其整个语言构架都是基于指针的。通过指针，我们直接操纵着内存地址的读写。当然有利必定有弊，C语言太难掌握，效率太低了。使用C写代码，就是和机器打交道。你得控制数据的读出写入，控制设备的初始化，控制内核交互。根本上说，一个强大的C程序员，并不强大在算法和创意上，而是强大在对系统的方方面面的了解上，强大在对基础原理的掌握上。
其次是C++，说实话，这语言有点高不成低不就。如果要掌握系统的方方面面，他不比C。如果要抽象要构架要快速要敏捷，他比不上所有的抽象语言。但是 C++的长处在于在系统的层级上引入了算法抽象，增强了编码效率。如果你确定需要在系统层级上编程，又不高兴从C的角度去写。C++可以极大的增加你写代码的速度。当然，他的弊端就是对底层的掌控力和抽象实现的复杂程度。C++(我指的当然是包括STL和Boost的)的长处在系统层级，所以你写代码的时候必须了解抽象的实现方式。然而抽象实现的越强大(例如boost的share_ptr)，其底层的机制就越复杂，你掌握的时间也越长。而如果不了解底层，往往会发生很多很奇怪的问题。例如smart pointer的问题，在其他语言中，这是语言系统的bug。而在C++中，则是你自己的问题。因此，想要真正玩好C++的程序员，必定首先是一个C高手，而不是拿着C++的OO特性把C++当普通OO语言的人。
再次是Asm，这种语言可以说没有什么生命力，因为他变化的太快了。一旦硬件构架改革，汇编就要调整。而且抽象层级不够高。除非你正好做操作系统底层，编译器优化和系统破解，否则最好不要考虑这种语言。这种语言的核心构架是寄存器。
然后是java，当然，还有很类似的C#。这类语言开始，语言的抽象层次提高了，因此可以提供反射(python中叫做自省)。反射是高级语言中必要的特性，然而C/C++并没有提供，原因么则必须说一下编译型和解释型语言。一般语言分为编译型和解释型，编译型的代码成型后只需要相关的库支持(其主要目的是代码复用减少复杂度和内存消耗)，而解释型的语言需要解释器。如果仅仅从方便使用角度说，解释型语言远远不如编译型(因为要单独安装解释器，当然，像 bash这类怪胎就表说了)，而且解释型的语言运行效率仅有编译型的1/10左右。然后当今语言界，编译型语言远远比不上解释型使用广泛。其根本原因有三个，一个是编译过程，一个是反射，最后一个就是内存管理。
如果读者有编译代码的例子，应当知道，除非在同等的条件下，否则编译C++代码是很麻烦的事情。而配置同等的编译条件则彻底失去了C++跨平台的意义。因此C++在不同平台下反复编译的时候，需要考虑大量的问题来达到跨平台的目的。往往这种事情麻烦到需要作者亲自指导编译的地步。如果一个软件，发布的时候声明可以跨平台，然而使用前需要作者指导用户做一堆繁复的操作。估计这个软件只会受到专业用户的欢迎吧。
所谓的语言编译，其实需要经过两步，编译和链接。编译的主要目的是将每行代码翻译成对应的汇编语言，而链接则是将符号引用转换为地址引用。举例来说，我使用了一个变量str来存放一个字符串，这个变量str就是一个符号。我需要在上文中声明(declear)这个变量，以便编译器在编译的时候代换这个符号对应的内存地址，和理解如何使用这个符号(关于上文没有声明的情况下的错误，请看&amp;rdquo;向下引用&amp;rdquo;特性)。我使用str的第四个字符的时候，str[3]就会被翻译到固定的内存地址或者基于基址的偏移，机器完全不用理会str是什么。而这点，则是反射实现的最大障碍。反射可以提供一个对象是什么，有什么的信息，并且可以动态创建对象。有了反射以后，才可以实现序列化，分布式等等高级应用。而C类语言在编译后失去了符号是什么的信息，只剩下一个名字，链接后连名字都没了。这种情况下，你怎么知道一个对象是什么呢？
Java/C#可以提供反射，因此属于解释型语言。但是他们又不属于完全的解释型，而是解释型的一个特殊分支，中间代码。中间代码型的语言，需要编译，执行的时候又需要解释器。看起来没什么好处，可是在支持反射的基础上，大概可以以C代码1/2的速度运行，比纯解释快多了。原因何在呢？我们可以看看 C++为什么不支持反射。反射是保存针对执行结构的数据并且提供交互，而C++则在编译时生成后丢弃了这些数据。因此，理论上说只要保存了这些数据就可以实现C++的反射。这就是中间代码语言所做的事情。当然，考虑到跨平台特性，编译的结果并不是汇编代码，而是类似汇编的代码(Java叫P代码，C#叫 IL)。后JVM直接执行P代码，C#则通过引擎编译IL到本地代码。因此JVM执行的时候效率基本恒定，而C#初次执行速度慢，后来则是比C++慢不了多少。
最后就是Java/C#的最强特性，动态内存管理。使用这个特性，可以使得程序员彻底的从内存分配和管理的泥潭中脱身出来。白痴的程序员写的程序可用，强大的程序员写程序的效率提高。可是成也萧何败也萧何，内存不到底不回收，又有额外的内存开销，结果导致系统的缓存命中率下降。我们平时觉得Java类语言执行慢最大原因在这里，半解释才不是根本原因。
因此这些语言的特点就是中间代码，其核心思想是对象。这类语言的最大特性就是抽象和构架，使用强大的设计模式，将大型问题拆分成多个小型问题解决。在解决问题的时候，其代码量并不比C++少多少。
再然后是python和ruby，当然，某种程度上还有bash，只不过他弱了点。这类语言的核心思想是抽象数据，例如字典，字符串等。bash是围绕着字符串处理设计的，python是围绕着集合设计的。这些语言解决问题的速度非常快，但是模块化特征和抽象特征相对弱。一般情况下，和C++相比，解决问题的速度大概是1:5，代码量则是1:3。</description>
    </item>
    
    <item>
      <title>程序员的几个分类</title>
      <link>//blog.shell909090.org/blog/archives/33/</link>
      <pubDate>Tue, 09 Sep 2008 22:36:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/33/</guid>
      <description>程序员有高下之分，可高下怎么分？到底什么是高程？程序员要完成哪些任务，怎么评价是否完成的很好？ 下面由贝壳同学来胡诌一下他的个人感想，以下的程序员都指商业程序员。当然，爱好者可以类推。
首先我们先讨论一个风马牛不相及的问题，程序值钱么？废话，人家账单大门兄都已经是世界首富了。可贝壳认为，程序不值钱，算法也不值钱，如果说值钱的话，就和软件光盘上面的光盘一样，是个成本性质的辛苦钱。软件里真正值钱的是软件的思想，我们大可以想象一下，写一个让人想穿脑子也想不出怎么用的程序——当然，会写的程序员想穿脑子——然后想想值钱不值钱。大家就会了解到，其实程序员，编程本身，是和装配线上的装配工一样的低附加值行业。不同之处在于，不同培训程度的人劳动生产率不同，而且生产率差异远远大于普通行业而已。好的Coding比差的生产率会高上数倍，而且很难多找几个差的来替换好的，水平不足。但是，做Coding，无论做多快，其价值只会线性增长。
那么为什么软件也被称为今年来发展最迅猛的产业呢？其实关键在于软件业让人可以实现以前无法实现的一些想法。例如，以前不会有人能做到让地球上所有的人 (好吧，是大多的人)坐下来一起讨论一个事情的方法。那么，今天我们的技术已经可以做到。有个人针对当前的技术，设计出一个很好的让所有人坐下来讨论事情的系统。包括一个BBS，带自动翻译系统。在线视频会议中心，可以附加购买在线翻译。一个邮件列表，带存档功能。一个文档编辑和管理系统，带同步编辑，版本管理和资料索引。当我说出上面这堆东西的时候，可能有的人已经晕了，当然，六牙四皂小姐估计已经不继续看了。不过做过一些时间和电脑有关商务的童鞋应当都理解这些东西的意义，并且可以想象这些东西带来的便利。在线翻译的支持系统，邮件列表存档系统，同步编辑，版本管理，资料索引，这些都是技术。尤其是资料索引和自动翻译，更是技术的巅峰之作。可是如果不是结合起来让客户用的舒服，这些东西有价值么？
软件业的价值在于将技术转换为客户的满意，并且最终转换成客户的钞票。越成功的规划，越能满足更多的客户，并且让他们付更多的钱。从这个角度讲，不论软件做的怎么样，微软的规划是全球一流的。同时，能促进这个过程的人，才是具有价值的。不过遗憾的说，到这步基本就不是程序员，而是CTO了—— 程序员的最高价值，在于根据技术和行业，判断应当发展什么技术，采用什么框架，从而低成本，高效的做出让客户满意度最高的系统——而且不是一个系统，而是一堆。这有两个非常苛刻的要求同时存在，对于技术非常熟悉，视野开阔感觉敏锐，否则怎么去感觉技术的价值，判断应当研发的技术？就这点而言，许多程序员在超过30岁后往往都可以在熟悉的领域内做到，有条件的话大概可以在多数领域做到。然而最麻烦的在于，做这个事情的时候，你必须熟悉客户，熟悉客户需要什么。这点往往是不可能的！客户是不可理喻的！技术不是万能的！要知道，使用最好的技术，设计你最喜欢的系统，往往是客户最讨厌的事情。行业客户如此，通用客户更如此。
如果上点你做不到，自然有高水准(也许吧)的人来做，那么你可以做次之的工作。什么呢？执行他们制定的方向。上层的人会告诉你应当发展什么技术，采用什么框架。现在要求你——不用会——能够整合实现这个目标。说明白点，你可以招，但是要求能留下人，低成本。你可以培训，但是要求能做事。你可以研发，但是要求好用。你可以买，但是要求低成本。如果你能实现这些目标，那么同样，你也是有价值的。
这个层次的程序员往往是Project Manager(当然，很多PM根本不是程序员)/Team Leader/Core Programmer。对于他们的要求往往是兼顾技术，行政和人事的。他们需要能够组织研发，积累技术，产生产品。很遗憾的，个人编程能力往往又是次之。不过程序员是很艺术化和个性化的一群人，在这个位置上的人，如果没有相当的技术水准，很难镇住下面的人，用普通管理人员来管理程序员的结果往往是给程序员联合起来耍。因此一般情况下也需要了解大致的程序，并且最好有一定技术水准。
最下面一个层次的人，基本就是能够实现程序，会用上面决定的框架和技术，编码效率高，工资要求低——别的没了——当然，以上是从职业分工来讲一个职业程序员的价值的，你可能说上面没道理，贝壳乱讲。不过事实是，职业的情况下就是上面的状态。当然，从业余爱好者，技术研发者来说，程序员又有另外一种不同的分法。 第一个层次，是刚刚学会技术。能够使用某种特定语言，按照一些例子编写一些程序。实话说，按照贝壳的程度，入手一般语言做到这点不超过7天。然而很多人会徘徊在这个水准无法进步，原因在于——他们能写程序了，而且写了能用。从这个引申开来，顺便说一下，程序员的进步是个很吊诡的事情。一方面来说，要勤于钻研技术才能进步。但另一方面来说，如果不够懒，是很难有足够动力学程序的。因此，好程序员都是勤于钻研的懒汉。
第二个层次，学会了使用框架，并且能够设计一些中度复杂的系统，开始接触第二语言。和初级程序员不同的是，他们能实现一套完整的系统，而不是一个个零散的功能了。这要求他们了解框架，什么时候触发什么函数，系统间怎么互相通讯。并且，有水准的还可以写一些小型的框架。
再上一个层次，了解软件工程对软件的意义，能够跨多种语言编程，灵活使用设计模式，能够设计复杂框架，习惯文档化。和上面的区别看起来不大，不过是能多用几种语言，朴素的设计被设计模式所规范，设计的框架复杂化，并且会写一堆无聊的文档。不过从这步开始，程序员开始了迈向大道的第一步，在这个层次以下的只能算爱好者。无论是研究技术，研究数学理论，还是什么，规范化都是必须而且是非常重要的。我们很难想象一堆工程师，各画各的图纸，最后房子还建的多快好省的。同样，作为高级程序员，头一步就是学会和别人合作。使用设计模式的规范进行设计，使用文档描述系统，可以跨越多种语言协作，了解多种语言思想，这是必须的。
再上一个层次，就已经不是程序员的境界了。作为程序员，上个水准已经到头了。更强的程序员意味更规范？效率更高？那是八级钳工！作为程序员，你可以不认识英文，你可以大字不识一个，然而你必须是个数学高手(其实现在数学高手大字不识一个几乎不可能)。作为程序员的巅峰，你可以很轻易和他人协作，使用合适的语言，然而无法规避的是对问题的抽象描述和求解。在贝壳作为程序员的这段时间里，无数次的碰到数学问题，有些往往是大学里面我们所不屑一顾的。例如蒙特卡洛法，拉格朗日乘子算法，这些在程序里面都有很重要的应用。有的时候更要自行抽象数学模型，并且设计满足时间限制和空间限制的解法。能够抽象问题，解决问题的，才是真正的技术系的高手。
OK，上面，贝壳从两个方面(工程和技术)论述了程序员的高下之分，作为他胡诌的结果，他目前的水准大致是——不知道。并且很遗憾的告诉大家，目前贝壳能看到的就这么多，再上面是什么样子——要么等到了再告诉您？</description>
    </item>
    
    <item>
      <title>C&#43;&#43;下的Variant</title>
      <link>//blog.shell909090.org/blog/archives/32/</link>
      <pubDate>Sat, 06 Sep 2008 22:50:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/32/</guid>
      <description>所谓C++语言，是一种强类型语言。即是说，C++种的某个变量，在使用时类型是已经确定的。这个并不是设计者的喜好或者是偏心，而是C++中的变量都会被翻译成准确的内存地址和大小，如果类型不确定是不可能处理的。但是在事实中，我们经常要处理一种&amp;rdquo;变类型&amp;rdquo;。例如，我们可能需要解析表达式，这个时候我们可能用一个或者两个栈来解决这个问题。可栈里面塞的东西就精彩了，对象，函数，数据，都在里面。这时候，如果是python，我们可以直接用list，他是弱类型的。但是C++怎么办？
一般来说，我们会使用Variant类型来解决这个问题。这是C++面对对象机制和算子机制所派生出来的产物，能够让用户自行定义对象的行为。如果一个对象，可以表现的像这个又像那个，那不就解决问题了？因此在COM中就有一个variant。不过贝壳看过机制，是一堆东西的集合，非常的不美丽。今天贝壳又看到一个variant的实现，漂亮多了。
废话少说，上代码。
#include using namespace std; #include using namespace boost; int _tmain(int argc, _TCHAR* argv[]) { any a; a = 10; printf (&amp;quot;%s: %dn&amp;quot;, a.type ().name (), any_cast(a)); a = 10.5; printf (&amp;quot;%s: %fn&amp;quot;, a.type ().name (), any_cast(a)); a = string (&amp;quot;str&amp;quot;); printf (&amp;quot;%s: %sn&amp;quot;, a.type ().name (), any_cast(a).c_str ()); return 0; }  当类型错误时，出现bad_cast exception。</description>
    </item>
    
    <item>
      <title>python的性能问题</title>
      <link>//blog.shell909090.org/blog/archives/31/</link>
      <pubDate>Wed, 27 Aug 2008 22:18:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/31/</guid>
      <description>贝壳最近在一个朋友的网站上看到了关于SICP零钱兑换问题的python求解，使用了记忆机制，然后他给出了代码。然而他的代码计时上有点小问题，也没有用包装器(奇怪的是，有写)，而且python的栈深度有限。因此贝壳做了几个修改的版本，需要测试下性能，下面就是关于性能的几个问题和过程。
本文详细论述了python语言下和C++语言下使用各种方法测试代码性能的方法，以及粗略的关于两种语言不同算法性能对比。
原始的python代码是这样的：
def change_coins(money): first_denomination = { 1: 1, 2: 5, 3: 10, 4: 25, 5: 50, } def cc(amount, kinds_of_coins): if amount == 0: return 1 elif amount &amp;lt; 0 or kinds_of_coins == 0: return 0 else: kind = cc(amount, kinds_of_coins - 1) kind += cc( amount-first_denomination[kinds_of_coins], kinds_of_coins) return kind print(&amp;quot;change_coins return %s&amp;quot; % cc(money, 5)) change_coins(300)  利用记忆原理包装后是这样的：
def memoiza(fun): cache = {} def proc(*arg): if arg in cache: return cache[arg] else: x = fun(*arg) cache[arg] = x return x return proc def decorator_change_coins(money): first_denomination = { 1: 1, 2: 5, 3: 10, 4: 25, 5: 50, } @memoiza def cc(amount, kinds_of_coins): if amount == 0: return 1 elif amount &amp;lt; 0 or kinds_of_coins == 0: return 0 else: kind = cc(amount, kinds_of_coins - 1) kind += cc( amount - first_denomination[kinds_of_coins], kinds_of_coins) return kind print(&amp;quot;decorator_change_coins return %s&amp;quot; % cc(money, 5)) decorator_change_coins(300)  不记忆，利用栈模拟递归展开是这样的：</description>
    </item>
    
    <item>
      <title>程序员入门的12个问题</title>
      <link>//blog.shell909090.org/blog/archives/28/</link>
      <pubDate>Sun, 03 Aug 2008 16:01:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/28/</guid>
      <description>以下题目是应一个朋友问而写的，适用于刚刚入门有志或者有需要做程序的朋友的题目。题目脱胎于日常编程中常见的一些问题，很多是贝壳实际碰到问题的变形。题目不注重所用语言，每道题目可以用不同语言解决。有意思向计算机方向发展的可以试试用不同语言来解决，看看哪种语言最方便解决这种问题。如果打算增加难度的话，请使用C++来做，并且尽量抽象复用。在这个过程中积累下来的可复用代码会对以后编程有很大帮助。
1.读出文件中的以下格式内容，计算逆矩阵，并按照同样格式输出。 1 2 4.5 3 0 1 9 5 2 数字间以空格分割，行以回车分割。 难点： 输入和输出应当可以选择是键盘输入还是文件输入，输出到屏幕还是输出到文件。 逆矩阵计算中有可能求不出，出现除零。设法避免直接的报错。 评价： 很中规中矩的一个问题，有点竞赛的味道。只要做过程序的人一般不会失手。
2.某个XML，其中记录了一些信息。信息是按照时间-地点-人物的顺序记录的，例子如下：
&amp;hellip;
现在需要你颠倒一下，变成这样的：
&amp;hellip;
难点： 看看能想出多少解决问题的方法。 试试尽量减小内存消耗。 评价： 解决问题的方法很多，比较一下这些方法的优劣。 有一年以上程序经验的就可以最终解决，但要解决的比较完善需要两到三年经验。
3.下载google的首页，跟踪二级连接(二级连接，就是首页中连接指向的页面，上面连接指向的页面)。 并计算其中所有页面，显示出的非空白字符的个数。(显示的文字中的非空白字符) 难点： 试试看跟踪js脚本链接。 登陆后的google首页是不一样的，包括提示，语言类型，设法统计登陆后的首页。 如果是多级呢？ 评价： 宽度优先和深度优先算法的应用，对集合运算有一定要求。 重点在于获取和处理html页面的方法。 一年以上即可解决，完善程度和技术水平关系不大。
4.运行两个程序，A和B，将A的输出输入到B中。 难点： 需要等待A的输出和B的输入，以及程序的终止条件。 评价： 需要对系统熟悉，知道管道和用法。知道进程间交互的API。 需要研究过系统，程序水平没有要求。
5.遍历某个目录，找出其中的特定图片文件。 难点： 怎么分析图片文件？文件名是比较粗略的方法，更好的是使用文件签名分析。 下次遍历的时候速度怎么提高(假定文件不变化)。 评价： 还是深度和宽度搜索题目，分析文件是难点。 扩展要求对于数据缓存有一定要求。 一年以上即可解决，文件签名分析看个人水平。
6.监视某个目录的变化，将新加入的mp3的相关信息(IDv3)邮件发给我。 难点： 怎么监视目录变化？ 怎么提取MP3的内容？ 怎么发邮件？ 怎么保证不漏内容。 评价： 要对系统熟悉，了解mp3格式或者能够自行寻找库扩展语言。 了解邮件发送协议，或者能使用系统库发送邮件。 两年以上可解决，完善需三年以上水准。
7.写一个程序，可以计算加减乘除，支持括号。 难点： 让你的程序算算1+2*3，看看是多少。正确应当是7，设计不良是9。 看看你的程序，2/6*3得多少，是不是1.0(最好是1)。 让你的程序设法支持乘方和函数。 评价： 对数据结构和算法要求很高。 一年以上可解决，要扩展支持算符和算法，需要三年水准。
8.画一只乌龟，保存为图片。 难点： 让用户动手画？ 试试保存为各种格式的图片。 评价： 实用项目，按照书本教程最多12小时就可以掌握。 然而需要自行解决并做好，至少一年以上。</description>
    </item>
    
    <item>
      <title>python的几个改进</title>
      <link>//blog.shell909090.org/blog/archives/17/</link>
      <pubDate>Sun, 11 May 2008 19:35:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/17/</guid>
      <description>首先需要增加的就是kill掉线程的方法，目前我们统统是调用系统函数。有没有搞错阿，需要针对系统写代码不说，还不安全。在线程关闭的过程中没有辗转开解和安全捕获。从最安全的角度上说，要关闭线程最方便的就是给其他线程抛异常。python并非不可以给其他线程抛异常，可非常麻烦不说，具体执行的时候发现，其实根本不是抛异常，而是在执行过程中检查异常。这样当程序在调用外部代码的时候死循环，想kill线程的时候根本不可行。所以安全的关闭线程的异常和直接kill掉线程的方法都要有。
其次，这东西没有什么可以快速辅助处理集合的工具类，例如STL中的set_union等等。虽说每个都不难，可是统一的实现和各自的实现毕竟是有差别的。很多时候，我们只需要抽象的计算两个集合，一个和一个的交集，就OK了。</description>
    </item>
    
    <item>
      <title>反射的几个类型</title>
      <link>//blog.shell909090.org/blog/archives/16/</link>
      <pubDate>Tue, 06 May 2008 16:53:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/16/</guid>
      <description>所谓反射，其实就是在运行时可以获得代码数据的技术，算是面对对象编程语言的专利。从这个意义上说，反射可以分为三个类型。
头一类是RTTI，其实这根本不算反射，本质上只能说多态。RTTI是一种鉴别某个对象是否为某个类的派生实例的技术，在C++中就有实现。简单的方法就是实现一个特定的虚函数，将当前对象所属的类虚函数表和所属父类的虚函数表一一返回。这样对比某个类的虚函数表，就可以知道是否为派生实例了。支持RTTI，程序才算真正支持了面对对象，而反射则是更高一层的技术。
第二类就是在C#和Java中盛行的反射技术，这种技术的核心在于可以通过名称寻找到对象。例如，我们可以寻找到一个叫做abc的对象，枚举其中的成员和方法，并且执行调用，这才是反射最大的意义。当我们遇到不同的数据输入时，我们可以调用不同的方法来处理这个数据，并且这个过程是动态配置的。而在C++中，我们无法通过编译器支持这个能力，必须手工的建立一个名称和一个对象的关联关系表，在合适的时候通过这个表，获得某个名称的函数入口指针。其实C#和Java中实现的方法和VM息息相关，他们的代码在目标文件中还保持着命名空间-类-对象的结构，Java还进一步的保留了源码(只是被翻译为了更快的P代码)，而C#只保留了IL代码。这样VM在执行的时候自然可以很轻松的找到对应的函数，并且获得函数签名。而C类语言的特征是汇编时代的&amp;rdquo;符号链接&amp;rdquo;方式，编译的时候保有符号，完成链接就没了。
中间插一句，其实我们完全可以写一个只支持高阶语言的系统。这样的系统未必高效，可一定方便阿。
最后一种则是python中的系统，当用户调用一个类中的函数的时候，使用一个专门的函数来决定调用哪个。因此当对付SOAP这种东西的时候，python可以直接上。而C#，Java，C++都要通过工具生成代理方法。再用代理方法去调用公共函数库，实现调用。因为python直接将调用定向到了一个统一的函数上，所以压根不需要这步。不过这步的代价是严重的性能问题，因为每次函数调用都要去检查调用目标。python是纯脚本语言，占了这点便宜，所以才能这么干。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;继承,虚,转换规则探究</title>
      <link>//blog.shell909090.org/blog/archives/15/</link>
      <pubDate>Fri, 02 May 2008 19:03:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/15/</guid>
      <description>以下讨论的东西都是在VS2005下跑出来的，如果想知道别的编译器规则，请照跑一遍。以下是类定义，函数内容为打印出当前函数名称，所以就不再贴了。
class Base { public: Base(); Base(const Base &amp;amp;amp; o); virtual ~Base(); virtual Base &amp;amp;amp; operator = (const Base &amp;amp;amp; o); void function1(); virtual void function2(); void function3(); virtual void function4(); //virtual void function5(); virtual void function6(); }; class Derive : public Base { public: Derive(); Derive(const Derive &amp;amp;amp; o); virtual ~Derive(); virtual Derive &amp;amp;amp; operator = (const Derive &amp;amp;amp; o); void function1(); virtual void function2(); virtual void function3(); void function4(); //compiler error //int function5(); protected: virtual void function6(); public: };  首先我们讨论继承下的构造/析构顺序。</description>
    </item>
    
    <item>
      <title>语言造就人</title>
      <link>//blog.shell909090.org/blog/archives/13/</link>
      <pubDate>Tue, 15 Apr 2008 22:07:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/13/</guid>
      <description>学汇编的是硬件，学C的是指针，学C++的是模版，学Matlab的是矩阵，学Lisp的是图灵机，学Java的是模型，学Awk的是字符串，学SQL的是数据集。</description>
    </item>
    
    <item>
      <title>python的非经典错误</title>
      <link>//blog.shell909090.org/blog/archives/11/</link>
      <pubDate>Tue, 08 Apr 2008 14:05:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/11/</guid>
      <description>def comp_tuple_file(tuple_file1, tuple_file2): for i in tuple_file1: if i in tuple_file2: tuple_file1.remove(i) tuple_file2.remove(i) if __name__ == &amp;quot;__main__&amp;quot;: t1 = [(1, &amp;quot;1&amp;quot;), (2, &amp;quot;2&amp;quot;), (3, &amp;quot;3&amp;quot;)] t2 = [(1, &amp;quot;1&amp;quot;), (3, &amp;quot;3&amp;quot;), (2, &amp;quot;2&amp;quot;), (4, &amp;quot;2&amp;quot;)] comp_tuple_file(t1, t2) print(t1) print(t2)  错在哪里？
头一次循环，i=(1,&amp;ldquo;1&amp;rdquo;)被正确移除了。但是接下来，i=(3,&amp;ldquo;3&amp;rdquo;)？
这个叠代器的行为很有意思哦，貌似叠代器内存储的是集合的索引。
def comp_tuple_file(tuple_file1, tuple_file2): collection = tuple_file1[:] for i in collection: if i in tuple_file2: tuple_file1.remove(i) tuple_file2.remove(i) if __name__ == &amp;quot;__main__&amp;quot;: t1 = [(1, &amp;quot;1&amp;quot;), (2, &amp;quot;2&amp;quot;), (3, &amp;quot;3&amp;quot;)] t2 = [(1, &amp;quot;1&amp;quot;), (3, &amp;quot;3&amp;quot;), (2, &amp;quot;2&amp;quot;), (4, &amp;quot;2&amp;quot;)] comp_tuple_file(t1, t2) print(t1) print(t2)  这才是正确的代码。</description>
    </item>
    
    <item>
      <title>链接上的问题</title>
      <link>//blog.shell909090.org/blog/archives/10/</link>
      <pubDate>Mon, 07 Apr 2008 18:34:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/10/</guid>
      <description>贝壳最近在用库上吃了不少苦头，先是crypto++5.52。编译后怎么也链接不上。后来发现需要用/MT参数编译为多线程。后来又在STLport上又吃一次苦头，可见VC2003的默认单线程模式确实不得人心。
下面说一下STL的编译手记。下载STLport，解压。运行vcvars32.bat设置环境变量,去build/lib下面，运行 configuare -c msvc71(如果你是2003，否则按configuare &amp;ndash;help察看你的编译器类型)。然后运行nmake -f msvc.mak install。可以看到有两个目录被建立了，bin和lib。把bin的复制到windows/system32下面，把lib的复制到系统目录下面。 安装就OK了。
上述和boost都差不多，然而和boost不一样的是，编写程序的时候，需要手工指定stlport的头文件路径。boost的可以以&amp;lt;&amp;gt;来引入，因此boost的头可以复制到系统里面去。然而stlport的必须以手工方式指定，否则就要覆盖默认的stl 了。</description>
    </item>
    
    <item>
      <title>显示自身的代码</title>
      <link>//blog.shell909090.org/blog/archives/9/</link>
      <pubDate>Tue, 01 Apr 2008 10:47:00 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/9/</guid>
      <description>void main(){char* a=&amp;quot;void main(){char* a=%c%s%c;printf (a,34,a,34);}&amp;quot;;printf(a,34,a,34);}  核心是使用printf(a,a)来代换显示，并且用34来规避转换。当然，完整的要带include，稍微有点区别。</description>
    </item>
    
    <item>
      <title>财务数据库</title>
      <link>//blog.shell909090.org/blog/archives/424/</link>
      <pubDate>Fri, 25 Jan 2008 21:15:26 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/424/</guid>
      <description>贝壳最近工作繁忙，一般都是晚上十一点到家睡觉，第二天早上继续上班的那种，所以blog基本没怎么动。现在放篇财务数据库的原型，大家参考一下吧。当然，是对程序员而言。像六牙四皂小姐这种下面估计是压根看不懂的，而且也不会有那种变态的资金准度要求。
首先建立一个账户表。
DROP TABLE IF EXISTS `accont_info`; CREATE TABLE `accont_info` ( `id` int(11) NOT NULL auto_increment, `username` varchar(40) NOT NULL, `accont` varchar(40) NOT NULL, `accont_type` int(11) NOT NULL default &#39;0&#39;, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`,`accont`) ) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=gbk;  输入用户名，账户名和账户类型，例如&amp;rdquo;许智翔&amp;rdquo;,&amp;ldquo;招行账户&amp;rdquo;,2。账户类型中规定1是现金，2是存款，3是信用卡，4以上不计算。这样可以使用多个现金账户，存款账户和信用卡账户。然后利用子查询把所有类型间的相互行为统计出来。
然后是类型表。
DROP TABLE IF EXISTS `type_info`; CREATE TABLE `type_info` ( `id` int(11) NOT NULL auto_increment, `type` varchar(40) NOT NULL, `subtype` varchar(40) default NULL, PRIMARY KEY (`id`), UNIQUE KEY `type` (`type`,`subtype`) ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=gbk;  最后是资金流动数据表，accont_id中填写出户账户名，to_accont中填写入户账户名。如果是外部(例如从别人那里拿钱或者给别人钱)，则写0。happen_time上填写发生时间，money上写金额，message上写备忘。</description>
    </item>
    
    <item>
      <title>libxml使用中的编码问题</title>
      <link>//blog.shell909090.org/blog/archives/423/</link>
      <pubDate>Thu, 27 Dec 2007 22:04:59 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/423/</guid>
      <description>libxml是gnome的XML解析库，具有强大的解析能力，支持DOM和SAX解析模型，属于验证型解析器。其内部是使用utf-8编码工作的，因此gbk之类编码的XML无法解析。为了解决这个问题，我们可以使用一个很简单的小窍门。
libxml是要和iconv一并使用的，头文件引用一般类似以下形式。
#include &amp;lt;iconv.h&amp;gt; #pragma comment(lib, &amp;quot;iconv&amp;quot;) #include &amp;lt;libxml/tree.h&amp;gt; #include &amp;lt;libxml/parser.h&amp;gt; #pragma comment(lib, &amp;quot;libxml2&amp;quot;)  这样的话，我们向libxml注册一个处理句柄，对其他编码的xml先执行一次转换，再进行解析。
iconv_t iconv_utf8_gbk = NULL; iconv_t iconv_gbk_utf8 = NULL; int gbk_input (unsigned char *out, int *outlen, const unsigned char *in, int *inlen) { char *outbuf = (char *) out; char *inbuf = (char *) in; size_t rslt; rslt = iconv (iconv_utf8_gbk, (const char **) &amp;amp;inbuf, (size_t *) inlen, &amp;amp;outbuf, (size_t *) outlen); if (rslt &amp;lt; 0) return rslt; *outlen = ((unsigned char *) outbuf - out); *inlen = ((unsigned char *) inbuf - in); return *outlen; } int gbk_output (unsigned char *out, int *outlen, const unsigned char *in, int *inlen) { char *outbuf = (char *) out; char *inbuf = (char *) in; size_t rslt; rslt = iconv (iconv_gbk_utf8, (const char **) &amp;amp;inbuf, (size_t *) inlen, &amp;amp;outbuf, (size_t *) outlen); if (rslt &amp;lt; 0) return rslt; *outlen = ((unsigned char *) outbuf - out); *inlen = ((unsigned char *) inbuf - in); return *outlen; }  初始化的时候运行以下代码进行句柄注册。</description>
    </item>
    
    <item>
      <title>继承函数的拷贝构造</title>
      <link>//blog.shell909090.org/blog/archives/422/</link>
      <pubDate>Tue, 25 Dec 2007 23:49:53 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/422/</guid>
      <description>从基类继承一个子类，基类有一个拷贝构造函数，子类重载了一个。那么在子类拷贝构造的时候会自动调用基类的拷贝构造函数吗？
答案是不会，自动调用的是基类的构造函数。
子类中如果需要调用基类的拷贝构造函数，需要这样用。
D (const D &amp;amp; o): B (o){...}  </description>
    </item>
    
    <item>
      <title>libxml2入门和中文支持</title>
      <link>//blog.shell909090.org/blog/archives/411/</link>
      <pubDate>Fri, 28 Sep 2007 22:43:40 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/411/</guid>
      <description>libxml2是gnome做的一个xml的库，支持SAX和DOM。
在解析xml的时候，libxml2会将xml中不属于标签的部分作为text节点插入。如果是属性，则添加一个属性节点到父节点上，一个文字节点到属性节点下。那么整个xml就变成了一颗单纯的树。
支持多语言的问题上，libxml2的内核只支持UTF-8。但是可以通过注册编码句柄来添加语言支持，一般是配合iconv[2]使用的，因为libxml2的编译依赖就是iconv。下面是代码。
iconv_t iconv_utf8_gbk; iconv_t iconv_gbk_utf8; int gbk_input (unsigned char *out, int *outlen, const unsigned char *in, int *inlen) { char *outbuf = (char *) out; char *inbuf = (char *) in; size_t rslt; rslt = iconv (iconv_utf8_gbk, (const char **) &amp;amp;inbuf, (size_t *) inlen, &amp;amp;outbuf, (size_t *) outlen); if (rslt &amp;lt; 0) return rslt; *outlen = ((unsigned char *) outbuf - out); *inlen = ((unsigned char *) inbuf - in); return *outlen; } int gbk_output (unsigned char *out, int *outlen, const unsigned char *in, int *inlen) { char *outbuf = (char *) out; char *inbuf = (char *) in; size_t rslt; rslt = iconv (iconv_gbk_utf8, (const char **) &amp;amp;inbuf, (size_t *) inlen, &amp;amp;outbuf, (size_t *) outlen); if (rslt &amp;lt; 0) return rslt; *outlen = ((unsigned char *) outbuf - out); *inlen = ((unsigned char *) inbuf - in); return *outlen; } static void print_element_names (xmlDocPtr doc, xmlNode * a_node, int n) { xmlNode *cur_node = NULL; xmlAttr *cur_attr = NULL; xmlChar *key; for (cur_node = a_node; cur_node; cur_node = cur_node-&amp;gt;next) { for (int i = 0; i &amp;lt; n; ++i) printf (&amp;quot; &amp;quot;); // key = xmlNodeListGetString(doc, cur_node-&amp;gt;xmlChildrenNode, 1); printf (&amp;quot;node %d: %s = %sn&amp;quot;, cur_node-&amp;gt;type, cur_node-&amp;gt;name, cur_node-&amp;gt;content); if (cur_node-&amp;gt;properties !</description>
    </item>
    
    <item>
      <title>DPI计算原理</title>
      <link>//blog.shell909090.org/blog/archives/386/</link>
      <pubDate>Thu, 17 May 2007 19:06:15 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/386/</guid>
      <description>DPI这东西大家不陌生吧，经常和像素啥的绞到一起。下面说说具体计算方法。
DPI是Dot Per Inch的缩写，每英寸点阵。常用的还有PPI，Pixel Per
Inch。同时，每英寸合25.4毫米。以此我们能算出19寸屏幕和17寸屏幕在1024*768下的DPI。
1024Pixel/(19Inch*0.8)=67.36PPI。所以要乘0.8是因为19寸是对角线尺寸，长宽比4:3，勾三股四弦五。
1024Pixel/(17Inch*0.8)=75.29PPI。同样分辩率，大小小了，DPI就高了。
我们由此可以看出，普通的显示器，我们按照72DPI计算的时候。所产生的像素密度刚刚好使得整幅图像在屏幕上按照原始的尺寸显示。呃，至少大致是这样啦。</description>
    </item>
    
    <item>
      <title>字符编码概论</title>
      <link>//blog.shell909090.org/blog/archives/384/</link>
      <pubDate>Fri, 11 May 2007 17:11:31 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/384/</guid>
      <description>首先，阐明几个基本概念。字符集，编码方案，编码范围，编码方法，编码位数，兼容性，编码兼容性。
字符集是指一系列符号的集合。计算机中只能处理数字，因此符号必须给予编码，而后储存符号编码。打印时按照编码索引到符号，再索引到字体。因此一个字符集编码为数字的方案就是编码方案。其中西文编码规范就是ASCII(ISO-8859-1)。
编码范围是指字符集的有效符号编码的范围。例如当前的ASCII编码范围是0-127，因此所有兼容ASCII的编码，其编码范围必定要回避0-127，否则就会出现编码冲突。而编码方法(不等同于编码方案)则是这个数字转换为计算机内数据的方法，一般分big endian(大端点)和little endian(小端点)两种。
big endian和little endian是CPU处理多字节数的不同方式。例如“汉”字的Unicode编码是6C49。那么写到文件里时，究竟是将6C写在前面，还是将49写在前面？如果将6C写在前面，就是big endian。还是将49写在前面，就是little endian。“endian”这个词出自《格列佛游记》。小人国的内战就源于吃鸡蛋时是究竟从大头(Big-Endian)敲开还是从小头(Little-Endian)敲开，由此曾发生过六次叛乱，其中一个皇帝送了命，另一个丢了王位。
当然，编码方法还有其他情况，例如UTF-8就也是一种编码方法，叫做非等长编码。非等长编码在安全性，扩充性和兼容性上优于等长编码，但是使用起来效率非常差。不信的可以用windows中的_mbsdec函数看看，除了当前指针，还需要起始指针进行逆遍历，效率可想而知。
在大端点和小端点的情况下，存储一个符号所需要用的位数叫做编码位数。位数分为固定位数和浮动位数。又因为编码位数一般都为8的整数倍，因此一般都使用编码字节数来代替。
兼容是指一个字符集的文字在另外一个字符集中全部存在。所以，A字符集兼容B，一般B字符集不兼容A，否则两者就相同了。编码兼容性是指一个字符集的文字在另外一个字符集中全部存在，并且同一文字表示的编码一致。可以想见，编码兼容的字符集本身一定兼容。
其次，GB3212, GBK, GB18030, BIG5, CNS11643, CJK, Unicode, UCS-2, UTF-8的区别。
简体中文来说，基本是GB系列的大陆地区简体中文国家标准，全部都是向下编码兼容的(附注：存在部分的兼容错误)。有GB3212, GBK, GB18030三个标准。编码方案都是兼容小端点序。(GB18030有变长编码)
1980年制定的GB2312是国家早期的字符编码规范。一共收录了7445个字符，范围是0xA1A1 - 0xFEFE。现在意义基本等同于国家最小字符编码集。支持中文的产品最小要支持所有GB2312字符的显示。
1995年制定的汉字扩展规范GBK1.0，简称GBK。收录了21886个符号，范围是0x8140 - 0xFEFE。现在多数电脑的字符集都是这个，向下编码兼容GB2312标准。
2000年的GB18030是取代GBK1.0的正式国家标准，该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。编码是变长的，其二字节部分与GBK兼容；四字节部分是扩充的字形、字位，其编码范围是首字节0x81-0xfe、二字节0x30-0x39、三字节0x81-0xfe、四字节0x30-0x39。向下编码兼容GBK1.0，当前使用中，GB18030和GBK的区别一般人无法区分(也没有多少人碰的上这种字)，所以一般GBK就通用指代了GB系列中比较复杂的那种编码。
繁体中文来说，有BIG5, CNS11643, HKSCS三种。贝壳实际应用比较少，下面可能存在错误，请大家指正。
BIG5是在CCCII不為政府單位採納，國家頒布的中文標準碼又不堪用的情況下。在1984年，由台北市電腦公會主導，聯合了十三家業者，
共同制定，并在2003年进行了修订(Big5-2003)，旨在提供一个小型基本字符集以便对当前的繁体中文字符进行编码。Big5-2003是Big5的扩展，仅有2个平面，包含13051个繁体中文字符和778个符号，共13829个字符。编码范围是0xA140 - 0xF9FE, 0xA1A1 - 0xF9FE。对于熟悉电脑的人来说，都知道Big5是繁体字的事实标准。
CNS11643在1992年制定，并在2004年进行了修订(称为CNS11643-2004)，旨在提供足够的字符编码以便对所有当前的繁体中文字符进行编码。CNS11643-2004是CNS11643的扩展，可以有 80 个编码平面。该标准支持： 8836 x 80 = 706,880 个编码点。原来的CNS11643标准仅有16个编码平面。在平面4以及平面12到15中，包含了台湾地区政府允许的所有法定人名用繁体中文字符。CNS11643直接取用了Big5的大部分编码，因此不考虑几个特例的情况下(准确的说，是两个)，CNS11643编码兼容了Big5。
香港增补字符集(HKSCS)原来叫做政府通用字库(GCCS)，分两个编码方案。其中Big5版是香港政府为big5加的3049个字，因此也可以说HKSCS编码兼容了BIg5。ISO 10646方案是香港政府在给Big5添加符号后向ISO标准委员会提交了申请的结果，和Big5的版本互相兼容，只是编码方案(不是编码方法)不一致而已。
再附加一点说明，一般我们说的编码转换，就是在Big5和GB2312间转换。鉴于繁体和简体文字的非严格对应性，转换可能存在误差。至于最大字符集组GB18030和CNS11643间的完美转换——还是等世界和平吧。
下面说明Unicode家族，根据网络上的介绍，原来Unicode联盟和ISO标准组织都要对整个人类的符号进行编码工作(背景音乐：数星星啊数星星～××)，后来两者联合，这事就成了(it was so，玩笑玩笑)。大家知道，中国文件和东南亚各国间互相交流，因此字符重复者甚众。其中CJK是原来中国(包括香港、台湾地区)与朝鲜、韩国、日本联合制定的三国文字集合，现在已经被收入Unicode中。Unicode是一个单纯的编码方案，不过编码方法就相对复杂了，分为UCS-2，UCS-4，UTF-8等等。
UCS-2和UCS-4是等长编码方法，简单来说就是U+65535以内的可以编码入UCS-2，以上就需要使用UCS-4了(目前这个范围还没有启用)。UCS-2总共有65535个编码点，又叫做UCS-4的BMP区域。本质上是使用大端点或者小端点编码方法直接编码，可以在字符串开始的地方加入FF FE或者FE FF加以判别。优点是将所有字符熔於一个体系，没有编码冲突问题，因此可以在一个容器内引用多国文字(例如在同一句话中引用简体和繁体中文)，效率非常高，但是有个致命缺点，不兼容ASCII。
为了解决这个问题，我们一般使用Unicode的时候，使用它的UTF-8编码方法。这个编码方法是非等长的，其中多数汉字需要使用三字节来存储。如果您看到有什么中文变成乱码后长度增加了一半的，那多数就是UTF-8编码。对于ASCII，UTF-8就是一字节码，于是就完整的兼容了ASCII。对于UCS-4中可能出现的最大编码来说，这时候就需要六字节来描述一个符号。因此可以想见，将来UTF-8是一定要灭亡的。
Reference:
[1].谈谈Unicode编码 http://www.windsn.com/article/viewmore.asp?id=227
[2].中文编码基础知识介绍 http://www.eygle.com/digest/2007/01/zhs16gbk_char.html
[3].The CJK package for LaTeX http://cjk.</description>
    </item>
    
    <item>
      <title>RTTI的几个应用</title>
      <link>//blog.shell909090.org/blog/archives/369/</link>
      <pubDate>Mon, 02 Apr 2007 23:39:23 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/369/</guid>
      <description>贝壳最近研究了下RTTI，发现几个有意思的事情。
dynamic_cast的应用。
dynamic_cast可以将一个指针的类型试图转换为指定的类型，是否能转换要看当前指针的动态类型是否是指定类型的子类，而不管指针的声明类型。当失败时返回NULL，因此可以用来识别一个指针的动态类型是否是某个类的子类。
typeid的应用。
typeid可以获得某个类的类型信息，最主要的就是name。指明了当前是哪个类，这在串行化中是必要的信息。当判断一个指针的动态类型是否就是某个类的时候可以这样typeid(*p)==typeid(class)。</description>
    </item>
    
    <item>
      <title>内存泄露检测简说</title>
      <link>//blog.shell909090.org/blog/archives/359/</link>
      <pubDate>Wed, 07 Feb 2007 22:48:13 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/359/</guid>
      <description>我们首先从一段代码说起。
#define _CRTDBG_MAP_ALLOC #include #include class test { public: test () { lpBuffer = new char[0x1000]; }; \~test () { delete lpBuffer; }; void *operator new (size_t s) { return malloc (s); }; void operator delete (void *pvMem) { if (pvMem != NULL) free (pvMem); }; void *operator new[] (size_t s) { return malloc (s); }; void operator delete[] (void *pvMem) { if (pvMem != NULL) free (pvMem); }; char *lpBuffer; }; test &amp;amp; tt () { static test t; return t; } //test t; void process () { test tf; // _CrtDumpMemoryLeaks (); } int _tmain (int argc, _TCHAR * argv[]) { // test tf; test* tp=new test(); _CrtSetReportMode (_CRT_WARN, _CRTDBG_MODE_FILE); _CrtSetReportFile (_CRT_WARN, _CRTDBG_FILE_STDERR); _CrtSetDbgFlag (_CRTDBG_ALLOC_MEM_DF | _CRTDBG_LEAK_CHECK_DF); process (); // printf(&amp;quot;hello, world.</description>
    </item>
    
    <item>
      <title>CPUID</title>
      <link>//blog.shell909090.org/blog/archives/358/</link>
      <pubDate>Mon, 05 Feb 2007 19:00:16 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/358/</guid>
      <description>近两天研究了下CPUID指令。虽然原本是准备作为加密技术的储备的，不过后来发现作为加密技术实在不可行，倒是平台识别有很大用途。
CPUID指令可以看做一个汇编中的函数，预先设定一个EAX的编号，就可以返回EAX,EBX,ECX,EDX四个数据。根据不同EAX，返回不同的数据。问题在于，对于EAX和返回的约定上，AMD和Intel是完全不同的。其中AMD根本不支持CPU编号特性。
我先给出我所用的函数：
void getCpuID (PDWORD pData, DWORD ID) { __asm { push ebx push ecx push edx push esi mov eax, ID cpuid mov esi, pData mov [esi], eax mov [esi+4], ebx mov [esi+8], ecx mov [esi+12], edx pop esi pop ecx pop ebx pop edx } }  其中pData是一个足够大的数组，ID是入口编号。根据Intel和AMD的约定，0,1,80000001-80000003是共同的。0在EBX,EDX,ECX中返回了厂商标识，例如目前机器上就是AuthenticAMD。(注意，不是顺序存放的，按照我刚刚写的顺序)80000001-80000003在返回中顺序存放了CPU的标识，例如目前机器上是AMD Sempron&amp;trade; Processor 2500+。1在EAX中返回了CPU的系列编号，EDX中返回了特性编号。以上都是标准的返回，可以看出在识别平台的时候很方便。
Intel的CPU在2中存放了配置参数，3中存放了序列编号。而AMD在这两者上都是0。由此大家就知道为什么无法用来作为加密技术了，难道这个程序只能在Intel芯片上跑吗？</description>
    </item>
    
    <item>
      <title>继承类静态对象虚拟化</title>
      <link>//blog.shell909090.org/blog/archives/357/</link>
      <pubDate>Fri, 02 Feb 2007 17:36:35 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/357/</guid>
      <description>其实这个标题不准确，准确的说，应该是继承类拥有自己的基类静态对象。
我们知道，类中的静态对象本质上是全局变量，不过名字在类命名空间里面。如果类B有静态对象S，D继承了B(先按照public继承讨论，其他其实也一样)。那么在D里面访问S的时候，其实是访问的B命名空间里面的静态对象S。验证代码如下：
class B { protected: static int S; }; int B::S = 0; class D:public B { public: void print () { printf (&amp;quot;%dn&amp;quot;, S); }; }; class E:public B { public: static void rewrite () { S = 1; }; }; int _tmain (int argc, _TCHAR * argv[]){ D d; d.print (); E::rewrite (); d.print (); return 0; }  上例中可以看到，两个继承类，其实都是将父类的命名空间导入而已。假定我们要使得每类专有一个静态成员，例如我们要计算每个类的生成对象个数，怎么办呢？
如果不用继承，我们可以在每个类里面加一个静态成员。然后在构造函数中加1，析构中减1。但是如果我们想把这个功能放到基类中，事情就麻烦了。因为所有类从同一个基类派生，我们算出来的其实是所有从基类继承的类的总对象生成个数。
当然，我们可以用实现的方法来做。把所需要的功能抽离出来，放到一个单独的计数类中。然后构造的时候调用加1，析构的时候减1。听起来很蠢，那是因为例子容易的关系。比较复杂的时候，这样抽象相对简单的。计数类可以用于多个类，实现了代码重用。但是仍旧没有解决关键问题，怎么让继承类特化基类的静态对象？(虚拟化和特化的意思差不多，就是针对具体对象使用具体方法)
答案最后被我在More Effective C++中找到了，正确的方法不是寻找一个特化的方法，而是继承不同的基类，使用同一套代码。既然是不同基类，怎么具备同一套代码呢？想到了吧，模版。
template&amp;lt;T&amp;gt; class B { protected: static int S; }; class D:public B&amp;lt;D&amp;gt; { public: void print () { printf (&amp;quot;%dn&amp;quot;, S); }; }; int B&amp;lt;D&amp;gt;::S = 0; class E:public B&amp;lt;E&amp;gt; { public: static void rewrite () { S = 1; }; }; int B&amp;lt;E&amp;gt;::S = 0; int _tmain (int argc, _TCHAR * argv[]) { D d; d.</description>
    </item>
    
    <item>
      <title>基础类</title>
      <link>//blog.shell909090.org/blog/archives/354/</link>
      <pubDate>Fri, 26 Jan 2007 18:28:28 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/354/</guid>
      <description>设计程序的时候，往往觉得怎么这么困难，基础类为什么不多提供些能力。现在风水轮流转，我开始设计基础类了。
站着说话不腰疼，设计基础类才发现基础类这东西真不是人做的。调用上讲究非常多。要返回引用呢？还是值？是需要const呢，还是不能const。返回的时候是一次拷贝构造呢？还是两次。算子需要不需要设计成friend，重复代码能不能消除。着重效率还是安全性，线程安全不安全。这些问题真是活活逼死人啊。
现在正在设计实现一下几个类，有兴趣的可以一起来研究。
LargeInteger 超大整数实现
计算RSA的时候很有用，考虑在内部实现一些有用的算法
Matrix模板类,容器类 矩阵实现
设计的时候就考虑到内部容纳的不一定是数据，也可能是字符串或者超大数
vector2D 两维矢量 专门针对平面计算优化
Line 两维线 专门针对平面计算优化</description>
    </item>
    
    <item>
      <title>关于Java和C&#43;&#43;的一点争论</title>
      <link>//blog.shell909090.org/blog/archives/353/</link>
      <pubDate>Fri, 26 Jan 2007 07:00:15 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/353/</guid>
      <description>不知道为什么，大家好像都喜欢争来争去。关于Java和C++的优劣不知道听了多少。碰巧我两者都会，怎么说也算是公平了吧。我就大着胆子，比较下两者的情况。
对程序而言，速度不是最终要素。否则我们都应该去用汇编不是？一个程序有六个特性，易学，易用，安全，高效，可变，成本低。然而他们一般都是两两冲突的，好学了，就不好用。强大了，就不好学。安全了，自然要执行很多检查，高效了，自然不安全。针对某个平添优化了，可变性就很差，又不能移植，又不好修改。成本低了，自然什么都差。
往往我们写企业应用的时候，都看重可变，低成本，安全，易用。高效呢？企业有钱买大服务器啊，这样的话效率差的不是太多也能接受。易学呢？企业有钱搞推广培训啊，只要有什么功能就加什么功能，不用考虑学不会。写用户应用的时候，则是看重安全，高效，然后易学易用里面要占据一样。可变呢？用户应用有多大？不行重写一个。低成本呢？这就是比较吊诡的事情了，没有啥经济效益的用户程序，往往是写起来最不怕费时最不管经济效益的。
首先从性能角度来说。也许C++程序员说到这里就得意了，不过先别高兴。如果单论速度，汇编语言还在C之上呢。现在网络上很多人讲C优化好了比汇编快，Java优化好了比C快。听听都要笑掉大牙的。C再怎么快，完成同样的步骤，都需要这些汇编代码。Java再怎么快，完成一个动作，底下C代码也不会少的。所谓Java优化好了能快过C，不过是一个Java高手一门心思搞优化，加上碰到一个C语言白痴而已。
我们先不讨论上面问题，就一般Java程序员和C++程序员而言(注意为啥我没说是C程序员，因为能自称纯C程序员的人要么非常精通语言，不会使用C++特性，要么就根本是个白痴)，Java程序员编写出的代码效率比C++大约慢5倍上下。这个数据是我个人写两个程序，一个运算，一个读取处理，对比出来的。都是没有优化的代码。经过极端的优化后，C++的代码我大概提高了4-8倍的速度。可惜我不是个很好的Java程序员，Java代码的速度大概提升了一倍还不足。就是说，最终C++代码比Java快了将近15倍。
但是C++程序员们先别乐，首先我Java语言并不好，这还不是最终的速度比。其次我牺牲了C++的很多特性。运算上几乎就是在写汇编了，接口都直接用了WIN32SDKAPI。没有移植性，没有可维护性，还需要特殊的技巧，怎么想都是牺牲重大。如果要真的这么追求速度，相信汇编会是更好的选择。我们在速度相差5倍左右的情况下就可以使用C++而不用汇编，为什么不能在速度相差5倍的情况下选择Java呢？
然后我们再看性能的另外一个方面，存储管理。说简单点，就是外围设备吞吐管理和内存管理。这方面上C++也是远远超越了Java。不需要的内存就不要，不必须的吞吐就不吐。C++是门培养人的语言，没有很好的功底是无法驾驭的。C++是门程序员负责一切的语言，任何错误都是程序员的错误。然而对于Java来说，就不必处理复杂而没有意义的内存管理了。假设一个Java程序员需要传一个对象给子函数，他只要传递就可以了。然而如果C++程序员直接传递，那么就会出现参数拷贝过程。不但效率差，还可能出现错误。单单一个参数传递，就有三种方式。传值，传址，引用。又分成四类，静态动态，常量非常量。交叉起来，总共是12种情况，需要量材选用。如此烦琐的管理方式，我们可以想想对于内存来说是很有好处的。嵌入系统中大型程序设计绝对是C的天下。然而这么困难的使用方式，需要多大的人力成本才能做到呢？这明显的违反了低成本的原则。
Java的内存管理从C++的角度看绝对是具有瑕疵的，内存释放了不管，直到没有空间了才收集。然而很多C++程序高手在特殊情况下，会重载operator
new算子。其中的行为就很类似这个，Java只是将特殊情况下的应用放到了一般情况。这样对于速度的后果就是，很多的缓存会被持续的从物理内存中挤压出去，导致磁盘吞吐效率降低。对于Java程序，我猜测提升效率的瓶颈将会在和系统交互以取得最佳的垃圾收集时间上。
下面的论题就可能是C++程序员所不高兴看到的了，安全性和可变性。
就语言来说，用户输入的检查这种安全性是一点意义都没有的。我们所说的基本包括几个方面，非正常用法安全，线程安全，异常过程安全。就语言来说，分为了解释型和编译型。那么怎么区分呢？我这里有个很简单的方法，如果程序本身能被本身修改，就是编译型的，否则是解释型。注意，不是让你修改了磁盘上的源码再运行。这个能力赋予了C++强大的功能，例如修改游戏，检查病毒，都需要这个能力。但是不可否认的，比起无法修改自身的程序，安全性就差太多了。线程安全性上讲，Java的所有对象都是系统管理的，也就很容易的可以管理互斥。用过C++的都知道，C++自身是没有互斥的，全靠系统的函数库或者第三方库支撑。好用不好用不说，无法移植是一定的！最后是异常过程安全，C++的异常过程是很恐怖的。关键在于C++的异常传递有三种办法，传值，传址，引用。而且在异常过程中还又涉及回了内存管理啥的。天啊，要是异常都不能专心处理异常，我还要异常干嘛？
至于可变性，那就更别说了。连处理异常都要小心内存泄露的家伙，你指望在修改代码的时候轻松到哪里去？C++是具备了强大的可变性，然而处于效率考虑，很多增强可变性的东西是选项的。例如RTTI，居然要开编译器选项的说。需要使用可变性就要牺牲性能，而且还要你小心的使用。如果使用不小心，抱歉，你又陷入效率和安全的问题里面去了。
如果你有很好的系统功底，准备往计算机领域发展(注意不是计算领域)。那么C++是门很好的语言，只是非常费时而已。而且建议你学C#，VB或者Java作为第二语言，选择Bash或者Perl作为第三语言。这样在处理问题上可以事半功倍。如果你打算增加自己的计算机能力，方便日常的电脑使用，而不准备深入学习这个领域。那么只学C#，VB或者Java就足够了。
最后要提到的是易学和易用，这两个特性都是软件设计所赋予的。也就是说，即使是以简单著称的VB.NET，也可以写很好用的程序。以复杂著称的汇编，也可以写很友好的界面。这就不在本文的论题以内了。</description>
    </item>
    
    <item>
      <title>多线程同步说</title>
      <link>//blog.shell909090.org/blog/archives/351/</link>
      <pubDate>Fri, 19 Jan 2007 00:00:13 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/351/</guid>
      <description>先给大家看个恐怖东西.
class TIFF2JPEG { public: static void newInstance (tstring &amp;amp; strFilepath, HGLOBAL hGlobal); static void waitObject (); protected: static ULONG_PTR initInstance (); static DWORD WINAPI ThreadProc (LPVOID lpParameter); TIFF2JPEG (); TIFF2JPEG (tstring &amp;amp; str, HGLOBAL hg); int Translate (); static ULONG_PTR gdiplusToken; tstring strFilepath; HGLOBAL hGlobal; DWORD dwSize; }; int ImageInMemory = 0; deque &amp;lt; TIFF2JPEG * &amp;gt;t2j_list; CRITICAL_SECTION CriticalSection_t2j_list; CLSID GifCodec; bool bThreadDelete = 0; vector &amp;lt; HANDLE &amp;gt; vThreads; TIFF2JPEG::TIFF2JPEG () { } TIFF2JPEG::TIFF2JPEG (tstring &amp;amp; str, HGLOBAL hg):strFilepath (str) { hGlobal = hg; dwSize = GlobalSize (hGlobal); return; } ULONG_PTR TIFF2JPEG::initInstance () { int i; HANDLE hThread; GdiplusStartupInput gdiplusStartupInput; ULONG_PTR gdiplusToken; GdiplusStartup (&amp;amp;gdiplusToken, &amp;amp;gdiplusStartupInput, NULL); GetCodecClsid (L&amp;quot;image/jpeg&amp;quot;, &amp;amp;GifCodec); InitializeCriticalSection (&amp;amp;CriticalSection_t2j_list); for (i = 0; i &amp;lt; MAX_THREAD; i++) { hThread = CreateThread (NULL, 0, TIFF2JPEG::ThreadProc, NULL, 0, NULL); SetThreadPriority (hThread, THREAD_PRIORITY_IDLE); vThreads.</description>
    </item>
    
    <item>
      <title>全局初始化</title>
      <link>//blog.shell909090.org/blog/archives/350/</link>
      <pubDate>Wed, 17 Jan 2007 18:57:57 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/350/</guid>
      <description>大家写代码的时候，假如写了一个组件，自身需要开一个线程的。那么多数是在初始化代码中直接写开线程的。如果要求这个类不在初始化代码中添加函数，怎么做？
MSDN中有个例子，不是解决这个问题的，但是可以用。
class DialogWindow{ public: static short GetTextHeight(){ return 1; }; private: static short nTextHeight; }; short DialogWindow :: nTextHeight = GetTextHeight(); int main(){}  在这里，把GetTextHeight里面添加上你需要的代码就可以了。
但是注意，这些代码的运行时间要早于main(准确的说，是在wmainCRTStartup里面运行的_c_init函数)。所以很多自然而然就有的初始化没做，你自己在main里面调用的初始化(例如WSAStartup啦，GDI+初始化啦)更是没做。所以必须严格测试。</description>
    </item>
    
    <item>
      <title>KMP</title>
      <link>//blog.shell909090.org/blog/archives/349/</link>
      <pubDate>Tue, 16 Jan 2007 00:53:52 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/349/</guid>
      <description>KMP是一个给人捧滥了的算法，其实单看同时有三个发明人这点，就知道这个算法是自古华山一条路，没别的想法的。KMP的算法每步虽然难想但是自然有道理，没有别的方法的。不像排序算法，一嘟噜的算法还没完。根据各种侧重点不同有不同的算法可用。
KMP的比较算法核心在于不回朔。我们先看一个正常的例子。
SSSSSSSSSSSSSS
TTTTT i=0, j=1,2,3&amp;hellip;
TTTTT i=1, j=1,2,3&amp;hellip;
TTTTT i=2, j=1,2,3&amp;hellip;
我们用T去匹配S，先对齐T和S的头部，然后对比T和S。如果T的范围内，TS内容一致，则匹配成功。不成功的话就将T向后移动一个字符。再次匹配T范围内TS的内容是否一致。ij的范围最大会在0&amp;lt;=i&amp;lt;=&amp;ldquo;j KMP算法的核心在于，如果T范围内TS的内容不一致，那么T向后移动不是一个字符，而是多个。而当前比较位置永远不向前移动。如果您写出来的算法当前比较位置向前移动了，那么肯定是写错了。
我们假定T范围内第i个字符匹配失败(0&amp;lt;=i
为什么能移动一个以上呢？Next[i]怎么确定呢？我们看一个抽象的例子：M代表匹配，N不匹配，U不知道。
MMMMMNUUUUU
TTTTTTTTTTTTTTT
TTTTTTTTTTTTTTT
我们可以看到，向后移动字符的时候，T自身有重合的部分。这时候有三种状况，我们先假定一种重合的状况。假定T向后移动了一些字符，P代表当前比较位置。在这个位置上TS出现了不匹配。
..MMMNUUU..
..TTTTTPTTTT..
..MMNTTTTTT..
在这个T向后移动一些距离后，在当前比较位置前已经出现了自身和自身不匹配的状况。根据上面我们知道，当前位置以前的T和S是匹配的。那么就是说，移动了这些字符后。T当前的位置上不可能取得匹配。我们称这种情况为这个位置的自身完全不匹配。
然后是另外一种匹配状况，符号和上面一致。
..MMMNUUU..
..TTTTTPTTTT..
..MMMNTTTT..
这个时候，T在当前匹配位置上自身不匹配，前面位置都匹配。同理可以知道，T在滑移到这个位置后可能取得匹配。我们称这种情况为这个位置的自身部分不匹配。
最后一种匹配情况是。
..MMMNUUU..
..TTTTTPTTTT..
..MMMMUUU..
这个时候，T在在前面和当前位置都匹配。我们知道前面是匹配的，然而当前既然已经被证明了和S不匹配。那么滑移这些位置后，新的位置上T也不可能和S取得匹配。我们称这种情况为这个位置的自身完全匹配。
然后我们可以回头看看比较过程了。当我们对齐TS，然后进行比较的过程中。出现了不匹配。
注意一个问题，我们回朔是为了知道移动后的T是否仍旧匹配。所以如果我们知道T匹配不匹配，就不用回朔。
这个时候我们不移动一次T，然后回朔。而是将T滑移一下，先滑移1位好了。假设出现了当前比较位置的自身完全不匹配或者自身完全匹配，那么滑动1位肯定也无法获得一个有效的匹配。那么就继续滑动，直到出现了自身部分不匹配，或者T已经完全的滑动到了当前位置的后面。这时候T的位置才是有可能获得匹配的位置，其余的位置就没必要浪费时间了。
也就是说，滑移距离Next[i]是i这个位置上滑动距离逐渐增加的时候，首次出现自身部分不匹配情况的位置。如果这情况不出现，那么就设定为&amp;lt;1的值。操作上将整个T滑动到当前位置的后面，并且从下一个位置开始比较起。
然后附上初始版的代码和比较过程。
int *cul_next (char *lpTpl)
{
unsigned int i = 0, j = 0, l = 0;
int *next;
l = strlen (lpTpl);
next = new int[l];
memset (next, 0, l * sizeof (int));</description>
    </item>
    
    <item>
      <title>构造过程</title>
      <link>//blog.shell909090.org/blog/archives/347/</link>
      <pubDate>Sat, 13 Jan 2007 22:12:10 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/347/</guid>
      <description>在进入正题前，我们首先回顾下我们的基础C++常识。如果调用某个对象的某个方法，那么会调用到什么？
一般来说，如果这个方法是普通函数，则按照这个对象的声明类型去调用。就好像(&amp;amp;obj)-&amp;gt;obj_type::function(param&amp;hellip;);。而如果是虚函数，则是按照这个对象的构造类型去调用。就好像(&amp;amp;obj)-&amp;gt;((&amp;amp;obj)-&amp;gt;_v_ptr[n])(param&amp;hellip;);。或者说简单点，一个是按照这个类看起来像是哪个类来调用，一个是按照这个类实际是哪个类来调用。
那么，如果在一个基类的某个成员里面调用这个类的另外一个虚函数，调用的是哪个呢？
任何正常人来说，都应该说是，按照这个类的构造类型来确定。基本上没错，不过有一个函数例外。
那么先看一个问题。
class B { public: B(){test ();} virtual void test (){printf (&amp;quot;parentn&amp;quot;);} void out (){test ();} }; class D:public B { public: virtual void test (){printf (&amp;quot;childn&amp;quot;);} }; int _tmain(int argc, _TCHAR* argv[]){ D d; d.out(); return 0; }  想像下输出，再运行下。想想为什么，再看下面。想通了就不用看了。
&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;我是无敌的分割线&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;
C++标准规定，任何一个带有虚函数的类都有一个_v_ptr成员，这个成员必须存放在这个类内存地址中头部。这个成员指向了这个类的虚函数表。于是，调用虚函数的时候，我们首先确定这个是虚函数。(按照这个逻辑，如果父类不声明为虚函数，子类重载为虚函数，还是没用的)然后，我们确定这是第几个虚函数(严格来说，这并不符合面对对象的设计规范，应该是按照函数名字查表的，_v_ptr也不应该仅仅指向虚函数表，而应该是类形态表)。最后，我们去虚函数表中取得入口地址进行调用。
那么为什么在构造函数中调用就无法调用子类的虚函数呢？问题在于_v_ptr的初始化时间上。某个类的构造函数启动前，这个类的_v_ptr才能完成初始化。如果是多重继承，那么首先调用最初类的，然后是次类的，最后是子类的。_v_ptr首先指向基类的，再是继承类，最后是子类。我们在父类构造函数中，_v_ptr指针还指向了父类的虚函数表，所以调用不到子类的虚函数。
其实我们可以这么说，构造函数以前，子类不存在。</description>
    </item>
    
    <item>
      <title>IDE</title>
      <link>//blog.shell909090.org/blog/archives/346/</link>
      <pubDate>Fri, 12 Jan 2007 23:09:53 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/346/</guid>
      <description>现在真是深深的为IDE所苦啊。
基本来说，现在用的IDE有几种，eclipse，MSVC，Anjuta，MingStudio，Code::Blocks。不过都有毛病。
eclipse好用的很，功能齐全，插件多，支持多，跨平台。可惜开发Java是本行，C就稍微有点小毛病，而且消耗资源太大。MSVC也是功能强大，可惜Linux下面没法用，而且不支持CVS。Anjuta只是Linux下面的开发程序，而且使用了Automake和Autoconf。MingStudio不开源，Code::Blocks编译困难。
不过想想也是，IDE都又好用又免费了，M$要$哪个去？
其中唯一好用点的也就是Code::Blocks了。前两天看一个论坛上说Code::Blocks是针对单语言的，所以要用Anjuta。我立刻喷笑。说起来一个人能会多少语言呢？三种？五种？要真的是多语言，不如用Eclipse或者Emacs。Eclipse支持Java/C++/Php，Emacs配置好了啥都支持。问题是支持多了，效果就差了。Eclipse在支持C++上就和MSVC没的比。
要比较一个IDE，基本来说是比较三个方面，自动写作，生成和版本管理，统一化测试/调试。
自动写作有四个主要方面，自动完成，符号提示，参数提示，自动格式化。说明白点，自动完成，就是使用某个范围的某个东西，例如变量或者方法。在写好范围(例如对象名或者类名)后会提示这个东西的名字。好比写了::Messa就基本可以自动给出::MessageBox。符号提示则更加智能些，在写作的时候自动判断当前最可能使用的对象并且给出提示。参数提示是指调用函数的时候提示应该传入的参数类型和个数，当然也有自动将最可能的变量传入的例子。自动格式化，就是乱糟糟的代码自动格式整齐。针对C++来说，MSVC可以自动完成，符号提示，参数提示，外挂插件可以自动格式化。Eclipse可以自动完成，参数提示(这就是那个自动填写最可能参数的例子)，外挂插件可以自动格式化。Anjuta和Code::Blocks没用过，不过Code::Blocks可以外挂插件格式化。
生成和版本管理来说，MSVC，Code::Blocks和Eclipse用的是自身的格式，脱离了IDE基本就没用了。Anjuta用的是Autoconf和Automake，即使没有IDE也可以编译。便于跨语言和发行原码包。
统一化测试/调试来说，基本都有行调试的功能，不过都不带测试工具的。</description>
    </item>
    
    <item>
      <title>getline的效率问题</title>
      <link>//blog.shell909090.org/blog/archives/341/</link>
      <pubDate>Tue, 26 Dec 2006 01:09:20 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/341/</guid>
      <description>用过C++的肯定都知道getline(cin, str)这个用法吧，用于将某行读入到一个字符串对象中。但是根据我的测试，这个方法有严重的效率问题。
正则表达式行匹配器，匹配一个23M文件。用getline的总运行时间是21秒，用直接文件读取方法只有7秒。getline方法在屏蔽对读入数据的正则匹配后还运行了9秒上下。这里有人可能弄不懂，即使读取不用时间，getline花费的时间加正则运算时间不应该是总时间吗？结论是不是的，因为多个接口上下调用需要时间，str对象得到指针需要时间。所以其中还有一些时间差。不过getline方法效率差是显而易见的。
原因在于istream的类型和行的长度。我们是从文件中读取的，一次获得一个字符的取得的。ifstream应该没有弱智到一次只ReadFile一个字节，估计是用了1-4K的缓冲簇。对于大型文件，这个缓冲簇应该越大效率越高。但是stream不会知道输入流的长度，所以——
而且即使知道了，50W个byte就是50W次call调用，花多少时间自己考虑吧。
还有一个是string类型的问题。getline istream一般都是用string作为接收对象的，因为string几乎可以无限制的接收。在STL的实现中，string是vector一样的连续块分配。当长度超出的时候，就必须重新分配，然后复制数据，删除原先块。因此STL中建议给string对象reserve一个块来提高效率。不过getline开始的时候会earse string对象，可能在这里面保留区域就被OOXX了——
所以在大规模数据处理中，还是手来吧。</description>
    </item>
    
    <item>
      <title>EPS转BMP和代码优化</title>
      <link>//blog.shell909090.org/blog/archives/340/</link>
      <pubDate>Fri, 22 Dec 2006 17:53:13 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/340/</guid>
      <description>EPS转BMP(我用的是PNG，不过还是一回事情)。EPS内部有两种图片，一个是TIF，位置和大小在头32个字节中描述。具体可以看EPS文档，在lp[5]保存位置，lp[6]保存大小。还有就是%%BeginBinary:
后面跟一个大小，然后跟beginimagex0D。在前文中应当有大小，自己找找看去，最后是一堆数据。存放方法是一位一位的像素连续存放，先存放一行C，然后是一行M，然后是Y，然后是K。当这4者全部存放完后，向后跳空一端区域，到本行开始的4字节对齐处，开始下一行的存放。
例如3个像素宽的图片(好简单——)存放方法就是，在0字节的最高三位(7,6,5位)，存放了这三个像素的C值。次三位(4,3,2位)，存放了M值。然后Y值存放在0字节的两位(1,0位)和1字节的一位(7位)。最后K值存放在1字节的次三位(6,5,4位)。然后跳空对齐，在4字节的位置开始描述下一行。
了解这个过程了，就应该发现，要转换到BMP需要大量的位操作。前置过程不说了，假定数据在内存里面(我当然不会用读取这种方法，用的是文件内存映射啦)，然后目标是GDI+的BitmapData对象。
BYTE getBit (PBYTE lpInData, int bit) { bit*=n; BYTE rslt; rslt = lpInData[bit / 8]; rslt &amp;gt;&amp;gt;= (7 - bit % 8); return rslt &amp;amp; 0x1; } for (y = 0; y &amp;lt; tgtData.Height; y++) { line_start = lpOut + l * n * Stride; for (x = 0; x &amp;lt; tgtData.Width; x++) { c = 1 - getBit (line_start, x); m = 1 - getBit (line_start, x + tgtData.</description>
    </item>
    
    <item>
      <title>正则表达式解析文本</title>
      <link>//blog.shell909090.org/blog/archives/339/</link>
      <pubDate>Thu, 21 Dec 2006 20:04:02 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/339/</guid>
      <description>最近碰到这么个问题，一个文本，每行都是乱糟糟的东西，要从里面解析出东西来。行匹配铁定是用正则表达式，我用了Boost，不会的看我前两天的blog去。
下面是按行解析问题。简单来说，写一个类继承Lister，然后实现里面的三个纯虚方法。maxSeqence返回最大可以支持的表达式，registe_regex返回表达式文本，seqenceProcess返回相应函数的指针。其实可以写成直接调用seqenceProcess加上匹配序号，然后让用户在函数内部做switch-case的。不过这样用户代码量稍微有点多，所以干脆玩一把技术。然后是几个非纯虚函数，nextSeqence可以根据当前状态来控制下一个要匹配的表达式，默认是+1，一个一个全部匹配。beforeProcess和afterProcess分别是处理前后，可以调整输入流。noMatch是一个比较常用的虚函数，用于响应没有匹配时的状态。
匹配的结果在cmatch &amp;amp; what中，详细请看boost::regex。不过what[0].str()可以获得整句的string型返回，what[1]开始就是正则的匹配结果。
&amp;mdash;&amp;mdash;&amp;mdash;2006-12-25&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;
原来的结果删除，我重写了一个。
主要有两个问题，一个是getline的效率问题，我会撰文说明的。还有就是两处细节不大好。
为了修正这两个问题，我突然发现整个的构架不大好了——怎么办？重写吧——
下面是新的，一个类line_regex，直接继承就好。line_buffer是用于解决getline效率不高的问题的，当然我偷了个懒，实现代码用了WIN32API，所以是不可移植的。而且数据是一次读取，最多256M。不过相信这种级别的问题还难不倒大家。line_buffer类中的函数都很清晰明了，就不介绍了。
Process (tistream &amp;amp; is)和Process (line_buffer &amp;amp; lb)是两大入口，同时支持自有的输入方法和流输入。当然流输入清晰明了标准化程度高。不过效率差的一塌糊涂。继承类初始化的时候，记得设置pfTable为入口列表，然后调用注册函数完成注册。nextSeqence和上面一样，可以定制下一个匹配式。noMatch用于无匹配的时候。beforeProcess和afterProcess分别会在某行开始和结束匹配后用，返回-1结束运行。其中beforeProcess返回正数会导致本行跳过，可以作为过滤器。
---------------------LineRegex.h-------------------- #include #include #include #include #include #include #include using namespace std; using namespace boost; typedef basic_stringtstring; typedef basic_regextregex; typedef match_resultstmatch; typedef basic_istream &amp;gt;tistream; #ifndef_LINE_REGEX_H_ #define_LINE_REGEX_H_ class line_regex; typedef int (line_regex::*ProcessFunction) (const tmatch &amp;amp; what, int line); class line_buffer { public: line_buffer(); ~line_buffer(); intopen(LPCTSTR lpPath); voidclose(); LPTSTRgetline(); longsize(); protected: UINTFileSize; LPVOIDlpFile; TCHAR *lpNow, *lpNext; }; class line_regex { public: line_regex(); ~line_regex(); virtualintnextSeqence(int seqence); virtual intnoMatch(LPTSTR strLine, int line); virtual int beforeProcess (LPTSTR strLine, int line); virtual int afterProcess (LPTSTR strLine, int line); voidregiste_expression(LPCTSTRexps[]); int Process (tistream &amp;amp; is); int Process (line_buffer &amp;amp; lb); protected: intProcessLine(LPTSTR strLine, int line); longmaxSeqence; ProcessFunction*pfTable; tregex*expressions; tmatchwhat; }; #endif//_LINE_REGEX_H_ ---------------------------------------------------- ----------------------LineRegex.</description>
    </item>
    
    <item>
      <title>Boost</title>
      <link>//blog.shell909090.org/blog/archives/335/</link>
      <pubDate>Thu, 14 Dec 2006 23:18:24 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/335/</guid>
      <description>谢天谢地，好久没有正常的用blog了。无论哪里都是能看不能改，痛苦死我。
先写个技术文，关于Boost库的。
首先，你得装Vs2003.net。VC++6的编译器在支持列表里面一片血红，用那个不如用Linux跑GCC。如果有MSVC8(不要脑子转不过来，就是Vs2005.net)，那就比较完美了。基本和Linux下的GCC4.1平分秋色。下面是按照Vs2003.net+windows的例子来讲的。
然后，下载一个boost的库源代码，解压安装，没有一点困难。好的很。
接下来，请在PATH里面确认添加C:\Program Files\Microsoft Visual Studio .NET 2003\Vc7\bin;C:\Program Files\Microsoft Visual Studio .NET 2003\Common7\IDE;或者等效路径，关键是要能将cl.exe，link.exe，vcvars32.bat，mspdb71.dll纳入搜索路径。然后切换到boost的目录boost_1_33_1libs\regex\build，运行vcvars32.bat，再运行nmake -f vc71.mak，或者等效的指令(其实就是71还是70 80)。再运行nmake -f vc71.mak install，向VC的lib目录里面添加库。至此boost库的regex组件库算是编译好了能用，如果你不用正则表达式，抱歉，上面的话在耍你。
然后是用法，倒不难。
cmatch what; regex reg(&amp;quot;^abc$); if(regex_search(str.c_str(), what, reg)){ .... }  what里面会保存从正则表达式里面匹配出来的东西。
利用这个库可以很好的做字符串拆分，验证的操作，弥补了C++没有正则表达式的缺憾。
我写了一个类，可以从流里面获得每行，然后做匹配，然后派发到相应函数里面去。有需要的可以联系我。</description>
    </item>
    
    <item>
      <title>JNI试用记</title>
      <link>//blog.shell909090.org/blog/archives/257/</link>
      <pubDate>Thu, 10 Nov 2005 19:35:19 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/257/</guid>
      <description>近两天要用JIN做数据加密系统，所以特别写了这篇。省得以后忘记，顺便造福大家。   下面是核心编码：   //CTX.java   public abstract class CTX {\ protected byte\[\] state = new byte\[20\];   protected long count;   protected byte\[\] buffer = new byte\[0\]; /\* input buffer \*/   protected byte\[\] PADDING = { -128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\ 0, 0, 0, 0, 0, 0 };   // 大端点序\ protected static void putChar(byte\[\] b, int off, char val) ;   // 大端点序\ protected static void putLong(byte\[\] b, int off, long val) ;   static {\ System.</description>
    </item>
    
    <item>
      <title>程序解释器</title>
      <link>//blog.shell909090.org/blog/archives/242/</link>
      <pubDate>Sun, 23 Oct 2005 03:26:29 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/242/</guid>
      <description>贝壳在费尽N天功夫后终于得到了一个程序解释器，目前可以无结构运行。正在附加函数声明和调用结构。先存念一个Output。
int i; i=0; i=i+15*50; i=i-1; print(i); Result Output: Parse Begin [;] [] [;, ;] [] Parse End Parse Begin [;] [var(i):0] [;, =] [var(i):0] [;, =] [var(i):0, 0] [;] [0] [;, ;] [0] Parse End Parse Begin [;] [var(i):0] [;, =] [var(i):0] [;, =] [var(i):0, var(i):0] [;, =, +] [var(i):0, var(i):0] [;, =, +] [var(i):0, var(i):0, 15] [;, =, +, *] [var(i):0, var(i):0, 15] [;, =, +, *] [var(i):0, var(i):0, 15, 50] [;, =, +] [var(i):0, var(i):0, 750] [;, =] [var(i):0, 750] [;] [750] [;, ;] [750] Parse End Parse Begin [;] [var(i):750] [;, =] [var(i):750] [;, =] [var(i):750, var(i):750] [;, =, -] [var(i):750, var(i):750] [;, =, -] [var(i):750, var(i):750, 1] [;, =] [var(i):750, 749] [;] [749] [;, ;] [749] Parse End Parse Begin Begin Function Expression Paser Parse Begin [;] [var(i):749] [;, ;] [var(i):749] Parse End Function Stack[var(i):749] 749 Function Stack[] [;] [] [;, ;] [] Parse End  以上为script读取文件运行，在打开调试输出情况下的结果。</description>
    </item>
    
    <item>
      <title>RTD of java</title>
      <link>//blog.shell909090.org/blog/archives/210/</link>
      <pubDate>Mon, 26 Sep 2005 07:04:12 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/210/</guid>
      <description>Everyone who use VC++ knows that VC++ have a Run Time Debugger in it. And you can watch assemble code of you program or even ofcommon library code. Farther, we use Ollydbg or softice or something like that which is called Run Time Debugger to track the program. Or looking assemble code, enumerate window handles or some other handles, searching stack for something importent like password. In a word, you can do anything you wanna.</description>
    </item>
    
  </channel>
</rss>