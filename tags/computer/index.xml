<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer on Shell&#39;s Home</title>
    <link>http://blog.shell909090.org/tags/computer/</link>
    <description>Recent content in Computer on Shell&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>CC-BY-SA4.0</copyright>
    <lastBuildDate>Wed, 04 Feb 2015 15:07:42 +0800</lastBuildDate>
    
	<atom:link href="http://blog.shell909090.org/tags/computer/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>openvpn的几种基本模式</title>
      <link>http://blog.shell909090.org/blog/archives/2724/</link>
      <pubDate>Wed, 04 Feb 2015 15:07:42 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2724/</guid>
      <description>vpn的原始模式 vpn的最简模型，相当于在两台机器上插一块虚拟网卡，然后中间连一根虚拟网线连通。因此vpn才得名vpn(virtual private network)。
其复杂之处在于，这块虚拟网卡如何配置网络，和别的网卡是什么关系。再加上多个节点间如何通讯。种种都够新手喝一壶。
虽然openvpn在科学上网上是废了，但是在不出国的网络上用来保护通讯，还是非常好用的。
tap模式 tap模式的特点是二层打通。典型场景是从外部打一条隧道到本地网络。进来的机器就像本地的机器一样参与通讯，你分毫看不出这些机器是在远程。
优点：
 配置简单。 不需要在所有机器上配置或者动网关。  缺点：
 tap在部分设备上不支持(例如移动设备)。 wlan加入网桥后不一定可以工作。 广播包会散发到虚拟网络中，可能极大消耗流量。  特别解说一下wlan。部分AP对一个客户只接受一个MAC地址，因此无法做网桥。这应该是wifi网络的常规问题了。解决方法是换AP，或者做mac-nat。
操作方法：
你需要先在当前网络中，为vpn预留一些地址。这些地址应该足够拨入用户使用，不应和dhcp撞车，不应有其他人使用。
而后，建立一个br，将当前工作的eth迁移过去。(具体细节就不说了，每个系统小有差别)再建立一个tap vpn，在启动脚本中指定加入这个br。
example 假定内网地址为172.19.0.0/24，其中保留172.19.0.16-172.19.0.31供vpn使用。
服务器配置:
port [port num] proto udp ; 参考我上一篇[vpn不要走tcp协议](http://shell909090.org/blog/archives/2722) dev tap ca ca.crt cert server.crt key server.key server-bridge 172.19.0.16 255.255.255.0 172.19.0.17 172.19.0.31 ; 或者可以采用这句 ; server 172.19.0.16 255.255.255.240 ; 注意掩码实际上等于/28，做掩码运算后，这段地址和上面的保留地址重合 script-security 2 up vpn-start ; 建议使用绝对路径，避免版本坑 down vpn-stop  vpn-start:
brctl add br0 $dev  vpn-stop:</description>
    </item>
    
    <item>
      <title>如何分辨网站真假</title>
      <link>http://blog.shell909090.org/blog/archives/2676/</link>
      <pubDate>Tue, 19 Aug 2014 11:44:57 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2676/</guid>
      <description>老婆想去新疆玩，结果她居然从百度上搜了一下新疆国旅就联系开了。我一直不知道，直到她和我说，对方要求缴500元到一个支付宝帐号里。我立刻要求她不要付钱，然后开始查证真假。
第一家网站 她开始给我的是这家：http://www.17xjly.net/。
老规矩，先whois，再dig，再whois。
whois域名的结果是没有任何信息？！
dig后的IP是113.10.247.20。再whois一遍，发现服务器在香港。此外也没有任何信息。
ICP是新疆的，查全国ICP登记无信息。
开始想不通，这家伙在新疆背景这么深厚？突然醒悟过来。这家伙是个.net域名，注册地不在中国，服务器不在中国，凭什么要人家ICP备案啊。就因为号称是新疆的网站？
CAO，这种网站给的支付宝，鬼知道打进去会发生什么。。。
第二家网站 百度上排名很高的是这家http://www.yuyutrip.net/和这家http://www.yoyotrip.net/。两家的页面很像，但是又明显有区别，不知道是竞争对手还是什么。
老规矩。
whois域名的结果是这个：
Registrant State/Province:Shanghai Registrant Name:shxg shxg  注册地上海？
dig了更好玩。这两个域名的IP指向是同一个。121.52.217.137。再whois发现是这个：
netname: TopnewNET descr: Beijing Topnew Info&amp;amp;Tech co., LTD.  没听说过。
ICP倒是有：
北京博通天下网络技术有限公司 U旅商旅网 2013-06-09  咳咳，漏底了吧。虽然号称国旅，但是是一家北京公司在上海注册的域名。
好玩的是，这家网站上面给出的地址，是真的（具体后面会说）。但是电话却不对。
真的国旅 google出手，马上就有。结果是这个http://www.cits.com.cn。
老规矩。
whois域名可以看到这个：
Registrant: 中国国际旅行社总社有限公司  注册者看着就很NB。
dig一下，发现IP是这个，219.143.192.35。这个IP可牛逼了。whois一下：
inetnum: 219.143.192.0 - 219.143.192.255 netname: CITS  我擦，专属C类IP段！
ICP查询后结果是这样的：
中国国际旅行社总社有限公司 国旅在线 www.cits.com.cn 2014-07-23 www.cits.net 2012-11-29  这个网站上有400电话，打过去说新疆只有团体游。不过人家给了正确的地址和电话，和第二家网站的地址一致，电话却不一样。
事情到这里，我的基本判断是。和第二家网站做生意还是有点谱的，ICP是真的，地址国旅也认。最低限度，他至少是一家合法的旅行社——虽然不保证是国旅下属。第一家么，谁爱信谁信。
上海国旅 后面有点更好玩的事情。国旅在线上有上海，而google查询结果上也有不少上海国旅。那么谁是真的呢？
上海国旅1 例如这家http://www.scits.com/。</description>
    </item>
    
    <item>
      <title>CVE-2014-0160(openssl)严重漏洞及其对应</title>
      <link>http://blog.shell909090.org/blog/archives/2618/</link>
      <pubDate>Tue, 08 Apr 2014 18:03:33 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2618/</guid>
      <description> 描述 openssl 1.0.1系列中，1.0.1f以前的版本在实现上存在漏洞，未正确处理Heartbeat扩展，导致攻击者可以窃取服务器端敏感数据。
对应  请立刻升级openssl到1.0.1g版以上，并重启整个系统，以保证不会遗漏某些已经启动的进程。 如果有自行编译的程序使用了openssl。当这些程序静态链接或链接了自定义的openssl时，需要重新编译。 在有问题的设备上使用过的key，需要升级私钥。 openssh不受影响，openvpn受影响。  作为证明，请执行以下语句自行检查。
ldd /usr/sbin/sshd | grep ssl ldd /usr/sbin/openvpn | grep ssl ldd /usr/sbin/nginx | grep ssl for i in $(ps aux | awk &#39;{print $2}&#39;); do echo $i; ldd /proc/$i/exe | grep ssl; done  其他 根据昨晚看到的信息，这个漏洞会泄漏服务器端的通讯数据。因此请将所有session清空，在受影响期间使用过的用户名和密码请务必在3-5天后再修改一次(具体看服务商什么时候补掉漏洞)。
参考  nvd debian ubuntu openssl Is OpenSSH affected by this as well?  </description>
    </item>
    
    <item>
      <title>安全的几点快速说明</title>
      <link>http://blog.shell909090.org/blog/archives/2611/</link>
      <pubDate>Tue, 25 Mar 2014 17:14:14 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2611/</guid>
      <description>这篇文章谨献给某些特殊环境下奋斗的人士。其他人参考使用。
物理设备 物理设备上存储着相当多的个人资讯，所以所有的机密资讯要保密这是常识。
物理设备上可能拥有的机密资料：
 各大站点的session token。借助这些，虽然不能抢走帐号，但是可以仿冒身份，发出假消息，或者诈骗。 浏览器启用了“保存密码”选项后，所有的密码都半明文存储在硬盘上。这些信息可以被用来抢走帐号。 个人的文档，照片，私密视频。万一笔电丢失就够倒霉了，再变陈老师岂不更痛苦？ 浏览某些特别站点的记录。咳咳，大家懂。  之所以要设备加密，是因为有一种破解方法是将你的设备存储拆下来，接到独立的读写设备上，直接读取数据。无论系统密码设定多强，也无法防范。
如果是mac，有一个选项叫做全盘加密。ubuntu有home分区加密的选项。启用这两项可以有效加密你的电脑。windows也有个类似的功能叫做EFS，但是据说不少国家级单位有解密权限。
 Windows Mac Linux  android上有加密系统的选项。但是要注意，如果启用会消耗大量电力，而且必须擦除整个设备才能解除。iphone我没用过，据一位挺熟悉的朋友说，只要设定了pin码，整个手机就会被加密。
加密只是第一步。对于经常保持开机的系统，如果能够轻易的进入系统，那么磁盘加密也形同虚设。所以，请给你的系统加上一个足够强的登录密码。
最低强度：
磁盘加密8位以上，系统登录6位以上，包含小写和数字。
推荐强度：
磁盘加密10位以上，系统登录8位以上，包含大小写和数字。
网络安全 首先，请把系统的防火墙开到最大：
 Windows Linux Mac  基本原则是，只许出不许进。如果需要可以开放特定端口。
然后，如果在不安全的环境下使用网络，请使用vpn。这里请允许我广告一把朋友的网站云梯。一般是用来大陆翻墙的，不过要用来绕过不安全的环境也可以。
有时间有条件的朋友可以自行架设vpn服务器，这里给出linux下架设pptp vpn的方法。客户端使用方法可以参考云梯的说明。
 How to Setup a VPN (PPTP) Server on Debian Linux PPTP Server linux pptp vpn服务器的架设 Debian系统快速搭建pptp VPN  注意加密一定要使用128位，不要使用56位。
网站访问 如果可以选择，尽量使用https。下面有一些插件，使你可以尽可能的使用https访问站点。当然，如果站点没有https则无效。
 Chromium Firefox  在https访问的时候，如果跳出证书是伪造的之类的警告，请千万不要确定。这是有人在man-in-middle的信号。正确的做法是使用vpn，看看问题是否消失。如果消失，上报给工程师。如果没有消失，请找可信的工程师来排查。千万不要轻易认可未经鉴定的证书(实际上不建议自行接受任何证书——除非那是你自己配出来的)。
另外，请关注证书的签署者。在我这里看到的信息如下：
 google的证书签署者是GeoTrust facebook的签署者是VeriSign twitter的签署者是VeriSign  如果签署者有异，请上报工程师。这可能是有人获得了某个根证书机构的密钥来做的签署(例如CNNIC之类)。原则上这样的man-in-middle可以攻击任何网站。</description>
    </item>
    
    <item>
      <title>google authenticator的特性</title>
      <link>http://blog.shell909090.org/blog/archives/2549/</link>
      <pubDate>Tue, 28 Jan 2014 13:08:45 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2549/</guid>
      <description> 算法  双方预先共享一对密码。 时间对30秒求整，用密码unbase64后HMAC签署。 如果当前时间前后一定时间内（几个误差）的值和用户提供值一致，就验证通过。  攻击者获得了数个时间和序列对，但是根据HMAC特性，他无法反向出密码。
因此  gauth不需要联网。但是双方时间必须同步。 gauth的优势在于，即使有人可以获得一次密码(例如keylogger)，只要不在1分30秒内登录，获得的输入就无法使用。 对于可以取得gauth共享密码的人，gauth不能提供安全性加强。例如sudo，验证的是自己的身份。而用户密码只要登录即可读，因此没有提供加强的安全性。 对于ssh，在登录后也可以获得密码。因此只要给别人获得了一次登录权限，后续gauth不能保护你。反之，如果能保证对方一次登录都不会成功，则可以作为辅助。因此用于ssh上必须加上一个token只能使用一次，以确保对方获得了token也是作废的。 如果有人可以从手机中读取应用的信息，就可以一直冒充用户。因此越狱和root肯定会降低系统安全性。这就是为什么很多TOTP使用硬件来做这个事情。系统单纯，而且没有读取API。 缓慢的重试，每次命中概率都是1/1000000。持续试1000000次，也不能肯定猜中。实际上只有63.2%的概率猜中。如果30秒内连续重试1000000次，肯定破解了。合每秒重试3万多次，不算多。所以必须防止暴力破解。 如果没有紧急密码，安全性大约是20bit。但是数个紧急密码为破解提供了帮助。因此紧急密码一般是7位数字，综合复杂度一般评估为20bit上下。 以复杂度而言，不足以作为身份验证工具，只能作为身份验证辅助。所以gauth叫做two-factor-authentication。  </description>
    </item>
    
    <item>
      <title>在PAM中使用google authentication</title>
      <link>http://blog.shell909090.org/blog/archives/2539/</link>
      <pubDate>Wed, 22 Jan 2014 13:31:45 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2539/</guid>
      <description>PAM是linux系统身份验证的核心，在用户登录/ssh身份校验中均有很大用途。但是很少有人想到，其实这个东西还可以用google authentication来进行身份校验。
安装 sudo apt-get install libpam-google-authenticator  设定 使用前，需要对用户做一个用户级配置，生成配置文件。这个文件就是这个用户的身份验证凭证。配置请使用用户执行google-authenticator。
上来先会问你是否使用基于时间的验证，肯定选是。但是注意，基于时间的验证要求服务器时间必须精确。更准确的说，是服务器时间和手机时间校准在30秒以内。由于手机一般都采用GSM校时，因此只需要在意服务器时间。建议是使用ntpdate来校准时间。特别注意，linux的时钟是会漂移的，必须按天级校准。
然后程序会给出一个url，还可能有QR码（真够不容易的，Console级别的QR码。。。）。记住，一定要用url去获得QR码给程序扫描。因为url获得的QR码算法是最新的，而直接生成的有可能不能跑。
下面是secret key和verification code，一般来说这两个不用关心。但是你需要记住emergency scratch codes。libpam-google-authenticator默认给你生成了5个，一般都够用了。通常用到3个就更新一遍吧。
 是否生成配置，选是。 是否拒绝使用同一个token的人登录。如果选是，30秒内只能登录一个人。建议选是。 是否放送时间验证，从1分30秒到4分钟。如果选是，允许更大的服务器时间偏差。看你服务器时间是不是够准。 是否防止暴力破解，30秒内尝试不超过3次。建议选是。  OK，你的配置就完成了。如果有多个用户，请多次配置。
手机app 按照系统安装以下app，下面以android版为例介绍。
 Google Authenticator Android Google Authenticator iOS Authenticator for Windows Phone Blackbarry  选择setup account，然后scan a barcode。程序会要求你使用barcode扫描软件扫描(推荐barcode scanner)。这时去扫描设定一节中访问url显示的那个qr码。
pam配置 对于ssh而言，请在/etc/pam.d/sshd的最后一行增加这句。
auth required pam_google_authenticator.so  注意，这样其实是密码/校验码双重验证。如果你不需要密码请注释掉下面这句。
@include common-auth  或者其他包含以下这句的地方。
auth required pam_permit.so  如果你希望增强sudo安全性，也可以把这句加入/etc/pam.d/sudo后面。如果同样不需要密码，请注释上面那句。
sshd配置 保证/etc/ssh/sshd_config里面，以下参数都处于正确的配置。
ChallengeResponseAuthentication yes PasswordAuthentication no UsePAM yes  如果你使用openssh6.</description>
    </item>
    
    <item>
      <title>golang和nginx的简单性能对比</title>
      <link>http://blog.shell909090.org/blog/archives/2536/</link>
      <pubDate>Wed, 15 Jan 2014 10:53:20 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2536/</guid>
      <description>说明 测试都是ab做的，中等并发量，统一采用10000并发，100000个请求。都是本机请求本机，避免公司内网IDS的干扰。
机器是一台双核CPU的DELL：Intel&amp;reg; Pentium&amp;reg; CPU G2030 @ 3.00GHz。配4G内存。
第一组数据是ab测试nginx，nginx的配置如下：
worker_processes 4; pid /run/nginx.pid; worker_rlimit_nofile 30000; events { worker_connections 20000; multi_accept on; } http { sendfile on; tcp_nopush on; tcp_nodelay on; ... }  第二组是ab测试golang，返回固定是个OK。
第三组是ab测试golang，返回某个目录或文件。
err := http.ListenAndServe(&amp;quot;:8080&amp;quot;, http.FileServer(http.Dir(&amp;quot;/home/shell/photo&amp;quot;)))  nginx Concurrency Level: 10000 Time taken for tests: 5.720 seconds Complete requests: 100000 Failed requests: 0 Write errors: 0 Total transferred: 172100000 bytes HTML transferred: 160000000 bytes Requests per second: 17482.</description>
    </item>
    
    <item>
      <title>青旅无线组网指南</title>
      <link>http://blog.shell909090.org/blog/archives/2478/</link>
      <pubDate>Thu, 12 Sep 2013 23:30:45 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2478/</guid>
      <description>本文不仅适用于青旅，还包括其他人员密集的场所，通过无线方式进行最低限度的上网。例如公司。
会写这篇，主要是旅行过程中，发现网络状况实在无法接受。像阿里地区这种没信号的区域就算了，在很多青旅里也因为种种原因上网不畅，实在让人很不爽。所以写一篇guide出来，说明一下各种问题。
容量估算 首先，你必须估计在一定范围内需要联网的设备数。一般来说，就是某个无线覆盖范围的人员数乘以1.2到2不等的系数。如果是青旅，大概乘1.2就足够了。因为很多出来玩的人只带手机，偶尔会带ipad。但是在公司，一般至少到2。因为有很多人会将笔记本和手机同时连接上网络。
每个设备连入网络，就会占用三样东西，IP地址，带宽和AP连接数。
IP地址一般问题不大，只要同时连入网络的设备数不超过200台，就可以塞到一个C类子网里。但是注意，这时候DHCP的空间要足够。
带宽的计算上，一般一个手机按照5KB算，一个电脑要10KB以上。粗略点可以将设备数乘以40kbps，得到所需的带宽。
AP连接数就是每个设备算一个。
例如，在某个青旅的大厅里，巅峰时刻可以坐下15个人。这时候，设备数估计是15*1.2=18台。带宽估计是720kbps，AP连接数18。
限制 容量估算有什么意义呢？主要就是决定你租用电信带宽的大小和选用路由器的质量和数量。带宽都懂，主要说一下路由器的质量和数量。
可能很多非专业人士不知道，路由器能够同时在线的终端数量是有限的。这个叫做AP的待机数。超过这个数字有的路由器也许还能接入几个，但是就开始各种不稳定了。例如TPLINK的TP703N，待机数就是8。同时接入8个设备问题不大，再多就不好说了。而TPLINK的一般路由器，待机数都在10-15之间。企业级的最高可以达到32（WVR450G），但是价格高达500多，也不合算。
很多青旅的问题在于，明明申请了一根很大的线路，但是却随便的弄了一个路由器。当人都集中到大厅里的时候，路由器待机数马上不足了，很多用户连都连不上去。由于智能手机的普及，这个现象正越来越明显。在旅行中我几次用自己的路由器，用网线连接到主路由器上。在别人羡慕嫉妒恨的眼神里面老神在在的上网，就是这个原因。
个人推荐使用TL-WDR3320。一方面他的待机数是20，不算低，价格只有200左右（京东价）。另一方面这台设备还支持5G网段，可以让支持5G的设备通过5G网段接入（例如苹果的设备），而不占用2.4G的宝贵频道。两台合起来，比WVR450G要支持更多，而且更便宜。当然，这种替换是有代价的，其缺点就是滥用了频道，可能造成频道管理上的困难，我们稍后再说。
继续上面的例子，大厅里18台设备，那么就可以用一台TL-WDR3320搞定。
覆盖 在计算完容量后，我们复杂的网络设计之路才刚刚开始。记得我上面强调过一个词，一定范围内需要联网的设备。这个词的意思是，如果人员分布在了各个角落，你需要独立计算无线覆盖。
很多青旅的问题在于，压根没有考虑无线的覆盖性，就在中央大厅拉了一个路由器了事。结果一帮驴子半夜三更不睡觉在大厅里刷手机刷明天的线路。。。
关于无线的覆盖，是一个挺复杂的问题。简单点的解法是在android手机上下一个wifi analyse软件。然后选个你觉得OK的点，把AP接上电（不用联网）。用软件可以看到AP的信号强度。然后来回走动一下，看看是不是每个位置都能保持70dbm左右的信号。如果不行，再换点。
还是上面那个例子。大厅里面15个人，但是在住宿区域分为三个部分，每个部分三间房，第一，二部分每个房间4张床，第三部分每个房间6张床。
首先带宽就要重算。第一，二部分都是15台设备（三间房x四张床x1.2），第三部分22台设备（三间房x六张床x1.2），总计52台设备，2080kbps。也就是至少2M的网络，建议申请4M。
注意这里算的时候不要重复加大厅的人了，一个人要么在大厅里要么在房间里，一般不会同时在。
其次，大厅，每个部分都要分别装一台TL-WDR3320，总共4台。其中第三部分的待机数略不足。好心的可以补一个WR703N补足，没这个闲功夫的就赌房间不会总是客满吧。
频道分配 这个就是更细节的问题了。
记住几点，wifi有11个频道可用，其中间隔5以上的没干扰。所以一般1,6,11不互相干扰。
当然，相邻的两个AP最好不要用互相干扰的频道。
所以你就知道，如果大厅人数多，只用一个WVR450G会在频道分配上好算很多。如果是两台AP，就比较难管理了。
刚刚的例子继续，把频道6分给离的最远的两台AP，就保证4台设备互相不冲突了。如果补了WR703N，那么就分配一个合适的频道吧。
连接结构 上面讲了半天如何计算需要几个AP，布在什么点。现在讲一下如何连接。
简单来说，就是用每个AP的LAN口拉一条网线出来，接到其他AP的LAN口就成。这样就能保证AP的彼此相连。至于彼此间是用星型，都接到一个AP上。还是用线型，一路AP一个接一个接出去，都可以。只要别接出环来就好。有的AP不支持STP协议，接出环就会无法工作。
最后，再把外网网线插到某个AP的WAN口，搞定。
插入WAN的路由被称为主路由。一般来说，如果用户数大于100，主路由需要足够强才行。如果TL-WDR3320不够，还是要一台WVR450G。
配置 一般路由器都是192.168.1.1，然后打开DHCP。当使用上面说的这种配置结构的时候，就不能这么配了。
你首先要将主路由配置为192.168.1.1，其他路由的LAN口依次配置为1.2 1.3等等。然后关闭其他路由器的DHCP功能，并为每个路由器分配合适的频道。
如果网络不需要保密，建议配置为随意连接，待机数还可以增加一些。但是一般这样会惹来大量蹭网的，所以一般需要将安全设定为WPA2。所有AP设定为一样的名字和密码，设备会自动寻找信号最强的那个。
如果用的是TL-WDR3320，那么还要注意分别配置2.4G和5G频段。建议2.4G和5G选用不同的名字，但是可以用一样的密码。这样用户可以自行选择是使用2.4G网络还是5G网络。
细节 有空的话，可以看一下我这篇合用两个路由器的几种方案</description>
    </item>
    
    <item>
      <title>使用getmail备份imap邮件数据(例如gmail备份)</title>
      <link>http://blog.shell909090.org/blog/archives/2438/</link>
      <pubDate>Wed, 03 Jul 2013 10:39:27 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2438/</guid>
      <description>使用getmail备份imap(例如gmail)服务器上数据的方法。
原因 随着7.1的到来，诸位geek最重要的事情就是备份google reader的数据了。很多人都在讨论gmail还要不要用。
废话，当然要。这么好的服务，为什么不用？
只是随着google reader的事，在用gmail的时候也得留个心眼。平时数据勤备份，不要所有的内容都绑定到这个邮箱上，否则有得你哭的。
安装和配置 getmail是一个用于将远程数据取到本地的系统，和fetchmail是一类东西。废话不多说，先装getmail。
sudo aptitude install getmail4  之所以用getmail不用fetchmail，是因为fetchmail我搞不定。而且getmail比较容易备份到指定地点。要是输出能gzip掉就更好了。
建立~/.getmail目录，下面放一个文件，例如gmail
[retriever] type = SimpleIMAPSSLRetriever server = imap.gmail.com username = [username] password = [password] mailboxes = (&amp;quot;[Gmail]/所有邮件&amp;quot;,) [destination] type = Mboxrd path = ~/shell/gmail.mbox [options] read_all = false delivered_to = false received = false verbose = 2 message_log = ~/.getmail/gmail.log  username填你自己的用户名，普通用户不需要@gmail.com，企业用户需要@你的域名。password填密码，两次认证的需要分配一个Application-specific passwords。mailboxes里面不要照网络上的填写[Gmail]/All Mail，那是英文环境用的。
~/shell/gmail.mbox是目标文件，你需要先touch出来。~/.getmail/gmail.log是log，建议和配置文件同名。
执行 把下面的gmail替换为你的配置文件名，注意不需要写.getmail/的前缀。
getmail -r gmail  系统就会开始备份你的数据。像贝壳的gmail这种数据，量比较大，时间也会比较长。
问题 getmail是python写的，备份数据比较大的时候，内存消耗会很惊人。而且当处理巨量数目的文件时。在启动时会将目录全部下载到本地，然后计算一阵。这个耗时，网络消耗和CPU都比较大。要有点耐性。</description>
    </item>
    
    <item>
      <title>用户友好的密码</title>
      <link>http://blog.shell909090.org/blog/archives/2430/</link>
      <pubDate>Thu, 13 Jun 2013 15:19:31 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2430/</guid>
      <description>用户友好的密码 何谓用户友好的密码？我是指在密码中尽量不给自己找麻烦，又能正常使用。
 不包含空白字符。否则你会烦恼有哪个空白字符，有几个的问题。 不包含特殊字符。否则会烦恼怎么输入。 不使用容易混淆的字母。不容易输入错误。 方便手机输入。  尽量少包含大写字母。 只包含容易在手机上输入的符号，或者不输入。   手机上容易输入的符号 在android上，以下符号可以在google输入法中直接输入。
@*+-=/#()&#39;&amp;quot;:?!~  总计15个。估计加上iphone后会更少。如果要用符号，建议从这些里面取，会减少你很多密码输入的烦恼。
容易混淆的字母  Il1 0O 连续的mn 连续的wv  强度规范 我把密码管理规范里面的结论总结一下，略去推导，凑凑数，把密码级别排列成以下几个：
 弱密码：不希望别人看到，然而别人看到并没有直接损失的内容。熵应当在20bit以上，五年修改一次。 中密码：不希望别人看到，别人看到会对你产生损失的内容。熵应当在33bit以上，两年修改一次。 强密码：有价内容。熵应当在45bit以上，一年修改一次。同时作为弱本地密码规范， 本地密码：熵应当在58bit以上。  每个级别之间大约差12bit的熵。初始熵强度至少20bit，低于这个水平就很难说这是一个密码了。
强度估计 以最容易使用的密码计算，符号应当最多包含26个字母+10个数字，排除l10这3个。每一位有33种可能，熵大约是5多一点。
 弱密码：至少4位。 中密码：至少7位。 强密码：至少9位。 本地密码：至少12位。  更强一些的密码可以用52个大小写字幕+10个数字，排除Il10O这5个。每一位有57种可能，熵大约是5.8。
 弱密码：至少4位。 中密码：至少6位。 强密码：至少8位。 本地密码：至少10位。  建议 网络：
 弱密码：4位小写字母+数字，5年修改一次。 中密码：7位小写字母+数字，2年修改一次。用于保护大部分内容。 强密码：8位大小写字母+数字，1年修改一次。保护重要内容。  本地：
 低：8位大小写字母+数字。 高：10位大小写字母+数字。  注意避开Il1O0，以及其他可能的混淆方式。</description>
    </item>
    
    <item>
      <title>vpn转代理</title>
      <link>http://blog.shell909090.org/blog/archives/2339/</link>
      <pubDate>Tue, 19 Mar 2013 10:54:59 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2339/</guid>
      <description>背景 贝壳自己的vps蒙难，不能正常工作了。所以贝壳买了一个vpn。是pptp/l2tp系列的。用起来很好用，但是这类ip-based vpn有几个不便。
 不能自动设定客户端路由表，实现智能翻墙选择。 每个需要翻墙的设备均需要拨号，而目标设备有容量极限。 不能实现非侵入式翻墙，打开之后连p2p都翻了。  与此相反，代理式翻墙可以比较有效的解决这些问题。一个点拨号，其他点可以共享代理。不需要翻墙的直接访问不设定代理就好。唯路由表没有办法。实际上，为了使得代理可以使用路由表选择，贝壳还是花了一番功夫做了antigfw项目的。
闲话少说。这次贝壳就展示一下如何在debian下设定pptp vpn，并且利用代理无缝共享的。
linux下的vpn设定 安装pptp-linux这个包，然后按照说明使用即可。
pptpsetup --create &amp;lt;TUNNEL&amp;gt; --server &amp;lt;SERVER&amp;gt; [--domain &amp;lt;DOMAIN&amp;gt;] --username &amp;lt;USERNAME&amp;gt; [--password &amp;lt;PASSWORD&amp;gt;] [--encrypt] [--start]  自己填充用户名密码服务器，就会在/etc/ppp/peers/下面生成对应的文件。使用pon tunnelname就可以拨号了。
路由设定 初始设定好的vpn不具有智能路由，因此必须添加一些内容。
首先使用chnroutes.py这个程序，得到ovpn下常规用的路由表。当然，我们可以用linux下的路由表，但是他的old gateway存放在了/tmp下面，对此我并不是很喜欢。所以我只用了他的路由 表信息，其余自己处理。如果你不确定自己执行时的默认路由，理论上也应当需要下面的一些配置。
使用下面这个topptp.sh，可以将输出的routes.txt转换为pptpup和pptpdown两个文件。
#!/bin/bash ETHGW=192.168.1.1 cat &amp;gt; pptpup &amp;lt;&amp;lt;EOF #!/bin/bash export PATH=&amp;quot;/bin:/sbin:/usr/sbin:/usr/bin&amp;quot; EOF cat &amp;gt; pptpdown &amp;lt;&amp;lt;EOF #!/bin/bash export PATH=&amp;quot;/bin:/sbin:/usr/sbin:/usr/bin&amp;quot; EOF sed &amp;quot;s:route (S*) (S*) net_gateway 5:route add -net 1 netmask 2 gw $ETHGW:g&amp;quot; routes.txt &amp;gt;&amp;gt; pptpup sed &amp;quot;s:route (S*) (S*) net_gateway 5:route del -net 1 netmask 2:g&amp;quot; routes.</description>
    </item>
    
    <item>
      <title>速度对比</title>
      <link>http://blog.shell909090.org/blog/archives/2287/</link>
      <pubDate>Sat, 29 Dec 2012 14:33:28 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2287/</guid>
      <description>引用
+------------+----------+-------------+------------+-------------+-------------+ |bps |B/s |network |storage |port |bus | +------------+----------+-------------+------------+-------------+-------------+ |56/48K |5.6/4.8K |Modem 56k | | | | +------------+----------+-------------+------------+-------------+-------------+ |57.6/28.8K |7.2/3.6K |GPRS | | | | +------------+----------+-------------+------------+-------------+-------------+ |236.8/236.8K|29.6/29.6K|EDGE (2.75G) | | | | +------------+----------+-------------+------------+-------------+-------------+ |1M |125K |Bluetooth 1.1| | | | +------------+----------+-------------+------------+-------------+-------------+ |1536K |192K | | |USB low speed| | +------------+----------+-------------+------------+-------------+-------------+ |1,536/512K |192/64K |ADSL (G.Lite)| | | | +------------+----------+-------------+------------+-------------+-------------+ |3M |375k |Bluetooth 2.0| | | | +------------+----------+-------------+------------+-------------+-------------+ |10M |1.25M |10BASE-T | | | | +------------+----------+-------------+------------+-------------+-------------+ |12M |1.</description>
    </item>
    
    <item>
      <title>Y Combinator</title>
      <link>http://blog.shell909090.org/blog/archives/2249/</link>
      <pubDate>Tue, 09 Oct 2012 15:38:44 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2249/</guid>
      <description>不动点理论 假定我们有一个函数f，例如，f(x) = x^2。对于某些点，f(x) = x。在这个例子里面，0和1很明显就是两个点。这样的点称为不动点。
不动点理论在各种领域有广泛应用，我记得其中之一就是在血型比例上。当ABO遗传规则固定后，存在一些ABO血型比例，这些比例的人随机通婚，生下来的孩子的血型比例亦保持不变。这是三种血型千百年来存在的基础，否则随着遗传规则比例转变，其中某些血型可能已经在地球上消失了。
也许你很好奇，当我们有了一个规则后，例如f(x) = x^2，或者ABO遗传规则（这也可以当作一个函数，将父代ABO比例转换为子代的），如何才能计算出函数的不动点。
答案是不动点算子。
高阶抽象函数的不动点 我们先不继续讨论不动点算子，让我们先讨论一下抽象函数。上面，我们的f都是具体的演算规则，x是一个数（例如x），或者一个矩阵（例如ABO，也可以当作一种数来考虑）。如果x是一个函数会如何？
我们先看一个递归的阶乘计算函数：
(define fact (lambda (n) (if (&amp;lt; n 2) 1 (* n (fact (- n 1))))))  这是一个典型的阶乘计算函数，没错。问题是，我们在lambda里面调用了fact。从语言层面上说，这样做合法。然而从语言的研究角度说，这难免会带来一个问题。函数的名字，到底是一个可有可无的别名，还是一个在递归中必须的东西。如果是前者，我们可以完全用lambda构造递归函数。而如果是后者，我们无论如何努力，也无法仅仅使用lambda来构造一个递归。
OK，这和不动点有什么关系？这时，我们先假定函数f，是真正的阶乘计算函数。即f(n) = n!。那么对于以下函数，((F f) n) = (f n)。
F = (lambda (h) (lambda (n) (if (&amp;lt; n 2) 1 (* n (h (- n 1))))))  看不懂为什么？这是一个柯里化函数。当我们传递真正的阶乘函数f给F的时候，在函数体内，他叫做h。而按照f(n-1)的定义，我们得到的值和(f n)没有区别。因此，我们有(F f) = f，你也可以写作F(f) = f。
是不是觉得眼熟？是的，f是函数F的一个不动点。要获得真正的阶乘函数f，我们只要对F计算不动点即可。
Y算子 Y算子(或者叫做Y组合子)是另一种高阶函数，用于计算任意函数的不动点。
假定对于函数f，存在不动点x，有f(x) = x，那么Y(f) = x，这是Y算子的基础。按照上文代入，我们可以得到f(Y(f)) = Y(f)，或者可以写作scheme格式：(f (Y f)) = (Y f)，这就是Y算子。</description>
    </item>
    
    <item>
      <title>计算机的相关法律管理</title>
      <link>http://blog.shell909090.org/blog/archives/2236/</link>
      <pubDate>Mon, 03 Sep 2012 14:28:49 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2236/</guid>
      <description>昨天翻了一下vpn的相关法律，结果是——没有。
唯一一部接近的，还是《境外组织和个人在华使用密码产品管理办法》。但是这实际上有两个问题。
首先，办法对含密码产品的限制太过严格，而现在的密码学衍生领域又铺天盖地。这导致实际上有办法没管法。例如我们公司的产品，为了升级，就在系统里面放置了升级系统。为了防止升级系统升入非我们的代码破坏系统，又要对升级系统做签名验证。这实际上就一脚跨到了密码产品的范畴里面去。不过幸好，我们的产品本身就是涉密产品，有公安部的认证。但是其他需要在产品中包含了安全系统的产品怎么办？别的不说，你想想有多少软件链接了openssl？哪怕是python这种东西，都是链接着openssl的。从某种意义上说，使用python也违法。
其次，办法只限制使用密码产品，可一字没提到提供密码服务和帐号。大家知道，vpn实际上是帐号和服务，至于使用这些帐号和服务的具体“产品”，那是windows，ssh客户端这种东西。而windows是经过国家认证的。退一步说，即使没有，也是使用者和软件发行者需要对此事负责，而管不到账户提供者头上。
另一个有关的，是《互联网信息服务管理办法》。可办法开宗明义第一句，是在中国境内。要提供vpn服务，你的服务器必须是境外的，境内没意义。但是相应的，你不能在中国境内进行收费，否则就算违法。然而，如果免费帐号漫天发，这条法律依据也是靠不住的。
OK，我们常说中国立法远远落后于时代，我们又找到了一个例子。实际上，你在看中国法律的时候，往往大疑不解，为什么会有这种那种狗屁规定？那是因为那些法律的制定年代往往都是上个世纪。例如地图法规定，私自使用精度在一定范围以下（我记得是100米）的地图是违法的。我找不到这条的出处，不过测绘法是上个世纪颁布的。大概颁布测绘法的人不会想到，在短短15年后，就会有大量个人手持的高精度（&amp;lt;10米）定位工具出现。
至于互联网，托这几年比较敏感的福，互联网立法始终是重中之重。然而，大部分立法还是针对的web而言的。其中有条规定，服务提供商必须进行备案，然后在网站上公布其备案号，目的是方便公安机关管理。问题是，目前很多网站是没有web界面的，直接通过手机使用。有些网络服务连客户端界面都没有，例如vpn，你说怎么提供？服务商倒是不会介意弄个网站，把备案号贴出来。问题是公安机关怎么知道提供服务的供应商网站是哪个？
再说法理基础吧，不仅是中国，在世界上，对于网络和程序这块的法理都是一塌糊涂。我们首先说一个简单问题，什么叫做引用，什么叫做使用？
之所以在GPL之外还有个LGPL，就是因为，如果你在编译时直接使用了某个GPL库，就会被传染这个库的授权。为什么？这主要是针对C语言而言的。因为C在编译时，需要引用对方的.h文件。而对方的.h文件是基于GPL的，这就构成了引用。而针对python程序，你可以很容易的反射和动态加载，这又是否构成引用呢？如果编译时，使用自己反推对方头文件构成的.h文件，是否需要被传染授权呢？又例如，在kernel中的license中，明确说明了内核调用不属于引用。然而如果在程序内以变量形态包含了firmware，又是否算是引用呢？别的我不清楚，debian是严禁这类软件进入仓库的。
当然，这些问题对于欧美法系不是太大问题，因为一切都是来自判例，判例构成了法律。对于新出现的问题，只要诉讼，就等于在进行立法。然而对大陆法系而言，这就是个噩梦了。</description>
    </item>
    
    <item>
      <title>家庭电脑的虚拟化</title>
      <link>http://blog.shell909090.org/blog/archives/2234/</link>
      <pubDate>Fri, 31 Aug 2012 16:39:38 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2234/</guid>
      <description>家庭电脑，谁都会用。会来看我blog的人更应当是家里有一台，我知道有些还有不止一台的——别人家我不知道，我家里就算老妈和丈母娘一起来打游戏，我还能保证我和老婆人手一台的水平。
一堆机器，有好处也有坏处。好处是，基本坏掉哪台都不怕，备用的比较多，随便来一台就能跑。坏处是，这些机器的配置不同，习惯不同，性能也不同。我们家里更特殊的情况是——连系统还不一样。我自己用的是linux，老婆是win7，老妈是XP。
为了解决文件共享的问题，我采用了NAS，而且是自己组装的小型服务器。对于小型家庭网络，NAS是个很不错的主意。然而电脑不仅仅有文件而已，还有配置呢。老婆的win7是直接连接到电视上的，所以我经常需要和她抢电脑。然而chromium的绑定gmail只能有一个——用我的还是她的就是一个问题，这是两个人用一台电脑的配置共享问题。同时，我的小上网本则是另一个极端。我希望上网本上和主机能共享同一个配置，虽然chromium的同步能力很强，但是很多东西不是chromium能同步的掉的。包括emacs配置，bookmark，打开文件。ssh密钥，系统环境。这是另一个问题，一个人用两台电脑的共享配置。当然，说到这里同时还有一个问题，我不希望用自己的小上网本，毕竟atom的速度和主机没法比，io速度也慢，内存也少。
所以，我最终的解决方案就是——虚拟化。在win7中装一台虚拟机，里面跑一个linux，再通过上网本远程控制这台linux，这样至少解决了我自己的问题。在小上网本上，可以高速的使用浏览器，和主机同一个配置。在主机上，和老婆分开配置。在老婆使用电脑的时候，和她分离的，不受干扰的使用电脑。
实际上，要解决这个问题，最好的方案是基于linux的multiseat系统。由于是multiseat，所以我和老婆同时使用。由于linux是用户分离的系统，所以可以互不干扰。唯一的遗憾是，同一个用户不能同时登录两个X，Xauthority文件会互相覆盖，因此在用户登录的情况下不能使用vnc。
当然，为什么不能用multiseat，你们懂。。。不懂的可以看我上一篇文章。</description>
    </item>
    
    <item>
      <title>关于昨天&#34;google drive你这是在找死&#34;的补充</title>
      <link>http://blog.shell909090.org/blog/archives/2156/</link>
      <pubDate>Sat, 28 Apr 2012 07:04:54 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2156/</guid>
      <description>随手就写害死人阿。
昨天写了一篇google drive你这是在找死，结果被人指出了错。我忘记注明了，没有文件夹上传的是android版本，linux版没有客户端，windows版可以看到客户端下载，但是我目前没有确认下来有人能用。
即使如此，我还是觉得google drive不好用。
基于文件的数据管理 基于文件的数据管理很简单，一个文件系统有很多目录，每个目录可以放文件或者其他目录，文件里面就是各个程序的数据。基本上每个用电脑的人都知道基于文件的数据管理是怎么回事。
问题是基于文件的数据管理很不好用。
文件就有文件名，我需要找一个文档，里面是上个月的财务数据，但是我不知道叫什么文件名，这种需求并不少见。然而，要在文件系统上干这个事情，你只有搜索所有doc/xls文件，然后一个个看。
蛋疼不蛋疼阿。
基于文件的数据管理的理由，多半因为多文件组合。例如，我有一个html，里面引用了两张图片，一段音乐。在html里面，我只要写明其他文件的文件名，就自然可以指定对其他文件的引用。这省去了“复合数据存储”的烦恼。但是，大部分情况下，我们用不到这个。
因此，目前逐步在向另一个方向过渡，基于数据集合的数据存储。
基于数据集合的数据管理 数据集合，听起来和文件没什么区别，但是本质上并不是一回事。大家都用过flickr吧，也用过google doc吧。他们基本上就是“基于数据集合的数据管理”。和文件的区别在于，数据集合是有“元数据”的。照片会有拍照时间，说明。如果运气好，还有地点和评论。文档是有作者，简述等等。你可以基于数据类型和元数据进行过滤，排序等动作。而基于文件的基本没有办法这么玩。微软winXP以上版本的资源管理器可以看到，如果文件夹里面多半是图片，就会变成图片专用视图，而显示出图片的内置元数据。然而，这个是逐个扫描的，速度慢。而且万一一个文件夹里面又是图片又是音乐，至少有一个得虾米。
google drive基本是google doc的升级替代品，可以打开多种格式的文件。然而，当上传一个文件时，必须显示的“转换”为google doc文档，才可以介入管理。而且，每个类型的google文档，都有限额。以文本文件为例，大小限制在2M以内。我上传了一个5M的小说，直接报错，要求原样上传。上传后不能直接打开，必须下载打开。
整合和过渡 两者如何整合？
在文件系统的管理上，同步，而非上传，是一个非常重要的功能。我不可能每时每刻都联网，即使联网，也不能每个文件修改好了就上传一次。我需要对传统的文件系统做持续的修改，然后通过手工的，或者自动的同步，将差异转移到云端上去。而不是我手工的对比每个文件差异，然后一个一个的上传更新和删除。
没有同步工具的云端存储是个垃圾，除非你共享的目标是少数几个超大的文件，例如电影，或者资源合集之类的东西。这是以共享为目的的云，说的更直白点，就是免费的下载空间，而不是个人云存储。
在个人文件被同步到了云端后，应当能够让云端的程序直接打开和修改某个文件，而不是强迫转换。
google drive是什么 从表现上看，还是基于文件的管理。我不能通过元数据直接查看我拥有多少张相片，也没办法找所有邓丽君的歌。
然而，他们又没有同步，至少linux不行。而且android手机上连文件夹上传都没有。也许有人说了，找个数据线和电脑连起来不就得了？要是我喜欢用数据线连，我到哪连一次电脑，玩个同步就完了，还要云干吗？
所以，结论还是不变。</description>
    </item>
    
    <item>
      <title>google drive你这是在找死</title>
      <link>http://blog.shell909090.org/blog/archives/2154/</link>
      <pubDate>Fri, 27 Apr 2012 03:36:47 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2154/</guid>
      <description>昨天收到了google drive的邮件，今天就做了个简单的测试。我不确定是否是我的错觉，但是google drive不支持文件夹上传。
？！
是的，我找了半天，没找到。即使有这个功能，它也被藏的很深，至少一个熟练用户花了10分钟找不到。据我看到的资料，这是因为谷歌试图抛弃文件概念。
好吧，抛弃文件概念是个先进的理念，我也认为那是对的。但是，当我需要为我的200多个手机小说，一个一个上传，然后再手工建立目录，重新分类，打tag的时候。你连从文件夹直接导入的功能都没有。
告诉我，我为什么要用你。
其余特性我就不多吐槽了，包括中国群众使用的不稳定(虽然不是你们的错，而且dropbox也不稳定)。才5G的免费空间。目前还没有客户端。至少这些问题都是可以改进的(除掉那个不是你们的问题)。
但是拿着已经存在的事实不当回事，只考虑未来是美好的—— ——那就是在找死了。</description>
    </item>
    
    <item>
      <title>无线网络问题的诊断</title>
      <link>http://blog.shell909090.org/blog/archives/2130/</link>
      <pubDate>Sun, 01 Apr 2012 03:10:12 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2130/</guid>
      <description>今天看到ZQ在坛子里面说无线网络卡，想想这对很多人是个问题。现在越来越多设备采用无线网络，本来看似够用的无线网络应该也会逐渐变的不怎么够用。这篇文章的大部分内容在blog中都有说，但是没有集结成文。今天集结一下，为大家提供便利。
关于无线网络卡这个问题，有多种可能，我们逐个分析原因/诊断方法/解决方案。
有终端连不上，即使这个终端就在路由器附近 这个主要是因为无线网络负载的设备达到极限所致的。这个极限，我见过最差的路由器是8个，普通路由器（包括dir-825刷openwrt）大概是50上下，苹果的要超过100。一个/24子网的最大负荷是253个IP地址，如果不另行设定，大多数的默认配置都无法超过这个极限。
解决方案很简单，加路由器，或者换一个更好的路由器。加路由器具体参考这篇。换路由器的意见是，不要用fastnet，推荐tplink或者dlink的设备，buffalo的也不错。如果你已经用了这些路由器，但是终端超过50个（好像通常只有公司会碰到吧），可以考虑苹果的，或者多扔两个路由器，辐射小信号好。
有终端离开一点距离后就连不上，或者离开一定距离后速度变慢 这是典型的信号衰减。作为不严谨的测试，你可以在android上安装wifi测试仪，然后走到各个角落。如果你的信号质量不足80dbm，那么就属于比较差的情况。大概能连接，但是经常断线，或者速度很慢。如果不足90dbm，基本就不可用了。
解决方案也很简单，同上一个。总之优化到家里的每个点信号质量都可以就好了。
明明信号很好，速度就是上不去 有可能是因为周围的channel干扰，也可能是因为你的路由器CPU不足。你可以用wifi测试仪，看看你周围当时有多少人在用你路由器的channel。两个channel相隔5以上才不互相干扰。所以，如果你使用channel6，那么channel2-channel10都会对你的信道造成一定干扰，相隔越远干扰越小。而如果你隔壁有一堆和你同channel的AP，实际带宽是均分给你们所有channel的。如果对方用的比较多，也会对你造成干扰。
这是非常难解决的问题，你总不能跑到隔壁说，你们改个信道吧。一方面，如果有条件，你可以对墙壁，门缝做信号屏蔽。这样能减小一点隔壁的信号干扰。另一方面，建议你采用5G频段。这个频段的信道更多，更不容易串扰。但是目前支持5G频段的设备少，而且5G的穿透能力比2.4G更差。
CPU不足呢 CPU不足最典型的确诊就是关掉加密，你的无线网速就会突然暴增。或者你保持无线空载，用有线狂用网络，无线的ping值从10变化到上千。
碰到这种情况，扔掉垃圾路由器重新买一个。
明明有些设备一点问题都没有，有些设备就是连AP都找不到 看看你的channel是否设定到了11以上，例如12/13/14之类的。各个国家对channel的许可范围不一，欧洲日本美国的许可比中国宽一些，因此有12等信道，中国最高到11。因此你用水货手机连外贸版本的路由器的时候，channel12没问题，而用中国许可的设备的时候就连AP都找不到。
解决方法很简单，换个中国许可的channel。
无线速度跟不上外网速度 自从20M以上光纤出现以来，这个问题就逐渐变成主要问题。11g的标准速度号称54Mbps，但是实际上通常只有18Mbps。而外网速度从常见的1/2/4Mbps骤然升到了10/20/30Mbps，就出现了严重的外网速度反超内网速度。
这个一点办法都没有，只能把11g的设备都淘汰光。只要有11g的设备在，11n就无法发挥极限速度，导致你的无线只能在18Mbps上晃。而换用11n的设备后，速度一般可以达到30-40Mbps以上，基本够用。
路由器被打爆 由于速度加快，导致现在有更多的小包可能被传输。虽然传输速率要求不高，但是由于路由器对每个包都需要做同样处理，所以大量小包的资源消耗和同样数量的大包是同一个量级的。我们做一个简单的计算。如果一个包是1500字节，128KB/s的网络可以每秒传输90个包。而如果每个包是64字节，就可以传输2000个包。而当速度升级到2.5MB/s（20Mbps光纤），如果是1500字节，每秒1700个，而64字节的就是40000个。如果路由器的处理能力是每秒10000个包，升级到光纤一跑小包就挂了。很多人在ADSL的时代没问题，升级到光纤反而频繁出问题就是这个原因。
现象比较多，如果是交换机挂掉，往往是一个机器链路OK但是就是有TX没有RX。怎么整也没用，但是过一会，这台机器突然就OK了，换下一台出同样问题。而如果是整个路由器挂掉，可能是路由器突然重启，或者ppp0断线重新拨号。还有的机器是死在那里没任何反应，必须拔掉电源线重新插才有效。</description>
    </item>
    
    <item>
      <title>国产软件更换计划</title>
      <link>http://blog.shell909090.org/blog/archives/2084/</link>
      <pubDate>Tue, 07 Feb 2012 01:52:47 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2084/</guid>
      <description>首先声明，我不是歧视国产软件，我自己做出来的也算国产软件，如果我真的在玩歧视，我是歧视我自己，OK？
不知道为什么，中国人做出来的软件，或者中文软件，和外文软件有完全不同的风格和特性。我很早就骂过，我们的软件充斥着免费的流氓和收费的冷屁股。现在更改一下，我承认有的软件很好用，所以中国的软件是好用的流氓大集合。
为什么？我怎么知道为什么？前两天千千静听的事情把我恶心坏了，而且还有中文putty后门事件。难道国内就没有好用的软件了么？自己想想，很杯具的发现，貌似可能性不大。首先，如果我们的程序好用而且免费，程序员就得从其他渠道赚钱。这年头程序员的第一需求是老婆需求，这是刚需。有老婆需求就有丈母娘需求，有丈母娘需求就有房子需求。OK，哪怕我们的程序员是个只对程序感兴趣的大宅男，只要他不是个Gay（说明一下，只要一不找我，二保持固定关系，我没有歧视的意思），最终还是会归结到钞票需求，而且还不是一般的钞票需求。
所以，大量的程序员都必须赚钱，赚大钱。相比起来，很多老外程序员的想法我们就觉得很奇怪。我有位朋友（在此先恭喜他喜得贵子，然后按照他的习惯隐去名字，请认识的人也不要写出本名给搜索引擎搜），他希望办一家中国公司做一项技术，因此曾经找上中国的干部。干部对这个技术很感兴趣，因此愿意给支持。我提醒他，有支持就有相应的条件，他以后将不能撤资，而且赚到的钱也不完全是自己的。他很奇怪的看我，开公司的目的是推广这项技术在中国的应用，只需要基本收入就好了。作为一个同样需要赚钱的中国程序员，我顿时觉得我们在两个世界。
而且，中国软件界普遍的情况是对恶和权不敏感，例如很多程序员都在用盗版VS。当然，我会听到很多理由，但是我觉得他们只能被称为借口。我认为盗版只在两种情况下合情理——用于教学实验目的和为了表达对版权制度的抗议。当然，后者虽然合情理，但是违法。如果说国内程序员用盗版的理由是一，那太侮辱智商了。而如果是二，我从没有看到他们举着反对版权的旗子去游行，也没有看到他们所写的所有软件都声明——本程序没有任何版权。
我也和不少程序员谈过所谓授权和回避方法，基本都是新手程序员觉得“很有道理”，老手就付之一笑了。因为老手知道，这些事情是没必要的。是否在软件包中声明使用了某个BSD的库？没有区别。商业软件使用了GPL的库？没人关心。你多此一举，只会引发项目经理的反感而已。OK，既然程序员对作恶和权不关心，那么绿坝版权问题的发生只是迟早而已。
难道中国软件界改良的希望需要寄托在培养基友程序员上？
这么大的问题我暂时无解，但是我需要做和我有关系的部分。我会逐步移除电脑中的国产windows程序，并且将其余国产程序加入观察名单。中文软件主要是指在国内制作和汉化的闭源windows软件，原生软件汉化不算，开源不算，linux软件不算。实际上，观察名单对我而言不会太长，基本就是QQ国际版，Foxit，和几大网银。
我建议读到这篇文章的人，也好好考虑一下，哪些软件真的是有风险的。这并不是让你马上回家删掉所有国产软件——实际上我至少得留着网银，他们没替代品——而是说，我建议你在脑子里面转一下，自己装了些什么东西，会造成哪些问题，是否愿意接受。这会花掉你几分钟的时间，但是也许会让你少碰到一些恶心问题。</description>
    </item>
    
    <item>
      <title>tcp连接的建立和释放</title>
      <link>http://blog.shell909090.org/blog/archives/2074/</link>
      <pubDate>Sun, 29 Jan 2012 02:03:43 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2074/</guid>
      <description>大家新年好，新年第一博，我们来写一点干货。
建立tcp为什么是三次握手？
从两军问题说起太远了，三次握手的假定是一条双工线路的每个方向，要么持续通，要么持续不通。就好比一个电话，你和对方可以同时说话，所以是双工线路。你说了对方能听到，这叫单方向。单方向上，要么通，要么不通。
如果从一个不保证稳定的电话线上（例如移动电话，这是典型例子），你怎么确定你们通话是正常的？
假如你首先说“喂”，这时候你什么都不知道，对方能听到，他就知道你到他这里的电话是好的。他会说“喂，我听到了”。你听到了，会知道他到你这里的电话是好的。
事情结束了么？没有呢，他还不知道你能听到他讲的东西，所以你还要回“我听到了”，然后开始说正事。
回想一下自己打电话的经历，是不是往往漏掉了最后一个“我听到了”呢？这样会使得对方无法确认你能听到他说的东西。不过一般来说，当你开始滔滔不绝的时候，他会假定你听到了那句“喂，我听到了”。因为通常没有人会没听到对方的回应就开始说话说个不停。这个模式在tcp中也是可以做到的，在最后一个ack上附加数据。
为什么由发起方开始？因为我们必须要假定有一个方向开始，任意开始就需要处理碰撞问题（就是同时开始）。接通socket总是由发起方开始传输第一个包，你不觉得直接在这个包上面开始测试连通会比较合理一些么？
电话为什么由被叫方开始说话？因为主叫方打电话后，被叫方决定了电话什么时候接通。电话接通的时候，被叫直接就可以说话了（假如电话稳定的话），而主叫要等到下一个“嘟”不出现才能有所反应。所以通常都是被叫先开口。当然，也有被叫方接起电话来等着主叫说话的情况。
另外提一句，如果你使用手机拨打的话，当听到对方“喂，这里是XX，您好”之类的信息的时候，应当先说“喂，我是XX，您好”。等对方确认能听到了，再开口说正事。因为手机有不算太小的几率，双方都听不到，或者单方向听不到。如果不巧是后者，很容易引起不必要的误会和麻烦。例如你滔滔不绝的说，对方作为反应，说了几句。然后你什么都听不到，继续说。对方当然会生气，对不对？
OK，现在我们来说说挂电话。
tcp的fin机制，其实是要解决这么一个问题。当你说“再见”后，能够马上把电话放下么？
不行的，因为对方可能还有一些重要的事情还没说。你一说再见就挂断，这个会造成问题。从简单的思考上，我们会得出一个结论。当你说了“再见”后，对方可能还需要说一些事情。当对方也说了“再见”后，你就可以挂电话了。
可是且慢，对电话而言这个模型成立，我们得稍作修改才符合网络——当你挂下电话机后，对方不会出现忙音。于是，当你说再见，对方说再见，你必须再说一次再见，对方才能确定你听见了再见。而且这次，事情非常符合两军问题——你们永远也无法就什么时候挂机达成一致。这个问题再折衷回来，也是一个三次模型，对方说再见，你说完你要说的话，然后说再见，对方再见，挂机。
被动关闭上，这个模型基本是正确的。当你收到“再见”后，把你要说的事情说完，然后再见。这时候不能挂电话，因为你不确认对方听到你的“再见”了。如果你的“再见“对方没收到，那么对方会死等到天荒地老。至于为什么对方可以肯定你收到了他的再见，是因为刚刚你说的那堆废话里，应该已经包含了“我知道你要挂电话了，我会尽快说完”的意思。所以，你需要等对方的“再见”回来。
当然，在tcp的实现上说，所有对对方的回应，都在ack里面。所以是FIN FIN-ACK ACK，关闭。最后一个ACK前，叫做LAST ACK状态。如果ACK丢失，会造成被动方挂断有问题，因此这里需要一个超时机制。用电话术语来说，就是最后一个再见没听见，你就要等到天荒地老，因此当对方首次再见完成的时候，你说再见，如果一定的时间等对方的最后一个再见等不到，就别等了，直接挂机。这个时间比等不到对方任何消息而挂机，要来的短。tcp标准设定为两倍最大生存周期，即2MSL。当然，如果等到了最后一个ACK，就直接删除连接数据结构。
主动关闭的时候，情况会更加复杂一点。为什么？因为刚刚的超时机制。我们从你说再见之前开始说起，这次你是主动告别一方。
你首先说了一个再见，然后进入FIN_WAIT1状态，换成电话术语，就是等对方说再见。tcp机制上，对方的ACK先到，就是FIN_WAIT2。对方的FIN先到，就是CLOSING——这种情况不多见，只在双方同时想挂断的时候发生。如果对方的FIN-ACK一起发送，那就直接保送上TIMED_WAIT。无论是哪种先，最后会收到一个ACK和一个FIN，并且发送一个ACK。换成电话术语，就是你说了再见，对方一定会说知道了和再见，并且你会说知道了。差别在于tcp需要用多个状态来表示哪个事情先，哪个事情后，打电话就不要这么麻烦了。
最复杂的事情，在于说了最后一个再见之后。当你说完最后一个再见，就可以直接挂电话么？电话可以，但是作为tcp，却不可以。因为某些情况下，对方的FIN包没有到就会进入TIMED_WAIT状态。另外一些情况下，对方的LAST_ACK等不到你的ACK，会把他的FIN重发一遍。如果直接销毁连接结构，那么最后一个FIN包可能对新的连接造成干扰，而且会阻碍对方关闭连接。所以，作为主动挂断一方，你有一点很不利的是，无论如何，你必须等这个2MSL的时间。这个值在linux中一般是60s，更进一步可以查看rfc1337。
刚刚解说的最后一个情况，就是很多机器TIME_WAIT很高的原因——因为你的服务器主动关闭了连接。作为本质解决方案，你需要理解为什么会发生这件事情，服务器端关闭连接是否正常。如果正常，那么加一些内存，并且启用tcp_tw_recycle来减缓这个问题。注意，这个参数不应当在NAT后的机器上被启用。具体可以查看rfc1323。</description>
    </item>
    
    <item>
      <title>哈希冲突漏洞的原理和对策</title>
      <link>http://blog.shell909090.org/blog/archives/2052/</link>
      <pubDate>Wed, 04 Jan 2012 03:59:57 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2052/</guid>
      <description>cpug上面最近在讨论一个严重级漏洞，漏洞的相关资料如下： ERT-VN:VU#903934 CVE-2011-4815 CVE-2011-3414 CVE-2011-4838 CVE-2011-4885
上面主要讨论的是这么一个概念，当用户post一个数据，而且这个数据又是一个form的时候，应用需要先将form解析为dict，然后才能方便的使用。例如a=1&amp;amp;b=2，可以解析为{&#39;a&#39;:&#39;1&#39;, &#39;b&#39;:&#39;2&#39;}。之所以1和2是字符串，是因为只有用户自己才清楚这个数据的类型。
通常情况下，这个form的key都是随机的，生成的hash碰撞概率很低，因此dict的默认实现——hash table没什么问题。但是当攻击者恶意构造数据的时候，情况就完全不同。我们首先讨论一下hash table的实现——开链法和二次探测法。
所谓开链，就是指对所有同余hash，将他们挂到一个hash表项上，形成一个链表。而所谓二次探测，就是在第一次hash冲突后，再进行一次hash，作为第二地址。
开链法对碰撞冲突是有先天缺陷的，因为同余碰撞的构造远比hash碰撞的构造简单。假定hash
table有11个表项，那么平均11次尝试就可以得到一个元素，和原始元素hash同余。如果选用这样的恶意key序列，在执行构造的时候，hash
table就退化为了链表。链表的插入复杂度是O(n\^2)级的。而作为攻击者，为了获得n个hash同余对象，所需消耗的复杂度做如下估量。首先考虑hash table length和n同阶，因此以n作为hash table长度。这样每n次尝试就可以获得一个恶意元素，获得n个元素的复杂度为O(n\^2)级。
也就是说，即使是sha256这样强的hash算法，只要保证哈希函数特性，对同样的值得到同样的哈希，就无法保证开链法的安全。
而二次探测法对这个是有先天抵抗的，二次探测法的第一次碰撞并不难构造，但是第二次哈希后依然保持同余的构造难度就由n增加到了n\^2，多次碰撞的构造难度以此类推。虽然我没有完整的计算过这个值，但是猜测难度量级应当是O(n*n\^n)级别的。这个级别基本就不用玩了——前提是哈希算法必须是安全的。
由于为了节约计算过程，因此python和php的hash算法都没有采用md5之类的高散列算法，而是一个很简单的算法。我摘抄一下Python2.7.2中的这段代码。python_string_hash.c
static long string_hash(PyStringObject *a) { register Py_ssize_t len; register unsigned char *p; register long x; if (a-&amp;gt;ob_shash != -1) return a-&amp;gt;ob_shash; len = Py_SIZE(a); p = (unsigned char *) a-&amp;gt;ob_sval; x = *p &amp;lt;&amp;lt; 7; while (--len &amp;gt;= 0) x = (1000003*x) ^ *p++; x ^= Py_SIZE(a); if (x == -1) x = -2; a-&amp;gt;ob_shash = x; return x; }  按照&amp;lt;python.</description>
    </item>
    
    <item>
      <title>理想的平板</title>
      <link>http://blog.shell909090.org/blog/archives/2050/</link>
      <pubDate>Mon, 02 Jan 2012 14:37:32 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2050/</guid>
      <description>7寸以下宽屏，原因，可以一手拿住。
 300g以内，原因，可以一手拿住。
 厚度1cm以内，原因，拿得舒服。
 10小时续航，原因，一天可以只充电一次。
 3g支持，原因，不支持3g的不叫理想的平板。
 IPS/PLS屏幕，原因，普屏的视角的却有的时候很不爽。
 usb可充电，原因，外部电源续航方便，充电方便。
 支持TF卡，原因，方便。
 USB OTG，原因，可以拖U盘和键盘。
 GPS支持，原因，地图是很重要的。
  好吧，我们合并要求起来看看。300g以内10小时续航，目前芯片和屏幕的功耗连电池重量都不够。所以这个无形就要求更加节能和强劲的芯片，还有更加节能的屏幕。同时，这个屏幕还不能比IPS视角差。
继续等吧。</description>
    </item>
    
    <item>
      <title>密码三文的补充</title>
      <link>http://blog.shell909090.org/blog/archives/2044/</link>
      <pubDate>Tue, 27 Dec 2011 10:01:11 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2044/</guid>
      <description>前两天写了两篇关于密码的文章，其实没说什么，都是程序员的常识和经历。实话说比较有意思的是大家的反应。
一个是，大家为什么纷纷盯上了第一条？我在写的时候，主要考虑的最多的是第五条，就是网站本身方便盗窃其他网站资料，或者为网站本身提供便利。具体可以看某个投诉知乎的帖子。但是来的人几乎无一例外，都在和我讨论第一条。我不知道理由是什么，大家都觉得政府这么值得怀疑么？实际上，除非政府觉得你有资格收集密码，否则基本没有听说密码必须明文存放的潜规则。你想想，你在国内搭建一个小论坛，需要备份明文密码么？
上级要求明文密码的过程大概是怎么发生的？我听一个朋友聊天的时候说到，网管部门要他们系统上某个用户的密码原文，还必须是原文。当然，作为管理部门，是不需要解释原因的。他们表示，密码都是md5之后的。做不成，对方也没有什么表示。后来老板说，设计系统的时候，密码就用明文吧。从这个闲扯中反推，我大概能窥见事情是怎么发生的。不过神奇的是，这个简单的事情，怎么会发展成“网管部门有保存明文密码的要求”的，我描述的太模糊了？
另一个是无所谓的忧虑。我发现很多过来的搜索都是“哪家银行明文保存密码”，还有朋友加我gtalk问我google是否安全。实话说我觉得大家太多虑了，而且考虑方向还错了。与其考虑谁明文保存密码，不如先无良的假定“你们都是坏人，密码都是明文”。然后再想，我的钱是不是还安全？我的系统是不是还安全？我要不要关注这个安全？你指望对方设计的时候使用了hash，多重hash，salt，还不如指望自己的密码强度足够，而且符合使用规范。
密码是什么？从信息学角度说，密码是某个密码空间中的一个随机值。你和服务器约定，提供这个随机值，服务器就验证你的身份。从这个角度说，每两个实体间验证身份都需要一个独立的随机数，而且这个随机数空间还必须够大。现在的主要问题，是大部分人对这个值的选择太过有规律，太过简单，而且更危险的，对所有场合使用同一个值。如果真的需要使用同一个密钥，除非你的密码体系是公钥体系。否则即使是challenge-response模式，也有差分攻击这个问题。
另外顾虑google的那位朋友就有点神经过敏了。当年google退出中国的理由是什么？被攻击。作为一个被攻击后，事情没人知道的情况下，反应这么大的公司，无论如何比其他闷声不响的公司更加重视安全，也应当更加安全吧？你们知道索尼的网站也有密码泄露么？你们知道国内网站在这次之前有多少入侵事件么？在事情没有曝光前主动反应的，google是最大，最严重的一家。如果他不可信，我觉得要找另一家可信的公司就更困难了。</description>
    </item>
    
    <item>
      <title>网络安全——你需要知道的东西</title>
      <link>http://blog.shell909090.org/blog/archives/2038/</link>
      <pubDate>Fri, 23 Dec 2011 12:00:41 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2038/</guid>
      <description>首先，我也不是专家，如果里面有什么错漏，欢迎补充。补充和转载请注明我的blog: http://shell909090.org/blog/，我会根据你的发言在上面直接修改，没同步过去可不赖我。
要安全的使用网络/服务，你所需要注意的头两个问题就是你的安全级别和客户端的安全级别。对于零级密码，你随便在什么客户端上输入，都没有关系的。但是网银之类的最高级别密码，你不能在不可信机器上输入。什么叫不可信？别人的机器，你要相信这个人的技术和人品。自己的机器，你要在上面装了杀毒软件，没有执行过各种奇怪的程序/小游戏。这才叫可信的终端。如果你的密码在别人机器上用了，回来马上修改密码（不要在对方那里修改，没意义）。最好的方法，就是找一台旧电脑，专门装一个系统，装杀毒，用来使用网银和各种安全应用。别用深度定制版的操作系统，别人用过就重装。
当然，大多数的人都觉得，这样好麻烦啊。好吧，你可以无视这条规则——只要你对下面的各种病毒隔离和恢复措施做的够到位，对自己的技术够自信——至少我还没有这个自信。或者你可以认为我在危言耸听，彻底无视我的建议。大部分的情况下，你都是对的。这些事情都是徒劳的白做工。不过很低的概率下，你会中招——自己考虑。
其次，不要使用不可信的服务/产品。这条的执行力度自己考虑。一家公司，曾经做过流氓插件，你用不用他的产品？一家公司，曾经被央视曝光，你用不用他的产品？一家企业，敢于劫持客户的数据，将内容替换成自己的广告，你用不用他的服务？很多时候，我们都是别无选择，只能听天由命。不过当你有的选择的时候，尽量使用名声比较好的公司的产品。也许你觉得——这个不重要。好吧，Who care是最大的无力。
接下来，你要注意你的个人信息。被各个地方窃取使用个人信息已经很无奈了，你自己再爆出去就是无语了。你有没有在开心上公布手机号？有没有公布自己生日？有没有写自己的邮箱地址？有没有说过自己的家庭地址？这些信息都会被用于社会工程攻击，例如伪装你朋友的邮箱给你的邮箱写信，说借我二百。。。别笑，从开心上很容易收集这样的数据，伪装和发送也很自动。
后面一点对一些普通人可能比较困难——你要区分什么是可以信任的，什么是不可信的。下面的事情你权当笑话去听，是否照做自己判断。
1.来电号码是不可信的，来电无法验证身份，短信和电子邮件也不行。如果你的一个朋友来电或者发消息说让你干什么事情，认证身份的最低办法是打回去。更加通用和安全的方法是共同知识验证——哎，大学的时候，我们隔壁宿舍摔断胳膊那哥们当时干啥摔断胳膊来着？伪装者怎么知道TM那倒霉孙子胳膊是怎么断的？通常人人上也不会说这个吧——除非丢的正好是人人帐号。
2.传票是邮寄到家的，公安局找你都是上门或者通过街道。如果有人电话给你说是某法院/公安局，你不妨要他的电话和部门名称，然后打114查号，再打过去。通常情况下，不管也行——真有问题他们会上门找你的。
3.网站什么都不能说明，即使那个网站里面有所谓的标识。例如qq.c0m（假如这个注册的出来的话）不代表腾讯，这个上面有人说你中奖一点意义都没有。即使来源真的是qq.com，那也不代表事情是真的。同样，靠谱的方法是要他的号码和部门，114查证后打过去。
4.400电话打过去都不可信，你要是打一个400电话，和打一个民居没什么区别。对方有个声音很好听的小姐接听，还有——请稍等，我为您转接一位同事——也一点意义都没有。号码来自百度也没意义。
5.用114电话比用百度的好处是，百度给钱就可以瞎排，这个都上央视了。114目前我还不知道有什么竞价排名的东西，所以你找一个电话多数都是靠谱的。注意，这个不绝对。
6.手机这东西少借给别人，尤其是不熟悉的人。里面多个窃听器发信器你都不知道是谁干的。现实中没那么玄乎，也就是拿你的卡号申请动态令牌，申请前找你借五分钟手机而已。
7.软件怎么判别是否可信？通常来说，敢开源的都是比较可信的，毕竟里面干了些什么大家都看的到。闭源的软件和服务就看你是否信的过这家公司了。
8.对于别人推荐的玩意，尤其是朋友推荐的玩意，你最好确定一下确实是本人推荐的。即使是，我也保留的打开——技术上说，就是专门找台机器来运行。
9.有的时候，要敏感。你打给一家订票网站，他们需要你的身份证和信用卡号，给不给？实话说，这是个风险，而且不小。很多人的问题不是评判失误，而是根本没意识到这样做的风险。要知道，目前一代身份证还没有完全废弃，万一对方拿你的身份证号伪造了一张身份证，然后申请重置密码之类的事情。虽然能不能成两说，但是这两个号码同时泄露给一家网站总归是个风险。同样的还有携程——去年我曾经向他们的客户经理投诉，他们的电话语音系统居然要我人工报卡号，身份证之类的。我说如果是电话输入系统还好说，人工操作万一你的接线员记下来怎么办？这个你能保证么？今年大家打携程电话去看看？虽然我没有完全信任携程，但是电话系统比人工系统的安全性总是高那么一点点——除非他们故意在设计时捣糨糊，明明是电话录入系统，还是能让操作员看到全部卡号。
其实万千方案归结到后来都是八个字，多听多看，谨小慎微。会来看这篇blog的都是多听多看的，那么只要谨小慎微就好了。哪怕这谨小慎微有的时候显得有点小人和扭曲——不敢用别人的电脑上自己的帐号，不敢打开别人给的软件，不给别人玩自己的手机。到底多谨慎，看你自己觉得自己多重要。要是觉得一人吃饱全家不饿，就算全国密码泄露也与你无关。如果你觉得自己还是有点身家，有些该坚持的问题上还是要坚持一下。
最后说一点无奈的事情。即使你上面的事情全部做到，有很多事情还是无可奈何。例如携程的问题，他们有一个业务是只需要输入卡号后四位就可以订票，很明显，这是记录过全部的卡号才可以做到的事情。如果他们的数据库泄漏，攻击者是否就可以直接从中划帐呢？外推考虑这个问题，你会发现所有输入过信用卡号的公司，无论他们是否可信，你都要假定他们保存了你的卡号信息。所以事情就只能信赖银行的信用卡系统，包括大笔消费警告，未经手消费复核，先行赔付等等。只有消费后能够复核的信用卡公司，才是可以信赖的公司。
PS:
另外做一点广告。全国各家涉密公司，如果你们不希望你们的管理员/操作员随意接触高级管理帐号，希望能够审查谁接触过用户账户信息，你可以用我们的系统。http://www.shterm.com/。我们目前做的是堡垒机密码托管，除了一个最高管理者外，管理员都不知道自己使用账户的密码是多少。同时，访问过用户账户信息会留下无法清除的记录，事后可以审查。
注意：普通用户上这套系统没用！</description>
    </item>
    
    <item>
      <title>关于密码——你们不知道的很多事情</title>
      <link>http://blog.shell909090.org/blog/archives/2035/</link>
      <pubDate>Thu, 22 Dec 2011 23:32:27 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2035/</guid>
      <description>1.hash密码安全么？
只要你的原始密码不大复杂，hash密码也完全没有安全性可言。不信？echo &amp;lsquo;abc&amp;rsquo; | md5sum，去www.cmd5.com，看看有没有。同样，拿你自己的密码试试看？
注：null同学对此提出了异议，表示这个网站的可信性也值得怀疑，不要输入你自己的密码。我考虑过后觉得有道理。从基本安全性上说，网站只能收集密钥，无法收集用户，所以密码泄漏的风险不大。从我个人来说，一个网站如果爆出hash泄露，基本等同于密码泄漏。所以本质上避免问题的方法是一次一密。但是鉴于国内很多网站还是直接使用了hash（尤其是md5）保存了密码，在这个网站上输入了密码等于将自己的密码加入了字典，从而减低了安全性。
在此，向所有被我忽悠的同学诚挚致歉。如果你在里面输入过密码，建议你将密码改为一次一密。即每个网站使用不同的密码。通常一次一密的同学不会再把自己的密码到这个网站上进行搜索了吧？
2.国内哪些网站不是明文密码。
我说出来你信么？再说，配合1，这个问题重要么？一次一密，经常修改才是王道，长度和频率看这篇文章《密码管理规范》。另外，现在记得去公布出来的密码表里面搜一下自己的密码。
3.一次一密就安全了么？
差了远了去了。你有没有在别人机器上登录的经历？你可以信任他么？你自己家里装的一堆插件你都相信么？你确定他们对你的银行密码没有兴趣？你要知道，银行开发安全插件的人和做恶意插件的人是同一个圈子的人——不会攻击就不能防范么。而且我们阴谋论一点说，你就确定这些软件商没有接到上级指令要求加入后门？现在你还敢在自己家里的机器上装中国软件么？QQ，迅雷，这些都算大软件，看着的人比较多。你自己可以搜他们抓你行为上传的文章——用谷歌搜。其他小站点的各种软件呢？你装了多少？
4.还有哪些比较低级的情况？
当年，有一个网站，提供一个功能。你可以在他的网站上直接登录其他邮箱。相信我，这可比这次的问题严重多了，那可是一收集一批阿。
5.为什么我以前都不知道？
要和你说我们有安全问题，你还用不用了？
再说我和很多人说起过这些问题，他们当年的态度都是——没关系，反正没人会对我的信息感兴趣的。我估计这次，还有不少人会说——没关系，反正我没有CSDN帐号/人人网上面的数据看到就看到咯。
很多人第一次知道安全问题的严重性，都是在他们丢了钱之后。往往都是莫名其妙，钱怎么丢的？
6.那银行呢？
银行还是相对安全的，不过你要确认银行有以下几个功能。登录失败警告功能。五次登录失败自动锁定账户，要隔天由本人解锁，解锁后最好强制更换密码。关闭网银和电话银行功能，不拿着本人身份证经过24小时以上申请不能打开。密码丢失需要一周以上的时间才允许重设。大额取款通知用户功能。
听上去很麻烦？通常来说，越麻烦的银行越安全。以上功能都有了，并且使用了，那么银行本身而言，还是比较安全的。
7.可是我要用网银。
那你用U盾，而且不要用水货版的。我07年选择招行的理由是，招行是唯一当时我觉得没有安全问题的银行。现在这个列表应该加入浦发，并成为首选——对linux友好而且不容易破解。但是不要用只有手机动态密码的模式。
有些U盾就是密码文件隐秘的放入的一个U盘，这种U盾我都可以复制出一堆来。用上这种U盾，最多满足你自己的心理因素。
而且，更好的方法是对信用卡申请网银，而银行卡关闭（如果银行支持的话）。这样的话损失最大不超过一张信用卡可用额度，我目前的信用卡而言，最多一次损失几千——总好过几万的学费吧。同类的思路可以选择支付宝，你一次打个1000进去可以用一阵，丢了只有这1000。
8.你知道U盾的正确用法么？
U盾应该在需要的时候才插上去，用完立刻拔出。虽然说不像拆炸弹，不过还是插入时间越短越好。
因为很偶尔的情况下，入侵者刚好在看你的电脑。发现U盾后，可以指挥你完成登录的网银系统进行交易。但是网银交易必须以U盾为基础，拔掉他们就干不了坏事了。
9.为什么手机不是安全设备。
手机安全是相对的，只能说比电脑安全。你以为手机就安全？首先，智能机上面已经满足了恶意软件存在的基础。例如小米——虽然我很喜欢他——你确定雷布斯没有在小米里面加入后门，截取你的密码再偷偷转发？现在没有——以后呢？同样，你确定你信得过苹果？将来苹果也不会出现安全漏洞？
即使退一步说，你的手机很安全。来，把手机给我，不要看它，然后告诉我，手机里有多少软件可以读取你的本机信息，有多少可以读取短信？即使是完全安全的系统，我只要写个小游戏，号称因为需要短信分享，需要操作你的短信。你会怀疑么？我趁着你不注意，读取你的手机，和泄露出来的卡号-手机信息交叉比对。对你的卡号申请动态密码，然后让我的程序偷偷的拦下来短信，不让你知道，发送到服务器端。你是不是丢钱丢的莫名其妙？
相信这条写到这里，九成九的用智能机的朋友已经满脸汗了——妈的这些程序能读取我的银行卡动态密码？技术上说，真可以。
普通手机用户也别高兴，我没记错的话，GSM协议已经被破解了。就是说，我可以在你旁边拿个设备直接接受你能收到的短信。这TMD叫安全设备？
10.那你说的keepass？
这东西能在手机和电脑上运行，就肯定不安全。数据文件放在硬盘上的时候没问题，即使入侵者拿到也没办法。但是你输入密钥的时候有keylogger就完蛋了。
所以我只在linux和android上用，虽然android不安全，但是目前我还不知道有keylogger。
11.妈的，我还有什么安全的。
这个真没有，RMS说过，安全是个笑话。让用户来完成安全更是笑话中的笑话。当然，没有用户的安全意识，银行/网站再努力也没用。但是本质上说，应当以侵犯隐私去起诉泄密单位，而且应该打下来是巨额赔偿。
然后这个事情就会变成，各家单位纷纷表示，我们不对免费用户的信息安全负责，并且推出免责条款。然后又是扯不清的糊涂帐——如同我们今天的EULA一样。
只是在景德镇，你连操作第一步的机会都没有。还是用脚投票，放弃一些实在不安全的公司吧。例如业界很知名的某个做恶意软件出身的公司，还有某个买了这个公司的前身的大搜索软件商。某个以动物作为Logo的公司，还有被国家大哥曝光多次的某家公司。凡是业界已经臭了名声的，最好都别用。
12.日子还过不过了？
淡定，我明天还会写一篇，你要注意的东西。虽然不说一定安全，不过普通用用问题不大的。</description>
    </item>
    
    <item>
      <title>密码为什么明文存放</title>
      <link>http://blog.shell909090.org/blog/archives/2032/</link>
      <pubDate>Thu, 22 Dec 2011 11:02:49 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2032/</guid>
      <description>很早就写过一篇blog，说到过，你的密码应当一次一密，至少某些密码泄露时不至于波及太广。结果这次CSDN不幸中枪。我不去讨论多少人急急忙忙修改密码，多少人数据泄露，单说说为什么很多时候密码是明文存放的。
就我有记忆以来，我写应用就从来没有明文存放过密码。最起先是md5方式存放。md5可以让你找到hash值，有的时候也会被用于穷举。但是无论如何，md5密码本身比明文安全很多。后来改成了challenge-response验证模式，也是用md5做的hash后进行c-r的。再后来，md5的碰撞冲突的论文出来，后面用的多数都是sha256了。从头到脚，我就没做过密码明文存放，并且，我认为这是正常程序员最起码的修养。（当然，明文存放的代码不是没有，不过那是调试模式）
但是现在我所知，很多系统的身份验证都是密码明文存放的，为什么？其实我不大理解。不过有时候问起，有些人和我说了几个我觉得不是搪塞的理由，现在抄录如下，告大家知。
1.不用明文密码没法应付检查。大家知道互联网审查，有时往往会一个电话过来，要XX用户的密码。如果你没法给出，上头就认为你不配合，事情各种难搞。作为审查机构的老板，当然没必要知道明文密码的危害。他们只知道，我要密码，为什么不行。所以，悲崔的程序员们就往往会得到一条死命令，保存明文密码。
2.压根不知道明文密码有什么问题。中国的互联网有太多的没基础的新人，从石头的缝隙中顽强的生长出来。这不是坏事，坏事的是这些人往往会在一些基础问题上出现奇怪的毛病。例如有些程序员，写程序很快，但是居然从来不知道密码明文存放会导致什么问题。更神奇的是，这些人中，有一家银行&amp;hellip;
3.自信暴棚的混帐。有些人的自信总比别人强，而且强在莫名其妙的地方。例如：我的服务器肯定是没问题的，所以我的密码一定要明文存放。如果不，就是质疑我的技术。
实话说，这种人真是少数中的少数。
4.遗留系统。很多系统设计的时候因为某个其他理由，使用了明文密码。等后来这个理由不存在了，密码系统升级成了一个困难。因为密码系统太重要了，所以在没有太大利益的情况下，总是倾向于不修改系统。但是有什么足够利益来推动系统修改呢？用户安全问题在发现前不是一个问题——好比这次的CSDN，不是被暴出来的话就根本不会被当作一个问题。系统的管理者，每个人都没有足够的动力去修改系统。
5.世界的阴暗角落。有的时候，程序员/老板明文存放的理由，是为了方便盗窃用户其他网站资料。例如我所知的某钓鱼案例，你注册网站，就提供很多免费服务，网站看起来也很靠谱——除了后来突然爆出这家网站其实暗地中用你的生日/密码猜解信用卡/银行卡密码，大家才突然发现，这家网站其实根本没有在美国注册，而是一个听都没听说过的国家。
而且很多网站提供从其他网站导入之类的功能，更加的危险。以前经常爆出twitter密码被窃取，主要就是因为OAuth开放以前，twitter上的第三方应用需要提供原生密码，导致很多小应用的目的其实就是收集密码&amp;hellip;
6.为了给用户提供方便。这个理由和上一个很类似，不过不是为了某些险恶的目的。而是客户经常要求——为什么我不能做XX事，为什么我不能blahblah。好吧，为了让你能，我们就必须保存明文密码。
明文密码的保存原因很多，不过结论都是一样的。在任何网站/服务上，你绝对不能使用同一个密码，零级密码除外。尤其请注意，不要在两家银行使用同样的银行卡密码/网银密码，原因不说。
从未来进化的角度说，密码的未来进化趋势是核心授权体系。就是你要向某个网站验证身份，只需要向身份验证商验证，剩下自动完成。现在的openid就是一种解决方案。密码都没了，还谈什么泄露呢？同时，实体交互和授权的精细划分也是一个趋势。某个网站访问别的网站的数据的时候，会形成一个访问令牌。这个令牌对需要访问的内容详细写明，并且需要用户授权。OAuth就是这个趋势的代表。另外一个趋势是利用某个足够安全的设备作为以上两者的终端载体。目前这个设备用的是手机，可是——手机不是一个足够安全的设备。也许这会是下一个XX门的隐患吧。
参考：《密码管理规范》</description>
    </item>
    
    <item>
      <title>python conf 2011无线组网总结和分享</title>
      <link>http://blog.shell909090.org/blog/archives/2002/</link>
      <pubDate>Mon, 05 Dec 2011 10:44:38 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2002/</guid>
      <description>这次python conf 2011结束了，具体成败sting去总结。我主要负责网络部分，把网络部分的总结一下吧。总体来说，网络不算成功也不算失败。在现有条件下，资源没有都发挥出来。但是万幸的是，关键部分还没有掉链子。下面是具体总结。
1.没在场地里面拉好线并且实地测定过所有地点信号的不算部署完毕。
这次的会场平时不允许进入，只能在工作日去，所以只能在会议前一天跑现场。而且进入时没有长网线，墙壁上也没有网线接口。因此是会议前一天先根据具体环境完成了设定，支支下午去买了线，第二天早上部署的。这留下一个严重隐患，我把设备间当成了贵宾室，凭经验估计信号覆盖范围的时候出了错，信号没有覆盖到贵宾室，而且没有考虑门口。第一天的嘉宾和志愿者们，是否感觉信号像渣一样（尤其是杨毅涛）。其实这主要就是因为根本没有考虑到信号覆盖的问题所致的。
要解决这个问题，必须先知道会场结构，包括贵宾室，设备间，签到处等等重要但是部署时又不容易想起来的地方。然后估算需要多少个多强的AP才能覆盖。例如本次的贵宾室，最佳方案是拉40米网线到贵宾室，然后再架一个AP。会场往往没有线，需要自带网线。因此最好是有人知道会场大致结构（手绘亦可，但是标注一下承重墙），然后计算AP位置和网线长度，再去购买。或者直接买一箱网线，配上水晶头打线剪自己做。会议前至少一天去部署，用android测试每个点的信号强度，最好都达到-70db以上。完成后把电线和网线都用胶带封在地上，以防绊倒。
2.足够的AP和信号。
在估算AP和信号的时候，这次经验是，多一个天线，信号强10db。支支的三天线AP信号明显强于我的双天线AP。AP的信号是和距离的立方成反比的，一个AP保证20-30米的无阻挡会场是没问题的。但是每穿一道墙，信号就会下降大约20db。低于-70db就开始出现大量掉包了，-80db的时候tcp重传严重，导致基本无法使用。
一个AP可以接入的客户端是有限的，按照我看下来，大约在50上下（TP-LINK）。这个和事先估计一致。本来我想用6个AP，但是很难凑够这么多，而且带宽不足，就没借这么多。预定就是需要一些人没有设备或者接不上去的，否则就是所有人都不能顺利上网了。结果有一个AP在连接10个设备后就会崩溃，所以等于无法容纳用户。大部分用户都拥挤在同一个AP上，导致踢掉非常严重。会场峰值时刻，300人，有120个设备试图获得IP或者已经获得成功，但是AP在线只有20/50（AP1/AP2），即40%左右的设备被踢掉或者自动断开了Wifi（部分手机为了省电会发生这样的事情）。如果三个AP完好，120人在线刚刚好支撑的起来（20/50/50），但是这样的话连线设备可能还要多一些。
下次部署的时候，除了要考虑信号覆盖问题，还要考虑预留一些AP作为备用。因为会场AP都是民用过去支持，这些设备以前也没有做过大容量测试。我只能说TP-LINK的两台机器很给力，说到50就到50，多了就不能支撑，但是不死机。有台机器就频频死机，这样就需要备机更换。
另外，我们这次最高三个AP，因此分别设定为1/6/11频道就行了。如果AP还要多，请注意让同样频段的设备分到会场的远端。
3.世界真的很麻烦，有的时候有位置却没有电源。
这次电源还算给力，从墙上引出了不少拖线板，基本满足组委需求。至于普通听众就抱歉了，自带拖线板坐到边上的，互相交错给便携设备还能充个电。中间听众只有依靠地接。偏偏地接基本都拉给了组委的摄像机，周围一圈的人可以沾沾摄像机拖线板的光，其他人就只能相信电池续航了。
我们的AP3，第二天搬到了贵宾室那个方向。反正上面只能接不到10个人，给贵宾室小规模用用还可以。结果线只有30米，拉不到贵宾室。合适的位置又没有电源。只好委屈在后门口接了一下，把贵宾室的信号提高了不到10db。
据说有的会场更恶心，只有一两个电源接口。这种会场就必须带够插线板和移动设备来保证电力。
3.留出会议运营所需资源。
这次还算成功的一点，是为大会组委和志愿者/嘉宾保留了一路AP。大会的签到系统，嘉宾演讲都需要Wifi支持，为了让听众上网导致演讲失败就本末倒置了。为嘉宾保留的是AP1，上面还有一些比较活跃，或者着急使用网络的普通听众，一般大约20人左右，相对比较空。可是这个AP又不敢开放给听众使用，一使用就怕嘉宾没法演讲了。
wifi管理者比较怕的问题，主要就是有人使用wifi下载比较大的内容。因此开始的时候，会议需要网络的时候，我都用平板监控网络使用状况。如果有人正在使用大流量，就准备踢人。幸好，大家都很安分（或者是AP上不来）。后来也就放松警惕了，结果老外演讲的时候延迟很厉害，我差点就跑去拔掉AP2的电源了。这会断开所有人的网络，但是演讲者的使用就通畅了。
按照雨苍说的，组委wifi组一个重要任务往往就是封锁各个debian/ubuntu镜像的下载。我们这次没有出现这么恶劣的问题，谢天谢地。
4.会场的网络使用有非常强的峰值效应
这次会议只有2M带宽，因此我一直担心不够。后来开始看看还不错。但是休息的时候一直接到wifi很慢的投诉，空下来一直测不出。我第二天休息的时候去测试了一下，我的天，带宽全满，延时超高。说明演讲者水准很不错，大家专心听会，不怎么用网络。一休息，得，网络不够了。
这个没法解决，要解决只有增加带宽，或者在不休息的时候再使用一些比较耗费流量的业务。一个缓解的办法是使用qos系统，但是这次dir-825没有前往会场，所以没机会调试qos系统。
相对来说，路由器的NAT让我很放心。TP-LINK普通路由器的NAT在支撑80-90人的极限在线的时候仍然很稳健，速度不快是带宽问题，路由器没有崩溃就是万幸。
5.根据具体情况配置。
WEP比较节约资源，所以我们开始配置的是WEP信号。但是测试下来，苹果系统对WEP的支持非常差，基本接不上去。所以就不要节约了，使用WPA/WPA2。
运营商的接入情况比较多变，而且很难控制。这次运营商给我们的是一个内网IP，192.168.1.2。他们已经有了一个路由器在前面。我使用了双重NAT方案，而且避开192.168.1.x网段，来避免修改它们的路由器（我们无权控制）。
这次我们使用的是192.168.0.1&amp;frasl;24网段，三台AP的连接模式是一主多桥。一个主router负责DHCP和NAT，其余的全部当单纯的AP使用。从1到3分别分配0.1-3的IP，2/3的DHCP关闭，1的DHCP从20开始分配起，直到254，共计最高容纳234人在线。20以前的IP让组委的人作为静态IP预留。如果还要多，建议使用192.168.2.0/23网段，最高可以容纳500人不到，足够大部分的会展使用。如果再不够——你们考虑10网段吧。
最后的经验总结。
1.会前勘察真的很重要，尤其是会场平面结构，承重墙位置，会场部署，电源插座位置，一定要提前至少三天确认。提前一天的时候要配好所有AP，备件和网线到会场部署，然后测试信号。
2.会场带宽一定要大，万一实在不够大，想办法ban掉debian/ubuntu的镜像，然后做qos或者squid。
3.自带足够材料，如果没有胶带/接线板/剪刀，那很多事情就要抓瞎。
4.据说TP-LINK之类的路由器在人数多到一定程度的时候会自爆，推荐使用高级设备或者电脑来做NAT/DHCP。不过我至少肯定100人的时候还没问题。</description>
    </item>
    
    <item>
      <title>从网页中爬链接的一个小技巧</title>
      <link>http://blog.shell909090.org/blog/archives/2000/</link>
      <pubDate>Fri, 02 Dec 2011 15:00:11 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/2000/</guid>
      <description>没啥好多说的，从verycd中爬所有的ed2k链接。
lynx -dump -listonly -nonumbers &amp;lt;http://www.verycd.com/topics/XXX/&amp;gt; | grep ed2k &amp;gt;&amp;gt; ed2k.txt  要看到ed2k未转码的内容也不难。
import sys, urllib with open(sys.argv\[1\], &#39;r&#39;) as fi: print urllib.unquote(fi.read())  </description>
    </item>
    
    <item>
      <title>openwrt特性——2.4g和5g频段的冲突</title>
      <link>http://blog.shell909090.org/blog/archives/1986/</link>
      <pubDate>Fri, 18 Nov 2011 17:02:30 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1986/</guid>
      <description>贝壳昨天想起，自己的平板是支持11n的，路由器也支持，为啥不做呢？于是把路由器的第二AP打开。结果——报错了。
具体过程就不废话了，老妈和外婆在唠叨各种废话，没那个心情。
DIR-825用户，把你的第二AP设定成和第一AP不同的频率。如果两者使用同一频率段，系统就会报错。估计是两个频率各自给了一根天线，混用没那么多天线。</description>
    </item>
    
    <item>
      <title>openwrt配置——arptables配置</title>
      <link>http://blog.shell909090.org/blog/archives/1973/</link>
      <pubDate>Mon, 07 Nov 2011 10:32:09 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1973/</guid>
      <description>让其他人的设备无法使用网络。
opkg install arptables --------/etc/init.d/arptables-------- \#!/bin/sh /etc/rc.common start (){ arptables -F INPUT arptables -A INPUT --src-mac aaa -j ACCEPT arptables -P INPUT DROP } stop (){ arptables -F INPUT arptables -P INPUT ACCEPT } --------end files--------  注意，千万把自己的mac地址写对了，否则一个/etc/init.d/arptables restart下去，你自己的机器就断线连不上了。不过一般来说，重启后arp限制会失效，因此可以重启来去掉限制。实在不行也可以拔下U盘，在电脑上进行mount和修改，然后再插回去启动设备。根据测试结果，内网还是可以访问的，不过路由器无法访问了。有一个链叫做FORWARD，也许改这个可以解决。但是我没有找到相关资料，因此没有下手。</description>
    </item>
    
    <item>
      <title>Openwrt pptp passthought</title>
      <link>http://blog.shell909090.org/blog/archives/1971/</link>
      <pubDate>Fri, 04 Nov 2011 14:43:37 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1971/</guid>
      <description>你还在为使用openwrt路由器无法使用pptp客户端而烦恼么？请看这个页面。按照他的说法，输入以下句子就可以解决你的烦恼。
If you use a pptp client behind an openwrt router, and pptp tunnel not work, look at thispage.
opkg update opkg install kmod-ipt-nathelper-extra  这个方法不仅对路由器内使用一个pptp有效，而且对多个pptp也有效。
It&amp;rsquo;s work for both single pptp tunnel and for multi pptp tunnels.
然后，记得重启。
Remember to reboot router.</description>
    </item>
    
    <item>
      <title>收稿子啦，宅男买数码</title>
      <link>http://blog.shell909090.org/blog/archives/1967/</link>
      <pubDate>Wed, 02 Nov 2011 11:13:20 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1967/</guid>
      <description>淘宝上东西很多，360buy东西也很多，电脑卖场多如牛毛，听起来买个数码产品是个很容易的事情。其实才不是呢，尤其是对于对数码有要求的宅男来说，买个设备要多困难有多困难。
贝壳上淘宝买一个充电器，要求也不高，5V/2A，可以用于我的台电P81HD平板。OK，上淘宝，找第一个卖家，狮王的四口充电器——结果，总电流不足，退货。第二个卖家，瑞能官方店——结果，有高频分量，在充电时无法正常操作，目前还在协商中。第三个卖家，三星的充电器——结果，充电有高频电流声，温度很高。gary说，他有个DELL的充电器也有类似问题。我很高兴的说，那是没事咯？他说，结果，爆了，连带烧了整个房间的电闸。然后拆开塑封看印刷，粗糙，肯定假货无疑，强行要求退货。第四个卖家，上去问，有货么？有货。真货么？真货。确定么？确定。我这么说吧，我不和您讲道理，到手后，我找三星干活的兄弟看。他说真货我就收货，他说假货我就退货，连邮费一起退。不退差评。
——先生？
——您好？
——还在么？
OK，这就是淘宝的品质。当然，我不是说淘宝无好货。Thomas老婆在淘宝上买的DIR-825路由器还是挺好用的，我在上面订花什么的也不错。问题是，对于产品挑剔的宅男来说，在淘宝上买东西是一个艰难的抉择。应该说，淘宝基本无真货。
那么京东之类的电子商城呢？
贝壳买过他们的两箱秋叶原六类线，结果其中一箱的中心龙骨缺失。我问他们怎么回事，他们就只负责退货。还好，退货，换发票的过程都是OK的，但是没有一个人出来说一句，这是为什么，也没有人道歉。看看京东上面比较热门的东西，基本都能看到旧货贴。啊——运气不好，终于让我碰到旧货了。看来他们也没靠谱到哪里去。
那咋办？
OK，贝壳简单说一下一个想法。
贝壳会收集您的文章，包括某个数码产品，您的购买时间，价格，个人评价，当然，最重要的，购买方式。因为文章要发在贝壳的blog上，所以您需要同意内容以cc-by-sa3.0相容版权发布。当然，文章会署您的名字。收集文章的前提是，我得认识您。您和贝壳是在哪里吃过饭，您帮贝壳解决过什么问题，物理世界里面互相有过交流。只要认识，我就会贴出，或者转发您的文章。注意，需要反复强调的是，里面需要提供购买方式。贝壳不介意那个卖家和您有没有亲戚朋友关系，只要这个东西是可靠的。为什么可靠？既然我认得您，我就相信您。一个人钻研半天技术，只为了其他几个宅买几样东西而说谎，这是不值得的。就好象贝壳写那么一大堆技术资料，开这么一个blog，不会为了几个钱的回扣专门骗你一回。因此，如果你认得贝壳，这个事情也是比较有保障的——至少你不会故意的被骗。至于运气好坏，个人感觉，这个就真不好说了。所以，如果您不认识贝壳，只是经常跑过来看技术资料的——那，就看您信不信了。不管您信不信，反正我信了。
而对于来挑选东西的宅男们，贝壳要说明的是。贝壳买东西的风格，是偏好产品的用途和质量，而无视价格的。所谓无视，既包括可能因为某个卖家不靠谱或者某个型号不靠谱而购买相对比较贵的产品。也包括某个东西虽然名声不显，但确实很好用，而无视东西的品牌。因此，您可能会问，为什么贝壳这里只介绍DIR-825路由器，还有那么多更物美价廉的呢？例如buffalo的某款。首先，可能因为贝壳的朋友只有人用过DIR-825。其次，贝壳知道buffalo的路由器都是单AP，而贝壳本身是一定需要双AP的。或者您也可能会问，为什么我们对苹果这样的东西，周边居然配了一个名不见经传的充电器/触摸笔。实话说，只要好用，我不在乎。
另外，我也希望从文章中挑东西的人，把您的经历也附加在下面。包括您买了同样产品，感觉如何？其他产品，好不好用？这也是给后来者一个借鉴。
好吧，废话半天，现在贝壳开始征集稿子了。
PS：个人希望，如果有买了小米手机量产版本的小白鼠，能够跳出来说说情况。贝壳希望入一个，可是网络上说法满天飞，不知道该信谁啊。</description>
    </item>
    
    <item>
      <title>一个充电器的小问题</title>
      <link>http://blog.shell909090.org/blog/archives/1963/</link>
      <pubDate>Fri, 28 Oct 2011 15:45:06 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1963/</guid>
      <description>我不知道我的blog读者有多少是使用手机/平板来看我的blog的，估计不会很多。但是如果说有多少人用电容屏手机/平板，那估计不会少。那有多少人知道，充电器选择不好会导致触摸屏出现问题呢？
今天贝壳就有幸碰到了这个问题。P81HD，买了一个单独的蓝魔的线进行充电。USB2DC，2.5mm头，内正外负。不知道有多少人看出来了，DC的电气特性和USB有个很大的区别——不是，我不是说没有信号引脚，当然DC是没有信号引脚的——最大区别在于，USB定义了一根地线，而DC没有。因此DC的屏蔽能力比USB差一点。差多少呢？如果你的充电器是2口的，那就是没区别。。。
不过，无论充电口怎么设计，电气参数都是5V/2A。从ipad以后，这都成了usb充电器的标准最大功率了。另外科普一下，usb的四种常见电流，100mA，500mA，1A，2A。100mA是电脑连接小型设备时的默认功率，500mA是电脑USB口的最大输出电流。1A的就是手机充电器/非标准电脑口的输出电流了。至于2A，这是非标准功率，ipad用的。
5V/2A的功率是相当大的，在使用的时候，如果充电器不好，会造成触摸屏不灵敏，甚至无法工作。贝壳的P81HD配合上瑞能的充电器（旗舰店出的，应该是正品），在一个手指点击的时候，会出现额外的触摸。本来点在左下角，在右下角会多出现一根触摸点，一跳一跳的。本来贝壳自己还想不通是什么理由，周四聚会的时候，旁边的LTN同学给出了答案。如果你用了不合格的充电器，会导致你的手机无法在充电时使用。具体可以看这里。简单来说，所有便携式开关电源，都会造成电容屏手机无法正常工作。不过有些开关电源做的比较好，在输出上加了滤波环。如果自己使用带有滤波环的数据线，一样可以缓解这个问题。
我找瑞能旗舰店的人反映，他们说让我打客服电话。先打了一个福建的电话，0595-22636088。接电话的是个售后，我描述情况后，他找了一个技术。技术告诉我，这情况他也没碰到过，我是头一个反映的。他们也没有办法，要退货找瑞能旗舰店的人。然后，旗舰店的又给了我一个电话，是800的全国电话，8008585185。打过去，这个客服靠谱多了，说这个情况他们见过。一个iphone用户，也有类似情况，重启后问题消失。我说我重启N趟了，他说，这个就不知道了，我找技术问问。
不得不说，人家做服务的态度真的非常好。过10分钟，电话打过来了。说，他们的产品都是经过严格的出厂检测的，应当不存在输出电流不稳的情况。我这个情况有可能是因为在使用时，瞬时电流超过2.1A，导致软件故障。我说，你知道我的设备的功率是多少么？他说，不知道。我说，电池是3.7V*4Ah的，应当是15Wh左右。可用5小时，功率应当是3W。除以输入电压5V，电流是600mA。如果充电电流维持2A不变，加入一个0.6A的工作电流，你这个充电器早严重超载了。这个理由说不通。他说，那要么你去我们上海的维修点，带着设备，他们会给你当场测试。如果确实不解决问题——你那里买的？我说，淘宝的瑞能旗舰店。他说——那个没事，他们会当场给你退货的。如果设备烧掉了，我们也有保险的。
当然，说是这么说，不过地址是在南站那里，贝壳过去太困难了。反正我把这个过程说给猫咪听，她说，废话什么，直接给差评得了。卖家的东西在客户这里用出问题，应当负责运费给换一个。让客户自己带来带去非常不负责。然而作为一个死理性派，贝壳比较反对没有弄清事情就直接下结论，何况人家态度很好。（当然，这些承诺你信不信就是另一回事了）因此打算找个人检测一下输出，看看是否带有交流。
然后，贝壳和小强说起这个问题，小强借出了他自己的ipad充电器。这个是上海苹果官方店里面买苹果附送的，带序列号，绝对正品。接上去——一样不行。可见并不是瑞能的问题，而是P81HD的屏幕太容易受到干扰了。当然，瑞能和苹果充电器本身有高频分量是一定的。为了解决这个问题，贝壳行险，在淘宝上买了一个三星galaxy的充电器，就是thomas借给我的那种。到货接上去试了试，一点问题都没有。这说明，三星的充电器在质量上比苹果的好多了。</description>
    </item>
    
    <item>
      <title>P81HD的特性和问题</title>
      <link>http://blog.shell909090.org/blog/archives/1947/</link>
      <pubDate>Tue, 18 Oct 2011 10:50:17 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1947/</guid>
      <description>情况简介和简评 1.续航问题 5小时，正常使用没有问题，包括看电影。如果比这个短，那就说明你在待机时有程序在工作。这个细节不解释。如果开启3G，或者拖其他OTG设备，大概会减少到2小时左右。
2.3G问题 别的不敢说，配送的eth网卡和MF190联通3G网卡可以顺利支持。 接入3G网卡后自动识别，大概需要20s启动和初始化。监控流量可以用3g watchdog。我一个月包了200M，估计用不掉。
3.物理按键问题 Home键的设计者是个白痴，这个键能不能换个地方？我每次拿的时候，都很容易误触。待机就唤醒，开机就程序消失。此为P81HD最白痴的特性，没有之一。 没有物理的回退键也是个错误，状态栏经常崩溃，消失后系统就没法用，没有回退键。有时会自动启动，恢复正常状态。有时三五分钟依旧不恢复，必须重启机器。这是P81HD第二白痴的特性，没有物理回退键，学3.0用状态栏，状态栏又不稳定。
4.屏幕问题 屏幕很清晰，但是细看的话颗粒很粗。从右边和下边看，屏幕发黑，典型的非IPS屏问题，视角很小。
5.性能评测 实际能够使用的最大内存是282M，其余应当是系统使用了。去掉系统进程后，可以用于程序的内存大约是150M。CPU基本都够用，安装和删除程序很快，输入无卡顿。3D加速一般，切水果时略卡，可接受（我打了550多分）。看flash的时候有小幅卡顿，不严重，可接受。有少数时候，系统会失去反应。怀疑是内存耗尽，回收导致CPU耗尽。发生频率不高，每次大约需要10-20s恢复。在驱动3g/同步/后台发生其他行为的时候，前台程序明显很卡，甚至会丢失按键，严重时无法流畅使用。估计是前台程序的优先级调整有问题，在htc g2上也有类似问题，可能是android系统的通病。使用双核的系统明显没有这个问题。
6.手感问题 512g，略重，再挑的时候希望轻一点。由于Home键的存在，手持的时候总要避开下方，并不很方便持拿。
7.零散错误 在首次连接3G网卡的时候，出现方向显示和输入错误。现象是显示方向和正常一致，但是点击左边，右边出反应。 在连接3G网卡的时候，反应缓慢。怀疑是由于开始同步和3G驱动导致CPU大量被使用。 周边的点击有时会错位。 有时莫名其妙死机，需要捅菊花。一周内发生十多次，不过其中有一多半发生在系统调整/安装程序的时候。
可解决的，或者不是问题的问题 1.root方法 这不是个问题，装GingerBreak，直接重启，不多废话。
2.充电问题 这是P81HD历来反应的第一问题，其实P81HD充电问题不一定和root有关，我没root的时候也碰到过。主要是这样的。你插入充电器，看到充电符号的时候，其实充电器不一定工作。只有你看到电量上升，才代表充电器工作正常。而且，当线被动过后，也可能会变成假充电状态。有充电符号没有实际充电。 设备不支持USB充电，但是很幸运的，充电电压是5V，电流0.5-2.5A。所以你可以买一条USB2DC线路，将USB的5V电压直接充上去。原装的线也太短，不爽。
3.不支持联系人/日历同步，没有gtalk的问题 默认的rom里面没有，你可以从这里下载到合适的apk文件。这些是从我手机（htc magic chock4 2.2 rom）中提取出来，2.2用的。安装后可以正常工作。 本地下载链接（请不要盗链）：GoogleCalendarSyncAdapter.apkGoogleContactsSyncAdapter.apkgtalk.apk
4.不支持的程序 不要用flash11，至少到目前为止不行。用flash 10.3就好了。链接在这里。
5.wifi channel 12&amp;frasl;13 中国设备规范中都不支持这两个频道，不要想了，在中国你就不应当使用这两个频道。
6.wifi tether 默认机器是不可以adhoc的，不但不能接入其他设备（例如手机）开的adhoc，而且连自己设定里面做的wifi共享3G的功能都不能用，用之会死机，必须捅菊花。不过你可以用barnacle这个程序。这个程序很牛，可以绕过wpa_supplicant工作，直接将wifi置于adhoc模式。这样其他机器能看到这个共享点。但是注意，由于android无法连接到adhoc，所以，你手机做出来的wifi热点电脑能用，P81HD不能。P81HD做出来的，电脑能用，手机不能。
不能解决的问题 1.adhoc连接问题 android设备无法连接到adhoc网络。据说这个特性是wpa_supplicant过滤了adhoc模式的所有网络所致。如果我闲的蛋疼，会去研究一下怎么绕过这个机制。直接使用网络上的补丁会导致网络无法连接。
2.vpn问题 默认没有额外的kernel modules支持，没有openvpn文件，没有busybox工具。busybox可以安装busybox installer来进行安装，openvpn可以安装openvpn installer来进行安装。但是即使完整安装工具链，也没有办法加载tun模块，使用openvpn连接。cifs没有测试过。 pptp/l2tp测试无法连接，服务器日志表明连接后马上断开，原因未知。 安全隧道测试无法连接，原因未知。</description>
    </item>
    
    <item>
      <title>Vnc动态调整分辨率</title>
      <link>http://blog.shell909090.org/blog/archives/1925/</link>
      <pubDate>Sat, 01 Oct 2011 06:59:29 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1925/</guid>
      <description>vnc可以调整分辨率，这个很简单。
vncserver -geometry HxV  就可以设定纵横分辨率了。
但是vnc怎么动态调整分辨率呢？RDP可以根据连接时参数来调整分辨率，vnc好像没有这个功能吧？
最近贝壳需要在电脑上和上网本上同时使用一个桌面，于是碰到了这个问题。经过寻找，这个问题的答案是这样的。
vncserver -geometry 1600x1000 -geometry 1440x900 -geometry 1024x600  然后，在进入系统后，输入xrandr，可以看到你启动时设定的多个分辨率。再用xrandr -s N，就可以选择合适的分辨率了。
这个是X的randr扩展，需要vncserver版本在4以上。我的环境是debian testing，vnc4.1.1。欢迎大家测试。</description>
    </item>
    
    <item>
      <title>合用两个路由器的几种方案</title>
      <link>http://blog.shell909090.org/blog/archives/1917/</link>
      <pubDate>Mon, 26 Sep 2011 12:03:30 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1917/</guid>
      <description>为什么用两个路由器？最常见的理由是延长信号。在超级大的场地中，中间放一个路由器，用四根线连接到周围的几个路由器上面，信号覆盖整个场地。这是最常见的理由。也有可能是因为你的主路由器LAN接口不足了。当然，也可能是因为蛋疼，或者其他原因。不论如何，为了在多个路由器上达到同时上网的目的，你有以下几个选项。桥接模式，路由模式，双层NAT模式。
我先解说一下一些基础的环境。我假定你有一个互联网线，有一个路由器的WAN口接到了互联网上面，这个路由器称为M。其他路由器分别称为S1,S2&amp;hellip;。直接连接到M的LAN口的电脑称为ML1,ML2&amp;hellip;，通过无线连接的就称为MW1,MW1&amp;hellip;。同样，连接到路由器S1的LAN和无线的分别叫做S1L1,S1W1，类推。
1.桥接模式
这是你第一个应当尝试的模式，连接方法是路由器S1的LAN口直接连接路由器M的LAN口。这个模式不一定能够配通，原因是因为要求路由器S必须支持桥接模式。基于某些理由，很多路由器并不支持桥接。一般来说，有可能LAN口支持桥接而WIFI不支持。因此S1L1支持桥接成功的概率比S1W1支持桥接成功的概率高。如果你需要一台支持桥接的路由器，TP-LINK的TL-WR*系列路由器好像大多支持。希望大家补充哪款路由器支持桥接或者不支持。
桥接是将路由器S完全的作为一个交换机使用，所以你的ML1和S1L1在同一个网段，两者可以互相ping通，发送各种包，也可以看到对方的广播。这种模式一旦连接成功，连接模式是透明的。因此，应当关闭DHCP，只启用一台路由器的DHCP功能。或者最好手工分配IP。
严格来说，只有S是一个无线路由的时候，这个模式才叫做桥接。如果只做有线连接，这个模式应当叫做交换模式。
2.路由模式
路由模式，是一个比桥接复杂，效果好，但是用途相对比较窄的方案。接法是路由器S1的WAN口连接路由器M的LAN口，并且为S手工指定IP，再关闭S的NAT功能。M的网段和S的网段必须不为同一个网段，例如M配置为192.168.0.0/24网段，S配置为192.168.1.0/24网段。S的WAN口手工指定为192.168.0.2。然后在M1上配置人工路由，将192.168.1.0的所有包交由路由器192.168.0.2处理。并在S1上配置默认路由为192.168.0.1(M的地址)。
这个模式是将路由器S和M作为路由器使用。当S1L1发送包时，会被S1转发到M去处理。而M收到要发送给S1L1的包时，会交由S1处理。这一模式能够工作的基础是你能够控制M的路由表，并且S可以关闭NAT。通常情况下，这个S最好是OpenWRT/DDWRT。这也是为什么用途比较窄的原因，毕竟支持桥接的路由器好找，OpenWRT/DDWRT就相对小众了。
当这个模式连接完成后，ML1和S1L1在不同网段，但是两者可以互相ping通，发送各种包，却无法看到对方的广播。因此这种模式的效果比桥接好一些，因为地址范围更大，而且很容易隔离广播风暴。这种模式一旦连接成功，连接模式是透明的。
3.双层NAT模式
如果上两种模式都不工作，你就必须使用双层NAT模式。这种模式保证一定工作，但是在使用上比较麻烦，需要用户自行计算访问规则。
接法是路由器S1的WAN口连接路由器M的LAN口，并且将S配置为DHCP。M的网段和S的网段必须不为同一个网段，例如M配置为192.168.0.0/24网段，S配置为192.168.1.0/24网段。
S的数据包会被NAT两次再发到互联网上，要进行端口转发也必须配置两次。性能相对比较差，而且无法做NAT穿透。
当这个模式连接完成后，ML1和S1L1在不同网段，S1L1可以ping通ML1，但是反过来不行。因此，S1L1可以主动连接上ML1，而反过来不行。这种模式不是透明的，两者进行连接时必须考虑网络转换和端口转发。</description>
    </item>
    
    <item>
      <title>密码管理规范</title>
      <link>http://blog.shell909090.org/blog/archives/1915/</link>
      <pubDate>Thu, 22 Sep 2011 10:26:25 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1915/</guid>
      <description>下面是贝壳自己总结的密码管理规范，大家可以参考一下。
概念解说
 网络密码和本地密码。网络密码通常很难暴力攻击，尝试速度受到网络限制，而且尝试一定次数后还可能被管理员发现。而本地密码则相对比较容易攻击，我假定本地密码攻击可以达到每秒测试2\^30个密码。
 密码长度推定使用如下计算方式。使用年数乘以攻击频率，得出攻击者在密钥使用期限内能尝试的最大次数。为了安全起见，尝试范围不应当超过总体密码空间的一定比例。以此推算出密码空间大小，进而推算出信息位数，然后还原为密码位数。
 数字密码，字母密码，数字字母混合密码，大小写数字混合密码。数字密码的信息量是3.3bit/位，字母为4.7bit/位，混合为5.17bit/位，全混合5.96bit/位。
  密码原则
 一次一密。除了零级密码，不要为多个系统设定一样的密码。有些系统并不像我们想像的安全，一旦这个系统出问题，被还原原始密码，就会牵连到其他系统。
 定期更换。没有什么密码能用一辈子。
 写下来。因为一次一密，所以我们会有大量的散碎密码。不写下来是不保险的，写下来是不安全的。折衷一下，还是写下来，保存好吧。推荐用高级密码加密低级密码的方法，例如keepass。
 生成型密码。用一个特定字符串+网站名，做sha-1然后取最后8位。这样的密码满足一次一密，不容易破解，不需要写下来，唯一的问题是你要现算&amp;hellip;
  零级密码
 零级密码是有些不需要保护的情况下，又非设定密码不可。对于这种情况，你只能设定一个不算密码的密码。例如常用机器的用户密码。这些密码可以通过livecd/liveusb轻易修改，因此没有一点保密价值。
 零级密码不需要安全性和保密性，因此好记就行。例如111，222，选一个常用的，爱用多久用多久。
  低级密码
 低级密码是用于保护一些你不希望别人看到，然而别人看到并没有直接损失的内容。例如家里机器的性能数据，普通相册的访问密码。这些内容被别人看到不会产生伤害，然而无成本的放出这些内容有潜在的风险，或是你自己主观意愿希望保护，内容安全性要求又不特别高。
 我假定低级密码在网络上会受到100次/年的攻击，本地密码会受到1小时/年的攻击，可用时间五年，穷举空间不超过总密码空间的1/1000。
 网络密码的攻击信息量为log2(100 * 5 * 1000) =
  18.93bit。使用数字密码应在6位以上，字母，混合，全混合应在4位以上。
 本地密码的攻击信息量为log2(2\^30 * 3600 * 5 * 1000) =  54.10bit。使用数字密码在17位以上，字母在12位以上，混合在11位以上，全混合在9位以上。
 结论，低等级的密码长度小，使用数字也并不难记。推荐使用4位以上字母（反正混合使用长度也没有下降），不要使用常见组合还有单词。推荐方式是将自己喜欢的一句英文首字母简写前后颠倒使用。例如：I  will be back，对应密码bbwi。
中级密码
 中级密码用于保护一些你不希望别人看到，别人看到会对你产生损失的内容。例如你的帐薄，日记等等。中级密码使用时，最主要的风险已经不来自于密码本身，而是使用密码的环境。包括电脑是否安全，中途网络是否安全，旁边人的肩窥攻击。
 我假定中级密码在网络上可能会受到10000次/年的攻击，本地密码会受到100小时/年的攻击，可用时间1年，穷举空间不超过总密码空间的1/100000。
 网络密码的攻击信息量为log2(10000 * 1 *100000) =</description>
    </item>
    
    <item>
      <title>悲崔的六类线</title>
      <link>http://blog.shell909090.org/blog/archives/1913/</link>
      <pubDate>Wed, 21 Sep 2011 15:39:45 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1913/</guid>
      <description>大家知道，贝壳家里用的是千兆交换机对吧？最近贝壳在装修（好吧，回头看情况，也许有装修手册出来），所以——布线的时候打算用六类线。
先普及一下常识，六类线和超五类的区别在哪里？
百兆网使用的是五类和超五类线，最大长度100m，接线规范使用EIA-768B，实际使用1236四根线进行通讯，频率100MHz。考虑双工后，可以在整根线上提供100Mbps的速率。而千兆网使用六类线，接线规范也是EIA-768B，但是实际使用了12364578全部接线（所以六类线必须全部连通，否则掉速，不要用五类的经验想当然）。频率250MHz，在整根线上可以提供1000Mbps的速率（别看我，我也觉得有点问题，资料来源wikiCAT-5CAT-6）。
为了在中间没有四根地线作为缓冲的情况下支持高速的数据传输，六类线通常使用22-23AWG的铜芯制作。尽管标准上允许24AWG的六类线出现，但是这通常是不堪使用的。而五类线和超五类大部分都是24AWG的线芯，粗细是0.51mm。23AWG线芯粗细0.57mm，22AWG粗细0.64mm。而为了隔离串扰，六类线中心通常有旋转的十字龙骨，将四对缠绕线分割在四个区域，防止电容效应干扰。
OK，有了基础常识，我们可以讲一下京东的问题了。他们提供的线问题其实很简单。有一箱线在中间有部分区域十字龙骨缺失。
如果我买的是普通线就算了，5元多一米的秋叶原线，在京东这种商城，居然会在中心位置龙骨缺失。我很怀疑我埋下去的另一箱是否也有类似问题呢。
更郁闷的是，我打给京东，他们的客服不道歉就算了，也没个活人出面解释一下这个是什么问题。就只有“你可以退货阿”，“你这样就可以退货拉”，的提示。退退退退你妹阿，尼玛另一根线回头出了问题我得重新埋线呐。更可气的是有个客服脑子堪比芙蓉姐姐，给我一个厂家电话，让我打给厂家。我说如果厂家不予解决呢？她说，你可以再打4006065500转3。我说那不就是你们的电话么？她说，你可以再打4006065500转3。我说是不是再打到你们这里？她说，你可以再打4006065500转3。。。尼玛你是鹦鹉阿，直接说再打我们电话不就完了么。再说了，你给我的方案就是打给厂家，厂家不解决，再打给你，你再咋办？哦，对了，这时候就不是你办了。真是好办法。
可见在天朝这种地方，产品质量是完全不用关心的，有退货就是最大的慈悲了。至于产品造成了后果，赔偿什么的。售后经理笑脸迎人，可以阿，有检验结果我们就赔。问题是TMD国家质检中心不给力阿，不但价格贵，而且很多事情根本不检。你不信在07年拿瓶三聚氰胺奶过去，就算清清楚楚的告诉他们有什么问题，得到的答复还是——抱歉，我们没这个检验项目。再说检验通过，厂家立刻变脸，抱歉，这个我们有规定，只能赔偿多少。然后你只能进行漫长的“调解-仲裁-一审-二审”过程。厂家有的是时间精力，不怕玩不残你。就算你侥幸通过，终于能获得赔偿，听上去天价的赔偿还不够你的时间成本。更不谈有些事情，损失十多万，按国家规定赔偿只有不足千元——“因为国家就是这么规定的”。</description>
    </item>
    
    <item>
      <title>gnupg密钥签署原理和过程</title>
      <link>http://blog.shell909090.org/blog/archives/1903/</link>
      <pubDate>Wed, 07 Sep 2011 10:52:29 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1903/</guid>
      <description>gnupg的密钥基础运用比较简单，有能力跑过来看我blog的应该都比较清楚了。不过最近接触了gnupg密钥的一些复杂运用，才发现——这玩意，居然能构造类似于PKI的复杂密码体系呢。
gnupg的密码体系和PKI类似，又有区别。PKI密码体系有数个根节点，负责验证服务。然而gnupg没有这种根节点，一切都是以社会关系网络运作的。更加复杂，也更加接近自然社会体系。
首先是gnupg的基本密码原理，公钥和私钥对。利用私钥签署，公钥验证。公钥加密，私钥解密。这是最基础的两种用法，我们略过不谈。密钥签署的问题提出来源于，我如何相信我得到的密钥，真的来自他所声称的这个人？
例如，我得到了来自Linus Benedict Torvalds的一封邮件，上面说blahblah。当然，听起来应当高兴，不过暂缓，这个信真的是linus本人写的么？这时候，我可以导入linus的公钥，验证签名——当然，如果有签名的话。不过问题又来了，你如何保证得到的是linus本人的公钥，而不是某个试图破坏系统的人伪造的呢？
好吧，为了解决这个问题，gnupg设计了互相签署机制。当我签署了某个人的公钥，并且将我的签署上传到公钥服务器（或者发送回给本人）的时候，我就为这个人的真实性做出了背书。例如，当我为thomas做了公钥签署，然后上传到了公钥服务器。然后thomas向某个他并不直接认识的我的朋友发送了一封邮件——例如发送给了julia。julia收到信的时候，会从服务器上下载thomas的公钥，然后看到我的背书。如果julia相信(trust)我，那么gnupg就会自动完成验证。当然，将公钥上传到服务器会略微降低安全性，所以如果限于安全考虑，我没有上传到公钥服务器，而是传回给本人。那么thomas就必须在给julia发送邮件的时候，附上公钥。julia一样能看到公钥上我的签名。
下面是如何操作。
首先你必须获得公钥，以下是从公钥服务器上下载的方法。
gpg --keyserver &amp;lt;keyserver&amp;gt; --recv-keys &amp;lt;Key\_ID&amp;gt;  而后，你需要看到这个公钥的fingerprint。
gpg --fingerprint &amp;lt;Key\_ID&amp;gt;  再然后，就是比较困难的部分。你需要和这个公钥的拥有者碰头，找个地方喝个咖啡，或者一起出来玩什么的。然后，查看他的有效证件，和本人对照，并且取得他本人认可的fingerprint。
这点非常重要，不要轻易的使用线上fingerprint交换来替代这个过程，也不要随意的为别人进行签署。你必须*确定*你签署了本人的密钥，线上获得的key，是完全可能被修改的，这是对所有信任你的人的负责。
再然后，就是简单的签署。
gpg --default-key &amp;lt;Key\_to\_use&amp;gt; --sign-key &amp;lt;Key\_ID&amp;gt;  最后，上传公钥，或者传回给本人。以下例子是上传到服务器的，不过记得先征求对方同意——除非你原本也是从服务器上取得的公钥。
gpg --keyserver &amp;lt;keyserver&amp;gt; --send-key &amp;lt;Key\_ID&amp;gt;  至于revoke什么的，暂且就不说了。
其中最麻烦的，就是上述过程中，两个人碰头的部分。为了简化这个部分，gnupg使用者经常有种gnupg
keysigning party[2]的聚会，互相交换和签署密钥。
reference:
[1].The GNU Privacy Handbookhttp://www.gnupg.org/gph/en/manual.html
[2].GnuPG Keysigning Party HOWTOhttp://alfie.ist.org/projects/gpg-party/gpg-party.zh-tw.html</description>
    </item>
    
    <item>
      <title>我有几台电脑</title>
      <link>http://blog.shell909090.org/blog/archives/1899/</link>
      <pubDate>Thu, 01 Sep 2011 11:53:39 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1899/</guid>
      <description>废话贴，数一下。
家里能正常工作的电脑四台，一台台式机，11年7月买的，一台笔记本，07年买的，一台上网本，09年买的，一台低功耗服务器，11年初买的。
两台租用设备，一个是空间，一个是vps。
公司一台电脑，10年换的。
两台嵌入设备，wince和android各一，还打算明年入个平板。
虚拟设备七到八个，常用的两个，一个xp一个debian。
差不多就这些。</description>
    </item>
    
    <item>
      <title>ACC lead to no core temp reading?</title>
      <link>http://blog.shell909090.org/blog/archives/1885/</link>
      <pubDate>Tue, 16 Aug 2011 14:55:36 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1885/</guid>
      <description>I bought a Phenom II X4 955 CPU month ago, recently I find that HWMonitor can&amp;rsquo;t read core temp, just motherboard temp. I googled it and find this article.
This article said that ACC is a tech will make AMD X3 work like X4 byunlock cores in BIOS. But CPU core temp sensors will not work, even use a real four cores CPU.
贝壳一个月前买了一块羿龙IIX4955（黑盒），但是最近发现HWMonitor读不出核心温度，只有主板温度。放狗搜了一下，找到这篇文章。根据这篇文章说，ACC是一种能够让AMD三核CPU像四核一样工作的技术，只要在BIOS中打开unlock cores选项就好。但是这个会使得CPU的核心温度传感器不工作，即使你真的有四个核，而不是仿冒四核。</description>
    </item>
    
    <item>
      <title>硬盘底座入手</title>
      <link>http://blog.shell909090.org/blog/archives/1881/</link>
      <pubDate>Thu, 11 Aug 2011 10:16:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1881/</guid>
      <description>贝壳买的新硬盘底座入手了，质感不错，很沉，只是在插入硬盘的时候对准不是很方便，总是要对一下才能对准。而且硬盘插上去有点摇晃，如果长时间使用还是会伤硬盘的。不过针对短时间使用，底座正是一个好解决方案。
硬盘底座，就是将硬盘插上去，然后接入电脑的器件。现在大部分硬盘底座都是sata接口的，以前有IDE接口的，贝壳试过，不稳。IDE本身就不支持热插拔，硬做上去当然好不到哪里去。通常而言，硬盘底座/移动硬盘/sata热插拔是三种相关又各有特点的解决方案。底座的目标是使得硬盘可以更换，使用底座的人，多数希望在一台电脑上更换使用一个接一个的硬盘，对硬盘没有特殊要求。移动硬盘，基本就是把底座的硬件和硬盘捆绑到一起。使用移动硬盘的人，是希望一个硬盘在一台台的电脑上使用，对电脑没有特殊要求。而sata热插拔是强调热，即可以不关机接入设备，对台式机用处不大。通常是现场空间不足了，不能关机增加存储设备造成的需求，对插拔次数支持并不好。有资料说，普通sata接口大概能承受50次的插拔。普通硬盘安装而言，50次是一个非常足够的数目了，但是移动硬盘使用的话，几天就用光了。
底座支持两种接口，usb2.0和esata。前者的速率是480bps，后者速率是3.0Gbps，合前者最高60M/s，后者最高375M/s。一块民用硬盘的突发速率往往高达150M/s，usb对于普通台式机而言显然是远远不足了。而且esata直接挂入硬盘控制设备下面，而USB则是挂入USB控制器链，效率上说差了一点不说，而且esata是作为普通硬盘对等管理的。
贝壳本次的方案，是通过一根sata 2
esata接线，将mini-itx主板上的一路未使用的sata引出机箱，连接到底座上。但是linux下要支持esata，必须在BIOS中将SATA设备模式改为AHCI，而后重启进入系统，可以看到设备变了。当然，这个改变对于windows系统来说是个灾难，但是linux系统完全不在乎这个事情。
debox:\~\# lspci | grep -i sata 00:1f.2 SATA controller: Intel Corporation N10/ICH7 Family SATA AHCI Controller (rev 01) debox:\~\# lsmod | grep ahci ahci 25089 2 libahci 22767 1 ahci libata 149043 2 ahci,libahci  这次更改造成的一个额外效果就是，机器上的普通sata硬盘速度也上升了。从原来的71M/s到了115M/s，提升相当惊人。</description>
    </item>
    
    <item>
      <title>openwrt配置——QoS配置</title>
      <link>http://blog.shell909090.org/blog/archives/1837/</link>
      <pubDate>Mon, 20 Jun 2011 10:10:39 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1837/</guid>
      <description>说到openwrt，就不能不提一下QoS。尤其是如果你需要用P2P软件（目前对迅雷的支持还不大好），基本就不能不开QoS。QoS的全称是Quality of Service，意即服务质量。是专门用于解决拥堵网络上的信号质量一视同仁的问题。例如，我们有一根宽带，两人共用。一个人视频聊天，一个人bt下载（我还不提迅雷个傻X呢）。玩bt的那个一开软件，视频聊天那个立刻没法用了。bt和视频聊天稍微好一点的是，视频聊天消耗的带宽是恒定的。你可以逐步限速，只要给视频聊天留了足够的带宽，两个就都能一起用了。但是，如果另一个人不是视频聊天，而是网络浏览怎么办？网络浏览，视频聊天，p2p下载一起来怎么办？实际上这是很多朋友家中常常碰到的情况。更不说有合租公寓里面你很难监控对方一定限速，软件无法限速甚至恶意抢占带宽（迅雷）。另一个更加技术的问题是，由于上传带宽不足，ACK包回应过慢，导致你的下载速度也不能达到峰值。玩p2p的常常会给上传限速到真实带宽差一点的位置，下载带宽立刻上去，就是这个道理。
怎么办？用QoS，解决你多年老便秘。QoS的底层是tc，其目的就是决定先发送哪些包。openwrt默认的规则是hfsc，设计了四个优先级。Priority最优先，处理22,53,icmp，以及小于128字节的syn,ack包中，不属于bulk类别的。我们可以看到，DNS，syn/ack的优先响应，保证了你的上传不会影响下载。其次是Express，处理5190和小于500字节的UDP包。这个我也不明白是为什么，好像是视频什么的。然后是Normal，包括20,21,25,80,110,443,993,995这些常见端口。涵盖http/https，ftp，邮件系统。最后是Bulk，包括其他包，尤其是ed和bt。
当你启用QoS后，你的p2p软件速度应当不会上升，反而会下降。下载速度不好说，有可能是上升，也有可能下降。因为原来p2p软件抢占了所有带宽，目前他们只能使用普通应用用剩下的带宽，速度当然慢了。然而，当你使用浏览器，收发邮件的时候，速度应当和不使用p2p的时候一样流畅。这才是使用QoS最大的意义。
方法很简单，安装QoS包，然后修改/etc/config/qos，注意修改你的带宽。不修改的话，流量会被无意义的限制死。
另外，打开QoS后，千万记得把你的p2p软件改为不限速。否则不能达到最高性能。</description>
    </item>
    
    <item>
      <title>openwrt配置——防火墙规则</title>
      <link>http://blog.shell909090.org/blog/archives/1836/</link>
      <pubDate>Fri, 17 Jun 2011 14:01:28 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1836/</guid>
      <description>如果说路由规则还能讲讲，iptables防火墙规则就彻底没法讲。简直是千变万化无所不能。下面就简单说一下，对于新增的tun0设备如何设定防火墙规则。
----------config/network---------- config &#39;interface&#39; &#39;tun&#39; option &#39;ifname&#39; &#39;tun+&#39; option &#39;proto&#39; &#39;none&#39; ** ----------config/firewall---------- config &#39;zone&#39; option &#39;name&#39; &#39;tun&#39; option &#39;input&#39; &#39;ACCEPT&#39; option &#39;output&#39; &#39;ACCEPT&#39; option &#39;forward&#39; &#39;REJECT&#39; config &#39;forwarding&#39; option &#39;src&#39; &#39;lan&#39; option &#39;dest&#39; &#39;tun&#39; option &#39;mtu\_fix&#39; &#39;0&#39; config &#39;forwarding&#39; option &#39;src&#39; &#39;tun&#39; option &#39;dest&#39; &#39;lan&#39; option &#39;mtu\_fix&#39; &#39;0&#39;  好了，新增了一个网口，叫做tun，处理所有tun+（就是任何tun设备）的吞吐。默认规则是可以收发，拒绝转发。转发规则是可以和lan互相转发。
/etc/init.d/network restart /etc/init.d/firewall restart  然后你看看你的配置是否正确。
iptables -L -v  另外，这个配置方法有个bug。由于你的网口是tun+，所以在启动时，无法自动启用这个接口。在路由器重启后必须/etc/init.d/network restart才能工作。对我来说，每次路由器重启后都是手工开启openvpn的，问题不大。但是对于某些人就比较麻烦。对此推荐这些人直接修改/etc/firewall.user，直接加入以下指令。
iptables -I INPUT -i tun+ -j ACCEPT iptables -I OUTPUT -o tun+ -j ACCEPT iptables -I FORWARD -i tun+ -j ACCEPT iptables -I FORWARD -o tun+ -j ACCEPT  使用interface配置的最终效果也差不多，不过比较简单整齐好理解。</description>
    </item>
    
    <item>
      <title>openwrt配置——路由规则</title>
      <link>http://blog.shell909090.org/blog/archives/1835/</link>
      <pubDate>Thu, 16 Jun 2011 10:37:02 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1835/</guid>
      <description>路由其实是个很简单的事情，不知道为什么在实际运用中被很多人误解。首先，路由规则是个纯IP层的事情，和TCP没有关系。其次，路由和NAT没有关系。实际上，和这两个有关系的都是iptables。
路由表的大概概念就是，你家门口有三条路，有一张路径表。到上海市，走左边，北京市，走右边，西安市，走中间。因此路由表的概念是发出规则。当你收到一个包，如果目的地址是本地，那么就交给监听程序处理。如果没有监听程序，那么就拒绝报文。（注意，下文讨论的时候都略去了iptables）如果目的地址不是本地，则看是否允许转发。不允许，丢弃，允许，加入发出队列。路由表就是发出队列的选择规则。这个规则之所以存在，主要是因为多头主机的存在。如果一台机器只有一个发出设备，路由表是没有任何用处的。
发出规则计算很简单，首先取目标网络地址，还有包网络地址，然后分别和子网掩码求与（AND）。如果两者相等，那么就转发到这个规则所指定的接口上，如果不等，继续匹配。规则顺序也很简单，子网掩码距离越长，子网越小，规则越靠上。其中有两种特殊的子网掩码，一种是255.255.255.255，或者叫/32，用于指定主机。一种是0.0.0.0，或者叫/0。这个子网只有一个，叫做default。因为按照规则用这个掩码计算的结果，任何目标地址都可以匹配这一规则。
当然，根据上面的解释我们可以知道，路由表只管发出报文。如果目标设备需要返回一个报文，他必须保证返回路由的正确。因此在下面的openvpn讲解中，你在vps也必须配置路由。很幸运，这个问题openvpn已经帮我们做好了。
通常而言，我们拨号上网后应当有三条路由规则，第一条不解释。第二条通常是内网IP通过内网端口发出——这是当然的，否则内网包就暴露了。第三条通常是其他IP通过外网发出。当内网需要向外网发送数据的时候，会设定路由器作为网关。路由器会转发内网的包到他的上级路由器上。而当外网有数据要发送给内网的时候，情况则正好相反。注意，实际中一般是要进行NAT的，不是这么直接收发。
如果当你使用了openvpn的routed模式，那么你就有了两个内网——常规内网和虚拟内网。我们可以想像，首先需要配置的是两个内网的互通问题。在你本地的网关上，需要配置虚拟网络段发送到tun0设备上。而在远程，需要配置常规内网段发送到拨号上来的这个IP上。大致要配置这些东西。
-----------------vps-server.conf------------------- client-config-dir /etc/openvpn/ccd route 192.168.x.0 255.255.255.0 --------------------ccd/openwrt--------------------- iroute 192.168.x.0 255.255.255.0  这样，当openwrt这个用户拨号上来后，vps上就会添加一条路由，192.168.1.0网段通过刚刚拨号的地址来转发。
其次，哪些数据发送到拨号网络，哪些需要通过虚拟内网呢？这规则通常由你来定。不过千万注意，不要用tun0这个设备来发送到服务器的数据——这会引发循环。这个问题一个不是那么明显的例子是，你设定使用tun0来发送default，但是又没有特别指定vps的地址使用ppp0发送。</description>
    </item>
    
    <item>
      <title>openwrt配置——openvpn的基础配置</title>
      <link>http://blog.shell909090.org/blog/archives/1833/</link>
      <pubDate>Wed, 15 Jun 2011 14:58:28 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1833/</guid>
      <description>在openwrt下面配置openvpn是非常简单的事情，当然我假定你有linux下面配置openvpn的经验。
首先，将配置文件，证书等等复制到/etc/openvpn下面。我的配置大概是这样。
client dev tun proto udp remote ipaddr port resolv-retry infinite nobind persist-key persist-tun ca /etc/openvpn/ca.crt cert /etc/openvpn/openwrt.crt key /etc/openvpn/openwrt.key ns-cert-type server tls-auth /etc/openvpn/ta.key 1 cipher DES-EDE3-CBC comp-lzo verb 3 script-security 3 up /etc/openvpn/dftup down /etc/openvpn/dftdown  注意，其中的路径必须写完整，貌似测试下来不支持相对目录。其中的up和down是指在启动和关闭时会自动执行的两个脚本。根据贝壳的测试，redirect-gateway是无效的，不知道为什么。具体的路由配置方法，会在下一章中具体介绍。
然后，你需要将这个配置启用，方法是修改/etc/config/openvpn，在其中加入以下内容。
config openvpn name option enable 1 option config /etc/openvpn/name.conf  name是你的配置名，下面的路径和配置文件路径吻合。
然后，你可以这样启动vpn。
/etc/init.d/openvpn restart  </description>
    </item>
    
    <item>
      <title>openwrt配置——extroot使用U盘配置规则</title>
      <link>http://blog.shell909090.org/blog/archives/1832/</link>
      <pubDate>Tue, 14 Jun 2011 10:10:43 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1832/</guid>
      <description>贝壳入手了一个DIR-825路由器，机器不错，可惜存储太小。所以要用extroot做成U盘启动。
首先，你需要安装kmod-usb2，kmod-usb-uhci，kmod-usb-ohci，kmod-usb-storage，kmod-usb-storage-extras这几个包，以保证系统可以正常访问你的USB key。而后安装block-mount block-hotplug block-extroot这几个包，来启用U盘启动。最后不要忘记安装kmod-fs-ext3，驱动文件系统。
当你搞定这几步后，修改/etc/config/fstab这个文件，如下配置。
config mount option device /dev/sda1 option fstype ext3 option options rw,sync option enabled 1 option enabled\_fsck 1 option is\_rootfs 1 config swap option device /dev/sda2 option enabled 1  然后，恭喜你，你就拥有一个可以从U盘引导的路由器设备了。当然，如果不从U盘引导，那么还是可以正常使用目前有路由拥有的普通功能。在使用U盘后，路由器的包和设定就完全存储在了U盘上。如果配置错误，拔下U盘就可以还原。你也可以复制自己的U盘给别人，在同样型号，并且安装了同样上述包和配置的路由器上继续使用（当然，会沿用你的配置）。
下面，是如何创建可被openwrt引导的U盘。
mkdir /tmp/sda1 mkdir /tmp/root mount /dev/sda1 /tmp/sda1 mount -o bind / /tmp/root cp -a /tmp/root/\* /tmp/sda1  上面几步，更详细的可以参考这篇文章（http://ddnas.org:88/blog/index.php/archives/2.html）。
下面说一下使用U盘启动后，你很可能需要的一些包。
 bash 当有了空间，你可以修改/etc/passwd来使用bash作为你的默认sh，这样比较习惯。 ifstat 非常常用的软件，监控各个网卡设备上的吞吐。 iftop 监控各个IP的访问情况。 iperf 测试路由器到各个节点的速度。 openssh-server sshd openvpn vpn软件 screen 一个ssh中运行多个bash的玩意。  注意，openssh使用~/.</description>
    </item>
    
    <item>
      <title>再论openvpn的搭建</title>
      <link>http://blog.shell909090.org/blog/archives/1797/</link>
      <pubDate>Thu, 12 May 2011 10:22:55 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1797/</guid>
      <description>从概念上说，openvpn类似于一根网线，或者一台交换机。你拨上vpn，差不多相当于给自己的机器装一个虚拟的网卡，从上面拉一根线到服务器的虚拟网卡上。所以，vpn的配置大概和网络配置差不多，分为几个大类。
一类是第二层交换，即虚拟网卡和真实网卡组成网桥。这样可以把虚拟网络上的设备引入真实网络，让虚拟网卡获得真实网络的地址，或者反之。坏处是配置复杂，稳定性差。
例如你家里是192.168.0.0/24网络段，你决定用tap配置一个网桥，就需要新建一个br0设备，将eth0和tap0设备加入网桥。这样，一台IP为192.168.0.10的家庭机器，在访问IP为192.168.0.110的远程机器的时候，所发出的ARP请求会被转发到远端，然后ARP响应转发到本地。通过这种方式，10就会直接把MAC报文发送到中转机上，然后再转发远端。可以看出，由于ARP请求往来非常费时，在子网内机器多的时候，会消耗不少时间和带宽进行ARP转包，以及各种链路级开销。所以通常除了两个安全封闭子网因为管理理由必须这么玩，并且两者间又都有服务器和高速链接的时候，其他时候我不推荐这种玩法。
更何况，在debian系统下配置网桥需要额外脚本，不如路由那样，可以使用默认脚本启动，然后动态修改路由表。
大部分是三层交换，即将服务器作为路由器使用。这又分为两种情况，网络地址转换，和网关互通。
网络地址转换是最常见的情况，这个又叫做NAT。网关在转发你的包的同时，会将地址转换成自己的地址。从而避免修改路由的行为。
同样是192.168.0.0/24举例，远程网络假如叫做192.168.1.0/24。当你拨号上远程网络时，你就拥有了一个远程IP和一个本地IP。你可以配置路由表，让哪些IP从远程走（这就是地址段选择翻墙的原理）。大多数情况下，会被配置为默认都从远程IP走，除了几个特定地址（例如VPN服务器地址，这个也走虚拟网络会引起循环的）。而远程的网关，假定是192.168.1.1，开启了NAT。这时候你的所有网络流量就都从远程的VPN服务器上发出和接收了，如同你正坐在远程服务器后面的小网络内一样。
网关互通是更复杂的一类情况，通常是小型企业为了多个连通多个地点办公子网而设计的。理论上说大型企业也适用，但是大型企业有钱，IT部为了防范责任问题，通常会直接采购Cisco之类大公司的产品直接使用。基本概念是将虚拟网络和真实网络配置成两个子网，两个子网可以互相访问。
还是192.168.0.0的例子，我们假定另外有一个子网叫做192.168.1.0/24。现在我们需要连通两个子网，或者，更进一步，多个子网。
我们首先配置一个虚拟子网叫做192.168.254.0，然后架设一台共用服务器。这是比较简单的模型。更复杂的可以将其中一个子网的某个服务器映射出去作为核心，配置就更加复杂，不过可以依照同样原理推导。架设好共用服务器后，我们需要在每个子网的网关上下手，否则就无法做到透明路由。修改这个网关的路由表，将192.168.0.0/16全部转发到虚拟网关（即共用服务器的虚拟IP）上去（当然，除去本网段不转发）。在OpenVPN上面可以配置，当某条链路拨接上来后，就在服务器上加入一条路由，将其后面的网段加入网关路由表。于是，当192.168.0.100的某台服务器希望直接访问192.168.1.100。首先这台主机会检查自己的路由表，发现这个需要由网关192.168.0.1转发，就先转到了192.168.0.1。192.168.0.1检查路由表，发现192.168.1.100需要被转发到虚拟网关，即192.168.254.1。于是通过虚拟网络，该网关做出转发。当192.168.254.1接收到后，他会依照上面的路由表，检查到这条链路是否已经拨接上来，拨接上的话对应的虚拟IP是多少，然后转发过去。最后是目标网关，192.168.1.1，转发给192.168.1.100的过程。整个过程复杂无比，不过实现起来都是自动化的。
在配置文件中，有ca certkey三项，这三项分别对应不同作用。cert和key是用于向客户端验证服务器身份的。客户端那里有一个ca.crt，服务器这里的cert和key必须是那个ca.crt签署过的。这样，客户端就可以验证服务器是否是可信任的。而服务器这里的ca则是验证客户端身份的，客户端那里同样也有cert和key，必须由服务器端的ca.crt签署过。通常，我们用同一套ca.key签署两个cert，分别部署在服务器端和客户端，就可以工作了。
另外一点需要注意的是，ns-cert-typeserver这个参数。在debian的默认系统中有这个参数，一旦指定，openvpn就会检验服务器证书上是否有server的选项。对于easy-rsa签署的证书，这个肯定是有的。但是如果自己用openssl签署，就要记得做ext，否则检验不通过会报错。</description>
    </item>
    
    <item>
      <title>个人文件管理的几个经验</title>
      <link>http://blog.shell909090.org/blog/archives/1721/</link>
      <pubDate>Thu, 10 Mar 2011 13:39:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1721/</guid>
      <description>1.明白你在面对什么问题。个人资料管理，永远是可靠性和价格的双重难题。廉价方案就不可靠，可靠方案就不廉价，因此弄明白你自己需要的是廉价还是可靠。作为如果你的选择是可靠性，就要假设明天电脑就坏了。任何设备在损坏之前都是不会打招呼的，因此现在立刻就行动。
2.由上文引出的第一个建议，区分高可用资料和非高可用资料。通常而言，我们有很多资料，林林总总一大堆。但是其中有一些是丢失了虽然心疼但还可以接受，另一些则是无法接受，往往要搞到去数据恢复中心的地步。与其如此，不如提前区分高可用资料和非高可用资料，尤其注意区分“你的资料”和“你下载的资料”。通常一个人的核心资料应当小于100G（我假定你不会比我更变态），如果你有大量录像资料要备份不在此列，以下的高可用方案也对你不适用。
3.文件的管理方法，区分大类，放弃小类。通常我们的文件管理都有随意性，每个人都有不同的文件放置习惯。建议对文件区分以大类，而放弃细节的文件夹分类。人类在区分大的类别上往往比较恒定，也比较节约时间，在细节分类上越向下越费时。通常我们对歌曲区分男歌手女歌手团体外文等非常容易，但是要细分某个歌手就比较困难了，要精细到某张专辑绝对会花费大量时间。然而人类在寻找东西时的难度，和总体规模大致成正比。为了减少一点复杂性而花费大量时间是一个非常不值得的事情。
区分大类的另一个理由，则是大类的区分经常关系到高可用和非高可用，高安全和非高安全。贝壳的分类中，几个类别的资料全是要求高安全性的，另几个类别则全随便。
4.文件的管理方法，文件名标识，运用搜索。文件管理的第二个建议，就是别用分类来查找文件，使用搜索。windows下肯定是everything，linux下可以用mlocate。通过将内容反映在文件名上，对文件进行管理。在需要用的时候搜索文件名，远比你整理所有文件来的省事。至于上面区分大类的建议，则是事关下面高可用数据的解决方案，所以还是要做的。
5.磁盘的稳定性研究。磁盘能稳定使用多久？贝壳听到最倒霉的记录是7个月，最长纪录是10年。但是通常来说，6成的硬盘会在3-5年内损坏。因此一旦硬盘使用超过3年，就处于临界状态，坏了也不要觉得奇怪的。对于临界状态的硬盘，建议采用SMART监控软件，随时保持监控异常。对于硬盘上发生过循环冗余检查错误，复制死机，文件读取错的，尤其要重视。
5.磁盘的分区方案。很多人拿到硬盘，就先分上三四个驱，好像不分区不专业似的。其实分区是上个世纪FAT文件格式留下的传统，作为NTFS而言完全不必分区，甚至分区是有害的。FAT在不分区的情况下最高只能使用4G硬盘，VFAT方案下windows也只能使用32G的硬盘。因此对于大硬盘都必须分区使用。NTFS最高能使用4T的硬盘，我想个人是用不到这么大的硬盘的，因此完全可以将所有磁盘都分为一个区。这样主要是空间互通，减少对一个磁盘区域的反复使用。同时，在一个磁盘空间不足时不用反复移动文件凑空间。但是对于C盘（系统盘）建议分区安装。这样便于不擦除数据的情况下重装系统。当然，这种情况仅限于windows，linux要重装系统是没必要擦除数据的。不过我仍旧建议/home和/分别安装，因为两者的读写乃至管理特性都相差很大。
6.数据量控制在60%-80%之间。太少的数据会导致利用率过低，而太多的数据则导致存储快速碎片化。windows的磁盘碎片整理程序在空间小于15%的情况下是不工作的，ext3也有类似的问题（低空间下的高碎片化）。
7.因为上文的原因，因此区分普通数据和可抛弃数据。有一些数据，我们总是不确定将来是否会有用，现在删除又太可惜。可以将这些数据集中起来加上标记，命名为可抛弃数据。硬盘空间低于60%的时候尽管留着。一旦空间波动超过80%，就开始丢弃可抛弃数据。
8.个人不要用RAID0。因为使用条带技术，RAID0的时候，如果一个磁盘损坏，则整个卷都没救了。即使另一个磁盘完好无损，数据也是基本拿不回来的。对于两个磁盘的情况，建议你将两个空间分为两个盘，其中一个设定为临时文件存放和非高可用文件存放位置，挪挪空间还是能凑合管理的。同时，我也不建议个人使用LVM，LVM2，活动硬盘之类的高级磁盘管理技术。主要问题是磁盘一旦损坏，剩余盘拿到其他系统上几乎如废物一般，要拯救起来非常困难。
9.RAID1必须打开数据非同步提示。这个原因如8所说，如果你没有打开数据的非同步提示，你根本察觉不到其中一块硬盘已经失效。这个时候往往会发生第二块硬盘级联失效（因为压力集中），这样的RAID1方案就退化成了一点好处都没有。
10.高可用资料的方案——移动硬盘。你的高可用数据是我们真正要管理的目标，哪怕其他资料都损坏，必须保证核心资料的可恢复。通常由于核心数据并不很大，因此我建议用移动硬盘作为核心资料的承载方案，数据在移动硬盘和主硬盘间定时同步。对于频繁修改的文件，建议在两个电脑上进行同步，乃至使用版本管理系统管理和同步。移动硬盘的一大好处就是随身，因此往往和主电脑分离存放。即使你主电脑出现问题，例如被偷走，移动硬盘内的数据往往也没有问题。
11.移动硬盘引入的问题，加密。一旦使用移动硬盘方案，就意味着任何人都可以接触到你的资料。这是一个非常难办的问题，所以你可能要加密数据。我建议不要使用EFS作为数据加密方案，因为EFS的密钥保存在当前用户帐户内，备份和管理比较复杂。我建议两种加密方式，一种是AxCrypt，一种是TrueCrypt，后者比前者更强更复杂一些。前者是针对某个具体文件进行加密的，后者会直接虚拟出一个磁盘来加密，因此更加复杂。然而一旦将数据加入后者的磁盘后，就真的一点痕迹都不留了。不过需要提醒的是，由于磁盘上的数据并不能真正的被擦除，因此一旦数据进入磁盘，在虚拟文件内所占的空间就固定了。即使删除文件也无法收回空间，这给管理带来了困难。
11.高可用的一种备用方案，使用大型硬盘（1T以上）复制然后冷盘存放。这种方案的好处就是稳定性很高，四年前的大型硬盘已经超过500G，足够存放下你所有的数据。由于不加电，因此安全存放五年以上是没问题的。但是建议也不要太长，即使不加电，随着时间推移，硬盘还是会出问题的。当然，与之相应的就是成本高，管理不方便。你多花了一个硬盘的钱（虽然我觉得和保存数据相比还算廉价），但是又不是随时能使用这些文件。
12.高可用的误区，刻录光盘。光盘是数据最大的敌人。我们计算硬盘的存放成本，2T大概700，1T400不到，大约是0.35-0.4元/G。DVD的存放成本大约是，一桶50张的卖70，大概0.32-0.35元/G，成本非常相近。光盘存放三到</description>
    </item>
    
    <item>
      <title>淘宝上的某个恶心卖家</title>
      <link>http://blog.shell909090.org/blog/archives/1698/</link>
      <pubDate>Thu, 17 Feb 2011 17:31:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1698/</guid>
      <description>最近为了拼小机器，在淘宝买了这家（http://item.taobao.com/item.htm?id=3259889569）的小机箱。由于我想装1T硬盘，因此提前查了，1T硬盘只有3.5寸，SATAII接口规格。所以我曾经问这个卖家的客服，你们的机箱可以支持3.5寸硬盘吧？这个尺寸的机箱普遍说不支持的，只有你们这里在参数中明确说明支持。客服答复我，支持。我说，你别光看页面参数，你确定。他说，我确定。
所以我就下单了。东西到的很快，在春节时段，倒也难得。问题是——机箱质量什么的不说，这机箱压根不支持3.5&amp;rsquo;硬盘阿。
我找客服投诉，你们卖的时候可是说好支持的。他查了一会，告诉我，对不起，不支持，您可以外接硬盘。废话，哥的硬盘比主板加机箱还贵，要外接还用买你的机箱？再说要外接我TMD当初问你干吗？没事逗闷子玩阿。我说我给你两条路，一条是想法弄个3.5&amp;rsquo;硬盘架给我，另一个是换。前一个比较简单，就怕机箱尺寸不符。后一个我是不会付来回邮费的，这是你们的错误，而且最终只有中评。对方问了一下老大，说这个机箱上不去3.5&amp;rsquo;硬盘架，而后一个这单他肯定亏，所以给我退货。TMD你亏我不亏，确认了能用的结果来一这玩意。搭10块钱退货不说，还浪费时间处理，老子TMD做咨询两小时足够再买个机箱了。
退货就退货吧，我问对方，我发起请求了，你是先同意还是我先发货。他说，你先发货，哥们。好，我先发货了。过两天一看，改为已经同意退货协议了，总算了了一桩心事。过年闹个肚子，春节后再上去一看——已成交？
喂喂，这算哪门子事儿阿。马上联系，结果改一个卖家的投诉帐号来处理这个事情。我问他，你们机箱没收到？他说春节刚过，人还不齐，所以要看看。我想想也是，春节刚过，事情一堆，也不忙于一时，就说，你慢慢查，我明天听回音。这是二月九号的事儿。十一号的时候我再催，说去年的帐存档了，财务要去查。十二号再问，说已经在处理了。
shell909090：（14:04:41）
您好，请问有消息了么？
候鸟信誉商城:投诉：（14:26:18）
财务已经在理了 确定后下午会打到你支付宝账户里
shell909090：（14:28:26）
好的，谢谢
到了15号我上去买东西，顺手看了看——还没到帐。上去问了一下，说财务支付盾在重新重新申请，几天内都不能支付。
候鸟信誉商城:投诉：（16:03:24）
请您耐心等1-2天 财务那边有记录的 但是支付盾重新申请过了，这几天都不能支付
候鸟信誉商城:投诉：（16:05:45）
你放心好了 我们也不是小店 不会蒙你的
shell909090：（16:05:45）
实话说，这次退货问题，我是无责的
shell909090：（16:05:57）
好吧，这样
shell909090：（16:06:00）
我联系一下淘宝的客服
shell909090：（16:06:04）
听取一下他们的意见
候鸟信誉商城:投诉：（16:06:09）
可以
候鸟信誉商城:投诉：（16:10:27）
我问过财务了 最快明天下午可以支付
我觉得有点不对，就算财务十二号当天转帐发现不能转，马上申请的话。淘宝和对方公司都在杭州呢，十五号怎么也申请到了。而且这家公司上来就坑了我一把，于是就多了个心眼，打给了淘宝客服去问问。客服MM建议我别等了，尽快做投诉。因为淘宝只开放15天的投诉维权接口，过后就关闭了，再处理问题就会更困难。得亏哥没信你们，信你们一回吃一回亏。下面是维权说明。
曾向客服询问主机是否支持3.5&amp;rsquo;硬盘架，客服很确定的告知支持。但货到后根本不3.5&amp;rsquo;硬盘，也无法改装硬盘架。因此要求全额退款。在春节前发现退款已经同意，因此将货物寄回。春节后发现变成已经成交，货款反复催促后仍未到帐。
投诉过后，对方是这样辩解的。
被维权人(候鸟信誉商城)的留言：
卖家于2011年02月16日 18:54:50不同意维权协议.
2011-02-16
被维权人(候鸟信誉商城)的留言：
当时是说好给你退的，我们点了同意退货，但是买家一直不点退货发货，最后退款自动关闭，年后因为跨年做账问题无法马上支付，要买家等等，聊天记录里说的清清楚楚，不用怕我们赖账的，没必要马上就维权，说了最快今天，最晚明天就给你支付到账上，请买家取消维权。
首先，你让我TMD先发货你再点同意退货的，谁知道同意退货后面还跟着退货发货阿。欺负老子新手不成？前面不是说支付盾么？怎么这回又变成做帐了？不用怕你赖帐？我倒是不怕你赖帐，我怕你失踪阿。第二天再看，果然还没到帐。不过这次倒可能不是卖家的问题，支付宝总算给力了一把。
淘宝客服留言：
根据维权的内容，淘宝网已经从卖家保证金中扣除175元给买家，已经提交申请将卖家的保证金扣除到买家的支付宝账户，该交易款项将会在三个工作日内到达买家支付宝账户，请买家关注。淘宝及卖家一直在努力为买家提供安全愉快的购物环境，感谢对淘宝支持！
2011-02-17
基本搞定了。
事情还有个小插曲。沈崴沈游侠最近也在买小机器，很兴高采烈的给我推荐神板和神箱，我看完箱子的第一句是，箱子很给力，卖家不靠谱。然后让他向下翻一翻，我那颗大名正在买家列表里面呢。最神奇的地方是，这是春节后的事情，我都投诉了，但是网页上还是赫然写着——支持3.5寸硬盘——到现在都没改。估计我这篇要是看到的人多，兴许卖家会改了页面来找我算帐吧。</description>
    </item>
    
    <item>
      <title>freenas和解决方案</title>
      <link>http://blog.shell909090.org/blog/archives/1681/</link>
      <pubDate>Wed, 19 Jan 2011 09:48:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1681/</guid>
      <description>freenas是一个基于freebsd构建的免费网络存储系统(network storage system)，关于他的简介可以看这里（http://beacon.blog.51cto.com/442731/109961），主页在这里（http://freenas.org/FreeNAS）。
freenas的一个特点是结构简单，易于安装和管理，可以在非常低的硬件环境下工作。例如低端的2.5&amp;rdquo;硬盘或者U盘，基于mini-ITX板子的EPIA等。512M内存的低端EPIA不带硬盘大约在250元上下，加上机箱不超过400。加上几块硬盘就可以组建可用的大型存储系统，稳定工作。安装freenas所需的知识基本不超过英语，当然，要组建微型服务器和RAID还是要正确理解服务器结构和配置的。支持smb/ftp/iscsi/http访问内容，通常在小型公司中可以处理掉大多数的文件共享需求。
freenas最强大的一点，就是使用“解决方案”级别提供。freenas的载体是一张安装光盘，而非一个freebsd下的软件包。这张光盘在服务器上的安装是通过特定的功能来完成，而不是复杂的安装向导，因此要安装使用非常简单。如果是基于freebsd的软件包，那么为了安装这个软件，首先必须freebsd的系统管理员来安装一个系统，并配置到合适状态。再在这个系统上安装软件包，再配置，整个过程就艰难无比了。
同样适合类似的解决方案提供的，还有邮件服务器。虽然很多空间商提供了邮箱服务，但是部分公司对邮件系统的需求远远超出空间商能提供的服务。对于企业邮箱系统，不仅仅是邮件发送和接收服务（esmtp/pop3/imap），而且包括一定的用户数据库（ldap）和在线交互系统（im）。严格来说，这已经不是普通的企业级邮箱系统，而是整合办公环境。对于这种整合环境，要完整配置出来还是有一定难度的。对此采用简化的方法，将一套系统作成整合解决方案，不失为一个简单好用低成本的方案。</description>
    </item>
    
    <item>
      <title>Cybersitter诉大正及索尼案</title>
      <link>http://blog.shell909090.org/blog/archives/1650/</link>
      <pubDate>Wed, 15 Dec 2010 12:59:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/1650/</guid>
      <description>准确的说，应该叫Cybersitter诉大正案。
1.这是一起知识产权案子，属于私人起诉私人，和政府没有关系，和美国表达对中国网络审查现状的不满一毛钱关系都没有。
2.美国法院和美国政界的总体倾向是判决Cybersitter胜诉，而且追偿不会太低。这次拒绝在中国审理而坚持在美国审理就是非常明白的表现。
3.这倒是不难理解，对于知识产权，老美向来非常重视的，尤其是这种能正大光明宰中国一刀的案子，能打多大就多大。
4.中国官方也许会试图通过外交影响判决，也许不会。因为绿坝这个问题上连自己人都觉得脑残。但是即使是国家主席去讲话，美国也肯定不会理会，因为美国对中国的版权惩罚已经作为一种对抗战略执行了。
5.如果真的跨国追偿，大正公司肯定以倒闭对应。他们会老老实实的准备应诉才是奇怪的事情呢。就算应诉，肯定也输，到最后一步，肯定倒闭了之。
6.更可能发生的，具有中国国情的事情，是大正公司不予理会。而后是美国要求中国履行版权协定的相关条款，否则诉诸WTO等等的威胁，而后是两国的政治博弈。
7.中国人民的税金肯定拿不回来了，中国的媒体对此表示完全不知道。
8.索尼，方正等几家公司是追偿的主力，肯定要出血。他们在美国有业务，基本不可能不理不睬。
9.工信部可能会以政策来换取几家外国公司高层的谅解，也可能不需要谅解。对于中国公司，完全不用考虑这个问题，因为这些公司属于被工信部管理的对象。
10.但是即使如此，工信部今后的命令在这几家公司也未必能得到完全的执行。因为在这个问题上，工信部出尔反尔在前，属于无智商的脑残。事后的政策也不可能给几家公司一个太大的漏。
11.这件案子影响最大的将是在国际上，尤其是美国有比较大业务的公司。他们在中国犯下的版权错误，只要一方牵涉美国版权，可能在美国得到审判和惩罚。</description>
    </item>
    
    <item>
      <title>一个软件工程师到底有多远</title>
      <link>http://blog.shell909090.org/blog/archives/139/</link>
      <pubDate>Fri, 03 Sep 2010 23:52:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/139/</guid>
      <description>从高中毕业生，到一个软件工程师的成本是多少呢？这得分是什么软件工程师。
如果是批量培训，学习某种语言的语法，针对特定领域（主要是网页）进行编程。大约需要六到八个月，差不多就是北大青鸟培训生这样的。这种软件工程师拿来基本没法用的，即使是打磨变成熟练工后，最多也就是消耗品。基本每年这个水准的人都会出来数十万，个个新鲜热辣精力充沛不怕压榨。
如果是常规软件工程师，需要一年的基础课程，软件工程导论，计算机系统原理，高等数学等。一年语言和实践，C语言，数据结构，离散数学等。一年系统学习和工程方法论，编译原理，操作系统，数值算法，软件工程学。最后一年的第二语言和实践。java，软件实际开发等。如果顺利，并且用功的话，一个常规软件工程师大约需要本科四年。
中国软件专业毕业学生据说150W之多，有多少能达到常规软件工程师的水准，并留在中国呢？大概一万出头。八成以上的学生由于学习靠混，或者实践不足，因此实际上处于批量培训略强的地步。有些还不如批量培训生。软件毕竟属于工程学科，是门硬功夫。虽然不如数学那么硬气，但是靠混是混不到软件工程师的，混软件销售还有点希望。这也是为什么很多软件专业出来的学生不做软件的原因。
当然，其实还有部分人是因为水准问题，考研或者出国了。
如果能完全掌握上面的一堆东西，那其实是相当牛的一个人了。加上一定的经验，基本可以胜任任何软件公司中层以下职位。可惜中国奇缺的就是这种人，10多年软件产业发展下来，总共积累了不到20万人。
如果在普通软件工程师的基础上，钻研某个细节领域，并且有所突破呢？研究生？错了，你成不了研究生，最多当上研究员。软件业在中国发展不过20多年30年的事情，没有任何一所学校有足够的学科积累，能够领导某个领域的发展。（当然有少数几个例外）我们用的流行网络协议，有多少是美国大学领导开发的？多少是中国大学？底层核心算法中，有多少是中国学校发明了去美国申请专利的？所以如果你在某个领域有所突破，最多被相关公司看中，招进去当研究员，活的很滋润。如果真有了本事去考研——你自己看结果吧。
程序员的最高境界是什么？那基本是Donald Kunth，Richard Stallman这种的。要么将计算机科学基础发展到极限，要么将某种哲学引入计算机领域，并且改变世界。
这种程序员，中国一个没有。十年内也不会出。</description>
    </item>
    
    <item>
      <title>版权保护的迷局――论微软状告东莞网吧</title>
      <link>http://blog.shell909090.org/blog/archives/132/</link>
      <pubDate>Wed, 11 Aug 2010 14:56:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/132/</guid>
      <description>微软把广州的网吧告了，索价158万。这案子要放在美国，怕是没什么悬念的。敢用盗版，158万的索赔只能算小数，后面跟着的各种费用和公众质疑足够让公司活不下去了。而中国网吧的董事长居然亲自出面陈词，宣称“这样会让东莞一半的网吧倒闭”，不能不说是中国和美国的不同文化造成的不同结果。
美国是一个注重知识产权的国家，其背后的逻辑是，保护知识产权，才能让更多的人有热情创造好东西。因此，维护知识产权是非常重要的（甚至被大公司使用到很过分程度的）。一家公司，哪怕只有一台机器使用了盗版，都会伤害整个公司的信用。因此，微软关于盗版的态度，Bill Gates说的很露骨：他们要偷，就让他们偷，回头我们会连本带利拿回来的。在西方，只有一种违反版权的使用是得到默许的，就是为了教育教学目的的评估试用。AST开始Minix的原因就是因为闭源软件不利于教学，这点后来也被RMS等很多人所认识到。因此学校基于教育目的的使用，多数不会受到追究，当事公司多数装个大方，给予“特别授权”了事。当然，仅限用于教授课程，若是滥用盗版Office办理业务，还是会受到追究的。
开源软件业也受益于版权良多。若非西方国家严格的版权保护，很多对开源没兴趣的人根本不会使用开源软件。开源软件算是游走在版权与非版权间的平衡者。若是版权执行过于严厉，则有开源软件来抑制软件商乱抬价格（若是不行，只有诉诸反垄断法了）。若是版权执行过与宽松，则开源软件业自然疲软，让软件商可以喘口气。因此，从理论上最反版权的GNU运动，反而最受到版权的保护。
而中国作为后起之秀，在知识产权上注定不能像美国那样保护。因为多数专利，美国是收钱人，中国则是付钱人，收自己人的钱给外人，这是国家公民无论如何不能认同的，尤其是在对于生死问题相关的知识产权上。例如印度曾声称，所有西方有关医药的知识产权限制在印度不生效，由此才得以廉价的生产各种抗热带病的药物。对发展中国家的知识产权保护弱化问题，发达国家多数持眼开眼闭，或者不过于紧逼态度。因为过度的限制发展中国家会导致对方另起炉灶，日后搞不好多出一家竞争对手。
然而反过来，过于弱化的知识产权保护，反倒是值得发展中国家自己警惕的问题。我们可以回想，知识产权的作用是什么，大概就能得知过于弱化的知识产权保护会造成什么后果。知识产权保护人的创造意识，而过于弱化的知识产权保护会产生创造依赖。虽然我们可以廉价的抄袭别人的东西，然而创造什么，核心是什么，给不给，还是别人说了算。更麻烦的是，没人愿意搞什么创新，因为知识产权弱化的作用同时作用于对方和自己。抄袭者才有机会壮大和发展，如腾讯就是中国特有的例子。
而董事长出面宣称，“东莞的网吧要倒一半”，这更是中国特色中的中国特色。这招携GDP以令政府的招数，房产商就玩的很透彻。你不给我政策，我就威胁要关门，看你怎么交代。实话说对于某些道德违规乃至法律违规的行业，不如关了好。要不怎么？贩毒的也跑出来宣称自己创造了多少GDP，严打会让中国哪里的经济崩溃？可惜对于地方官员来说，GDP才是命根，至于执法的严肃性这个问题，在和谐社会的基础上都好商量。
根本上说，版权保护是个迷局。若是严格执行，怕会伤害整个经济和技术的发展。若是宽松执行，则会伤害整个国家的创造力。</description>
    </item>
    
    <item>
      <title>代码过程管理</title>
      <link>http://blog.shell909090.org/blog/archives/130/</link>
      <pubDate>Thu, 05 Aug 2010 14:39:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/130/</guid>
      <description>无论是做产品，还是做项目，无可避免的要碰到代码过程管理的问题。这个问题主要是平衡产品质量，生产速度，开发投入的关系，并且设法增大乘积。
通常来说，质量，速度，投入三者是互相矛盾的，有的时候还要加上风险。质量越高，速度越快的生产过程，其投入也就越高。但是这几个关系并非单纯的并行替换关系，正如人月神话中所说的，人月这个单位暗示人和月是可以互换的，但实际不是。项目中主要碰到的问题往往是，在控制质量不变的情况下，增加投入不能提高速度。在控制速度不变的情况下，减小投入不能降低质量。偶尔，我们想方设法找到了一个方式，能够很好的满足质量-速度-投入的三元平衡，但是时灵时不灵，这就是风险元的问题了——通常情况下我们不会碰到。
作为平衡三者的起点，你不能从项目/产品的开始才考虑这个问题，而是必须从招聘/团队组建的时候开始考虑。一个不靠谱的人就会破坏整个团队，所以在招聘的时候，保持宁缺勿滥的思想。通常的项目/产品并不需要一堆天才，你只要一堆能够良好执行计划的员工就行了。靠谱的人的有几个要点，能够比较好的进行沟通，良好的计划制定和执行能力，大量的编码训练。有的时候我们往往以工作年限来衡量一个人的编码训练，实际上编码训练和工作年限并没有特别大的关系。好的项目经理/产品经理，应该能从编码的设计和实现中，嗅出编码训练的程度。
坚持只招聘合适的员工，事实上是以增大人力资源成本来解决速度-质量问题。因此通常只会被用于质量不变的情况下，增加投入提高速度。不幸的是，要实行这个步骤往往必须在项目的开始前进行计划。因此项目的正确做法不是添油战术，而是减油战术。减油战术的要点是强迫项目使用它天然能够使用的最多人手，使得项目处于人力资源相对充足的状况。再设法控制每个人的工作周期，不要让被分配的人做和他特质不吻合的工作。例如程序员完成编码后，不要让他去做文档/测试的工作，而是提前撤出项目。如果项目顺利，逐步撤出闲置人手组建其他项目，并保持项目依旧按时完成。如果项目仍旧不顺利，至少我们做到了我们能做的最快速度。
同时，这个战术涉及另外一个问题。我们都知道，越大的项目，需要的人手越多。而越多的人手，每增加一个人所能提高的效益就越低（俗称边际降低）。因此，平衡三者的另一个要点是切分项目，使其拥有完美的边界。假如一个系统，我们需要12个人工作半年。我们将其切分为两个相对独立的子系统，每个系统分配六个人，通常不用半年就可以完成项目。正常来说，项目所需资源随着复杂度增加往往是三次方到四次方增加的，而项目切分有助于使得前者随着后者线性增加。切分的优劣只取决于其边界的清晰程度和复杂程度，和需要多少人手，如何分配等等问题皆不相关。
在完成上述几个步骤后，我们就拥有了完美完成项目的一个起点，合适的成员，充足的人手，适当的边界。不幸的是，通常我们无法做到这么完美，成员不都是适当的，人手是不足的，需求是修改的，所以边界是模糊的。那么在整个代码过程中，我们依旧有一些可以做的事情。
首先是问题的早期发现，方法是代码规范，单元测试和交叉检查(cross check)。通常建议将人手编排成水平交错的一个环，按照顺时针方向，由一个人检查另一个人的代码。交叉检查有三重目的，帮助新手学习编码，抑制不小心和设计失当所造成的错误，当其中一个人无法工作时有人可以接手其工作。虽然这将付出一定时间，但是可以比较好的在前期发现和控制问题。同时，按照逆时针方向，编写另一个人的单元测试代码。单元测试有助于隔离问题范围，减少在实现中的一些无聊问题。
其次是问题的快速沟通和持续聚焦在工作上。强迫所有人每天写下需要处理的问题(todo list)，然后每天勾掉解决的问题。这方法可以从各种GTD书籍上看到细节。同时，每天召开快速例行会议。将当天处理掉的todo list，碰到的问题和解决方法读出来。快速的沟通方便在早期把握员工的心不在焉，同时也方便其他员工发现潜在的可能与其相关的问题。
最后就是快速文档和后期文档相结合。在项目过程中提倡快速文档，即写下某个问题相关的精简描述和姓名，方便其他人联系你即可。在项目完成后，逐步补充文档，细化条目成为完整的文档。</description>
    </item>
    
    <item>
      <title>C10K的卡通解释</title>
      <link>http://blog.shell909090.org/blog/archives/121/</link>
      <pubDate>Sun, 13 Jun 2010 13:39:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/121/</guid>
      <description>以前有一帮医生，帮一个城市看病。当然，医生少人多，政府就开始动脑筋，怎么样让医生给更多的人看病。
最开始是医生去病人那里看病的，医生花在路上的时间很长，于是成立了医院。让病人过来，节省医生的时间。当然，病人肯定比医生多的，这是整个文章的假定。为了保持原来的模式，病人到了医院后，会有自己独立的一间屋子，完全模拟在家的感觉。这样会有什么问题呢？问题在于病人独占了医生，在病人抽血，验血的时候，医生无所事事，因此效率很低。
后来转换了一个模式，医生过一段时间就离开当前病人，看看哪个病人那里空着就过去。这样的目地是为了防止一个病人拉住医生不放，将医生的时间平均分配到多个病人头上。这样的动作快多了，但是医院受不了了。原本8个医生，一人一个病房。现在8个医生要在N间屋子里穿梭，万一每个屋子里的病人都是在抽血，那这个N就会无穷大了，现在是屋子不足了。
然后又换了个模式，对不起，现在不是一人一间屋子了，是一堆人一间屋子。每个人只要一个床和一个病例记录，其他的设备可以有限的共享。这样屋子不足的问题得到了部分的缓解。问题是医生又不干了。一方面离开病人再找空病人费事又费精力，另一方面抢设备也是个困扰。医生需要设备的时候会让护士去看看，如果有就拿过来。可是两个医生一起下这个医嘱就会出问题，一个护士看看还有，回去说有，再去拿的时候另一个护士已经拿着最后一个离开了。就算是同一个医生，下这个医嘱的时候，两个执行的护士也会这么打起来。
医院方面动了动脑筋，干脆这样吧。一个病房里只能一个医生负责，多个病房公用的设备看到有就可以预定起来。这样病房里的设备是不会抢起来的，而病房外的设备先到先得，也算公平。医生在病人去抽血等等活动的时候再离开病人，而不是每隔固定的时间。每隔一个很长的时间护士会去巡房，如果医生还在被同一个病人纠缠，护士就会让这个病人强制休息。
不知道有多少人看懂了？下面是答案。
第一种模式叫做服务队列模式。医生是资源池，病人是待处理请求。这个模式的问题是请求过程中往往会有大量IO出现，此时CPU陷入等待，很不合算。
第二种模式叫做多线程。医生是CPU，病房是进程。一个病人新建一个进程，系统将CPU在多个进程间调度。此时的问题是进程对系统资源的消耗比较大。
第三种模式叫做多线程，医生是CPU，病房是进程，床是线程。每个请求新建一个线程，CPU在多个线程间调度。此时系统资源消耗的问题得到一定缓解，问题变成上下文切换和资源锁定造成的浪费。
第四种模式叫做协程。CPU只在必要的时候离开当前请求。什么是必要的时候呢？就是大规模IO之前。IO完成后，CPU会再度调度回来，这样避免了频繁的上下文切换。而在一个CPU的情况下，这样的模式不会造成竞争。（多线程模式就算只有一个CPU一样竞争，因为CPU可能在任何时间离开线程，包括原子操作内部）
沈游侠曾说过，好的构架是让瓶颈只出现的CPU上。当然，从更广义的来说是只让瓶颈出现在最紧张的资源上。显然，如果是服务器，CPU和总线带宽多数是最紧张的资源。</description>
    </item>
    
    <item>
      <title>关于王江民先生几点</title>
      <link>http://blog.shell909090.org/blog/archives/110/</link>
      <pubDate>Wed, 07 Apr 2010 11:30:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/110/</guid>
      <description>前几天惊闻王江民先生离世，我说不上是高兴还是难过。按理说，逝者已矣，种种是非也应当随风而去。然而一个人存在过，就必然有存在过的痕迹。我仅从我个人的观点，追述一下江民杀毒的印象。
我是谁？平凡的电脑用户，95年接触电脑，97-98年刚好赶上KV300L++。然后换用了金山毒霸，04-05年换用Avast。08年换用Linux，因此裸奔到现在。
在DOS时代和前Windows时代，江民杀毒是杀毒软件中的佼佼者。最初的时候，最流行的杀毒产品是防毒卡。好像当时做电脑的人有硬卡情节，什么产品都搭配卡。汉字系统有汉卡，杀毒系统有防毒卡，就是放个VCD，也有解压卡。Whatever，防毒卡一路很牛，直到DIRII病毒出现。这个病毒直接将自己挂入了DOS的设备驱动链，从而直接修改了系统，这个方法很像现在的Rootkit技术。这个思路直接导致了防毒卡的失效，而KV系列，就是这个时候涌现出来的佼佼者。KV系列的成功，一在于他强大的杀毒能力，二则在于强大的抗盗版能力。当时我也有玩汇编/反汇编，底层编程一类东西。因此很是惊艳王江民先生强大的代码能力。KV系列当时可以查杀几乎所有的病毒，电脑报纸上几乎每期都有专栏，说最近出了什么病毒，大家要扩充防毒码。现在的用户可以想象这种情况么？
在97-98年的时候，我碰到了KV300L++事件。简单来说，江民公司在KV300L++版本中加入了主动逻辑锁，当满足某些条件的时候自动触发，锁定用户的电脑。无法重装，也无法解除。具体的手法是通过修改硬盘的分区表链，做出一个循环的分区表，导致DOS系统识别失常。必须使用特殊的方法进行解锁，或者联系江民公司，进行书面的原因说明(其实就是盗版举证)。这篇文章(http://hi.baidu.com/inetpm/blog/item/9e7bea0f02e0e9266059f33a.html)中，将此事描述成正版软件商对盗版的战争。对此我表示强烈的抗议，这根本不是事实，而且我强烈怀疑此人是个枪手。我是一个KV300的受害用户，自然很清楚当时是什么情况。上文中有一段文字，我引述如下：
L＋＋事件出来以后，王江民受到围攻。网上各种言论都有，但就是找不到L＋＋事件的真实受害者用户。这一方面是因为L＋＋网络升级版只在网上放了六天，二是因为正版用户和使用没授权的解密版KV300的用户绝不会受伤害，被锁住机器的是那些在大量生产假冒KV300的盗版商。王江民自信“这个逻辑锁就是这样准确！“
KV300L++在判断用户当前插入的盘片不是江民的原始加密盘之后，会释放主动逻辑锁。这就是上文说不会波及正常用户的理由。然而，当时有大量正版用户受到伤害。至少我当时去抗议的时候，看到某个大叔拿着一堆正版包装在那里骂人，全公司都买了正版，为什么锁他电脑。为什么出现异常波及呢？因为KV300L++释放逻辑锁的条件并不是“插入的盘片有某个盗版加密盘特征”，而是“插入的盘片不具有正版加密盘特征”。这两点看似一样，但是实际上天差地别。前者逻辑炸弹很难释放，也很难奏效，而后者就很容易伤及无辜。我中标的原因就是因为搞不清哪张盘是正版的KV300加密盘，把一张游戏盘片插了进去。我相信大多数中标的人也是基于类似原因。
从更深的层次来说，软件公司有权对盗版用户做出惩罚么？可以，但只能走司法途径。如果允许软件公司私下对盗版用户进行惩处，这就等于赋予软件公司权力来伤害任意个人。因此当年，公安部对江民公司罚款3000元，不再追究。与其说是惩罚，不如说是保护。如果没有这个处罚，我相信江民公司会面临遍地开花的侵权诉讼官司——按照法理，即使盗版用户都可以起诉。因为逻辑锁是未经认定的，因此从法理上说，被逻辑锁锁定的人并不能认定就是盗版用户，更何况这个认定机制根本不准确。只要不去解锁并承认错误，江民公司就无法举证受害者一定使用了盗版。江民公司锁定用户电脑是事实，很容易举证确认，而反过来举证用户使用盗版却很困难。前者是侵权官司，证据全面，法律完善。后者则是版权官司，没有什么确凿的证据，更何况当年连版权法都没有——如果有版权法江民公司更倒霉，版权法规定基于学习目地可以合法使用24小时，这下更难举证。
何况其中大量的无辜正版用户，其中有很多人被无辜波及。至于后来Windows时代的没落，也不能说和这个无关。上文我看到的大叔，直接赌咒发誓，他这辈子不会用任何江民公司的产品。而江民的KV系列软件为了保持加密优势，在Windows时代还继续使用底层的软驱设备直接编程。先不说稳定不稳定的问题，我01年配的电脑连软驱都没有，用个P啊。直到很后来，江民公司才改掉了这个做法。更严重的问题是，由于后Windows时代，尤其是2000以后，对用户权限进行了严密保护，加上系统API的更新换代。导致杀毒软件技术推翻从头再来，杀毒软件商大洗牌，江民公司从此一蹶不振。现在的新用户也许听说过卡巴斯基，也许听说过瑞星，也许听说过金山，但是有多少听说过江民杀毒的？给别人推荐软件的人自己想想，你推荐过么？
当然，就我个人感觉而言，王江民是强力的程序员。做事踏实，技术高超。然而任何人都只是人而不是神。他是个好程序员，但不是好的商人。当技术上的领先没有被放到正确的方向，而是向着错误的方向发展的时候，一个伟大公司的没落就无法避免了。</description>
    </item>
    
    <item>
      <title>在各个平台上启动emacs的技巧</title>
      <link>http://blog.shell909090.org/blog/archives/103/</link>
      <pubDate>Fri, 12 Mar 2010 23:06:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/103/</guid>
      <description>今天在推上，一帮人讨论了emacs如何启动的问题。这个问题我是这么解决的。
这个配置针对三个上下文起作用。Windows，Linux图形，Linux+SSH。在Windows下，不使用alias，因为emacsclient会在找不到server的时候自动启动一个新的emacs。将emacsclient加入到注册表中，就可以对任意文件“使用emacs打开”。
Linux和Linux+SSH中，需要使用alias技巧，因为emacsclient不会在没有server的时候自动启动emacs。过程如下：
首先在系统相关的配置中，加入server-start，以便启动server服务。系统选择上，linux和windows加，console不加，因为后者没什么意义。然后，在系统中加入alias设定。
alias emacsclient=&amp;quot;emacsclient -a emacs&amp;quot;  这样，当系统中没有emacs启动的时候，就会启动一个。当有emacs启动后，就会调用这个emacs来打开文件。
在ssh环境下，需要开启x forward。这样就会打开远程emacs。这是比较慢的用法，快的方法是直接在本地emacs上使用tramp。</description>
    </item>
    
    <item>
      <title>关于无线的安全问题</title>
      <link>http://blog.shell909090.org/blog/archives/97/</link>
      <pubDate>Fri, 26 Feb 2010 11:10:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/97/</guid>
      <description>一个无线路由只有150上下，安装方便使用简单，可以让你在床上躺着的时候还能和朋友聊天。大多有笔记本的家庭都会考虑买一个无线路由，组建自己的无线网络。不过先别高兴，如果你选择买来就用，我想你碰到艳照门只是个时间问题。下面简单说一下无线网络从决策到安全完成安装的全步骤。
首先是决策，无线路由不是随便用的。有几种情况我建议你重新考虑这个问题。有孕妇者不用，这东西的辐射虽说不大，也不是忽略不计的。万一我乌鸦嘴，你孩子出点啥问题，你触不触的慌啊。电脑全堆在一起可以拉线者不用，这种情况下再买无线纯属烧包。房间太大者不用。最后一个要用也可以，建议你买多个。无线网卡在收信差的时候速度很慢，用起来很不爽，而且辐射大，所以一定要保证你的家里能被无线信号完整覆盖。一台标准路由器能覆盖的范围大约是10-30米内的所有区域，加穿一道普通墙(非钢筋水泥承重墙)。普通人家买一个无线路由器可以覆盖全家，但是我不保证有钱人家&amp;hellip;.
其次是采购，推荐大家选择好一点的无线路由器，但是不用太贵。差的无线路由器往往不控制辐射功率，你高兴家里天天开一个大功率辐射源么？
后面跟着的是环境检测。如果你有android，有一个软件叫做wifi检测仪，可以检测周围的wifi信道和功率。挑选一个比较空的信道，否则人家的通讯就会变成你的背景噪音，从而降低网速，增加辐射。而后确定你的无线路由的最佳安装位置——通常是在网络出口处。但是如果造成信号覆盖不好，可以考虑加长网线。毕竟加长网线只是一次的事情，天天断线再连接就痛不欲生了。
然后是基础安装——这个都会，就不多罗嗦了。
最后是重头，安全设置。请先设置不广播SSID，这样别人扫描的时候，你的AP是隐藏的。当然，如果你高兴，可以在AP名字上把偷网的人骂一顿。我记得某个咖啡厅的AP名字就是“你还要不要来杯咖啡”。其次，需要选择WPA加密，WEP的破解时间太短，在你通讯频繁的情况下，最多几个小时肯定可以破解——最少只要几分钟。而且更麻烦的是，一旦WEP被破解，对方可以嗅探到你的通讯包。到时候所有的聊天记录，明文密码，全部都是敞开了让别人看的。WPA即使别人破解了AP能上网，最多也只能上网而已。除非使用主动嗅探技术，否则无法造成威胁——而主动嗅探会造成你的网络超级不稳定，马上会被发现。
以上两步保证了别人无法连接进你的网络，而下面我们还要保证网络内的安全。
请先给你的路由器和Windows账户更换一个强密码——你可以自动登录和使用浏览器记录密码来避免输入，但是一定要强。否则当有人进入你的网络的时候，如果一次就拿到了管理员权限，其他安全措施就没有意义了。然后开启路由器防火墙，禁用所有的人连接，除非特定MAC地址。这样只有指定的几个机器可以上网，一般人进入网络后的兴趣就小了很多。最后，请开启你电脑的防火墙，以免进入网络的人利用漏洞进入主机系统。
最后，如果有条件的话，可以用vmware部署一个honeypot，做一个漏洞百出的系统，引诱入侵者先进攻这里。一旦他发起进攻，那么你马上会发现他的踪迹——不过这个就不属于普通用户的范畴了。</description>
    </item>
    
    <item>
      <title>领导的艺术</title>
      <link>http://blog.shell909090.org/blog/archives/96/</link>
      <pubDate>Tue, 23 Feb 2010 17:19:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/96/</guid>
      <description>啥都不说，先上背景阅读。
帕金森定律
英国著名历史学家诺斯古德・帕金森通过长期调查研究，写出一本名叫《帕金森定律》的书。他在书中阐述了机构人员膨胀的原因 及后果：一个不称职的官员，可能有三条出路，第一是申请退职，把位子让给能干的人；第二是让一位能干的人来协助自己工作；第三是任用两个水平比自己更低的人当助手。这第一条路是万万走不得的，因为那样会丧失许多权利；第二条路也不能走，因为那个能干的人会成为自己的对手；看来只有第三条路最适宜。于是，两 个平庸的助手分担了他的工作，他自己则高高在上发号施令，他们不会对自己的权利构成威胁。两个助手既然无能，他们就上行下效，再为自己找两个更加无能的助手。如此类推，就形成了一个机构臃肿，人浮于事，相互扯皮，效率低下的领导体系。
曾仕强似乎说过，一个能干的干部起什么作用？一个能干的干部只能证明他的所有下属都是白痴。
所以，从上推导，我们只要找一堆傻瓜当干部，公司就能兴旺？</description>
    </item>
    
    <item>
      <title>PC使用android上网</title>
      <link>http://blog.shell909090.org/blog/archives/95/</link>
      <pubDate>Mon, 22 Feb 2010 10:27:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/95/</guid>
      <description>最简单的方法是使用android-wifi-tether，不过我这里使用不成功，原因不明。所以今天我们不去说他，我们说另外一个软件，azlink(http://code.google.com/p/azilink/)。
首先是安装。检查是否满足安装条件，如果满足的话，安装apk，这个不用多说。azlink.ovpn需要复制到电脑上，并且准备好openvpn和adb。另外，推荐在手机上也保存一个azlink.ovpn和adb，openvpn，以便在多个机器上使用。
下面开始正式的连接操作，作为测试，请先关闭手机的wifi上网功能和电脑的wifi，有线，以免影响测试结果。本文中的范例系统是Debian Testing(Squeeze)，网络环境是中国移动的CMNET(8元80M包月，很合算的)。如果环境有所差异，请照您的环境做相应调整。
1.使用usb线连接andriod和PC，此时android上会出现USB已连接的提示。
2.在android上执行azlink，并且勾第一个勾，Service active，保证系统运行。此时状态应当是Warting for connection。
3.在PC上执行adb forward tcp:41927 tcp:41927，此时可能出现service start。这个是首次运行的原因，不影响结果。
4.执行openvpn azlink.ovpn。此时会出现虚拟网络，并且android上的状态发生变化。
5.在android上，设置-&amp;gt;高级属性-&amp;gt;手机信息中，查看下面的GSM信息，一般能看到网关和DNS。请去ping一次网关，如果成功，你的事情已经成功了大半。
如果上面不成功，请联系我。如果成功，请在你的系统内重设DNS。azlink.ovpn将你的DNS指向了手机上，可手机本身无法做DNS的。因此请将你电脑的DNS重设为手机上的值。如果你高兴，也可以将azlink.ovpn中的值改掉，理论上说一个地区的移动网络中，DNS应当都是一样的。不过如果你要跨地区，这个DNS就会发生变化。因此，我无法预先给定值，也无法获得。
这是整个过程中最关键的一步。很多人说为什么无法上网，其实是可以的，只是你的DNS没有指向正确的值而已。
6.如果是CMNET，事情就到此为止了。如果是CMWAP，你还需要做一小步。找一个CMWAP能够访问的代理，设到你的浏览器里面。
作为关闭，其实拔线就可以了。不过作为程序员，我们习惯完美的析构过程。所以，下面是关闭过程。
1.恢复浏览器原先的代理设置。
2.断开openvpn，此时android上的状态会恢复Warting for connection。
3.PC上需要执行adb kill-server。这样会kill掉adb的daemon进程，否则adb会一直假转发，并且始终占用进程号。
4.在android上，关闭Service active的勾。并且，如果你喜欢，可以kill掉进程以回收内存。
5.拔USB线。
如果你曾经关闭了手机的wifi，电脑的wifi和有线，现在也可以恢复了。</description>
    </item>
    
    <item>
      <title>CNNIC的证书</title>
      <link>http://blog.shell909090.org/blog/archives/91/</link>
      <pubDate>Wed, 03 Feb 2010 11:41:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/91/</guid>
      <description>最近，技术圈里面在争论CNNIC的证书被加入到信任根证书里面的问题。本文章试图和专业人士探讨这一变化的过程，以及向非专业人士说明会造成的影响。所有段落前会标明针对的群体。
事情的起源，是有人发现CNNIC的证书被加入了Mozilla和系统的信任根证书链里。这引发了大家对早年CNNIC所做的流氓软件的回忆，因此大量技术人士强烈反对。所做的反应包括发起BUG讨论提请Mozilla删除CNNIC的证书，发起投票，写信给Entrust阐述问题等。下面会简述一下信任根证书链，还有CNNIC的背景和历史。
本段适合非专业人士阅读。我们在访问一个网页的时候，通常有两种常见的通讯方式。http和https。区别在于，https会使用网站证书加密通讯过程。证书加密包含了几重的意义，首先，证书保证了你们的通讯没有第三者能截获。其次，证书验证了你访问的网站，是否是他号称的那个网站。也许很多人无法理解，这两种攻击怎么可能发生。要理解一点，中国电信也不是铁板一块，你完全无法指望他们的员工也绝对安全。否则的话，为什么所有银行都使用https来加密访问过程呢？
本段适合专业人士阅读。那么，不使用证书会发生如何的攻击呢？一旦有某个人更改DNS(这东西让百度都吃了亏)，以某个服务器替换了你的银行(或者gmail)。那么，你访问你的目标域名的时候，就会被定位到他的中间机器上，他再使用代理技术，通过ssl访问目标服务器。整个过程如同走代理一样，唯一的问题就是你的密码泄露了。那么证书是如何防御这个攻击的呢？如果你访问目标机器，目标机器会让你验证一份证书，标明他的域名(用于防止域名劫持的)，签署者。一旦域名不符合，或者你不信任证书，就会报警。那么攻击者如何复制这个证书呢？首先他无法通过访问的方式获得证书原文，因为证书给你的其实只有公钥部分。其次他无法将这个过程也代理下来，因为如果这么做，下面的内容就全是不可解的了，那他就纯粹花钱把自己弄成代理服务器了。最后，他也无法生成，因为按照规定，只有域名的拥有者可以向特定的单位申请证书。于是，他无法复制证书，攻击就会失败。
本段适合非专业人士阅读。然而，你需要信任什么证书呢？如果你要一家一家的信任证书，会发生什么？你见到是否信任就会习惯的去点，这对安全于事无补。因此，这里引申出一个证书链的问题。通常系统内内置了一些证书，这些证书叫做信任根证书。这些证书的权限是，可以让你信任其他证书。而被他们授权的证书，则分为可以继续授权和不可以继续授权两种。一旦被他们签署授权的证书，最起码你访问的时候不会有警告了。现在，CNNIC加入了这个根证书链。那CNNIC是个什么公司呢？他自称是中国科学院下属的中国互联网络信息中心，服务于科学和研究的机构，但很多人指出CNNIC的直接主管是工信部。当年，CNNIC推出中文域名服务，这项服务需要在几乎所有人的电脑内安装插件。他为了提高安装率，使用了不可删除的保护技术。这导致很多人的电脑安装后，无法卸载程序。至于安装呢？也不全是自愿安装(我不排除自愿者，绿霸还有自愿的呢)。他们曾经利用系统漏洞，向大量电脑上强行安装插件。而且CNNIC还借助官方身份，大量推行中文域名——其实他们根本就不是政府机构，而是非营利机构。并且，在前两年拼命忽悠CN域名，最近又突然停止域名解析(虽然是国家规定的)，道歉赔偿啥都没有。大家自己想，真的可以信任这种公司么？
本段适合所有人阅读。现在CNNIC已经进入了信任根证书链，如果配合国家级的DNS劫持技术，理论上可以构造一个假的mail.google.com，或者www.hotmail.com。走代理，自己给自己签署一个证书。从而获得你的完整会话。这里(http://autoproxy.org/zh-CN/node/66)有比较大的说明和讨论。
我对这个事情的观点是。作为Mozilla或者任何根证书的发行机构，在没有直接证据的情况下，不大可能拒绝一个国家级机构的要求。然而，无论任何原因，信任一个机构，就代表你要为他的行为负责。如果CNNIC做出任何危害用户安全的行为，Moziila，微软，Debian.org会被我作为同罪者考虑和抵制。同时，系统发行的根证书系统，是否要去信任，是我们每个人的问题。如果你觉得CNNIC根本不值得信任，那么你可以删除他的所有证书，以及签署了他的所有证书。目前而言，我删除了CNNIC和Entrust的所有证书。</description>
    </item>
    
    <item>
      <title>关于减少使用gmail的建议</title>
      <link>http://blog.shell909090.org/blog/archives/88/</link>
      <pubDate>Tue, 19 Jan 2010 21:18:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/88/</guid>
      <description>这次，google又不走了。
事情处于很奇怪的状态，google本是不可能留下的。既然它留下了，我们说，事有反常必为妖。这次妖在哪里呢？
我建议大家减少使用gmail，最好别用。原因如下：
如果google的却是受到了某些关于知识产权的攻击，但是却愿意在中国留下，并且在发生这次的事件后，还能留下。这说明google(非中国的谷歌公司)已经和北京达成了某种秘密的和解协议。无论这个协议的细节是什么，我们有理由猜测，google的产品不能完全的信任了，包括gmail，google reader，bloger等。
另一方面，如果google并没有受到这些攻击，那就是出于各种原因的新闻炒作。既然google背弃不作恶的宣言在前，那杯葛在后也是自然而然咯？
所以说，如果google打算继续在中国留下，那么包括gmail在内的各种google产品，都必须视为非安全产品看待。建议尽量减少使用，并准备替代方案。</description>
    </item>
    
    <item>
      <title>关于google退出中国的FAQ</title>
      <link>http://blog.shell909090.org/blog/archives/86/</link>
      <pubDate>Thu, 14 Jan 2010 12:52:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/86/</guid>
      <description>F:google真的准备退出中国了么？
Q:历史告诉我们，两个人谈价的时候，如果出现有人生气要走，那可能是讲价的手段。如果出现扇耳光，那么多数是谈崩了。除非被扇的人授意这么做，否则双方都没有回头路可走。目前google等于明确的在指责中国进行网络监控，并试图进行网络攻击。耳光都扇出去了，下面就不是谈价的问题了。
F:中国政府会怎样处理google的谈判呢？
Q:这也是个挺头痛的问题，要是让google就这么走了，无异于变相承认了中国的网络舆论监控和网络安全问题。但是要答应无控制的搜索，那是绝对不可能 的。可能会派出发炎人，声明，中国要求google进行网络控制的理由是为了防止网络色情和网络暴力，这是我国内政，其他国家无权干涉。目前没有证据表明 入侵google的黑客得到中国政府的授意，任何试图联系两者的人都是邪恶和别有企图的。中国是一个开放的市场，任何人进入和离开是个人自己的选择，中国 依旧欢迎其他公司来中国建厂投资。
F:google退出中国真的是因为不作恶么？还是为求一个体面的退出？
Q:别太把自己当回事了。google在中国的利润有多少？不超过总利润的10%。投资有多少？鬼知道。市场份额多少？33%。我们不看其他，就算中国市场全争取过来，最高也只能将利润增加到25%((10*3)/(100+10*2))。也就是说，中国最多是一块肉丝，而美国是块肥肉。如果肉丝真的有臭掉的风险，宁可丢块肉丝，也别丢肥肉。
而且，一旦明确指责网络舆论控制和网络安全问题，那么，同样进入中国的其他大型厂商就会陷入被动，包括微软，雅虎等。撤吧，他们的市场份额更大，问题也更复杂。不撤吧，他们在美国的形象会受到影响，有利于google在其他地区的业务。
F:google走了，百度得益了？
Q:短期来看，没错，长期来看，市场会重新平衡。由于百度在谈判上的强势地位，因此会导致代理商和广告主非常难做，同时互联网广告的成本会增加。进而加剧劣币驱逐良币，最后让整个互联网的所有广告都变成近乎于废纸，互联网广告业务名存实亡。
而且，一旦google离开，百度就会直面政府。从政府需要&amp;rdquo;团结和依靠&amp;rdquo;的多数，变成需要&amp;rdquo;警惕&amp;rdquo;的&amp;rdquo;怀有异心&amp;rdquo;的人。可以预见，政府对百度的监控和利用会达到一个新的高峰(因为用不着让你活着对付google了)，并且可能会提出注资成为某部下属机构的要求。
F:google走了，我们将会怎样？
Q:google的离开，标志着中国的互联网整体倒退了6年。在IT界，3年是一个时代，6年的倒退，让我们退回了两个时代去，变成了上个世纪网络刚刚兴起的时候，那种上网艰难的状况。这不是用备份邮箱，备份新闻标签等方法可以解决的。
更严重的是，这会严重打击整个业界，工程师，对于中国的网络发展的评价。在这个问题解决前，我们可能落后其他国家10年以上。当然，之所以我这么担忧，其实还是因为这直接影响到了我的饭碗。</description>
    </item>
    
    <item>
      <title>论BTchina的倒掉</title>
      <link>http://blog.shell909090.org/blog/archives/83/</link>
      <pubDate>Tue, 08 Dec 2009 11:29:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/83/</guid>
      <description>BTchina倒了，死的很惨。被广电总局直接勒令关闭，连整改的机会都没有。无疑，大家都知道，VeryCD会紧随其后。无论是非如何，请允许我先向这两家陪伴我多年的网站道声感谢，一路走好。
就打击这个问题来说，我无疑是赞成的。广电总局打击集中向两个关键词，盗版和非法。无论哪个，都是应该打击的对象。但是这次打击本身却值得怀疑，主要集中在三点，是否允许整改，选择性执法，还有实际效果。
首先，拿整改问题来说。BTchina和VeryCD做的是下载业务，其中有盗版下载再正常不过。一般打击都是先责令整改，然后再关服务器——虽然我们知道责令也不见什么效果，BTchina肯定改不过来的。不过样子还得做啊。不过从某种意义上说，样子做不做也就是政府内部的事情。无论做不做都是合理合法的，所以这点问题还不大。
其次，我质疑比较大的一点，就是选择性执法。有个朋友说的比较精辟，每只猫都有他的目的。我总是不惮以最大的恶意来揣测咱们的政府——他们这回想干啥？如果要打击盗版，那问题严重了去了。中国桌面上，十有八九都是盗版Windows。哪怕你买了个笔记本，上面带了个正版Vista，一般也非要装个番茄花园不可。中国人看的电影，听的歌，乃至于用的手机，都是盗版产品。所以从这个角度说，我到真的很愿意国家打击盗版。盗版没了我们的软件才更好卖，盗版没了才有人被逼用Linux，盗版没了我们这行才能赚钱。不过咱得看事实，不能听风就是雨，更不能YY。广电总局要真有决心打击盗版，首先应该奔着卖盗版盘和卖盗版书的去——虽然他们也被互联网下载整的生不如死。问题是，他们没有。
那，会不会是打击非法音像呢？这话说的更搞笑了。BTchina和VeryCD上有没有色情我不敢说，不过要有也绝对少于新华网。这不是指责新华网有多色情，而是阐述两者身为不同主体的无奈事实。BTchina和VeryCD要是碰到色情门那是沾上就死抡上就亡。作为半国企的新华网，就算偶尔行为出格，只要不出大差错无非就是检讨一下而已。这种情况下，前两家的审查力度，和后一家怎么可能同日而语？实话说，我当初还非常努力的试图在VeryCD上找什么色情资料。只能说他们的版主比较尽责，连疑似的都没有。要打击非法音像，还得找小网站——就是那种准备烧一把就走的。除非碰上严打，否则等查处来的时候，人都没了。
那我就得怀疑了，广电总局想干啥呢？说打击盗版，不像，说打击非法音像，也不像。这事情我怎么看怎么觉得像上海政府查处黑车，黑车不黑车不重要，重要的是规范正当市场——说白了就是交钱。百度百科也涉嫌抄袭Wikipedia啊，怎么没看广电局找他们麻烦呢？人家3000万春晚赞助可不是白交的。
那这事靠不靠谱呢？我只能说，越来越不靠谱了。从本心来说，我希望打击盗版，但是从现实而言，无论是美国政府，欧洲诸国政府，还是中国政府，对打击盗版都没啥办法。前两者有海盗党——当然，他们也被人盗版了他们的logo，真是讽刺。后者则有1亿多网民，每天发明各种奇怪的办法。现在的网民水准是越来越高了，或者说软件是越来越傻瓜了。原来下载必须在中心节点上投入大量资金，而且政府一来就玩完了。后来则是中心节点上只要搭个论坛，剩下的自然有P2P软件搞定。现在，根本就没中心节点。DHT的普及，使得去中心化的优势体现的淋漓尽致。Emule里面可以用kad搜索，直接搜索你需要的资源——正常情况下不比VeryCD差。而torrent里面则有个种子市场，可以直接搜索你要的种子。
好家伙，连服务器都不要了，这次广电局再要下手，只有从网络传输上下手了——中国为了解决轮子问题，为GFW投资了不少钱。不知道广电局是否能收到足够的钱，把这个系统扩大个几倍，把P2P的混淆协议也全概括进去。作为一个老程序员，我劝诫所有的下载者一点。下次再弄的时候，用emule的kad搜索来找你需要的资源，你会发现其实verycd也不是必须的——虽然对他们来说，这是个比广电局查处更不利的消息。</description>
    </item>
    
    <item>
      <title>MSN强制升级</title>
      <link>http://blog.shell909090.org/blog/archives/81/</link>
      <pubDate>Wed, 11 Nov 2009 10:19:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/81/</guid>
      <description>从前天开始，单位里的MSN8.5就无法登陆，老是提示我要升级。今天家里的MSN也无法使用了，被逼无奈，先用pidgin顶一阵再说。不过现在贝壳正在考虑MSN的用户搬迁工作，目标是迁移到Gtalk上，不行QQ。
有几个朋友问贝壳，升级不就好了，何必兴师动众呢？首先，MSN8.5的安装程序只有20M，而MSN9的安装程序高达132M。其中多出来的100多M东西可不是白装的，他们大概会吃掉你30-40M的内存。而且9里面有很多插件(其实8.5也有，不过就一个，总算还好屏蔽)，安装上去后，工作的时候做调试麻烦异常，工作机器上装这个纯粹给自己找麻烦呢。而且微软素行不良，有劣迹在前。盗版黑屏问题大家还记得吧？升级提示上说是安全修补补丁，结果装上去屏幕就黑了。不说黑屏现在如何了，就说这种欺骗用户安装的手段，有谁还相信这次的强制升级是为了安全问题么？微软系统安全是出了名的差，一个安全公司用测试用蠕虫在win7上跑，只有20%不到能被微软自己拦截。其中固然有安全公司危言耸听，但是测试过程是全公开的，做假不来。这还是微软主推的最新操作系统，安全性据说很好。如果真是为了安全问题，先把Windows里面那堆雷死人的安全问题解决了才是王道。
反倒是QQ的强制升级政策我觉得尚算可以。 QQ协议分为2005/2006/2007/2008多个版本，通常而言可以使用当前版本和前一版本。就是说，现在用的协议是2008的话，那么2007协议还可用，而2006协议就不再支持了。通常而言，这种时候继续使用2006协议的人微乎其微，基本可以忽略不计。这个政策主要是给不愿意升级的人一个缓冲的空间。对于腾讯而言，实施这个政策其实比微软更有压力。因为微软的协议是公开的，而腾讯则是采取封闭协议，甚至打击第三方客户端的企业策略。我们姑且不论这个策略的得失，但是维持两个协议版本，就给破解协议的人留下了破解的时间和空间。因此对于腾讯而言，这个策略是和公司战略相违背的。
更深一层的问题是，强制升级问题说明了我们所依赖的服务的脆弱性。MSN在中国占据的客户群体并不算大，远远不比QQ。然而就是这样一个客户群现状，微软就敢于强制升级。今天是强制升级，明天收费呢？所以说任何事情依赖一个公司是不行的。我还是会使用MSN，但是会逐步将用户迁移到Gtalk和QQ上，并以开心网和Facebook做补充。力争做到这三个IM中任意两个能覆盖大部分朋友群体，开心和Facebook保留所有联系可能。这样可以适当制衡某些软件公司(不仅是微软，还有腾讯)，也可以减小出问题时的损失。
其实要做到这点并没有任何困难。当你认识一个人的时候，只要和他保持两种以上的IM，并且在开心和Facebook(当然，这个没法强求了，毕竟中国的GFW&amp;hellip;)上交换一下好友就好了。对抗强权，从小事做起就好。</description>
    </item>
    
    <item>
      <title>软件自由英雄谱</title>
      <link>http://blog.shell909090.org/blog/archives/78/</link>
      <pubDate>Mon, 14 Sep 2009 13:53:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/78/</guid>
      <description>谨以此缅怀那些为了今日软件事业的自由做出贡献的先辈们。(注1:多数人没牺牲，谢谢)(注2: 排名不分先后)(注3: 科普作品，大家别怕)
我在撰写这篇文章的时候，避免使用自由软件这个词，而改为更普遍意义上的软件自由。因为自由软件是RMS提出的一个专有词语，指软件的开源，复制，协作等
特质。而我试图通过软件自由这个词，表达人们在使用软件上的自由，以及使用软件来为我们获取自由。我们拥有知道软件一切内幕的自由，我们拥有修改软件的自由，我们拥有思考的自由，我们拥有挑战老系统的自由，我们拥有拒绝通过软件收费的自由，我们拥有通过软件获得信息的自由，我们拥有不受任何人，包括政府监控的自由。为了这种自由而付出的，不仅是自由程序的拥护者，也有商业程序的拥护者。
 Richard Matthew Stallman  大名鼎鼎的RMS，GNU的核心人物，自由软件的布道者。要是在这个列表上没有他的名字，那我不知道还有谁能留在这张表上。具体可以看这里(http://zh.wikipedia.org/zh-cn/%E7%90%86%E6%9F%A5%E5%BE%B7%C2%B7%E6%96%AF%E6%89%98%E6%9B%BC)。简单来说这家伙最大的几个成就：创立了GNU和FSF，为自由软件的传播奠定了基础。制作了emacs，当今黑客世界两大编辑器之一(另一个是VIM)。制作了GCC，世界上使用最广泛的编译器。
RMS的核心想法是，因为软件而收费是罪恶的，这种人是撒旦(当然，Bill Gates是其中最大的那个)。他认为软件应当自由分享，程序员从中收取的应当是服务费。今天，RedHat正是继承了这一模式。通过免费的软件和收费的服务来进行持续的开发。
2.Linus Benedict Torvalds
常常和RMS并提的一个家伙，具体在这里(http://zh.wikipedia.org/zh-cn/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%89%98%E7%93%A6%E5%85%B9)。
一个低调又火爆的家伙，没有什么太多言论，但经常语出惊人，最有名的是以“一群自慰的猴子”(OpenBSD crowd is a bunch of masturbating monkeys)来形容OpenBSD的团队。最大的成就就是写了个操作系统——没错，就是叫Linux的那个。
3.Donald Ervin Knuth
哈，这个人就不像上两个那么广为人知了。他(可不能叫这家伙，得敬老)有个中文名字，叫高德纳，页面在这里(http://zh.wikipedia.org/zh-cn/%E9%AB%98%E5%BE%B7%E7%BA%B3)。
最大的成就是写了本书，叫做《计算机程序设计艺术》。有意思的是，写到一半的时候，觉得现在(那是上世纪80年代的事情)的排版软件不爽——于是自己下手，写了一个叫做Tex的排版系统——然后再回来继续写书。这本书算起来已经写了30多年了，估计成书时间和《浮士德》有的一拼。而Tex是当今高端排版中最流行的系统(多数都不是直接拿来用，而是用了LaTex之类的包装)，如果有向国际期刊投稿过的应该有印象。Tex也是被誉为最接近完美的程序，它的介绍在这里(http://zh.wikipedia.org/zh-cn/TeX)。%E3%80%82)他的版本号是以圆周率为基准的，头一个版本叫3，后一个叫3.1，以此类推。目前的版本号是3.1415926，刚好是祖冲之的密率。高伯伯曾表示，等他死之后，版本号就改为π，剩下的bug就作为程序的功能放在那里。
有一个未经证实的故事。据说上世纪Internet还没出现的时候，美国军方找人设计了TCP/IP协议，他们希望有人为他们实现基于Unix的TCP/IP协议栈。于是他们花了四千万美金，找人写了一个协议栈，并且拿到高伯伯的学校去用。对此高伯伯非常不满意——别误会，我指的是实现的效果。于是就自己花了点时间写了一个，结果比原版的协议栈更快速而稳定。美国军方觉得非常困惑，问他是怎么做的。高伯伯说，读你们的协议，然后编码。
4.Andrew Stuart Tanenbaum
这个知道的人也不会太多，当然，职业玩家例外。当初AT&amp;amp;T禁止UNIX7的代码公布，因此大学里面都没什么实际产品可以用来教操作系统这门课。
于是，有个叫AST的老师就怒了，你不让我干，我自己干。于是写了一个叫做Minix的系统，并且还写了本书，叫做《操作系统：设计和实现》。后来有个学生，觉得这个系统改改能干别的，于是给AST去信。AST说，改什么改，我写这东西是拿来教书的。于是这个学生就自己写了一个系统——对了，这个学生就是上面的Linus，而那个系统，就是大名鼎鼎的Linux。
时至今日，Minux已经发展到了第三版(他的版本号是跟着书走的，第一版，第二版，第三版&amp;hellip;)，是大多数大学里面教授操作系统基础原理的标准教材。
同时，也在嵌入式系统等领域有非常大的应用。但是，由于AST还是坚持他的教学和精简原则，因此在桌面和服务器领域就别指望了。关于AST，大家可以看这里(http://en.wikipedia.org/wiki/Andrew_S._Tanenbaum)。
5.Ian Murdock
这个人很多人都听过，不过看着名字还是认不出来。他是Debian系统的作者，具体可以看这里(http://en.wikipedia.org/wiki/Ian_Murdock)。
Debian有什么特殊呢？其实就本身来说，Debian并不算特别成功。但是Debian有庞大的衍生系统群，更有Ubuntu这样充满活力的发行。
Linux世界有所谓三大发行，四大包管理系统之说。其中三大发行指三个在世界上最广泛用于服务器的发行版本，即RedHat Enterprise Linux，SuSe，Debian，其中只有Debian是无服务商支持的。而四大包管理系统就是指RH的RPM系统，Debian的APT系统，arch的PCMAN系统，和Gentoo的emerge系统。
6.Ken Thompson
有没有听说过？至少看着眼熟吧。这家伙是贝尔实验室的，最大成就就一个：Unix作者。详细内容请看这里(http://en.wikipedia.org/wiki/Ken_Thompson)。
7.Dennis Ritchie
没听说过？也很眼熟？这家伙和上面那位是朋友，最大成就也就一个：给上面那位提供了基础语言，C语言。详细内容请看这里(http://en.wikipedia.org/wiki/Dennis_Ritchie)。
8.Bjarne Stroustrup
又是一个怎么看怎么眼熟的家伙？那当然。他和上面两位不怎么熟，不过他们都是一路的。他是C++的作者，详细内容请看这里(http://en.wikipedia.org/wiki/Bjarne_Stroustrup)。
9.Phil Katz
这个就很少有人知道了吧，不过大家肯定天天和他打交道。大家用记事本打开任意一个ZIP文件，开始的两个字肯定是PK，这就是Phil Katz，具体请看这里(http://en.wikipedia.org/wiki/Phil_Katz)。
这是一个有点悲剧的人物。在上个世纪的时候，大家还在BBS上混。由于速度有限，因此下载站的资源都是压缩提供的(当然，直到今天肯定还是如此)。最初的压缩格式大多是ACE的，这是一家商业公司，直到今天还活着。由于PK不满意这家公司的压缩软件，压缩率低，速度慢，而且还不断提出高昂的收费。因此他决定自己写一个压缩软件，就是最初的PKZIP。由于软件免费提供使用，压缩率高，解压速度快，因此很多站长自发的将数据格式转换为ZIP。后来PK就干脆开了PKWARE软件公司，免费发行压缩程序代码，同时提供方便使用的图形界面版本。
但是非常可悲的，由于格式开放，因此这个软件有个非常大的竞争者，winzip。我想有些Win95时代的老用户还记得这个软件。PK在软件开发上很有天分，但是在市场策略上却不很成功。WinZip对ZIP格式的熟悉其实比不上PK(那当然，人家是原作者)，然而WinZip却拥有很多用户友好的特性，右键菜单解压，虚拟解压(将压缩包的内容临时虚拟成一个目录，用户可以无缝的使用，XP中集成了这个功能，但是WinZip的虚拟解压很容易撤销)。所以最终PK的软件公司破产了。他本人在2000年4月14日因饮酒过度，在一家小旅馆内死去。
至于WinZip呢？碰到了一个更强大的对手，WinRar。功能类似，但更简洁，最主要是支持大多数流行的压缩格式。因此目前压缩软件领域还是WinRar占据着主流，市场就是这么残酷。
10.Phil Zimmermann
这个人基本没人知道，但是却是这张表里面最典型和突出的一个人。他是PGP的作者，具体可以看这里(http://en.wikipedia.org/wiki/Philip_Zimmermann)。他的成就很难用一句话说明，要阐明他的成就，就必须从美国的国家安全出口管制说起。
在上个世纪，美国政府有一种观点，他们需要能随时随地的窃听任何一个人和其他人的通讯。同时，作为延伸，他们制定了国家安全出口法案，将密码产品作为军用管制品，限制出口。这其实是很荒谬和不合逻辑的，任何公开的算法都可以被多个人独立的实现。只要算法是公开的，即使产品不允许出口，国外也可以没有任何阻碍的实现出来。而如果算法是不公开的，则会出现两个弊端。一个是阻碍密码学的交流和进步，更麻烦的是，根据密码学的内在逻辑，这样的系统，由于验证不完全，因此比公开的系统更加不安全。
在1991年前后，PZ制作了PGP软件，用于保障当时备受争议的电子邮件的安全(小常识:电子邮件默认是明文的，安全程度和你写在明信片背面寄给你父母的句子差不多)。这个软件使用了1980年以来提出的现代密码系统几大密码系统，实现了签名安全和秘密安全。这里我们小小的讲解一下电子邮件的两大安全系统，对此无爱的人自行跳到下一段。签名安全就是指，你收到一个邮件的时候，能够确信，这个信的内容是原始发件人的真实意思表示，而不是被篡改过的。秘密安全就是指，当你收到一个信的时候，你能够确信，除了你没有别人能够偷看到内容。对此，一般采用公钥系统来实现两者的安全。所谓公钥系统是这样一种系统，用公钥加密必须用私钥解密，用私钥加密必须用公钥解密，私钥很容易计算出公钥，公钥非常难计算出私钥。当你要签名安全的时候，将邮件内容用自己的私钥加密再发送一次(实际是将内容hash了再加密的)，接收者解密后对比。由于篡改者只有公钥，因此虽然可以拦截和修改内容，但是无法伪造出一对匹配的内容，用公钥解密后刚好一致。而秘密安全则是用对方的公钥加密。对于更高层级的要求，你的公钥不仅要求公布，而且必须在国家认可的部门公布，这样就由国家认定了你的公钥和你的身份的一致性。当你对一个内容签署的时候，只要能用公钥验证签名，就可以认定内容是你的真实意思表述，并被法律所承认。
当时的PGP当然还没有这么复杂，但是对于当时缺乏任何安全性特征(当时连TLS都没有)的电子邮件来说，是非常必要的补充。可是我们上文说了，美国禁止出口这些产品。于是，PZ免费的将软件的最初版本散发给同事和其他人使用，而这些人又可以免费的分发出去——这和自由模式非常的吻合，除了我找不到具体信息标明当时PZ是否从授权上同意他们做这个事情。法律上说，PZ并没有“出口”密码产品，但是实际上，是他实现并且向全世界推广了高强度的电子邮件安全系统。从某种意义上说，PZ可以说是叛国者。非法散布军用管制品，危害美国的国家安全(这还不像中国那种含糊不清的指控，这里的军用管制品定义是明确的，并且是由国会制定的)。于是，PZ受到了三年的官司和五年的调查，直到96年的时候，克林顿签署了新的法案，放松了密码产品的出口限制。其实也没松多少，从40位到56位——大概就是从5个字符到7个字符的区别。反之，我们改变观点，从世界的角度说，由于他的勇气和决心，我们每个人从中受益匪浅。
EDIT 2016-09-08: 按照我听到的更新消息，PZ当时实际上是出版了一本书，这个书里面就是完整的源码。他虽然没有“出口”这些源码，但是实际上任何人都可以在书店里买一本，然后带去海外，照着源码keyin一遍。美国政府虽然希望禁止这本书的出版，但是禁止个人出版图书违反宪法第一修正案——言论自由。当时政府还不能因为国家安全因素就随意禁止公民出版书籍（这都是911之后的事了），所以只能用官司和调查来整PZ。</description>
    </item>
    
    <item>
      <title>互联网的黄金时代</title>
      <link>http://blog.shell909090.org/blog/archives/75/</link>
      <pubDate>Thu, 20 Aug 2009 15:25:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/75/</guid>
      <description>今天，一个朋友推荐我看了篇《创业成功80%是运气？》的文章，作者可能是雷军。里面说，99年是互联网成就的年代，几大互联网巨头都是在99年成就的。 因此作者推测，09年也是互联网成就的年代。前者我认为很有道理，后者就纯粹在胡扯，拉人去投资了。退一步说，即使是对的，也是蒙上的。
为什么？我们首先得看，为什么99年是互联网成就的年代。这就得讲到98年以前，电脑是什么样的一个形态。记得贝壳95年刚接触电脑的时候，那时用的是 286。和现在完全不同，电脑最主要的功能是文书处理。因为当时根本没有互联网建设，电脑用户沟通的途径主要通过点对点拨接的BBS(不用了解是什么东 西，贝壳自己都不怎么明白）。这种BBS和现在的BBS完全不是一个概念，但是BBS这个词却来自于当时的这个形态。这种沟通方式非常不方便，也非常贵。 因此用的人很少，基本都是专业人士和各个高校，这等于限制购买电脑后只能单机使用。由于电脑根本是单机使用，因此但凡要增加功能就必须买盗版盘。要 WPS，盗拷(最早还没有盗版光盘呢)，要看电影，买盘。于是电脑的主要形态被限制到了预设的几个功能上，而不是根据客户的想法随意定制。而这几个功能中 呢，最常用和实用的就是文书处理。96年的时候，最火的就是UCDOS和WPS。凡讲电脑入门如果没有这两个那就是落伍，是怪胎。而在98年的时候，接连 发生了几个事情，因此才酝酿出了风起云涌的互联网大潮。
首先，98年前后，Win95/98在中国大量普及。在此之前，由于受到文字，版权，习惯，配置等诸多限制，大家还是停留在dos6.0的年代不肯出来。 Win9X系列的普及(当然，主要是盗版普及)对电脑降价和普及起了不可磨灭的作用。也许有人听不懂了，软件的普及能降低硬件的价格？话是这么说的。从总 体来说，DOS6.0的入门难度高，高到要维持一个能够运转的DOS系统，就非要经过专业的，正二八经的学习不可。而Win9X的入门和维护难度基本是 零，你就算不明白，也不阻碍你的使用。因此，有大量的普通用户可以使用电脑，电脑的组装量就大了。更具有决定作用的是，由于DOS的入门难度高，因此很多 客户必须购买专门的电脑公司的电脑系统，即所谓的“品牌机”。使用品牌机的最主要理由是需要电脑公司的服务，来维护电脑系统。而Win95安装维护简单， 任何一个人都可以拿着盘装套系统出来。除去偶发的硬件故障，着实没必要非买品牌机不可。于是，当时品牌机对市场的垄断被打破了。大量的小作坊稍微经过培 训，就可以拿着一堆电脑配件组装起一台电脑来。教客户几分钟，他就可以自行安装起Win9X和Office。而后机器如果出现故障，顾客也可以很轻松的重 装。于是大量的小作坊相互竞争，使得电脑的价格直线下滑。我记得96年时主流电脑的价格在2W上下，98年时只有1W上下，01年时更是只有5000。注 意这里比较的是主流电脑的价格，不是同等硬件。里面固然有着摩尔定理的作用，也相当的得益于Win9X的普及。
而此时，更具标志性的事件是国内大多主要城市，都开始了电话拨号上网的业务。虽说中国从89年就开始接入互联网了，然而真正标志着普通民众上网的事件还是 98年前后的163/169电话拨号上网业务。大家可以想像一下，要是没有网络了，你的电脑还能干什么？怕是只剩下看书(还得买盘)，听歌(也是买盘)， 放片而已了吧？我们今天所用的大多数功能，都是以网络为基础，或者要基于网络获取数据的。电话拨号业务一开，等于就开启了一扇通向无限可能的大门。虽然当 时的价格大约是1.6元/小时，而速度一般只有5K/s。这种流量下基本无法承载什么复杂业务，多数都是基于文字的业务。例如QQ，当时肯定只能做文字， 不能做视频聊天。又例如BBS，当时也是以文字为主，图片点缀一下。要是哪个搞不清楚放一堆图片上去，站长到还没头痛呢，用户先受不了了。
现在我们看到，98年的时候，互联网具备了大量的潜在用户，也打开了通向无限可能的大门。可谓是万事俱备，只欠东风。而东风从哪里来呢？所谓的东风，就是 亚洲金融风暴和2000年互联网泡沫中的时间差。在98年的时候，东南亚发生了非常严重的金融风暴，相信大多数人都有所耳闻。而98年的时候，正是互联网 飞速发展的时候。2000年的互联网泡沫还没有提前到来，投资回报比高到吓人。在金融风暴中损失惨重无处容身的热钱，碰到了一个飞速发展回报极高的产业， 就如同火柴碰到了汽油一般，瞬间就无可阻挡的燃烧起来。而引爆点，就是互联网门户和娱乐。腾讯，百度，携程等互联网公司，都在那个时候纷纷发展起来。金融 环境的影响究竟有多大呢？我们不妨想像一下，如果是2000年的时候，用户和网络才准备好。这时金融相对稳定，金融风暴中跑来跑去的热钱也该投资的投资， 走的差不多了。而互联网公司普遍表现不好，美国各大网络公司一片惨红。这时候，中国的各个网络公司才组建起来，他们还能顺利的拿到融资，完成由小到大的华 丽转身么？
当然，当年之所以成为互联网的黄金年代，还有其他的很多因素。但是就贝壳的浅见来说，当时互联网的成功，和广大的新增客户群，新出现的网络，还有相对良好 的投资环境是分不开的。现在，中国的网民已经发展到了极限，12亿人口4亿网民，即使还有发展空间，也是屈指可数的事情。不像我们的前任，永远会出现新的 客户(这里顺便提一下，实际上互联网大量出现用户的时间大约是在05-06年前后，宽带包月普及的时候)。我们的投资环境呢？不利，很不利。美国经济刚刚 打了个喷嚏，现在全世界人民都在重感冒，没空搭理中国一堆互联网公司的脑残想法。那么，我们的下一个黄金年代在那里？
接下来，我们有几件事情会引发互联网的大革命，不过贝壳和大家一样头痛的是，我们谁都不知道这些事情会什么时候到来，是否会一同到来。
首先，是真正的3G网络。现在所谓的3G网络都是花架子，没有什么实际意义的，3G最大的优势在于低廉的随时在线成本。当前，所有客户上网都是通过电脑拨号，而电脑是需要了再开机的。但是我们的很多应用需要客户随时在线，例如IM类业务，对客户在线就有严格要求，微博客也有类似问题。为了能让用户随时在线，就必须让客户在手机上使用电脑的应用。问题是，如果没有一个廉价的网络接入，哪个客户愿意付出N高的网络费用就为了用个IM？那还不如打电话。现在的 3G曾有个笑话，什么叫3G？一秒3元，所以叫3G。这个价格至少要下降到一个月100-200的范围内(流量不限制，甚至还要在其中包括有线的接入费用和电话费)，才有大量用户愿意入网。更好的接入模式是两台手机一根ADSL线路，包含电话/手机/电视/网络/3G在内的所有通信业务，总价200上下。 不过以目前的垄断形式而言，大家可以口水收起来了。
其次，是全球经济复苏。要是大家都没钱，是没人愿意投资电脑产业的，也没人愿意用。
而后是取消互联网备案和审查制度这滩狗屎，建立一个真正公平公正的法律环境。众所周知，互联网属于服务业，而服务业对于环境的公正性要求是最高的。即使经济复苏，也绝对不会有一个投资者愿意把钱投资到一个政策整天变化，商业运作随时为政策让路的地方。以饭否为例，如果某个投资者投资了，而后饭否因为种种不 明原因关闭了，那么投资者的损失谁来负责？对于这类问题，必须有个公正的，公平的政策，提前说明。如果投资违背了政策，那么损失没什么好多说的。如果没有 违背政策，那就不应该让投资者受到损失。而不是暧昧不清的制订一个根本实行不了的政策，然后看谁不顺眼就关谁，对其他人的违法不闻不问。只要这个大山不真 正的走开，中国的互联网就不可能真正的走入下一个黄金时代。</description>
    </item>
    
    <item>
      <title>电脑操作与人机工程学</title>
      <link>http://blog.shell909090.org/blog/archives/67/</link>
      <pubDate>Mon, 01 Jun 2009 22:41:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/67/</guid>
      <description>贝壳大学念的是工业工程，毕业导师就是人机工程学方向的，贝壳的人机工程论文就是按钮的大小和操作效率。因此，今天贝壳罕见的回归本专业，谈谈电脑操作的速度问题。
首先一点就是，无节制的优化速度是万恶之源。为什么？道理和优化程序一样。你实施一个优化必定有一定成本和代价，为了一个一个月进行一次，一次三秒钟的操 作，进行一次优化。假定你搞定优化用了半个小时——一些情况下的却需要这么长时间。这样你需要100年才能收回你的投资，显然，这很愚蠢。
那么，什么是优化，为什么要优化？
操作优化，指的是你利用一些专业和非专业的方法，将日常最常用的操作简化。减少操作次数，减少操作时间，减少精力集中的负担等等。最常见的方法是“按键精 灵”或者是快捷键。而之所以要进行优化，则是因为——我懒——俗话说，只有懒人才是好程序员。也许有人会想，那设计者为什么不设计的效率高一些？拜托朋 友，你也讲讲道理。设计者怎么知道你是要经常复制还是要经常剪切？于是他只能假定你经常剪切（或者复制）。如果不幸，你恰恰相反。也许你就需要优化，也许 贝壳的文章就能给你的工作提供非常大的便利。
那么贝壳下面逐个讲解贝壳碰到的一些优化方法和范例，具体的运行则要靠大家的发挥，没有一定的模式。如果你觉得你的电脑操作工作平淡无聊，那就说明你需要 优化了。每种优化方法需要一定的专业知识配合，贝壳会给出评价。评价有三种，适合普通人，就是说一般稍微会一些电脑的人，可以根据网络上的讲解来使用。适 合专业用户，指用电脑3年上下，电脑比较熟练的人，可以经过试验配置成功。还有疯子专用，指这个方法基本就和您无缘，除非您正好是程序员或者疯子。
首先我们从最基本的开始，鼠标，按键，快捷键，快捷键排位。这个方法适用于普通人，但是下面一段是比较专业的论述，不感兴趣的可以跳过。
鼠标和键盘是我们最常用的输入工具，而根据贝壳的人机工程论文，鼠标的输入效率低于按键。但是要注意，这个结论并不永远成立。对于某些图形操作，尤其是高 精度操作来说，键盘上可以操控的方法变成上下左右四个键，效率大大降低。如果使用其他键来辅助，这不是人类能接受的方法，疯子也不行。此时使用鼠标比键盘 效率高多了。键盘输入快的根本原因在于一般人精神集中后，一秒可以按三个键——至少也有两个。而无论精神怎集中，区域怎么大，要输入一个点击至少要一秒。 按照信息量计算，键盘的可用信息量要比鼠标大一个量级。然而，除了输入文字，键盘并不好用。根本原因在于鼠标的模式是阅读-选择，而键盘是记忆。因此，键 盘操作是用户不友好的。
通常来说，我们可以用键来定义一些常用功能，这样会加速操作。通常而言，这个被称为快捷键。例如，Atl+Tab是切换窗口，相信大多数人都知道这个热 键。这个热键好用的根本原因在于快速的在两个窗口见切换——如果用鼠标会累到死。我们可以记忆一些常用热键来加速，毕竟之所以定义常用热键是有意义的。例 如Atl+F4的关闭程序，结合windows使用可以以&amp;lt;win&amp;gt;,Atl+F4,U的顺序来关机。整个操作只要一秒，单手就可以，真是酷 到不行。Atl+Space可以唤出系统菜单，因此Atl+Space,X可以最大化，Atl+Space,N可以最小化，这两个也可以单手操作。
单手操作热键的意义在于免去频繁的键盘/鼠标切换。当你需要双手执行热键的时候，你需要半秒将右手从鼠标上移动到键盘上，再花半秒移动回去。这样就平白多 了一秒的时间——这还是高手的时间，普通人更长。对于加速操作来说，这么移来移去很没有意义。而键盘/鼠标的配合才是操作电脑的理想境界。你可以在资源管 理器里面试试一个操作，在一个文件夹内选择一些文件复制到另外一个文件夹。这是贝壳最熟悉的配合动作——因为太频繁了。首先点中头一个文件，按下 Shift点最后一个。放开键盘鼠标，按下Ctrl+C。点击目标目录，按下Ctrl+V。速度快的原因在于，Shift放开后，按下Ctrl+C的动作 基本是下意识的。这样鼠标可以轻松的去找目标——同步的。按下Ctrl+V也是下意识的，所以整个动作的时间序列是——点头一个文件，点最后一个文件，点 目标。当然，拖曳选中区域，拖曳到目标目录一样可以，而且是单手鼠标操作。只是这样一来，首先你无法添加选择零散目录——用Ctrl键就可以做到。其次如 果不小心在移动的时候松开左键，就会触发麻烦的同文件夹文件复制。因此上述方法兼顾了稳定性和速度。
也许你觉得无聊，不就是文件复制么？我点右键也可以啊。问题是，如果点击右键，再点选菜单，至少需要1.5秒的时间。比这个方法至少慢了1秒。如果你每天的工作需要整理大量的文件，我想你不会高兴遇到这个问题的。当然，如果你基本不复制文件，好吧，当我没说过。
更多的时候，我们需要定位目录中的某个文件或者文件夹。对此，你可以输入文件的头两个字母。这时候光标会被带到符合这两个字母的头个文件——我想离你的目标不会太远了吧。这个同样是双手配合操作。</description>
    </item>
    
    <item>
      <title>手机病毒的真相</title>
      <link>http://blog.shell909090.org/blog/archives/60/</link>
      <pubDate>Sat, 04 Apr 2009 12:11:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/60/</guid>
      <description>转载自http://blog.wangyingqi.com/2009/04/03/137/，以下为内容。
**** 防止被骗，帮我宣传，随便转载，不用署我的名字都行。
作为一个软件从业者，我有很多其他领域的知识盲点，当我看到有人揭露私人豆腐坊的生产过程之后，我就再也不敢到小市场买豆腐吃了。当我了解到药品销
售者和医生勾结向病人推销过量药品这个事实后，到医院买药我都要仔细查看药品的名字和功效。没有人是全能的专家，我很有自信不会在计算机和软件上受骗，但
是难保
其他人不被骗。写这个文章应该算是社会责任，于是，我这次充当内部人士揭秘，来看看手机病毒的真相。
普通用户对手机的了解还是太少，能分清智能手机和非智能手机的人就更少了。能知道所谓Symbian和Windows
Mobile系统的区别，知道iPhone和RIM这些单词的人算是很高端用户了。不单单普通用户不知道这些概念，连同样是作软件但是不做手机软件的技术
人员，也都不清楚这些操作系统的最基本的知识。于是，目前大家能见到铺天盖地的手机病毒爆发，3G来了要装手机杀毒软件，手机中毒后隐私外泄等等如此骇人
的广告和说辞。那手机病毒很多嘛？我的手机很慢是中毒了嘛？到哪里装手机杀毒软件？哪个手机杀毒软件最好？一个月多少钱？如果你心中有以上那些问题，那么
很荣幸的告诉你，你已经被骗了，你忽略了一个最重要的问题。
手机病毒真的有嘛？
首先我们来区别一下智能手机和非智能手机，目前的数据是国内已售的智能手机占整体手机市场20％，虽然我坚信这个数据会越来越高，但是就目前来看，
如果你
的手机不是诺基亚，三星，摩托罗拉，苹果iPhone，黑莓，Palm，多普达，HTC等这些稍高端品牌的话，就基本不用担心手机中毒的事了，也许有人说
手机品牌不就是这些嘛，其实能看到这篇文章的人也算是互联网信息圈内的人了，外面有大把的普通用户在用着低端手机，而他们才是最容易受惊吓，最容易以讹传
讹的不明真相的群众，传播正确的理念都靠我们了。如果问具体哪个型号的手机是不是智能手机怎么办呢？很简单的方法是到淘宝上搜索该手机，然后找一个信誉最
高的商家，产品介绍里面就有是否智能手机这一栏。在知道自己的手机是否是智能手机后，一个最浅显的结论是，如果你的手机不是智能手机，那么手机病毒和你无
缘。放心睡大觉吧，别为这事儿烦心了。 糟了，我的是智能手机哦。
别怕，继续往下看。软件病毒实际上是一种对系统有害，更改用户数据，给用户造成经济或名誉损失并能够自我复制自动传播的软
件。这个定义里面的一个很关键的词是&amp;rdquo;自我复制自动传播&amp;rdquo;，也就是我们常说的感染。智能手机都可以安装很多软件的，看起来就像普通的电脑一样，智能手机好
像具备了被感染的能力，也就有中毒的风险。那怎么才会被感染呢？又一个重要的概念出现了，一种智能手机操作系统的软件不可能安装在另外一种智能手机操作系
统上（这个说法有一个小漏洞，后面再补上）。如果不理解这句话的话，我来举个例子：棉铃虫是是棉花种植中的一种很严重的病虫灾害，在棉花的主产区很容易传
播和互相感染。但是，人是不会长棉铃虫的。我们不用担心去收棉花的时候染上棉铃虫。智能手机操作系统也是一样，塞班（Symbian,诺基亚智能手机的主
打操作系统）的软件只能在塞班的手机上运行，绝不可能在用微软移动操作系统(Windows
Mobile)的手机上运行。拿iPhone的软件跑到诺基亚的手机上运行也是天方夜谭。结论就是，你只能被使用同样智能手机操作系统的手机感染。目前能
找到的智能手机平台大概是Symbian,Windows
Mobile,Blackberry,iPhone,Andriod，Linux，Palm，还是一样，到淘宝上搜索自己的手机，查一下看看自己属于哪个
帮派？接下来我挨个介绍。
我知道我的系统是什么了，那哪个系统最容易中毒呢？
先说iPhone吧，这个最容易讲，一个正常的iPhone想要装软件只能到苹果官方的软件店上找，而苹果对软件的功能和安全性审查的极其严格，虽然有人
对这种封闭垄断行为很是不满，但是对最广大的普通用户来说，至少在安全这个问题上，用iPhone的根本不用操心。Google推出的Andriod智能手机操作系统，目前也是沿用这个策略，你只能装官方的软件店上的软件。用这个系统的朋友也可以放心大胆的用了。
Symbian是一个比较复杂的系统，市面上能见到的有Symbian
s40,s60第一，二，三，五版，UIQ等。先找个简单的来说，Symbian s60
的第三版以及之后的所有版本，包括UIQ，在上面正常安装的所有软件都必须通过Symbian官方进行安全认证。或是用户自己给软件打数字签名作认证(这
个不讲了，普通用户不会这么干的)。Symbian虽然没有官方的软件店限制，但是签名认证这一点就已经给s60高端智能机一个很好的安全保证。不用
说做一个病毒传播出去，就连作一个正常的软件想要发布都会有很多门槛，必须买一个$200一年的开发者资格，每次发行一个版本都要付给官方$20认证后才
能大范围的安装使用。要想写一个恶意软件很容易，但是要装到很多手机上用并传播，基本上不可能。至于s60的第一，二版本，诺基亚在2005年的机型
N90以后就再也没出过这两个版本的智能手机了。他们的安全认证等级确实比较低，但是市面上已经没有这些产品卖了。大家也不用为古人担忧了。
Palm大家可以忽略了，已经很久没有Palm系统的新机出现了，近来要推出的Palm
Pre会搭载新的操作系统WebOS。目前没有真机，但我相信这种现代的操作系统，都会十分注重安全性的。也先不用为未来担心。
至于Linux，其实手机上用的很少，摩托罗拉的A系列一直在折腾，单从血统来看，Linux的手机安全性肯定不必担心。另外，像这种比较偏门的机型，现在占有率不高，未来发展方向也不好。不用说病毒，就是正常的软件开发商都不想为他作软件。所以用这一系列的商务人士们也可以无忧了。
Balckberry的软件安装目前未见到安全认证机制，同上面未说完的Symbian
s40一样，是市场上占有率较高且有中毒风险的系统。但是很有意思的是，基本上没有病毒爆发的迹象。**而Windows
Mobile也继承了Windows一贯的光荣传统，安全认证机制基本为零**，
属于高危范围。而为什么目前没有很多手机病毒呢？其实，目前在电脑上，单纯
的病毒已经无利可图了，写病毒已经不再是一种技术炫耀，病毒作者已是无利不起早的经济利益偷窃者，电脑上的网游盗号，网银盗号才是他们要关心
的。手机上没有他们想要的，我们的认为重要的亲密短信，隐私图片，对犯罪者是没有吸引力的。这也是目前在这些相对危险的操作系统上也没有手机病毒爆发的重
要原因。
如果说要窃取利益，装了软件后在后台偷偷的发订阅服务的短信应该是最常见的方式了。但是为什么目前也不泛滥呢？这个和几年来整治SP提供商有关系，短信特
服号和厂商直接关联，SP资质非常的难拿到，敢作坏事就再别想作SP了。他们想赚钱倒是真的，但是没必要作这个犯罪风险这么高的事情。这也就是大环境好，
立法好会很好的杜绝犯罪，也会很好的杜绝软件病毒。电脑上也是一样，如果能有好的立法保护每个人的虚拟财产，目前的盗号木马绝对不会这么猖狂，说远了，不
要跑题。
差不多都说完了，再补一下刚才的那个漏洞，实际上一些Java的程序是有可能在各种不同的智能手机平台上传播的。但是有一个前提要说的是，Java的程序
能作的事情很有限，访问网络，访问手机上的文件，发送短信这些都会有十分明显的提示，让用户确认后才会进行。这个安全限制是在Java这一层次就已经解决
了。所以基本不会对大家造成什么风险。
可是手机病毒这么多人在说，他们都是骗人的嘛？为啥你说没有就没有阿？有人说有阿？到底有还是没有阿？
其实是真的有过手机病毒，当然目前都是恶作剧形式的，我看到的都是s40,s60第一，二版本，和Windows
Mobile的早期版本的几个样本，为什么会中毒的原因，想必大家也有概念了，就是操作系统的安全性差造成的，但是大家不用担心，目前这些样本都不再活
跃，也基本没有啥传播能力了。算是一些待在实验室里面的样本而已。和广大普通用户没关系。就当前的流行手机操作系统看，我没见到任何可以称作病毒的东西。
那现在手机杀毒软件都是骗人的？
关于这个问题，我来分析一下目前国内一个卖的比较好的手机杀毒产品，网X。他在官方网站上放出了所有他可以查杀的病毒名，
一共216种。里面大部分的病毒样本是没有标明可运行的平台的，看了我上面写过的都应该知道。平台不吻合根本没法运行，还谈什么病毒行为？另外，他的产品
承诺每月升级4次病毒库，每次升级2块，或是8块钱包月，包年98（您没看错，就是比按月买还贵），两年的卡188元。从第一个有时间标注的病毒2008
年4月17日到2009年4月2日，一共有病毒53个，想起来也还不错。刚好平均每月4到5个，有这么巧嘛？接下来我们再看一下所谓的病毒是什么，最近的
一个病毒样本是一个Python脚本，我来解释一下这个东西要怎么才能运行，首先你要在诺基亚的s60手机上装一个目前只有程序员才关心的Python脚
本解释器，然后又碰巧别人传了这个脚本给你，而且你还要跑到系统中找到这个脚本并手动运行，OK，病毒爆发了，不断发短信了。听不明白吧？不知道</description>
    </item>
    
    <item>
      <title>笔记本选购不完全指南</title>
      <link>http://blog.shell909090.org/blog/archives/58/</link>
      <pubDate>Thu, 02 Apr 2009 12:26:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/58/</guid>
      <description>这几年来，贝壳接触了不少电脑，并且经常被人叫去选购各种电脑和配件。其中最为复杂的就是电脑配置，因为电脑配置具有很强的可换性，可以根据需求精确定 制。喜欢A的CPU加B的主板？完全没问题，买了组装就是。回顾贝壳玩电脑来14年的趋势，组装机逐步的在驱除品牌机。95年的时候品牌机还有很大优势， 而现在只有公司才会考虑进品牌机。最主要的原因也不是出于性价比，而是资产管理和经营者的回扣。作为个人来说，找个信任的人配个配置，去电脑商场比价，讲 价，组装，大多数人都可以做到。而在维护上，遍布各地的维修点，电脑基础维护知识的普及，也大大削弱了品牌电脑的价值。但也因为电脑配置的这种灵活性，使 得电脑选购组装上的普及完全不可能。一个电脑配置单要考虑无数的事情，实在不是非专业人士能够处理的。反倒是灵活性略差的笔记本选购可以由非专业人士搞 定。今天贝壳就讲一下笔记本电脑选购上的几个要点，最近需要下手购入的朋友们，注意了。
首先一点，请先搞清楚你为什么要买笔记本，这有助于确定你要买什么笔记本。买电脑的理由有很多，工作学习娱乐都有可能。不过买笔记本的理由只有一个，移动 使用。如果你是因为地方太小，可以用小机箱加液晶和无线键盘。无论花费大多少，绝对比笔记本便宜。如果因为你有两个地方要用，可以买两台机器，配置同步， 也比笔记本便宜。如果要考虑不断电，那更简单了，一个UPS就可以解决问题。只有多个地方要用或者移动使用，才需要考虑笔记本。而对比买电脑的理由，一般 来说，娱乐是不需要移动使用的。因此我强烈的建议那些买笔记本的理由是打游戏的朋友，买个台式机。如果因为你懒，想在床上玩，请弄个无线键盘鼠标加上液晶 电视接口，或者干脆弄个桌子专门放你的液晶屏幕。无论是效果还是价格，都会比笔记本优秀很多。
而后我们说一下移动学习的问题，一般来说，贝壳不怎么推荐移动学习。要录音，请用MP3。要打字，请回宿舍。要计算，更不用非在餐厅或者教室里。一般来 说，要使用电脑的范围应当不会大于你的宿舍，但是贝壳倒是经常看到一些特例。因此，具体情况请自己分析，想想你是否真的需要一台笔记本。
另外还有一种就是混合应用，外出要学习，回来要炒股，父母打游戏，老婆买东西。这种混合型的应用是实际情况中最多的一种，通常具体情况很难分析，不过请把握上述的原则。只要不要带来带去的，请尽量考虑其他方案。
最后一种就是商务应用，无论是出于保密的原因还是出于方便的原因，贝壳都推荐使用笔记本。
按照上面的讲法，我们推荐使用笔记本的情况基本是三种，商务应用，混合应用，移动学习，还有少量的赶时髦分子。根据这几种原因，我们可以相应的确定你应当 买哪种品牌的电脑。通常而言，商务应用的主力就是Lenovo和Dell，几乎找不到其他机器。其最主要的原因就是这两种本本的商务气质。以Lenovo 为例，他的技术是收购IBM的，因此有很多非常有用的技术。包括指纹识别，硬盘防震，超长电池和增强型电源管理。这些技术有助于你在商务活动中避免为一些 意料外的事情耗费精神，例如窃取，数据丢失，没电（这是普通本在商务应用中最容易碰到的问题）。通常而言，商务本的定位价格有两类，一类是 8000-12000，定位基本就是对着Lenovo去了。另一类是4000-8000，基本就是Dell了。Dell的电脑价格便宜，服务也还不错。唯 一问题是总部设在厦门，一旦你发生需要返修级别的问题，需要回厦门处理。一次往返的时间和价格，有点配不上它商务本的定位。不过看在价格的份上，是否有吸 引力就是见仁见智的问题了。
做商务的同志们需要留心一类本子，通常我们称之为廉价本。价格在2000-4000之间，一般由国内的一些厂家出品。这里并不是说崇洋媚外，而是这些本 中，有相当一部分的是“看上去很美”的本子。配置也不低，和Dell本子4000的机器比也不丢人，价格却非常平易近人。但是，本子却相当的容易出现各种 小毛病。原因在于，一般生产中往往会出现一些有很小瑕疵的成品，我们称为二线产品，或者叫下线货。以这些零件拼装的电脑，价格当然便宜，也当然容易出问 题。一般而言，一流厂商一旦定位为商务本，自然会关注质量问题。如果是下线货，照例是不会用的。一旦出现质量问题导致客户损失，这无疑是拆自己招牌。但是 所谓廉价本，就是针对“坏了也无所谓”的客户的，只是可以肯定，他们不会这么宣传。如果买这种本子，一切问题自行负责。
如果是移动学习，贝壳反到会推荐廉价本。原因在于学生本身钱就不多，多资料损坏也不会太在乎（当然，关键资料还是自己备份起来的好），和厂家折腾几次更是 可以当作磨练。用一个方正或者神舟的入门本子，3000上下就可以挺个3-4年，直到你毕业。可能会坏个一两次，不过也没有什么太大关系。这想必对大多数 学生有相当吸引力吧？当然，如果你有钱，喜欢烧一个顶极的Mac来，那也是你自己的嗜好。
还有两类本子，贝壳分别称为鸡肋本和专用本。例如Sony的一些游戏本，双核，独立显卡，17寸，2W上下。买这种本子，要带的话不如弄个台式机背着，不 带不如弄个台式机放着。整个一个鸡肋。还有Mac的一些高端本子，就是针对图像处理和视频处理去的。你要专业到这个份上，自然会知道这些机器。你要不知 道，就是不够专业。（好——无语的逻辑——）
最后一类就是混合应用，这是非常多的一类，也是最难定义的一类。冲着什么本子去就看你的混合定位和要求最高的一个需求了。如果整个里面混合进一个高端商务 应用，恐怕就非冲着Dell或者Lenovo去了。如果全是看电影打游戏，弄个廉价本吧。如果要不间断的炒股，建议你弄两个本——我没在开玩笑。第二个本 可以考虑采用小型上网本(坚决不推荐某品牌)，价格才2000-3000。本子超小，方便移动应用。 另外就是自配件的估计，普通用户现在推荐160G硬盘，1G内存，准备好升级2G。高端用户建议250G硬盘，2G内存，准备好升级4G。上述估计适用于2009年上半年。</description>
    </item>
    
    <item>
      <title>emacs简介</title>
      <link>http://blog.shell909090.org/blog/archives/48/</link>
      <pubDate>Wed, 17 Dec 2008 11:14:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/48/</guid>
      <description>emacs一定是我梦想中的编辑器，设计者一定是个超级的混蛋。
emacs是一种多平台的编辑器，具有非常古老的历史，和vi一起并称为黑客常用两大编辑器（在贝壳学习linux后，就“顺带”学习了vi——因为根本没有其他选择）。作为编辑器来说，他只接受文本编辑，但是却具有收发邮件，编译软件，调试程序，甚至煮咖啡等各种诡异的非正经功能。很多人疯狂的热爱他，认为他是人工智能的结晶，化妆成编辑器的操作系统。但也有人疯狂的咒骂他，认为这东西纯粹就是折磨人用的。贝壳这次的blog，就是侃侃emacs到底是什么。
说emacs是人工智能平台，其实这个说法并没有错。emacs的运作机理和我们通常的编辑器都有不同。通常来说，一个编辑器可能有多个windows啦，frame啦什么的，但是最终作用于一个文本。你可以添加，删除，修改，或者标记一段文本，进行剪切，复制，粘贴等动作。设计比较完善的还有回退和重做。让我们专注于其中一个任务，例如，删除，看看我们的编辑器是如何工作的。
以notepad++为例吧，在选中一段文字删除的时候，你可以用键，同样，如果没有选中文字，这个键作用于当前光标后面的一个文字。（在此我们不讨论和前后删除的关系）这很简单，一个内容，按删除，就没了。但是你是否注意了这个过程本身，为什么按下是删除，为什么不是按下键或者键？
按照程序员的思维来说，编辑器的基础是一个文本内容和一个光标（或者说一个position），我们通过修改数据结构变更这两者以达到某种目的，这个过程被称为操作。例如，作为删除操作，我们移除（remove）了文本内容的position处的字符。而后，我们将这个操作（也可以称为函数）绑定到键上。于是，我们在按下键的时候，触发了删除函数，导致内容被删除。这个是能够删除文本的核心过程。从正常人思维的角度来说，一般我们都会将这个功能绑定到上面，而不会是或者，或者其他更疯狂的键。同样的机理，我们按下，文件存盘，是因为存盘的功能被绑定到了这个键上。好的编辑器一般带有键绑定修改功能，notepad++就可以自行修改热键。而emacs则更进一步。
emacs允许你自行编写扩充函数，并且将这些新的函数绑定到键上，这样就赋予了编辑器无限的可能性。例如，你可以写一个过程，每次触发就在当前光标处插入当前时间对应的纽约时间。或者你可以写一个过程，自动根据一个预定义的数据表格补充你输入人名的头衔。可以想象，当你需要重复单一工作时，这种扩充能力是非常重要的。你可以免除记忆一堆领导的详细头衔，免除重复输入，免除繁重的劳动，只要你编写一次扩展程序，并且绑定到某个键上。然而现在编辑器的趋势是，我们使用编辑器从事各种不同的工作。有的时候，我们用编辑器记事，有的时候用来写程序，有的时候用来看源码。因此我们对编辑器的个性化能力和强大都没有要求，反之对编辑器的标准化要求很高。说的更通俗点，我们不需要自行扩充一个插件来省事，但是我们一定要用来复制，用来粘帖。因为我们（指普通用户，而非以电脑为生的专业用户或者是变态的geek）不会程序，或者不喜欢为了某个目地花费时间来编写程序，毕竟现在不是70年代，当时接触电脑的都是智力最高的一帮变态。现在接触电脑的都只是普通用户而已，我们不需要强大的扩充，但是我希望我用一个编辑器的时候，这些基本功能在另外一个编辑器上不会产生区别。从这点来说，emacs差劲透了。
emacs的键绑定是根据上世纪70年代unix下（那时候linus都没出生，何况linux）的键盘来的，因此emacs假定你有一个Meta键。这个键在今天的电脑上已经找不到了，我们用Atl来替代。但是同志们，Atl是系统键，这么替代是有副作用的。例如自动补齐的函数热键是M-Tab，但是请试试在windows下按Atl+Tab。亲爱的，你会跳到另外一个程序上。那是windows切换程序的热键。还有我们经常用来复制，来退回。可是在当时的linux下，代表终止程序运行，代表挂起程序到后台。emacs当然要避免这两个热键，于是——你自己试试在emacs下按这两个热键的结果吧。
从热键约定的角度说，emacs是当之无愧的最差编辑器。不过这个很难怪罪emacs，毕竟他出生的年代不用说windows，连dos都没有出生，cp/m还只是个样品。要怪只能怪windows的设计人员在考虑热键的时候根本没有考虑emacs的现有标准，自己瞎设计一通（尤其是最常用的，虽然从人机工程角度这个是最合适的键）。
emacs更强大的特性是，可以根据当前文件的特征鉴定文件类型，并且采用正确的模式。例如，我可以在python模式下编写python程序，在C++模式下编写C++程序。对于用户来说，这两种模式看不出区别，然而他们本身有着非常多的细节不同。例如，在C++模式下，/**/是注释，而python下，#才是注释。灵活的模式允许你使用同样的方法操作不同类型的文件，并且还具有各种扩充。对于C++，他可以编译，对于python，他可以校验。并且有一些比较常用的超级扩充，例如etags。这个程序可以用来生成一些文件，帮助你找到一个符号的位置。利用这个扩充，你可以快速的寻找符号位置，自动完成，等等。这些近几年才在VSIDE和eclipse里面出现的特性，早在数十年前就出现在了emacs里面。
如果你有程序基础，并且长期从事相似的工作，例如写程序，写文档，并且有很多重复的工作，希望解放自己的劳动力，那么推荐你使用emacs。如果你是个找酷的新新人类，希望找一个很少人用的编辑器，具有真正酷的特性，被很多人称赞，那么建议你用emacs。除此外的人，请珍爱生命，远离emacs——这东西太容易上瘾了。~~~~~~~~~~~~</description>
    </item>
    
    <item>
      <title>竞价排名和不作恶</title>
      <link>http://blog.shell909090.org/blog/archives/47/</link>
      <pubDate>Sun, 23 Nov 2008 22:58:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/47/</guid>
      <description>前两个月贝壳才刚说到百度的竞价排名，果然，这回又出问题了，而且还出的很好笑。
央视曝光了百度竞价排名中的一些问题，主要是有很多医疗信息，百度并没有核实来源。此后，百度总裁李彦宏声称，法律没有要求百度对付费信息负责。从法律角度说，这是对的，我们今天说的主题也不是他，而是这个(http://www.cnbeta.com/articles/69964.htm)。
本来曝光百度，怎么转眼变成google了？
看来百度不应该叫搜索引擎公司，而应该叫公关公司。前两个月讲三鹿问题，他是公关。央视曝光医疗问题，他是公关。现在出这个，还在公关。不过你可以公你的关，不代表股东会买你的帐。详细情况大家可以看这里(http://realtime.zaobao.com /2008/11/081120_21.shtml)。
估计我这篇blog的百度排名应该会很低吧——
下面贝壳废话一下，讲解一下竞价排名的问题，google的价值观和策略。
竞价排名在前两年是一个非常好的模式，通过竞价本身，我们就可以发现很多有价值的信息。例如，我们在搜索IBM的时候，肯花钱的蓝色巨人总比不肯花钱的国际大嘴(International Big Mouth)来的有价值吧。然而问题在于，由于搜索引擎价值的外在性很大，又没有监管，搞不好就要出问题。而且往往不是竞价排名供应商出问题，而是上游下游出，他们没法管。首先我们说外在性的问题，所谓外在性，是指由不应当承担后果的人承担后果的一种状况。好比我在XX地开了一个工厂，生产在欧洲要花很多环保费的东西，破坏了当地的环境。我获得了收入，但是后果由当地人来承担。不论出现的原因，由于外在性的存在，会破坏社会公平，因此很多国家都有补偿外在性的措施。例如排污税，针对富人的高所得税等。竞价排名的外在性在于，有人花钱买排名，并不总是发现价值的过程，也可能是减少价值的过程。而减少价值的损失并不总由百度承担，而是由百度的用户承担。更麻烦的是，这个过程是不可监管的。
我们举例详述整个过程。假定有人在百度竞价买了“流产”(这也是百度最贵的排名)这个关键词，那么，什么人会最乐意去购买呢？我们分析一下流产的潜在市场。正规医院的流产总要通过手续，未成年需要父母签字。很多有钱的小孩宁可多花钱也不希望父母知道，因此他们会选择一些非正规的医院。于是，这些市场一般都是非正规的医院把持的，因为正规医院的收费公开固定，流程有一定监管，肯定没法和这些非正规医院去竞标这个关键词。那么非正规医院中，我们可以想象，应当是付出最高价格的人能够获得这个关键词。如果你按照百度的去，那么你去的地方一定是市场上拥有最高的成本收益比的地方——因为只有这样他才能标到百度的关键词。问题是，什么样的医院会拥有最高的成本收益比？如果是监管医院，这个答案一般是私人贵族医院——如果中国有的话。如果是非监管，那肯定有问题。因为他不能贵族化，收入上不去，又要保证成本收益比，只有降低成本咯。而且医疗系统里面，降低成本普通人根本看不出来。不普通的人——不普通还需要自己找非监管医院么？同样，一些用户不希望被监管的医疗问题中，这个关键词应当也是非常贵的。例如生育，肾亏，等等。这个过程也是不可监管的，百度自己难道还逐个核查竞价排名的真实性？他又如何有权力做这个事情呢？
一家不在监管下的医疗机构，这个问题够严重了吧？但是百度有做什么非法的事情么？没有。从法律角度讲，任何人有权付费将某个信息在百度的排名变更。例如，我可以付费将布什是条狗的网页调整到最高——如果我对布什不爽的话。这个不触犯任何法律，除非你调整有悖法律的关键字。你不能说布什是条狗不是事实，因而不允许我调整排名。那么，百度调整这些有问题的医疗机构的网页，并不能说他触犯了任何一条的法律——从法理上讲是这样的。
通常来说，如果是普通机构，市场会自行调整。如果一个公司提供的信息是违背市场本意的，那么这个公司本身就会被市场淘汰。如果你天天提供广告给我们，我们应当一脚把你踢开。问题是，百度获得了足够的互联网资源，百度搜索是个太重要的东西了。因此他可以屏蔽对自己不利的消息。于是，即使百度有问题，大家也不会知道，直到上面的这幕出现。百度被另外一个媒体的老大——央视——点名，他屏蔽不掉了——总不能屏蔽央视吧？当然，他还是屏蔽了部分消息，并且留下了相当的尾巴。
google的核心哲学观点之一就是“不作恶”。简单来说，就是不因为外力——包括广告，赞助，等等——人工改变排名。google的排名一般有两种变更方法，一种是被发现作弊或者犯规，另一种是更改算法。用google的话来说，即使我们认为某个关键字结果是错误的，修正错误的方法不是我们调整这个页面的pagerank，而是使用更公正的算法，保证每个人在同一个起跑线上。这个和美国法律的精髓如出一辙。即使我认为这个判例是错的，我也不会行政干预这个判决。而是通过议会修正法案来修正法律，保证一个更公正的法律。
至于google的广告，不要误会，google也是卖广告的。google的广告都统一显示在页面的右边，和左边的搜索结果严格分离。大家可以很容易的识别出google的广告。如果你们对广告内容有兴趣，可以点击广告——这是google广告的本意。如果你们对广告内容没兴趣，不强迫你们。这个是“不作恶”的本意。</description>
    </item>
    
    <item>
      <title>一些关于盗版、黑屏、开源的事情</title>
      <link>http://blog.shell909090.org/blog/archives/44/</link>
      <pubDate>Mon, 03 Nov 2008 14:04:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/44/</guid>
      <description>大家都知道，微软搞黑屏了。贝壳暂时就这个事情不发表评论，而是先说一些其他的事情，然后大家再回过头来看这个事情怎么说。
首先是软件的版权区别。开源软件，自由软件，免费软件，共享软件，收费软件，盗版软件，这些我们经常说的名词究竟有什么意义，有什么相同和区别？
首先，大家要了解一个事情，上述对软件的不同称呼，其实是不可并列称呼的。免费收费，是指软件的付费方式，开源闭源，是指源码的公布方式，正版盗版，是指是否侵犯版权。这些其实是不同的事情，只是很多事情有前后的因果关系，因此大家容易混为一谈。一般我们可以将软件分为是否收费，是否开源，什么版权三种分类方式。分清其中的区别有益于阅读下面的内容。
开源软件是指源代码开放的软件系统。多数情况下，开源意味着免费和自由，但是也存在收费的例子。例如许多大型系统（好像有些UNIX就是，但现在具体什么情况，贝壳没有用过，也没有看过软件协议），其源码对使用者开放（注意，开源并不代表对所有人开放，只要使用者有权获得源码即可。当然，如果范围缩小到使用者中的特定群体有权，则不算开源，例如微软的不可泄露协议），但是属于绝对的收费系统。大家很容易理解这里面的原因，既然源码已经开放，那么多数人都可以轻易写出类似的系统，在这种情况下还要坚持收费就愚蠢了。除非源码庞大，需要相当的水准和时间来理解，这样才能保持收费。当然，更多的情况是开源免费，收取专家服务费。
这里中间还要插入一句法律问题（怎么感觉写成法律普及文了），目标软件的作用是给予使用，源码的作用是表达思想，这是公认一致的原则。换言之，如果你发布的是病毒目标，则是违法。如果你发布了病毒源码（当然，要排除恶意发布），则是研究之用，不属于违法。当年DeCSS的审判之所以被判定无罪，即是基于上述原则。
免费软件是指授权方式是不要钱的。现在免费软件的很大一个来源是来自开源社区，然而并非只有开源了才免费，共享软件和试用软件就是其中的两个典型。共享软件的作者允许你可以免费的使用它的软件，但是并不开源。试用软件的作者允许你在一定期限内免费使用软件或其中的一定功能（其实试用软件的完整授权也不一定要用钱，写个邮件把作者夸一顿或者给他做些事情，例如翻译软件，一样可以获得授权）。这些软件虽然免费，但是往往会因为有其他的原因而选择闭源。例如微软的Process Explorer，就是属于共享软件的典型。这个软件原属于sysinternels的作品，后被微软收购。如果是开源软件，搞不好要和微软打官司，也不可能被收购。而Winrar则是试用软件的典型，大家都听说过Winrar推动检查中国大型公司内使用非授权产品的例子吧。这个例子难就难在取证这个软件产品超过了使用期限，因为大多数人可以通过重装来避免提示。
自由软件是一个非常复杂的概念，要理解需要了解一些西方法律精神。自由软件现在在中国基本被视同为开源软件，其实两者是完全不一样的两个东西。自由指的是你拥有软件的选择权，包括是否使用，是否修改，是否散发，是否改善，具体可以参考这个文档（http://www.gnu.org/philosophy/free-sw.zh-cn.html ）。为了保证以上权力，开源是必须的，然而开源并不代表你拥有以上权力。我们在上文提到过，是否开源和什么版权是两个事情。开源软件可以选择收费版权，也可以选择非收费版权，但是禁止你修改，再散发软件。这些都不属于自由软件的范畴。
自由软件的起因来自于上世纪70年代出现在美国的自由潮。受到自由潮的影响，当时很多软件大牛都是黑客精神（不是现在这堆脚本小子讲的黑客）的拥护者。他们认为人类学习和使用软件的自由不言自明，他们拒绝为他们的帐户加上密钥，并且以破解软件系统为乐。他们所写的程序也是免费分发。很难想象，在上世纪70 年代的时候，很多现在具备极大影响力的项目在当时只是几个人看不爽而随手做的一些小程序。很多自由项目直到现在还无人可以超越，发挥着重要作用。
自由软件运动是天赋人权观念在知识领域的延伸，目的是推动知识的扩散。因为知识产品都有一个学习的概念，新手需要不断的观摩和学习成熟的系统才能成长。然而如果允许其他人无限制的学习，那么新知识的发明就无法给创造者带来利益，从而导致没有人愿意发明创新。因此专利法规定专利的存在，给予了发明人一定时期的权限，使其可以从中获利。而同时规定了专利期限，使得新手可以学习。（贝壳注：现在的很多专利期限动辄50年70年，实在是太长了一点，10年到20 年的期限应当是合适的）而自由软件在创造伊始就放弃了自身的专利权，给予了其他人学习和改进的权利，因此被认为是软件业的第一推动力。尤其是近些年，在 GNU的推动下，出现很多很优秀的软件产品。当然，其中大部分是和普通人无缘的。例如flex分析器，emacs编辑器。
盗版软件这个词很不好界定，因为有两种界定线。一种是收费软件不付费使用，一种是违反软件使用授权。从范围上说，后者比前者更广泛，因为付费主要是取得软件使用授权，不付费一定违反了授权原则。而违反授权则不一定是不付费，也可能是试用软件超期（违反试用授权中期限限定），未授权可以修改而进行修改（这个尤其多出现在使用源码库的时候），违反最终用户协定（在共享软件中常见）。一般我们说的时候都指前者，但实质上，后者也属于软件权违法的例子。我们不妨用违法软件来称呼后者，而用盗版软件来称呼前者。
盗版软件是否是自由软件思想影响下的产物？绝对不是。我们上文说了，自由软件运动的主要目的是普及软件知识，那么破解软件成果如何普及软件知识呢？无法自圆其说。也有人说这个是打击收费软件，以扩大开源软件的影响力。这就要讲到西方的毒树毒果理论，这个理论认为，非法手段（毒树），无论为了什么目地，其产生的结果一定是恶意的（毒果）。开源软件有着自己的适用范围，不需要也不可以通过这种方式强行介入收费领域。再者说，如果没有收费软件来为大型项目提供资金，没有大型公司来消化软件人才，那么程序员的将来也就无法保证，更谈不上进一步普及和推进计算机研究发展了。
盗版软件只是一些不喜欢付费或者根本不拿版权当回事情的人，为了自己的利益编造出来的一堆谎言。例如微软的这次黑屏，很多人都在抵制，都在骂微软。我们可以想象一下，如果微软的产品出来的时候就带着黑屏措施呢？他们照用不误，最多就是搞一下破解。Winrar也带了保护措施，用的人照样一堆堆，破解照样满天飞。微软只和合法购买者订立了合同，保证不会侵犯他们的权益。非法使用者从根本上就没有依据来保障，你的系统即使上了Windows就当场机器爆炸，也无法控告人家。
其实本质上说，贝壳也是违法软件使用者。在这个社会里面，看清每个软件的版权，然后一点不差的照做是完全不可能的，可能的只有知道行为违法后想法弥补。使用盗版windows则是因为贝壳根本是linux用户，但是同事全是清一色的windows，沟通不方便而被迫使用。既然我不是主动高兴买的，就上个盗版得了，被发现最多回到linux下结束（中国的法律对个人侵权行为只纠正行为）。使用盗版windows，我们人人知道违法，但中国的法律基于告诉乃论，就是所谓的民不告，官不纠。自己知道怎么回事，回去闷声发大财就算了，明明是违法者，还跳出来义正词严的指责受害者，做人不能太CNN。
就如同我在MSN名字中写的那样。我虽然不赞成你黑屏，但是我捍卫你黑屏的权力。</description>
    </item>
    
    <item>
      <title>VeryCD版电驴(eMule)存在封锁</title>
      <link>http://blog.shell909090.org/blog/archives/38/</link>
      <pubDate>Wed, 24 Sep 2008 17:11:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/38/</guid>
      <description>eMule是一个GPL程序，所以VeryCD的改版必须公开源码。今天听说VeryCD版有封锁的现象，所以贝壳抓源码来看看。如果大家认为老调重弹的话，不妨把文章拉到最后。
源码从此处下载：http://www.emule.org.cn/download/
最下方链接：http://download.verycd.com/eMule-VeryCD-src.rar
贝壳下到的文件大小13,703,064字节，打包时间2008-09-11。经过贝壳查找，在eMule-VeryCD-srcsrc WordFilter发现两个文件，WordFilter.cpp 2008-03-12 09:57 13374和WordFilter.h 2007-11-20 17:56 1009。仔细阅读里面，发现有以下内容。
void CWordFilter::Init() { HANDLE hFile; DWORD dwRead; int nLen; BOOL bResult; CStringList list; //m_count = 0; CString saaa = thePrefs.GetMuleDirectory(EMULE_EXECUTEABLEDIR) + FLITER_FILE; CString sbbb = thePrefs.GetMuleDirectory(EMULE_CONFIGDIR) + FLITER_FILE; // 如果文件目录不对，程序移动一下，到config目录下 added by kernel1983 2006.07.31 if (PathFileExists(thePrefs.GetMuleDirectory(EMULE_EXECUTEABLEDIR) + FLITER_FILE)) MoveFile(thePrefs.GetMuleDirectory(EMULE_EXECUTEABLEDIR) + FLITER_FILE, thePrefs.GetMuleDirectory(EMULE_CONFIGDIR) + FLITER_FILE); if (!PathFileExists(thePrefs.GetMuleDirectory(EMULE_CONFIGDIR) + FLITER_FILE)) { // 不存在，所有的都过滤 added by kernel1983 2006.08.08 m_filterall = true; return; } // Open file for read hFile = CreateFile(thePrefs.</description>
    </item>
    
    <item>
      <title>紧急修复</title>
      <link>http://blog.shell909090.org/blog/archives/36/</link>
      <pubDate>Mon, 22 Sep 2008 10:36:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/36/</guid>
      <description>贝壳周四的时候收到消息，烟台的系统崩溃，于是在24小时之内走了一趟天堂和地狱间的旅行。
开始的时候，贝壳在查一些业务有关的资料。期间和一个同事开了几句玩笑，但是发现他一脸便秘的样子，和我说没空。贝壳很郁闷，怎么这么没面子？过了几分钟，事情就发展成贝壳也一脸便秘的没胆子了，原因是烟台的系统崩溃。由于远程无法连接，只能让客户去机房重起整个系统。可重起后也没有反应。于是贝壳怕了，马上通知了老板。老板马上做了决定，要我们当时飞去烟台，并且在几分钟内给我们搞定了机票。于是在贝壳头处理紧急问题的时候，就受到了&amp;rdquo;飞机-出租- 零反应&amp;rdquo;的待遇。
中间首先要感谢一下给我们做Oracle技术支持的纪锋老师，这次如果不是他的大力协助，恐怕问题不会这么快解决。我们在零时间往烟台赶的时候，纪老师也马上打车往机场走。我们是五点接到的问题通告，五点半就联络好了各种问题，乘公司的车子往机场走(主要怕下班高峰不好打车)。六点多点的时候，我们拿到了登机牌，去做安检，然后顺便讨论起问题原因。当时认为基本不可能是软件问题，因为软件问题重起后基本都可以解决，也不会弄的机器停机(这个最终被检验是正确的)。可能是维护问题或者硬件问题。按照机器安装时间来计算，硬件问题的可能居多(系统才刚刚交付几个月)。
飞机是8点50在烟台落的地，落地后我们心急火燎地坐出租往报社赶。车刚出机场，收到一个消息，问题消失了。我们顿时安心很多，要是问题继续出现导致更严重问题，怕我们全都吃不了兜着走。现在，虽然我们还要去找出根本原因，可总比被客户拷问着检查系统来的好的多。到了报业后，我们先检查了系统。第一个被发现的问题是备份机已经满了，怎么会这样？系统的设计容量是三年500G，按照现在的数据量估计，最高不会超过30G，可备份机上足足有100G的空间！我们倒推了数据，发现备份要用140G以上的空间。怎么会这样呢？
原因我们没有找到，不过按照纪老师给出的原因，是备份的时候大量的归档日志造成了数据量暴增。但是备份暴增怎么会造成系统不能访问呢？贝壳陷入了奇怪的感觉中。虽然直觉上觉得就是这个理由，但是实际上却无法确定。按照我和同事说的话，如果用这个理由来说服我，是无法说服的。但是如果在目前让我给出一个理由，恐怕只有这个了。当天比较晚了，因此没有进一步分析，只是让纪老师调整了备份策略就去睡觉了。
第二天，贝壳仔细检查了所有的系统日志，找到了真正引发错误的理由。Linux9号错误，原因是因为文件无法访问。可是，究竟为什么造成9号错误呢？又是为什么导致重起后错误不消失，过后错误又莫名消失呢？进一步分析日志找到了这后两个问题的理由，客户重起节点1未完成时，直接重起了节点2。RAC似乎在所有节点同时失效后无法自动重连，即使重起也不行，必须重起客户端。最后按照数据倒推，认定问题在本地磁盘耗尽上。只是开始为了检测数据库备份，执行了 crosscheck，释放了部分磁盘空间，因此查不出来。
从这次事故恢复来说，最大的问题在于客户那里没有人及时进行系统维护，最终导致了磁盘耗尽。因此说做一个系统简单，然而要长期维护系统，恐怕就没这么简单了。</description>
    </item>
    
    <item>
      <title>avast4 collide with ext2ifs</title>
      <link>http://blog.shell909090.org/blog/archives/27/</link>
      <pubDate>Thu, 31 Jul 2008 01:16:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/27/</guid>
      <description>引用 Affected Product: Avast4 home edition ext2ifs 1.10c ext2ifs 1.11 Description: avast4 home edition is a free anti-virus tools. In 2008-07-30 it update some files, include some file called &amp;lsquo;aswSP.sys&amp;rsquo;. According infomation in autoruns, it&amp;rsquo;s avast self protection module. [Here is info from autoruns.] aswSPavast! self protection module ALWIL Software c:windowssystem32driversaswsp.sys [Here is info from update-log] 2008-7-30 7:36:14 file Direct move of file: C:Program FilesAlwil SoftwareAvast4SetupINFAMD64aswSP.sys 2008-7-30 7:36:14 file Installed file:C:Program FilesAlwil SoftwareAvast4SetupINFAMD64aswSP.</description>
    </item>
    
    <item>
      <title>新种病毒出现</title>
      <link>http://blog.shell909090.org/blog/archives/25/</link>
      <pubDate>Thu, 10 Jul 2008 12:14:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/25/</guid>
      <description>有新种病毒出现，大家当心。
病毒症状如下：
有MSN好友给你传一个网址，如同http://[用户名].imagecroco.info/。(贝壳注：现在已经被Mozilla列为欺诈网址)当浏览后中毒，会继续给好友发送网址。发送网址时用户离线，发消息用户不回复。中毒用户提示已经在另外一个地址上登录。
机理估计如下：
当你访问网站时，会被要求输入用户名或密码。或者被挂上马，等登录时被套出用户名和密码。当你不使用时，服务器会自动使用你的用户名登录，给你的好友发送病毒。如果不修改密码，即使本机清理病毒或者设置名称提醒也未必有用。</description>
    </item>
    
    <item>
      <title>晒一晒我的firefox</title>
      <link>http://blog.shell909090.org/blog/archives/433/</link>
      <pubDate>Wed, 05 Mar 2008 22:43:32 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/433/</guid>
      <description>firefox是很有名的浏览器，以其短小和安全而著称。相信很多朋友喜欢使用firefox，然而你真的会用么？
首先纠正一点，最标准的浏览器虽然不是IE，但是也不是firefox。而是以下三个，Safari(WebKit) / Opera(Presto) / Konqueror(KHTML)。Safari是Mac上的浏览器，Konqueror是Linux上的，Opera则多数用于手机上。Firefox 2.0.0.3 (Gecko 1.8.1.3)稍微差点，Internet Explorer 7.0 (Trident)和Internet Explorer 6.0 (Trident)是最不标准的。具体请看Acid2测试(http://www.osxcn.com/css/the-second-acid-test.html)。当然，也有消息称Firefox和IE已经都通过了测试(http://www.appbeta.com/50226711/ie8afirefoxasafariaoperaecaeacid2ce_133101.php)。
其次，当你用着号称国人精华的XX浏览器的时候。首先请注意一下他是否使用了ie内核。IE有一个非常大的框架，其内核是Trident。所谓的浏览器内核，就是负责将html转换为DOM，然后渲染的组件集。当然，还有一些执行js等等的组件。微软的IE内核一般在mshtml.dll上，如果你有procexp，可以看看所谓的XX浏览器是否用了这个dll。如果用了，没的说，肯定是Trident内核。如果没有么……将mshtml改名转移，直到IE无法正常浏览。然后看看您的XX浏览器怎么样。
Firefox的内核是Gecko，据说将来要使用Cairo。这两种组件……嘿嘿，贝壳都用过。但是firefox最强大的是他的插件组，效果终身难忘，让人不忍舍弃。下面贝壳介绍一下firefox的部分插件，脚本。
/find/，这是个很小巧的插件，可以使得firefox能够以正则表达式在全文进行搜索。普通用户就表想了，这东西可是专业人士的杀手工具。可以做出&amp;rdquo;搜索全文中的所有电话号码&amp;rdquo;或者&amp;rdquo;搜索全文中的所有email&amp;rdquo;等等强大功能。当然，如果你需要的话。
CustomizeGoogle，GFan一定要用。这个插件可以定制Google，例如可以在其他搜索引擎搜索，剔除赞助商广告，修改搜索的语言(贝壳的firefox就老阿达到英文上去，用这个插件就一切OK)。适用于Google的多个产品，包括gmail，google reader等等。
fasterfox，强力推荐，加速插件。不过通常我都是用来调整性能参数的。自定义设置，不启用增强预读，缓存32M。这个配置对于0.5-1G的本本很有用。
firebug，这东西也就网站开发人员用。不过绝对是杀手阿，可以看到网页的css，javascript，在线调试，察看ajax的网络通讯。通过这个东西，很容易调试多数的网页。
fireshot，推荐看小说的的人用。可以将当前的网页整个导出成png(贝壳注：这不就是Cairo的基础功能么？导出到虚拟interface)。想想你看小说，将当前页面打印到png。不用截屏拼接，嘿嘿。当然，更好的方法是用firebug，直接可以提取内容。不过……看你水准了。
flashgot，强力推荐，用这个东西可以将firefox的下载转到flashget上。当然，也支持迅雷，netant和bitcomet。这个东西弥补了firefox不支持专用下载软件的尴尬。当然，也有人喜欢都在firefox里面做。这个就如人饮水拉。
gladder，用于爬GFW看Wikipedia的东西。如果听不懂，我不再解释。
gmark，推荐多个电脑的人用，可以在各个地方用google bookmark，就好像用自己的bookmark一样，方便统一bookmark。如果你不喜欢在线bookmark(我觉得没有必要，用浏览器必定在线，除非google故障离线bookmark才有用)，那么可以用gmark的导出功能，导出到html。然后用firefox的导入，同步两个bookmark。其他插件要么是使用不习惯，要么就是不能和firefox自身的bookmark同步(都是单向的从firefox bookmark导出)。
google reader notifier，推荐用google reader的挂线族。这个插件会提示你有多少东西你没有读，定时刷新。
google笔记本，这个需要到google去下载，和gmark一样是让多个电脑同步的好东西。可以直接弹出一个google note让你记东西，并且在任何地方访问。同时也可以选中网页中的部分内容，点击加笔记，自动添加到笔记本中。
greasemonkey，强力推荐，将用户脚本插入到页面中的组件，可以动态修改页面行为。下面会专门讲用这个组件挂脚本的技巧。
IE tab，强力推荐，有的时候突然需要看IE，但是单独开一个IE非常麻烦。直接点右下的这个图标，当前页面就会自动切换成IE浏览。只是如果处于登陆中，恐怕会退出。
keyconfig，可以自己配置firefox的快捷键。
MinimizeToTray，最小化到托盘区的组件。配合上面一个，对付老板的利器阿。
NoScript，强力推荐，拒绝恶意脚本，增加安全性。当然，弄不好就是拒绝正常脚本，增加麻烦。
Session Manager，强力推荐，可以保存你当前在看的所有列表，下次恢复。也可以同时恢复登陆状态(例如你登陆了网站，下次上线就如同中间没有做任何动作一样，当然如果超时被踢就没办法了)，恢复关闭窗口。对付firefox的重起，减少内存消耗(手动重起)，看一堆页面看到一半有事……等等。非常有效。
Tree Style Tab，另类的tab样式，把tab在左边做成树，可以折叠展开。如果你和我一样，经常喜欢大量的打开页面。此时，上面的tab往往缩的很小，看都看不到，但是还是长的要左右乱翻。这个时候这个插件非常有效。而且可以看到浏览的派生关系。如果平时觉得浪费空间，可以改回去。等需要的时候改过来。
Update Scanner，扫描页面变化，如果有变化提示。对于看小说/泡论坛……等等。不用你们一天老去刷帖子了，这个插件可以提示你页面是否更新。当然不是没有更好的，不过那些东西都要写变化脚本，天哪～～
上述的插件大都能在addons.mozilla.org或者addons.mozine.cn找到，如果不行就去google搜索。注意使用插件会消耗一定内存，尽管上面的大多插件都不怎么消耗内存，可都放上也比较让人受不了。一般贝壳都是将不用的转到禁用的。
下面讲解greasemonkey的用户脚本技巧，多数脚本可以到userscript.org找到。
GoogleTagCloudMaker，最好用的greasemonkey脚本。可以将google搜索的广告移除，变成关键字云。点击关键字云往往能追踪搜索，直到找到需要的东西。
Show Btchina，让你可以浏览bt.btchina.net。这是个bittorrent种子搜集站，但是firefox无法浏览。使用这个脚本使得firefox可以正常浏览。
Download Youtube Video III，在youtube的播放文件下面显示一个download，链接到播放的flv文件。可以很轻松的进行下载。以前贝壳都是用youplayer，老开着占内存，不老开就要重起firefox。虽然有session manager，不过也很讨厌。使用脚本就可以针对页面工作，减少内存消耗。
以上的脚本在安装greasemonkey后可以直接点击安装。</description>
    </item>
    
    <item>
      <title>用firefox看facebook的问题</title>
      <link>http://blog.shell909090.org/blog/archives/432/</link>
      <pubDate>Mon, 03 Mar 2008 14:37:26 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/432/</guid>
      <description>用firefox看facebook的时候老出问题，主要是验证码无法通过。会么？这年头连live spaces都可以用firefox了。(当然图片上传例外，除非你用IE Tab)而且facebook还有firefox的toolbar，要是再无法使用firefox就太奇怪了。
今天总算发现了问题的所在，facebook使用了ajax技术，这种技术会动态的载入和卸载一些页面内容。而我使用了NoScript脚本，并且将facebook加入了白名单。这下可中计了。facebook常规浏览的时候，脚本都来自facebook本身。而当验证的时候，使用的另外一个公司的服务。在验证前，页面的脚本都是不被阻止的，因此我也没有发现异常。在点击验证后，由于页面没有刷，所以我压根没有注意到，下面的阻止从完全通过变成了部分阻止。当然，被阻止的就是另外一家公司的验证脚本。
因此，我将这家公司也加入了NoScript的白名单。OK，世界从此清静了。</description>
    </item>
    
    <item>
      <title>通知时代</title>
      <link>http://blog.shell909090.org/blog/archives/428/</link>
      <pubDate>Thu, 21 Feb 2008 22:54:36 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/428/</guid>
      <description>以下内容可以说是作为一个时代的预告，请大家见证将来是否按照我的预想进行。
首先请大家想想，当大家上网的时候，都做什么？也许是打游戏，也许是看电影，也许是泡论坛，也许是看好友的blog。随着web2.0时代的到来，我们每个人都有发布自己话语的能力。看上去和上世纪末的主页时代类似，然而不同的是，发布的频率增高了。假定你和我一样，有大约20-50个好友在网络上进场写blog。每个人每月写一篇，那么你每天就有1-2篇blog要看。你喜欢的电视剧有10个，它们每周更新一次，那么你每天就有1-2集电视剧要看。依此类推，你所关心的东西在网络上绝对不缺。每天平均下来都要看3-5篇东西，和几个朋友聊聊最新的生活，看几集电视剧，多好的生活。然而，当前却有个不和谐的问题，你需要持续的检查更新！
按照我们上文举出的数据来推算，如果这个人每天需要看这些东西作为日常的网络活动。那么他就需要检查30-100个页面来确定哪些内容更新了，需要跟踪10-20个页面来确定需要下载的东西。在网络小众的时代，也许这不是个问题。我们的习惯是每天上网，然后收一次邮件，检查书签里面所有的页面，看看是否有更新了。下载最新的东西，把写好的信件发出去。以天为单位来说，这不是一个问题。然而正如在线时间的增长催生了IM来替代Mail一样，长时间的在线使得我们希望简单的获得&amp;rdquo;第一时间&amp;rdquo;的东西。邮件到达的时候，我希望&amp;rdquo;第一时间&amp;rdquo;的获得。有新闻的时候，我希望&amp;rdquo;第一时间&amp;rdquo;的关注。朋友写了blog的时候，我希望&amp;rdquo;第一时间&amp;rdquo;的回复。OK，假定5分钟是你可以认可的&amp;rdquo;第一时间&amp;rdquo;。那么你需要每5分钟&amp;rdquo;检查30-100个页面来确定哪些内容更新了，需要跟踪10-20个页面来确定需要下载的东西&amp;rdquo;。
幸运的是，我们可以使用程序来自动做这些事情，并且现在已经有了部分解决方案。有一种邮件跟踪程序，可以跟踪pop3，hotmail，yahoo等常见的邮箱，检查是否有新的邮件。好友的blog和新闻都可以用rss软件来跟踪是否有新的内容。然而不幸的是，每种解决方案都是单独的。如果你需要持续的跟踪，就必须挂上邮箱的检查程序，rss的检查程序，网页的检查程序(用于部分不支持rss的网页)。不但复杂难以管理而且资源消耗也相当惊人。
我预期将来大家都会持续的挂线，因此预计将来的模型是&amp;rdquo;通知&amp;rdquo;而非&amp;rdquo;检查&amp;rdquo;。当你有邮件时，会收到邮件到达通知，当你关注的新闻更新时，会收到新闻更新通知。而具体怎么实现呢？我估计是IM系统整合。当今IM界发展的趋势是互通，IM的特点又是即时，因此有很大可能性会是使用IM来通告新的内容到达。你可以向一些支持的网站注册你的IM，而后他们会视图加你为好友，并且向你提供验证号。当你将验证号回复给网站后，你的网站账户(如果需要的话)就和IM绑定在一起。而后你可以主动订阅一些内容主体的更新通知，当网站程序更新这些内容的时候，会读取到你的订阅。而后将内容更新和你的IM发送到一个队列中，这个队列再将这些消息发送到你的IM中。
当然，IM接受这些消息的显示方式很可能不会用通常的消息界面，更可行的界面是类似google
reader的聚合通告界面。当你完成订阅后，你的IM就会将源放到一个通知树中。每个源是一个列表，代表了这个源的内容。例如邮箱源的列表就是邮箱内的邮件，rss源的列表就是rss的新闻，&amp;rdquo;越狱&amp;rdquo;这种源的列表就是一堆的&amp;rdquo;越狱&amp;rdquo;影片下载地址(当然，如果合法的话)。甚至论坛的某个帖子都可以做源。源代表了内容，并且通告变化，而IM则记录了客户是否看过每个源的具体内容。有可能还会出现一些服务网站，负责每一定时间去检测不支持源的页面，如果满足一定的更新条件，那么就通知页面更新了。
通过这种模式，你每天上线后就可以看到没上线时更新的内容，直接点击过去看。并且在线的时候各种需要的消息还会持续的通告过来。当然，你也应该可以(只要客户端支持)设定某种消息会强制的弹出(例如公司的邮箱里面有新邮件)，而某些只是更改托盘区的图标(例如某些有点关心的新闻更新了，你不会希望这个原因把你从游戏里面拉出来吧)。理论上说，当IM的客户端范畴拓展到手机后，我们甚至可以如同宣传中说的一样&amp;rdquo;随时随地，掌握信息&amp;rdquo;了。</description>
    </item>
    
    <item>
      <title>IM之争</title>
      <link>http://blog.shell909090.org/blog/archives/420/</link>
      <pubDate>Sun, 02 Dec 2007 06:56:53 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/420/</guid>
      <description>我不记得这个Title是否已经写过了，不过无所谓，因为国际形势发生了变化。
以前是ICQ和QQ争霸中国市场。后来MSN加进来一脚，ICQ淡出了。现在Fetion跑进来了。那么未来呢？
我们先看看IM软件的发展方向吧。IM最早的远亲应当是IRC和电子邮件。不过电子邮件对于服务器需求太强大，用于实时对聊做不到。IRC虽然需求小了点，但也在不可承受的范围内。随着网络的发展，大家挂网时间越来越多。所以大家要求一种廉价有效的即时通讯手段。可以和某个人对话，而不用耗费太多的服务器成本。于是，ICQ应运而生了。ICQ可以说是最初的P2P体系者，两个人聊天的时候数据都是互相发送的，只有登录的时候才和服务器通讯。这样的好处是避免了大量的服务器开销，坏处是无法穿透防火墙。
从协议上说，IM的协议互动机制和电子邮件基本是一致的。如果不介意服务器开销的话，我们可以把IM协议构架在POP3和SMTP上。对于这种倾向，有人应该感觉熟悉。那不是MSN的离线消息么？差不多。我们定义发送逻辑为，如果可以找到对方IP就找对方IP，不可以找到对方IP就给对方发送邮件。接受的时候我们就接受邮件，如果碰到特殊格式的就解析掉当做消息处理。同时如果在线则服务器会主动推送邮件消息过来(如果不这样就要非常快的定时查询新消息，非常耗费资源)。那么我们就构成了一个跨越服务商的IM方案了，并且还支持多种客户端和离线消息。例如我们通过智能手机的终端接入进来(记得么？我们的客户端其实只是个特殊点的邮件程序)，那就成了无线IM。
问题是，我们动了谁的奶酪？
服务商恐怕对此会非常不高兴。大家知道，电子邮件服务商的竞争比IM残酷多了。那么多IT公司，有多少是纯粹做电子邮件做发起来的？几乎没有。为什么呢？因为电子邮件的开放性强。开放性强是历史的产物，早在主机时代邮件协议就已经固定了，而且有了大量的实现。如果哪个ISP不遵循，那么就没有用户。但是遵循标准的结果就是谁都可以被谁替代。也许某某邮箱系统的界面好看点，某某邮箱系统的容量大点，某某邮箱的速度快点，某某邮箱的垃圾少点。但是都不是不可以替代的，属于非强用户粘着性的产品。(注意我没有使用弱这个词，因为一般人习惯用一个邮箱后也就不怎么更改了)如果邮箱服务收费，ISP会发现，几乎是立刻就没有用户了——
然而IM则是在端点时代才发展出来的，而且始作俑者不是IETF成员，IETF也没有太关注。——这捅了大篓子。现在的IM产品，几乎一个产品和另外一个无法连接。一旦你大部分的朋友使用了某种IM，你也必须被迫使用某种IM。好比贝壳虽然不喜欢QQ(这厮没Linux版本还老封锁协议)，但一帮朋友都是QQ的，难道不用？这是意味着IM是扩散用户粘着的产品！
这意味着什么呢？ISP们不用推销，只要他们拥有一定的用户了，用户就会自动扩展用户群。而且你的用户不会轻易离开你，即使你收费，也有相当的用户。如果改成开放的形式，很多大型的IM商就等着客户流失吧。因为他们有相当的客户群，因此往往会收取一定的费用或者产生较多的广告。而IETF已经开始制订IM的交互协议了，即SIMPLE协议。先不说这个协议是否先进是否安全，至少这个协议是开放的。开放的协议意味低附加值的服务，因此IM商肯定会抵制协议的推行。一般的逻辑是。如果SIMPLE协议的总客户集群无法和自己的客户群比较，则不和SIMPLE互通。这样有利于维持自己的IM群，进而取得收益。如果SIMPLE协议的总客户集群已经大大超过了自身的客户群，则和SIMPLE互通。因为可以扩大自己的群，进而扩大用户。所以SIMPLE协议应该是从新兴公司开始推广的。
因此，作为一个用户来说，我更希望大家现在开始使用带有SIMPLE特征的服务。这样更有利于促使更多IM商互通服务，而且还会减少服务的费用。
从历史上说，当今的各大IM厂商自有其来。QQ是特殊历史时期的特殊软件。开始的时候其实就是简化的ICQ中文版，除了中国制造外没有什么特长。后来中国的互联网娱乐潮起，QQ向娱乐转型，主攻大众市场，结果红的发紫。MSN则是更晚时期的产物，是MS攻占全球IM市场的拳头产品，主攻的是商务市场。Fetion是中移动今年新推出的IM产品，特点是和手机互通。
就发展趋势来预期，IM主要呈现两个特点，一个是全分布化，一个是嵌入化。
虽然IM软件的工作原理对于服务器要求不高，然而很多后续服务对于服务器却有强烈需求。我们先仅仅计算基础通讯消费吧。一个人登录的时候先认证，后回传所有好友的名单，套接字。一般登录一次开销最小也要在3K上下。一般成熟的IM软件总用户量至少是1000W以上(国内市场)，峰值冗余计算为五倍。计算结果就是一天的通信最少300G，最低带宽需求是20M。这还仅仅是登录造成的通讯成本。我们再考虑持续心跳激活某个特定客户端的重复时间——那这个开销就不是某个服务器所能支持的了。现在的IM服务器端，一般都是服务器组来完成这系列的需求。当然——未来的IM软件，我们的期许绝对不是仅仅1000W用户这个级别了，至少要包含国内的上亿人，加上国际的上亿人。每个IM的有效注册用户规模可能达到数亿这种恐怖规模。加上嵌入化的发展，在线时间也会越来越长。因此服务器的规模也会随之上升，进而造成IM收费时代的到来。
如果要IM持续免费，则我们就必定要发展分布式IM。简单来说，用户登录，持续心跳等等都不以服务器为中心，而以分布网络为中心。服务器只辅之以用户入口和统一的模糊查询的功能。这样会大大减轻服务器的负担，但是也会带来几个问题。
首先是用户的注册，没有用户数据库了。不过不难解决，可以让用户不需要注册。因为没有一个统一的服务器，因此用户注册只需要生成一个UUID，生成一对公私密钥，就算完成了。登录的时候即是告知别人自己的UUID，公钥和套接字即可。需要寻找一个好友的时候，可以使用UUID查询此人的套接字，具体方法请看DHT，Kademila，我上面有写的。
其次是大规模块内容的传输，简单来说其实就是传文件。这些数据如果可以直接传输则没有问题，但是在无根分布系统中，间接数据传输是要过中间机的。这样会造成中间机的网络开销。这个还要看人家乐意不乐意呢。这个没有什么好的解决方法。
最后则是安全问题。这倒不难解决，发送内容用私钥和对方公钥各加密一遍，接受用对方公钥和私钥解密就好了。第一次发送一个统一加密块，后面就用这个块加密，定时更换。兼顾了安全和效率。
IM的另外一个特点就是嵌入化，简单来说就是移植向手机上。中国的移动运营是特殊状态，不过世界的发展大致都是一样的。就是将手机发展为网络终端，然后尽量用软件解决问题。那么中国移动现在的短信优势还能持续多久就是一个非常大的问题了。当然不排除短信优势消灭前飞信拥有了新的特性的可能。</description>
    </item>
    
    <item>
      <title>网络银行安全性的理论分析</title>
      <link>http://blog.shell909090.org/blog/archives/419/</link>
      <pubDate>Wed, 28 Nov 2007 23:55:11 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/419/</guid>
      <description>最近好像用网银的人比较多阿，贝壳就做件好事，简单介绍下密码学体系。让大家了解下网银安全性的方方面面。
我们说，银行系统的安全性和易用性往往是一个磁石的南北极，不大可能出现在一个地方的。从易用性角度来说，输入用户名和取款密码直接操作的网银是最方便的。可惜，你的钱被偷的概率也是最高的。因为你和银行间的通讯过程需要流经无数节点，任何一个地方都可以轻易拿到你的登录密码。那么重复这个过程就可以登录并且操作你的钱。所以，任何一家银行都不会提供直接的登录手段。
一般来说，银行在设计网银的时候，往往会提防以下的攻击手段。社会工程学，嗅探，重复发送，钓鱼，中间人钓鱼，猜解，内部盗窃。我们先来大致了解下这些攻击手段的方法和实施条件，然后再说银行的对应手段。
社会工程学攻击是成功率最高的，技术要求最低的攻击。其要决就是一个字，“骗”！社会工程学攻击主体上就是各种骗术，例如把机器塞上，旁边写一个处理电话。等你打电话的时候，就过来一个“工作人员”。然后弄出你的卡来，说要验明你是否是卡主，问你密码。等确认好了身份，你拿到的就不是自己的卡了，那个工作人员也就拿了钱跑了。诸如此类的攻击核心要点就是骗取客户信任。所以社会工程学的对应手段只有让客户提高警惕，其他没别的好办法。
嗅探指的是从登录的机器上或者附近符合一定条件的机器上(具体是哪些需要一定的专业知识)，窃取登录过程数据，并且从中还原出用户密码的手段。这种攻击往往和重复发送一起使用。无法还原密码的情况下，将原先登录的包重新发送一次。对应嗅探攻击的方法很简单，就是挑战-回应方法(Challenge-Responses)。现代加密算法有专门对应已知明文攻击的，用于对抗已经知道明文和密文情况下反解密码。服务器发送一个随机数过来，客户端加密后发送回去。服务器端核验客户端的加密结果和服务器端的加密结果，就知道客户端是否通过认证了。而嗅探者需要相当数目的明密文对才能知道密码。所以相对安全程度更高。
钓鱼是一种社会工程攻击。一般是通过邮件或者其他手段引导你到某个网站上，看上去和网银很像。等你登录想用的时候，会发现上面说网银现在正在调整。如果当时没有在意，等下次登录的时候帐户里面的钱就没了。由于窃取的是密码本身，所以挑战-回应方法无法解决这个问题。这种情况下就必须使用挑战-回应方法的变形，例如零知识验证。大致上看起来就是这样的，银行给你本很长的书，里面写什么你也不知道。然后银行问你，第512页三行15个字是啥？钓鱼收集到这个知识就没用了。但是中间人攻击还是有效的。中间人和钓鱼看起来很像，只是中间人不是窃取密码，而是窃取会话。当你以为登录到银行的时候，其实是登录到了一个中间服务器。一切你的操作其实是通过中间服务器代理上去的。当你退出的时候，中间服务器就会替换你的操作，实施一次转帐和退出。要屏蔽中间人攻击，就必须使用签名证书系统来认证服务器地址。
猜解和内部盗窃是通过对主人情况的了解来猜测或者偷窃密码/密码设备的攻击。目前没有啥好办法，只有想点自己都想不到的东西作为密码才行。生日，电话，车牌，名字，都不可以直接作为密码。当然，做一些基础变形后作为弱密码还是可以的。例如将生日倒过来作为查询密码。
目前网银的认证系统有以下几种，密码直接验证，文件证书验证，密码卡认证，手机动态认证，硬件设备认证。
密码直接认证一般使用了SSL技术来防止嗅探，但是对于钓鱼，中间人，猜解，内部盗窃都没有防护能力。一般都是各个网银的最差防护状态，为某些对安全不在意的人设计的。只是使用方便而已。
文件证书验证是利用密码和文件数字证书来验证身份的方法，对于钓鱼，中间人有比较好的防护手段。可以防止猜解，但是无法防止内部盗窃。因为文件证书为了方便起见都是存放在电脑内部的，所以文件证书的安全就又成了问题。即使是存放在U盘上，也会在使用的瞬间被复制。电脑中木马，文件或者U盘被盗拷，都是产生不安全的原因。
密码卡是某种零知识验证的变形。差不多就是给你张密码卡，刮一次能上一次。对于钓鱼有一定防护能力，但是对于中间人攻击无能为力。可以防止猜解，但是无法防止内部盗窃。
手机动态认证是通过手机收取临时动态验证码来确认客户的身份。如果要窃取客户的身份，就必须同时得到用户手机卡和用户密码。所以，也是防嗅探，钓鱼，猜解，但是不防中间人和内部盗窃。注意这里有种特殊形式，大家也许不知道，手机发送的短信是可以被特殊设备截获破解的——
硬件设备认证则是将密钥和计算放入了特殊硬件内。银行发送挑战数到硬件上，硬件设备返回数据到银行。如果要窃取身份，就必须获得设备和密码。因此，也是防嗅探，钓鱼，猜解，但是不防中间人和内部盗窃。一般就是指银行的U盾设备，但是要注意区分U盾究竟是用来计算呢，还是用来存放密钥。后者的安全级别和文件证书一致。
我们对比各种攻击之前，先去掉两个特殊选项，社会工程和中间人攻击。社会工程某种意义上是无法防御的，你说你要把东西交给别人，银行怎么防范？拿你的生物特征？那就太麻烦了。中间人则是因为可以用CA证书验证地址有效性，因此现在很少成功。当然，也有先欺骗DNS服务器的。碰上这种蓄意的中间人攻击，差不多就和碰上人强奸一样——反抗是没意义的。这两种方法，只要是有心算无心，基本都可以成功。因此我们先去掉这两个成功么未必成功，防范么没法防范的选项。
SSL技术是网银登录的基础技术，没有的话请记得早日离开这家银行。文件证书使用方便，但是电脑一旦中木马就立刻危险。密码卡看似安全，其实对于精心设计的钓鱼还是没用的。而且使用麻烦，不如趁早不用。手机动态验证的安全性是非常高啦，可是要记得手机的安全就是帐户的安全。所以手机卡千万看住，别被人复制了。(手机卡是可以复制的，然后就可以用这个号码打电话了。当然这种事情发生概率很小，一般倒是用在一卡多号上比较多)还有手机信号问题，找个深山老林上网吧。
硬件设备认证是比较硬的方法，一般是比较完美的。可惜价格太贵。
综合下来，偷懒的可以用手机。怕事的还是用硬件。</description>
    </item>
    
    <item>
      <title>Google Calender</title>
      <link>http://blog.shell909090.org/blog/archives/418/</link>
      <pubDate>Mon, 26 Nov 2007 17:49:12 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/418/</guid>
      <description>Google有很多产品，Google Calender就是其中之一，这个东西主要的目的就是管理日历。
其实从常规角度考虑，这是最不适合bs的产品。日历的要点就是随身，谁会高兴为了看个日历找宽带上网阿。可不能不感慨Google的水平，凭着各种技术的支持，这么一个产品居然还真让我觉得好用。
Google Calender的两个核心思想就是同步和共享，同步用的是iCalender标准，共享也很类似。Google Calender的管理中，允许在多种客户端内同步Google Calender的日程。这样Google Calender就从一个不适合的产品一下变成了多个日程工具的平台标准。贝壳现在是利用他同步多个机器上的多个软件，主要的产品包括Sunbird/Lighting，raincalender，部分的手机日历，相信很多人也会做这个应用。贝壳用的就是其中的Sunbird，这个软件是Mozilla的产品之一。(贝壳现在是Mozilla的忠实用户，FireFox，Thunderbird，Sunbird三件套常备，都做了跨系统共享)不加载Provider for Google Calendar的情况下，可以读取iCalender格式的远程日历。加载插件后会多出一个Google日历的选项，用Google中的个人xml链接，保存入个人的用户名和密码(个人的gmail，带域名)，然后就可以双向同步gcal了。
至于共享，在管理的时候应该可以看到和谁共享。做项目的时候，拉组员进来共享。或者没有gmail的可以用全可见加给html链接的方式。这样就可以给组员看他们的工作状态，别人的工作状态，将来的项目安排。如果组员可信任，可以给予写权限。这样他们会自动更新进度，可谓超级省事。
最后，Google Calender可以被结合入iGoogle里面，成为标准平台的一部分。</description>
    </item>
    
    <item>
      <title>关于程序的一点想法</title>
      <link>http://blog.shell909090.org/blog/archives/416/</link>
      <pubDate>Sat, 13 Oct 2007 07:06:16 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/416/</guid>
      <description>以下内容六牙四皂小姐可以看看，至于看的懂看不懂不负责。
程序届有个说法，只有你想不到的，没有我做不到的。当然，程序是基于数学的。如果违反了数学的基础理论，程序还是无法实现的。可程序又不同于数学。说穿了，程序有一个时间，成本和环境的限制，有的时候还有法律问题。理论上说，任何一个水平足够的人都可以写一个windows出来。但是，首先是一个人写需要多少时间。其次是这些时间，还有其他投资(例如电脑)所造成的成本。然后是这个windows所能运用的环境。当然windows也许没有这个问题，可如果是程序就必须考虑适用系统(Windows,*nix)，字长(32bits,64bits)等等限制。最后，一个和windows一样的系统是否会侵犯了微软的版权？
对于程序员来说，可能这些都不是问题。程序员面对的是明确的目标，环境，解决方法和框架。他们要解决的是按照构思来实现功能，并且按照算法来构建代码。例如一个播放器，对程序员来说可能就是一个确定的接口，向里面写入固定格式的数据。或者引用某种算法读取压缩数据，解压为通用数据进行播放。或者是实现解码器的注册和管理。这些都是已经被严格确定了的目标。程序员有一个固定的环境，一个统一的框架。解决方法或者是被说明的，或者是不言而喻的。
可是由一个抽象的需求来获得一个明确的目标，并且确定环境和实现方法由谁来做呢？一般这些人被称为需求分析师和系统构架师。需求分析师的工作在于帮助用户确定需求，分析需求的可能性产出(例如播放器中是否需要一个屏保屏蔽功能)，分析系统的目标环境。这些任务更多的是出于用户角度考虑的，主要是我需要做什么(what,
why)。系统构架师则是一个对称的职务。其主要职能在于确定如何使用目标环境中的各种技术实现目标需求，使用这些技术完成目标需要多少时间，多少成本，是否引发法律问题。等等等等。这些问题更倾向于从程序员角度考虑，主要是怎么做(how,
when)。
当然可能没有这种职位，但不可能没有这种职能。有的时候分析和构架是由项目经理兼任的，有的时候是由客户驱动的(尤其是外包的时候)。至于完全没有的时候，就只有将需求分解为零散的问题，对问题求工具了。理论上说这是一种很好的方法，强大的bash语言体系其实就是由一堆解决细节问题的工具组成的。问题是，这种情况下，对于工具的使用者就提出了很高要求。往往会把工具的使用者变成另外门语言的使用者。例如我们看电影，一般用户只是点开就看而已。如果是针对问题求解，可能我们会出现一个播放容器，一个编码分析器，一个视频解码管理系统，一个音频解码管理系统。最后还需要一个注册器来关联适当属性的播放容器和某种文件类型。从软件结构角度，这样的软件有利于构架和编写。可从用户的角度，这是最差劲的播放器。事实上，mplayer就属于这种播放器。我们用起来觉得简单是因为一些高手制作了一些预先设定的包，将所有组件关联起来。
我们回到原本的问题上来。如果用户驱动了系统的构架，那问题自然不大。只需要制作方评估系统规模，然后按照规模给出成本和时间。双方讨论一个可以接受的成本和时间，东西就可以做了。至于客户变更了系统，那自然有相关的人员会重新评价，给出新的成本和时间。问题是如果约定不清晰，可能会造成比较大的麻烦。例如客户认为他们给出的解决中必须实现某个东西，而程序这里认为是最好实现某个东西。那就扯不清楚了。因此一般建议编程人员向客户要求一份详细的制式计划书，然后双方签字确认。根据合同法规定，如果制式合同中出现纠纷，应当被解读为不利于提供方的方式。倒过来显然是不行的，既不能指望编程人员提供计划书，也不能指望客户不会对计划书随便解释。
如果是由非客户的分析和构架人员来做系统构架，那么情况就复杂了。问题实质上其实变成了五方会谈。客户方，代表客户方的需求分析师，制作方，代表制作方的系统构架师，还有程序员。看起来有点重复，但是其中都有利害关系的。客户方希望需求分析师提出尽可能多的需求，因为这样才能产生好用的软件。系统构架师则希望需求分析师提出尽可能少的需求，这个才容易制作和维护软件。制作方希望系统构架师提出尽可能高的成本和时间预算。这样有充裕的时间制作，不会制作失败，还可以多赚钱。但是客户方不会喜欢很高的成本和迟到的软件。程序员希望系统构架师给出的解决方案足够清晰，而且改动少。系统分析师总喜欢在程序员的失败中改进方案，因为简单啊。客户方希望程序员给出完整的文档和后期维护，但是程序员都不喜欢写那东西。
所以需求分析师往往会提出一堆怪怪的功能，即使这东西一般人八辈子用不到。系统构架师往往会提出高的吓人的成本和时间预算。和股指差不多吧，没几个有脑子的相信。真正的成本和时间就会在客户和制作的吵架声中被确定，并且往往成本高出正常值，时间低于正常值。程序员就在一次次的咒骂声中修改系统，并且经常忘记跟着修改文档。客户拿到手的往往是一个延期了再延期的系统。它们十有八九跑的起来，刚好可以完成预定目标。只是往往会有一些Bug，并且只有不同步的文档。系统就会在客户的抱怨声中被退回，而且客户还会追加两个需求，加上句“钱不是问题”。制作方看在孔方兄的面子上，往往也会说“保证完成任务”。系统修改的结果往往是Bug越改越多，文档越改越老，系统越改越奇怪。最后系统分析员往往会找到一个下家而跳槽，客户往往会因为钱是问题而拖帐，制作方往往会保证完不成任务，程序员往往会抱怨天天加班，唯一没问题的需求分析师往往是客户亲戚兼任的。
到底是哪里出的问题？</description>
    </item>
    
    <item>
      <title>空之轨迹SC中文版部分攻略</title>
      <link>http://blog.shell909090.org/blog/archives/415/</link>
      <pubDate>Fri, 12 Oct 2007 00:28:18 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/415/</guid>
      <description>贝壳望眼欲穿望穿秋水(好像是一个意思)，总算盼望到了英雄传说SC中文版的发行。Falcom牛阿，卡卡布三部曲那么强的东西在前面，空之轨迹居然还能超越，而且一部比一部好。做到这种境界真的不容易。轩辕剑系列就有点略略的走下坡的样子。
现在讲几个解迷中比较恶心的地方。
头一个是被盗的招牌。先找钟楼背后，然后是卡佩尔里面的对话。然后是三个联在一起的烟囱，最后到地下找菲。
然后是和小女孩捉迷藏，找过所有地点(四个)后可以进入接待室。在台子的底下，别到处乱找了。
下面是玲暗语。头一个是钓师工会的标本，然后是西区的咖啡厅。下面是东区的冰激凌店，最后去空港。
再然后是消失的订婚戒指，在翡翠塔顶部。
下面是被盗的勋章。头一个地点是在导力工厂后面的花盆里面(倒置密码)，第二个是协会三层的书里面(维基尼亚密码)。下一个在机场下面的铲车上，最后去教会上面的书里面。
消失的侄女那章，那位小姐就是市长小姐的女仆，关系很好的那位。看发色应该看的出吧～～
在利贝尔方舟上面领福音的时候，选择名字赛雷斯托.D.奥赛雷斯。就是一堆晶体里面有写的那位，公主的祖先。所以要验证身份的时候只有公主能验证通过，要记得带人过来，比较麻烦。
最后是最终的大BOSS，合体后的白面。这家伙血99999，而且硬的下不去手。正常的攻击魔法都伤不到100点，还有一堆小怪在旁边消除空间。消除了的空间就会永远消失，地板会越来越少。正确的做法是经常看看这家伙的属性(一定要有情报一类的回路啦)。这家伙会轮流跳来跳去，在火土水风不防护，其余免疫上。属性对了一刀就是3000-5000。如果都是100，那用物理攻击。如果缺哪门只有死的份了。
贝壳攻略这个游戏的时间大约是50小时，其中还修改了游戏的很多关键属性(主要是钱和晶石，后期修了一堆神圣挂链和土人偶)。虽然省下不少打游戏的时间，但是还是完成了很多支线任务(有几个不知道状况的被错过了)。解迷真的很费劲阿，尤其是被盗的勋章和一个地宫的怪物。那家伙强力气绝，一个弄不好就是全灭。三五次没过去花了我两个小时，一怒干脆弄出堆神圣挂链当手信了。</description>
    </item>
    
    <item>
      <title>英雄传说6空之轨迹SC修改</title>
      <link>http://blog.shell909090.org/blog/archives/413/</link>
      <pubDate>Wed, 10 Oct 2007 06:01:26 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/413/</guid>
      <description>以下是空之轨迹SC的存档修改方法和部分物品代码表，六牙四皂小姐可以跳过了。
晶片数目：
0x2534C 金钱
0x25354 地
0x25358 水
0x2535C 火
0x25360 风
0x25364 行动
0x25368 EP
0x2536C 时间
个人经验：
0x1F460 艾丝蒂尔经验
0x1F514 奥利维尔经验
0x1F550 科络丝经验
0x1F604 金经验
物品代码：
01c9 最终浓缩药草茶
01c8 大麦奶酪果冻
01c7 苦味兽肉焖
01C6 每日天妇罗
01AE 提神果冻
01C4 营养果汁
019F 清凉药草茶
01B9 内陆佳肴
01BD 卡布其诺薄饼
0195 千层薄饼
01a0 红莲炖兽肉
01a6 春风螺狮面
01ba 阳光冰淇凌
01bb 月光冰淇凌
01A1 不可思议的糊
01AF 激情蛋卷
01be 终极冰淇凌
01b0 海味鲜珍
000f 火绒草杖
0014 蓝璃
001b 麒麟</description>
    </item>
    
    <item>
      <title>散热器的种类，测量和挑选</title>
      <link>http://blog.shell909090.org/blog/archives/403/</link>
      <pubDate>Tue, 28 Aug 2007 05:36:17 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/403/</guid>
      <description>上篇文章中贝壳提到了散热垫。非常不幸的，经过贝壳的实际测量，贝壳所购买的散热垫基本没有任何效果。为了让大家对散热产品有个了解，贝壳就大致介绍一下散热器的分类和作用。还有一些常用术语，常见参数和解释。
首先一类是散热垫，这是最常见的产品。优势在于可以非常快的散去表面温度，手感非常明显。缺点在于不方便携带。主要分为吹风式，抽风式和双向循环三种工作方式。同时可以按照表面材质分为非金属，铁，铝合金三种，按照供电方式分为外接，USB, USB HUB三种。
吹风式的主要特点是从后部或者其他部位吸收空气，向底部吹风。吸风式则相反。双向循环两者都有。一般笔记本如果带风扇，都是从下面吸收空气向外排出(大多数是左上或者后面，因为没有鼠标干涉)。这时候如果采用吸风式，则会产生干涉，导致效果不明显。贝壳的头个散热垫就是这个问题。但是一般吸风式的散热效果比较明显。热量不必经过复杂的通道流转，因此对于表面温度的抑制非常明显。建议如果是带风扇的本本，按照风扇方向选择，没有风扇就用吸风式的。双向循环是最好的一种，可惜比较贵。
表面材质是关于被动散热问题的关键，如果本本底部是平的(没有垫脚垫高)。金属材质的表面会有很明显的散热作用，尤其以铝合金的为最(BTW，其实纯铜的导热最好，可惜价格贵，容易腐蚀，所以没听说谁用)。但是如果底部被垫高了(多数主动风扇散热的本本都要垫高的)，那么效果就大打折扣。建议如果本本是小型式的，平底无风扇的，千万记得选购一个铝合金的吸风散热垫。
外接的供电最充足，功率相对大。可惜需要额外的电源，而且噪音大，因此相对少见。一般只有在特别固定的场所，例如家中，才会固定放置一个。否则带散热垫还带一个电源和插座，谁也受不了的。USB是最常见的形式，需要用本本的一级供电口。一般取用电流都在200mA上下，功率大约1W上下，因此无源hub口是用不上的。但是大家知道，小型本本一般usb只有两个，分一个出来专门供电怎么行？因此好的散热器是usb hub的，正如上篇文章所说，取电的同时还能输出至少两个usb接口(严格是四个，不过限于功率问题，大家应该知道是无法同时接上的)。
再下来就是主动抽取式的外挂风扇。现在我只看到EVERCOOL有一款。也是唯一用下来对我有价值的一款。上文说了，散热垫的主要作用是整体散热。对于主板过热和硬盘过热都有很好的抑制作用。不过什么时候这两者过热呢？一般空气温度都要超过30度了，这两者才会过热，多数环境下是比较少见的。而CPU的温度则不是特别受散热垫的影响。一般CPU的散热过程都是从CPU上直接接一个热管到散热器上，将CPU的热能通过热管传输。如果热量很大，热管传输不足的话，就会造成结构性的热能堆积。这是散热设备无能为力的。而有的时候是热管传输出去的热能堆积在散热器上，导致热管效率下降(热管的工作效率取决于两端温度差，这根本是牛顿散热定律)。这时候可以给散热器强制排风增强散热，这就需要主动抽取式风扇了。按照以上所述，主动抽取风扇最擅长的是给CPU降温。缺点是价格高，使用范围有限，对主板和硬盘无效。顺便说一下，贝壳的主动风扇使用后，温度下降5度，是唯一能看出明显差距的散热器。
下面就是非本本的散热器了，首先是我们最熟悉的CPU风扇，主要用途就是给CPU散热。大家别小看这风扇，弄个不好上百的CPU就会毁在一个几块的风扇上。CPU风扇和散热器合起来叫做CPU散热设备，按照散热器材质分为铝合金，纯铜两种，按照散热器造型分为方阵和鳍片两种。鳍片就是大家在显卡上经常看到的从中心向外辐射的散热片，一般Intel的原状散热器这样居多。
CPU有几个参数，首先是最重要的，转数。越快越好。这决定了CPU本质的散热能力。其次，口径。这东西是匹配CPU的，小口不用大风扇，大口不用小风扇，不用贝壳废话。然后是CFM，这是排风量，可以根据口径，叶片角度，转速来计算。最后也是最重要的，轴承。决定了风扇的寿命和噪音。转速的一般性指标是1000－10000转，视具体产品而定。一般的机箱散热器都是1000多转的大口径风扇，排风量大，散热也很快。只是风无法聚集吹送，用来给CPU散热就废物了。CPU风扇最小是3000转起，高的有7000多转的。CFM小的只有10上下，大的有60多的，一般都在30上下。一般风扇都是滚珠轴承的，高档的才用液压轴承。
除了风冷外还有一类，水冷介质。如果您不是超级超频DIYer，这节对您没用。如果是，您还来看我的文？所以跳过。同理，液氮冷也跳过。我们说说半导体冷却。
半导体是贝壳觉得最有实用价值的一类冷却设备。不便宜，可效果好。一块CPU同等大小的半导体制冷片所最需要关心的问题是凝露而不是过热。就是说，CPU同大小的制冷片足够把热量降到0度以下。唯一遗憾的是所需的功率也很惊人，大约在30-300W，足足半台电脑的功率。贝壳在考虑是否将来的本本会加很小一块在热管和散热器之间，然后将热管扩展到整个本本(其实不用这么夸张，大多数的纯铜散热片，中间热管穿以下就够了)。热管的工作足够将整个本本的所有热量导入到高热的散热器上，然后排出。只是这功率的问题——
另外说以下贝壳积累下的经验数据，经验而已，大家指正。下面的室温都是25度上下。
硬盘，Hitachi的。经常性非工作温度为38度上下，全力工作温度为44度上下。根据贝壳经验，建议温度不要超过45度(台式硬盘在这个温度挺了几年没事)。按照这个计算，机器大规模使用硬盘的环境最高温度为25度。
CPU，AMD Turion64 MK-36。经常性非工作温度为45度上下，全力工作温度为65度上下。根据贝壳读到的数据，建议不要超过70度。加装散热器后温度低了5度。按照这个计算，机器大规模使用CPU的环境最高温度为35度以下。
手感温度，按照室温25度衡量，无热感为20-30度，30度以上有热感，40度以上温暖，50度以上开始烫手，60度差不多就无法留手了。</description>
    </item>
    
    <item>
      <title>散热器和扩展坞</title>
      <link>http://blog.shell909090.org/blog/archives/401/</link>
      <pubDate>Tue, 07 Aug 2007 01:04:09 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/401/</guid>
      <description>贝壳的本本烧了一次，大家都知道吧？痛定思痛，贝壳认为，这是给热的——
于是贝壳上网查了下本本的散热状况。不查不知道，一查吓一跳。贝壳本本的出口温度体感大约是40度，内部温度至少是50度。长期这样工作，难怪会烧。最简单的解决方案是垫高本本底部。垫高一厘米后，下层手感倒是没了，但是出口温度基本没有变化。看来需要更强劲的解决方案。
贝壳去中关村淘了一个本本用的散热器，带一个usb hub，85块，便宜的也有70多的。垫在本本下面非常稳当，电源使用usb端口取电，不用变压器，直接用线接在本本上就好。usb的标准电压是5V，初级端口的最高电流是500mA，小型设备的最高电流是100mA，因此一个无源hub可以扩展4个小型设备。这个散热器的功率是0.9W，电流消耗小于180mA，加上一定的hub芯片和中途损耗，还可以在hub端口上连接两个小功率设备。悬点能连接三个，不过总电流就达到了纯480mA以上，稳定性就要掂量着点了。反正加一个鼠标一个U盘还是没啥问题的。三个风扇全开后，出口温度在平时没有升温的感觉，大约是20-30度上下，全功率工作的时候才有温感，大约是30-40度。内部温度不会超过40度。硬盘温度降低到不明显，因为风扇没有正对硬盘，而是对上了硬盘的进风口。硬盘又没有辅助散热片，所以温度自然无法明显降低，大约目前是40度上下吧。
由这个散热产品，贝壳想到了本本的两重化问题。一个是要求小型化便携化，要求可以发挥本本的长处，到处带了跑。一个是要求全面化，要求能够替代台式机，能够个自行更改升级。这是两个违背的要求，一个要求设备少设计紧密，一个要求设备多设计松散。就拿光驱来说吧，带了个光驱到处跑，怎么做到小型化？但是不带光驱，怎么和主机比？打个游戏放个电影都是问题。
解决这个问题的曙光是扩展坞，很多超小型化设计的本本，为了追求超小超薄，经常就牺牲了很多周边设备，包括最关键的usb端口数目。一般小型本本上都只有两个，一个插一个鼠标，这必定要用的吧。另外一个呢？移动硬盘？摄像头？打架了吧？所以很多商家就增加了扩展坞，最常见的主要是IBM的ThinkPad系列扩展坞。但是一般一个扩展坞只能用于某个特定产品，原因是需要专用接口。
我们可以想象一个产品，其接口基于usb/1394系列，作为本本的通用扩展坞。区分出用于13-17寸的几个尺码的型号，附加上不同的配置，就形成了不同的扩展坞。通过usb连接本本，并且提供一些usb接口。无源的时候可以解决基本的散热问题和usb数量不足的问题，有源的时候可以驱动内部的DVD光驱等等，形成完整的工作平台。
我们再具体细化一下产品，假定本本上只有两个usb输出，一个无线网卡，没有PCMCIA扩展，没有光驱，散热一般。那本本应该可以做到很小的地步吧？缺少的东西可以通过扩展坞增加，无源的时候就当一个hub和散热器，也许还可以启动一个有线网卡，一个读卡器，光驱肯定没戏了。加电源的话，为了求简单可以使用本本电源，然后再输出到本本中(等于串联上去)。这样可以附加驱动一个光驱，一对串行/并行接口，一个猫，一个有线网卡，一个读卡器。等等等等，还可以再输出部分的usb接口。电力上由于截取了本本的主电源，因此基本等于无限。数据带宽上说，光驱的典型平均带宽大约在10M/s上下。摄像头的典型带宽消耗大约是5M/s上下，网卡的极限带宽是12.5M/s。鼠标的带宽可以忽略不计，串行并行带宽也不高。一个usb2.0高速的极限速率大约是60M/s，一般最高只能发挥出一半。但是即使如此，全加在一起也照跑不误。问题比较大的就是移动硬盘一类的设备，硬盘的内部典型速率是50M上下，突发速率可以高达100M/s以上(而且以上很多)，如果接入在扩展坞上铁定是占满全部带宽。幸好一般移动硬盘也需要比较大的供电，干脆直接接入本本好了。只是本本的两个USB接口必须使用分离的控制芯片连接到南桥上，否则还是会出现带宽耗尽的现象。
通用扩展坞的缺点是电源限制，虽然可以截取主电源，但是所有设备加起来数十W的功率。如果外电断电就彻底完蛋了，等于突然拔设备。不过这问题单纯主机也有，而且更糟糕，直接关机。但是其优点就非常明显了。首先是分离了常用/非常用设备，从而使得本本轻巧容易携带，放下来又功能强大。其次是设备外置分散开来，散热问题就比较容易解决。(那东西自己主体就是一个散热设备，解决不掉撞豆腐去算了)然而最大的意义却在于，由于分离了周边设备和核心设备，并通过usb通用连接接通。使得本本的外设成为常规设备，具备充分的扩展性和互换性。因此可以充分降低外设的成本，不会出现sony的本本非配sony光驱的问题。也容易进一步挤压本本外设市场的利润空间，从而降低本本的平均价格。
估计这个过程应该从通用(第三方)扩展坞的流行和可定制化开始。在这个过程中，所有精简外设本本的销量会上升，而外设强大的本本销量会下降，从而促使市场完成转变。估计各大本本厂商不大会喜欢这种变化，因此不知道他们会如何对应这个产品。但是可以预期将来这种产品应该会大行其道。</description>
    </item>
    
    <item>
      <title>笔记本电脑维修问题</title>
      <link>http://blog.shell909090.org/blog/archives/400/</link>
      <pubDate>Wed, 01 Aug 2007 23:46:36 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/400/</guid>
      <description>最近贝壳碰到一个非常恶心的问题。
大家都知道吧，贝壳的电脑是托Nicole同学从LA带来的，中间过程煞费周折。不过到手之后用起来还不错，感觉物有所值。
但是，最近贝壳碰到一个非常悲惨的事实――电脑烧了――
7月16号晚上，贝壳生日刚刚过一天，晚上贝壳正在看电影――
突然，屏幕上的人呆住了，维持在一个傻傻的样子――
贝壳开始没有在意，刚刚升级过系统，可能是不稳定吧。因此贝壳重启了电脑，然后再次进入系统，可是出现执行异常！
贝壳觉得不大妙了――于是重启进入2.6.18内核，这个比2.6.21稳定很多，贝壳用了很久――照旧执行异常！
再进入windows――根本不行――
再重启――黑了――
从此后，贝壳开机最好的情况就是进入系统选择单――然后不是死机就是花屏。一般情况下根本没有自检――一律黑――
贝壳基本肯定是CPU或者内存问题，于是第二天打给了宏基维护人员。得到答复是，全球联保必须带护照！
这不是和没有一样的条约么？贝壳哪里来的护照？加上贝壳公司着急需要其中的程序，贝壳就按照维护人员的推荐――拆机器了。
幸好，硬盘是好的。挂在一个公司电脑上照样跑。
这时候就要感慨下Linux的彪悍了。windows开始是鼠标键盘不能用，因为只有USB的。后面是网卡不能用。Linux就修改了几处配置，一路畅通无阻。
贝壳这个时候后悔自己的轻率了，虽然贝壳买电脑是没有护照的，不过老妈应该能弄到一个旅美的护照。可是硬盘已经拆下来了――怎么办呢？
算了――明天先让老妈送修看看――如果便宜的就不搞事了。否则让老妈吵吵看，两个月就故障也太过分了。
7月18日，老妈拿去送修了，说是先到蓝岛的一家代理，因为近。
过不了两个小时，老妈超级气愤的打电话回来，说那里要这要那的，一点诚意都没有。然后准备去中关村的总部碰碰运气。贝壳心想，这次可能要上备用方案了。
不过还是没有用上，中关村那边爽快的收下了，压根没有提证件，也没有说拆下笔记本硬盘的问题。就说检查是否是人为故障，如果是还需要付钱。电池先拆下自行带回，省得说他们换电池说不清楚。老妈乘机投诉蓝岛那里的代理，被告知原来其实也很繁琐的，不过最近简化了。蓝岛那里是代理，因此很多事情不敢作主，所以啥都要。
过了两天，贝壳打电话过去问，据说是主板坏了。和贝壳预期的一样，反正就在主板内存CPU之一了。问多少时间修好，回答说不好说了。因为是国外发行产品，需要从国外调货，如果没有货还需要付费升级。贝壳不由腹诽宏基总部的白痴，这电脑型号也不是太老，怎么会没有全球备货呢？不过腹诽归腹诽，事情还是要处理的。贝壳着急要硬盘中的数据，所以问是否可以先把硬盘要回来。对方态度很好的，说你提前打电话通知预约就可以拿。
7月25的上午，贝壳的老妈又跑了一次中关村那里的总部，顺利的将硬盘先取了回来。没鱼虾也好，至少可以顺利的升级系统和收发邮件，工作不至于耽搁。不过贝壳要求北京总部这里在修好后写明修理内容和时间，需要的话回头找宏基总部算帐去。
7月26日的上午，总算通知修理好了，虽然很高兴，不过心里却有点被耍的不爽。昨天我才刚刚去拿硬盘，今天就修好？算了算了，至少比再过两天好。最后的单子上写的是CPU损坏，不知道怎么回事情。
总体来说，北京这里的服务还是非常不错的，办事人员都很通情达理。不过最好不要去蓝岛的代理那里，太麻烦了，而且还可能有服务质量问题。总部的管理很难说是否有瑕疵，不过修理时间的公示是两天，实际却已经一周以上了。虽然事出有因，但是网上压根不用写那种疯狂的公示。送修最短一天，最多两周，都尚在可以接受的范围内的。</description>
    </item>
    
    <item>
      <title>论P2P构架的变革</title>
      <link>http://blog.shell909090.org/blog/archives/393/</link>
      <pubDate>Fri, 15 Jun 2007 01:56:38 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/393/</guid>
      <description>目前P2P正在蓬勃发展，不过其中也有很多问题。本文试图列举目前P2P所碰到的最大几个问题，并分析成因和解决方法，最后提出一种P2P传输方式。
P2P传输目前所碰到的几大问题有，传输数据不可控，及其衍生出的版权控制问题，广告控制问题，病毒控制问题。传输速度和传输持续性的冲突。“吸血”、“限速”和“卡种”。搜索的敏感性和代价。传输过程的保密和安全性。
首先讨论最大的一类问题，传输数据不可控，又称为无障碍特性。所谓传输数据不可控，是指所有通过P2P共享传输的数据都无法被某个人标记和阻止。Http的网页内容很容易被封锁掉，而ED/BT的数据可就封不住了。基于这个特点，很多人都用P2P来下载XXX内容。不过相对来说有利有弊，这同样造成了病毒，色情，暴力的泛滥。而且衍生了另外一个相当巨大的问题，版权问题。
上文可知，单个个体是无法对P2P内容的传输构成干扰的，此处的个体不单单指个人，还包括了企业实体等等。相对的全体则是指所有个体的集合。其实从某种意义上说，上面一句根本就是说，P2P传输内容不受干扰。那么我们可以想见，如果是一般传媒，个人利益受到侵害的时候个人是无力的，企业利益收到侵害的时候企业是财大气粗的。但是P2P这里，企业和个人一样无力了。因此P2P就成了很多企业的眼中钉肉中刺，而保护版权，就是他们最好的理由。其实从某种意义上来说，传统媒体就没有版权的问题吗？P2P传播方式就一定带来版权问题吗？
而更进一步来说，我们面对着自由传播和反自由传播的斗争。前者认为人类的知识财富应当为人类所共有，前人的知识应当能让后人学习。而后者则认为人类的知识应当保密，以便能带给创造知识的人利益。前者为黑客时代的精神核心，目前的开源软件基金即继承了此种思想。其中哪种更好确实难说，没有学习就没有进步，可是没有利益谁去学习呢？
OK，言归正传，当前我们面对着版权保护上的困难。从根本上说，我们应当考虑的是如何才能在新情况下重新分配利益，而不是如何阻拦技术的进步以保护旧有的利益格局。尽力争取将其价值内在体现而不是外在化，更直接的说就是尽力使得公开技术本身就能获得收益，而不是拿去卖钱。例如将内容公开，而且从感兴趣的人中收集潜在客户，或者是在内容中引导宣传等等。此时P2P的无障碍特性不但不是缺陷，反而是优势。
而后，P2P的传输速度和传输持续性的矛盾。其实严格来说这并不是矛盾，P2P越热，传输速度就越快。但是一个东西的热度总是有限的，因此就P2P应当牺牲持续提供下载的能力来保持传输速度，还是牺牲传输速度来保证持续下载的能力。P2P分成了两类，ED阵营和BT阵营。本质上说没有什么问题，要保证又有持续下载性又有速度是很困难的。因此这个问题是一个内在的矛盾。
再而后，“吸血”、“限速”和“卡种”的问题，这也是P2P最为内在和难以解决的一个问题。所谓吸血，是ED术语。指仅仅从别人那里下载，而不为别人提供上传的人。在BT中就是减小上传，下了就跑。限速是P2P术语，指限制上传和下载速度。卡种则是BT术语。指当上传到99.9%的时候停止发布，使得大量的人维持在99.9%无法完成下载的方法。实践证明短期的卡种可以“强迫”下了就跑的人持续“做种”上传，使得整体速度提升。但是时间长一点就会打击某些下载积极分子的积极性，导致跑种，浪费带宽。在ED中，使用收益上传者来解决此类问题。
本质上，这个问题是源于P2P的核心思想的。P2P认为，我为人人，人人为我。但是有人的带宽要收费，有人懒得为别人做贡献，怎么办？于是吸血骡等等软件和方法就应运而生。下载的时候凶猛，上传的时候不给。于是整体的速度就被吸血骡拖慢了，所有人的下载也越来越困难。为了对应吸血骡和下了就跑的人，人们开发了收益上传者系统和卡种方法，不过都是治标不治本。技术无论如何进步，都解决不了人自身的贪婪。
至于限速，则是一个两说的话题，有人认为限速拖慢了整体网速，有人认为限速无妨。其实应当这么说，如果一个人限速的时候同时限制了上传和下载速度，那么无所谓。如果上传限速一点点，下载限速非常高，或者根本不限速。那么只能说RPWT了。
搜索的敏感性和代价，这个问题不是一个完整的P2P上的问题。可以说，这个问题牵涉了互联网的本质，即信息的收集和获得。作为P2P来说，在信息的敏感性和代价上具有特殊的特点。
最简单情况下，数据被集中到核心服务器上，搜索者驱动核心服务器来做搜索。当数据量增大后，核心服务器就无法支撑了。于是这时候出现了集群服务器，即以一组服务器替代一个服务器。按照读写发生的频率，又可以分为多对等服务器和多分离服务器两大类型。多对等服务器将每个服务器视为具备相同的数据，查询操作可以在和单服务器同等的时间内完成，但是更新和修改操作就必须花费原来时间的N倍，同时数据存储成本是单服务器的N倍。而多分离服务器则认为每个服务器负担一部分数据，更新和修改操作的时间比单服务器略长，模糊查询操作则需要付出原先N倍的代价，数据存储成本则和单服务器一致。前者可以看做是RAID0的变形，后者则是RAID1的变形。当前主流产品都具有多负载冗余的能力，基本就是RAID5的变形。
在更复杂的情况下，例如互联网的数据索引，当前的服务器根本无法支撑。于是就产生一个基础想法，分布式数据库。分布式数据库又可以称为网格数据库。和分布式数据库本质的区别在于，无协调状况下可以自适应的分布数据，并且完成数据的冗余工作。简单来说，理想状态下一个机器加入或者离开网格的影响只体现在性能上。
听上去很好，不过实际还有很多问题。例如ED中使用的Kadimila协议就是一种分布数据库系统，具体请看前面的一篇文章。Kadimila的最大弱点在于无法模糊搜索。通俗的说，一般搜索引擎，“国家体制”搜索的出的东西，“国家”的搜索结果中一定也有。虽然不一定靠前，能让你一次看到。然而，Kadimila协议中，“国家体制”搜索的出的东西，“国家”基本就出不来了。这是因为需要通过关键字来计算HashNum，然后查找索引了数据的计算机。关键字变了，索引也变了，因此结果就不一样了。
这是一个关键而难解决的问题，问题的关键则在于“必须根据关键字做出索引”上。如果没有关键字索引和根据索引查找机器，那么查询就会在所有机器上实行。从而带来非常大的开销。而通过关键字索引的话，目前没有一种算法能够获得一个上下文所有的关键字。因此我们只能将内容和可能最大的几个关键字关联，最终导致搜索不全。
最后就是传输过程的保密性和安全性，这是一个密码学上的双重意义的概念。保密就是传输的内容不会为第三者所知道，安全性则是传输的内容不会为第三者篡改。当然，在这里还要加入一个不会为第三者阻拦。
P2P的客户端大部分数据都来自其他客户端，由此，其他客户端可以巧妙的构
造传输内容，使得客户</description>
    </item>
    
    <item>
      <title>买机器的问题</title>
      <link>http://blog.shell909090.org/blog/archives/373/</link>
      <pubDate>Tue, 17 Apr 2007 17:18:58 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/373/</guid>
      <description>前几天碰到一个朋友买机器，结果买的不怎么满意。3800+的机器，双核的愣没开双通，预计配置7900的显卡配了7600，EPoX的主板换了精英的。虽然价钱上确实就是这个价钱，但是总体讲性价比就不高了。到我们的一个邻居那里配的机器，看来熟人也不能全信任啊。尤其这个熟人没有权又不懂电脑的时候。
不过想起周岚的电脑恐怕性价比更差，周岚同学兴冲冲喊要买电脑，逼着老爸平了股票去拿钱。结果拿出钱来打我电话，发现我刚刚好去了烟台。等我烟台回来，没错，电脑便宜了300多。不过股票从3块涨到5块，到今天已经是8块了。虽然话不能这么说，不过如果这么计算。这台电脑可理论上价值22000多。算我配的电脑里面最贵的一个。</description>
    </item>
    
    <item>
      <title>惊魂记</title>
      <link>http://blog.shell909090.org/blog/archives/355/</link>
      <pubDate>Mon, 29 Jan 2007 19:07:01 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/355/</guid>
      <description>大家知道贝壳的财务是通过自己写的程序进行跟踪合计的。以前是excel表单上面加VBA宏，后来移动到了Mysql数据库。因为数据存储量大，运行稳定，使用方便，所以贝壳一直很得意。
昨天贝壳发现自己的财务怎么也算不对，因为单位的工资发到了浦发的卡上，而程序里面是没有浦发的账户的。本质上是由于程序中使用硬编码导致程序对数据库存在非合理依赖(有点专业，听不懂就算了)。所以从理论上说，我需要修改表结构。
于是贝壳就先备份了表结构(悲惨啊，大家后来就知道了)，然后修改了账户的表结构。然后贝壳发现财务表里面没有使用UNIQ限定，于是又对财务表修改了结构。但是无法通过，原因是因为现有数据中有的不符合UNIQ限定。于是贝壳又合并数据，做了半个小时多的操作，好算添加了UNIQ限定。这时候，贝壳送了口气。处于不可告人的怪癖，贝壳运行了自己写的核算程序，上面赫然写着，当前现金，-1034。
不用说，一定是合并数据的时候出现了错误，问题是错误在哪里呢？不知道，贝壳只有删除了UNIQ限定，然后恢复数据——shit，没备份。
开始的时候，贝壳只需要修改表结构，于是就只备份了表结构，数据还是上个月的备份。OMG，怎么办？怎么办？怎么办？
于是贝壳就开始了悲惨的修复经历。
首先我确定合并的数据都是在上个月备份以内的。就是说，这个月新添加的数据都是没有经过合并操作的。于是贝壳导出当前错误的数据，并且从中截取出这个月新的数据，这部分数据一定是正确的。然后和上个月的备份合并到一起，放到新的文件里面导入数据库。运行财务核算程序，OK，当前现金380.89。
贝壳又一次低估了上帝的决心，高高兴兴的删除了临时文件。然后导出新数据，准备关闭程序睡觉去。然而运气的是，贝壳在关闭前看了眼数据。啥？注释是乱码？
财务软件并不使用注释字段，那个是被贝壳用的，所以财务软件不会报错。可是注释乱糟糟，等于一半的功能被砍掉了。贝壳赶快想怎么解决。当前数据和备份都是错误的，上个月的备份还在，可是少一个月数据。就是说贝壳丢失了一个月的数据！
没办法，贝壳紧急安装修复软件。但是超级RP的是，贝壳上次Uninstall了一个东东还没reset(这是贝壳的一个坏习惯，Uninstall了以后不reset，等系统自然需要reset)。FinalData的Installer在Uninstall事件没有完成前不能运行。我靠～～～贝壳顿时怒了——上网找了半天，找到一个免安装绿色修复软件，Recover4all。运行，找到了上次导出的数据。
吃一堑长一智，贝壳先完美的备份了这个文件(包括扔到了U盘上一份)。然后将这个和上月的备份重新合并，切换编码，重新导入——蓝了——
靠——上帝的决心是无止境的——比客户的变态还无止境——当导入超长的时候，居然诱发了XP64的溢出。由用户输入诱发溢出，我还真是伟大。
贝壳重启，重新合并，然后切分成两次，切换编码，分次导入。总算数据正常了。然后运行财务核算程序，也正常。去手工看表，也正常。不过贝壳的几个新修改和半小时的合并工作就作废了。
忙碌两个小时快，总算让数据库恢复到了以前的状态。还真是——
不说啥了——</description>
    </item>
    
    <item>
      <title>TTS杂论</title>
      <link>http://blog.shell909090.org/blog/archives/352/</link>
      <pubDate>Thu, 25 Jan 2007 06:19:51 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/352/</guid>
      <description>近两天按照公司要求，试用了下TTS。现在能看到的TTS主要有4个，MS TTS,IBM TTS, FreeTTS, Festival.多少都有点问题啦。 Festival只支持英语，西班牙语，威尔士语。FreeTTS居然是Java程序(不过想想也是，要是Java没款TTS产品才奇怪了呢)。MS TTS倒是简单好用，可惜效果太差。微软研究院放出的线上版本又不知道怎么购买。IBM TTS很贵，而且还只有服务器版本。所以这里就挑用过的说(其实就是MS TTS)。 MS TTS很简单，安装，然后核心组件就会在系统内注册到COM组件。然后按照COM组件来调用就是了。使用哪种发音库可以在控制面板里面修改，也可以用发音语法标记来定制。可以解析多种情况，例如标准化存储，文件，字符串。可以输出到特定设备，例如WAV文件。基本就这样。</description>
    </item>
    
    <item>
      <title>用户和软件制造商的博弈</title>
      <link>http://blog.shell909090.org/blog/archives/345/</link>
      <pubDate>Thu, 11 Jan 2007 20:40:18 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/345/</guid>
      <description>作为用户来说，软件越便宜越好。制造商来说，越贵越好。
软件的价格和很多因素相关，生产基础成本，市场竞争，应用市场，技术含量。不过我们今天分析三种因素，服务，技术和市场。
软件的价格中，有很大一部分是用于服务的。大致上包括客户服务费用，安全保证费用(例如出现产品造成客户损失等等)，软件升级和维护费用。免费软件和收费软件在这方面区别最大，收费软件自然可以做好(应该说是必须做好)服务，免费软件也可以做好服务。但是免费软件既然是免费的，让我免费写了大家用我不介意，反正没人用也是浪费，有人用还可扬名。但是还要提供服务，恐怕没人乐意了。所以免费软件的服务基本都是空白，或者是收费的(例如apache的文档)。这个因素基本和我们今天讨论的主题不相关，只是讨厌于某些厂商的服务质量有感而发。
市场的领域和含义非常复杂，大致上领域包括了某个产品理论可以用于的领域和当前用于的领域。理论上说记事本可以用于超大的程序开发，实际上你看到有人在用记事本写代码吗？含义的话，市场不仅仅是一个可用的范围，还应当包括所有用户和所有竞争对手，以及所有人的互相关系和当前状态。其实这已经是非常简化的状况了，软件的市场远远没有传统行业来的大，但是复杂程度却尤有甚之。美国的一个农民可能出售牛肉到日本，中国的一个农民也可能出售牛肉到日本。但是这两个农民互相间不认识，他们不构成直接的竞争动力。他们的代理出售者可能竞价，但是他们本人基本不可能调整自己的产品(当然，我也想像不出来牛肉可以怎么调整——除去中国某些恶心商人的手段外)。然而美国的一个公司卖软件到日本，中国公司也卖，他们一定认识，而且会根据对手行为和当前处境，以及客户状态来调整他们的产品。
最后一个是竞争的关键，技术。这里讨论的是广义上的技术，即抛却含量，纯粹从跑马圈地的角度来讲。如果讲技术的发展性，那最好大家公开所有技术内幕，不过看来不可能的。
技术的意义在于做别人不能做的事情。windows的进程管理器不能显示用户加载模块，sysinternals的就可以。这就是技术。有技术就有仿制。为了保持技术，一般有两种方法。一种是持续研发，成本高，但是优势十足。还有就是专利，恶心人的无奈东西。
如果说技术只是单纯能或者不能的问题，结合到市场上就有复杂的变化。最重要的一种就是利用技术特性来占领市场。如果某个产品是开放的，例如开放标准，出售代码。就可能出现很多不准确的免费仿制品。这些仿制品的大量应用奠定了这个产品的基础，使得产品具备非常大的市场和价值。然而市场，准确的说是用户，是具备产品粘着度的。也就是说，如果喜欢一个产品，就会一直使用这个产品。如果一个产品不具备粘着度，那就完全的没有价值了。因为他的用户随时都会转变为别人的。培育市场，就是培育大量的用户，并且使得他们具备高的粘着度。技术上说，存在这么一种情况，专利A，开放标准，出售研发代码(SDK)。专利B，封闭标准，出售研发代码，但是兼容专利A。那么专利B的产品会给客户一种导向，就是B比A更好。如果价格一样的话，我们不难想像客户的选择。这样的话A不仅仅是流失客户的问题，而且在后续产品上，用户会有惊人的粘着度。一直都是B专利兼容A专利，一直被压了打。
理论上这样会导致大家不愿意在核心格式上开放标准，然而标准的开放会带来非常广阔的兼容性好处。例如著名的开放标准XML，从技术角度讲几乎就没有什么难以理解的高级技术。然而这个标准本身却是伟大的发明。所以比较流行的方式应当是授权标准，标准是免费的，但是是授权的。如果在此上面衍生变化必须得到标准化委员会的认可，然而其中还是有很大问题的。例如微软就变更了java的标准，并且在事实上(虽然从来不承认)变更了html的标准。IE可以浏览标准的html，但是标准的html浏览器却不能浏览IE的格式。由此可以看出各个生产厂商在专利上的竞争方式。
作为厂商来讲，最好的运作模式是没实力兼容标准，这样用户觉得你功能强大。有实力就修改标准，这样可以养成用户粘着度。然而在用户看来，最好选择仅仅使用最开放最便宜的标准的软件。虽然这样会在使用中造成不便。然而却杜绝了大厂商篡改标准圈地的可能，在用户和软件公司博弈的时候获得更大的优势。</description>
    </item>
    
    <item>
      <title>code2dia和cpp2dia</title>
      <link>http://blog.shell909090.org/blog/archives/344/</link>
      <pubDate>Wed, 10 Jan 2007 18:35:00 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/344/</guid>
      <description>前两天找自动化工具，发现两个工具，叫dia2code和cpp2dia。两个都已经玩过了，还不错。这两个工具是基于UML的建模工具，和IBM Retional有异曲同工之妙，只是没有那么完整好用而已。
dia是一种矢量图编辑工具，其中包含了UML模块。不过只有UML图的建模工具是不完整的，dia2code可以将UML转换成多种语言的定义文件，其中包括了C++和java(我也就要这两种就够了)。画出关系图后，一条指令就可以自动生成代码框架，套用indent格式一把就可以拿来写了(java的话自然是eclipse)。美中不足的是，如果生成代码框架可以自动扩充就好了。例如当前我已经在某个框架上写了代码，然后发现要添加一个函数。难道还要重生成一遍，然后再Ctrl+C,Ctrl+V吗？回头估计要写一个程序来解决这个问题。
cpp2dia到是可以部分的解决这个问题。如果说dia2code是以UML模型为基础，cpp2dia就是以程序代码为基础。cpp2dia可以从代码中生成出dia模型来(当然，看名字就知道，只支持C++)。如果要添加函数，尽管修改代码，回头重新生成dia就是。不过这个毕竟不是比较完美的解决方案。
我做了一个测试。画了一个图形a.dia，然后用dia2code生成一堆框架。拿框架去套cpp2dia，结果出来一个output.dia。output.dia和a.dia拓朴结构一致，但是位置就差很多了(这也没办法)。最后用output.dia生成框架，生成结果和原来框架完全一致。
这两个工具的意义，在于编写代码的同时，可以清晰的看到代码的相互关系。代码写好了，文档也自然有了。UML图在手里面，代码自然也好写多了。同类的解决方案有IBM的Retional，Sun的JavaStudio，Microsoft的Visio，虽然都是要收费的，而且是白花花的银子啊～～～</description>
    </item>
    
    <item>
      <title>超级牛力</title>
      <link>http://blog.shell909090.org/blog/archives/343/</link>
      <pubDate>Mon, 08 Jan 2007 06:27:29 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/343/</guid>
      <description>用过debian的朋友，在用apt-get和aptitude的时候会发现有句声明。
#aptitude --help ... 这个 aptitude 没有超级牛力。 #apt-get --help ... 本 APT 有着超级牛力。  什么是超级牛力呢？
超級牛力是 Debian 系統中一股神秘的力量。
/*
..暴打ing..
*/
其实说明白点，超级牛力就是一个彩蛋。详细可以参看SuperCowPowers。
$ apt-get moo (__) (oo) /------/ / | || * /---/ ~~ ~~ ....&amp;quot;Have you mooed today?&amp;quot;... $ apt-build moo (__) ~ (oo) / _____/___/ / / / / ~ / * / / ___/ *----/ / / / ~ ~ ...&amp;quot;Have you danced today ? Discow !&amp;quot;... $ aptitude moo 此軟體沒有復活節彩蛋程式。 $ aptitude -v moo 此軟體真的沒有復活節彩蛋程式。 $ aptitude -vv moo 我不是已經告訴你這個軟體真的沒有復活節彩蛋程式了嗎?</description>
    </item>
    
    <item>
      <title>P2P和DHT的结构</title>
      <link>http://blog.shell909090.org/blog/archives/336/</link>
      <pubDate>Fri, 15 Dec 2006 19:29:29 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/336/</guid>
      <description>最近P2P是越来越盛行，按照公司要求，我们要写一个P2P下载支持。老板发话，越小越好。想想有道理，只是要减轻服务器压力，又不是要和P2P下载商抢生意。不过老板又发话，必须保持核心服务器高可用性。偶当场啥掉，怎么办？
说起P2P下载的原始面目，其实是很简单的技术。假定你一个人在下载一个文件，同时你又知道所有有这个文件或者在下这个文件(那就有一部分)的人的套接字。那么连接上去下载，并且提供你可以提供的部分就好了。其中只有两个问题(也和算法没啥关系)，应该先下谁的，应该先给谁。但是困难在于，你如何知道谁有某个文件呢？
按照获得这个信息的方法不同，P2P分成三代。
第一代是核心服务器型的，术语叫做中心化拓扑（Centralized Topology）[1]，例如Napster[4]。这种类型的P2P下载可以说是传统下载和P2P下载的结合体。他同时具备了P2P的特性，例如带宽占用分布，高容错，高可用。也具备了核心模式的特性，例如中心依赖，可模糊搜索。Napster可以说就是因为核心依赖性而输掉了官司。
这代P2P的运作方式是，用户上线的时候把自身的资源提交到服务器。由服务器维护表来做查询，并且定时删除过期的客户。用户查找文件的时候需要向服务器提交请求，服务器返回拥有文件的客户端。由于文件信息提交到服务器端，因此服务器上可以说是拥有版权文件的索引。
第二代是泛洪/限制性泛洪型的，术语叫做全分布式非结构化拓扑（Decentralized Unstructured Topology）[1]，代表就是Gnutella[3]。这种类型的P2P才是完全意义上的P2P，因为去掉了核心服务器，因此没有中心依赖性。拥有P2P良好的带宽占用分布，高容错，高可用性能。但是致命缺点是，当网络节点扩展时，维护网络的带宽消耗就会成几何扩展。在大规模应用中，这无疑是不可接受的。所以有限制性泛洪的结构，不过限制性泛洪只是增强网络的抗性，没有根本的改变现状。
这类P2P的运作方式是，用户维护自身拥有文件的列表，和其他一些客户的列表。当一个用户需要知道谁有一个文件的时候，就向他所有知道的其他客户查询。如此反复层级查询，并且用SPT或者TTL来做优化，最后可以得到结果。不过可想而知，网络消耗是惊人的。
这代P2P有个变形，术语叫做半分布式拓扑（Partially Decentralized Topology）[1]，代表是KaZaa。简单来说就是把核心服务器型的一个核心服务拆成多个分布在某些比较强大的节点上。核心服务间使用泛洪/限制性泛洪型的方式通讯，核心和非核心间还是核心服务器查询的老路子。这类P2P修正了核心服务器型的中心依赖问题，并且可模糊搜索。也修正了泛洪的带宽占用问题。但是资源消耗分布不均匀，结构比较复杂，而且长期运行的核心节点可能莫名其妙就成为了被告，因为核心节点也拥有版权文件的索引。
第三代是DHT型，术语叫做全分布式结构化拓扑（Decentralized Structured Topology）[1]，代表就是Chord[6]，Pastry[5]，Kadamila[2]。这种的P2P也是去核心的，拥有P2P良好的带宽占用分布，高容错，高可用性能。同时资源消耗比较平均，网络消耗小，扩展性好，抗网络不稳定能力强。缺点就是失去了模糊搜索的能力，只能变通的模糊搜索。
DHT是Distributed Hash Table的缩写，用于节点搜索的。在此之前，我们先来想想数据结构课程的一些东西(没学的就表看了，看下面的吧，这节看了铁晕)。如果我需要知道一个对象，找出关联的一个对象，那应该用哪种结构？map！那如果要增加map的效率怎么办？hash table！那么hash table的内存布型怎么处理？如果要经常删除添加，那应该用链表。OK，我们想像一下，假设一个节点就持有链表中的一项，上下项的指针改成上下节点的网络描述，那是啥？Bingo，DHT。当然，DHT不会傻到让一个节点就保存两个网络描述，那一旦断裂就全玩完。DHT中是先给予所有节点一个ID，然后定义一个距离算法，再按照ID来保存hash的。一个节点保存和他的ID相邻的一定距离的hash(当然还包括值)，并且保存一些ID近的节点的网络描述和一些节点远的网络描述。就好像在hash table里面，一个节点保存了上下临节点的同时，也保存了很远的节点的指针。这样在链表查询的时候速度可以更快。
DHT的运作原理是，一个节点加入DHT网络，就会生成一个不重复的ID。然后会寻找一些节点来扩充自己的相邻节点列表，并且获取于自己相邻到一定程度的Hash的内容。当节点够多的时候，所有的Hash都会有一个以上的节点来维护，这样就有了足够的容错性，性能，稳定性。在寻取一个内容的时候，会寻找自己的临节点列表中最近的节点，然后向他查询进一步的消息。这个在几次循环后就可以足够近到获得目标信息了。当然，大家可以看出，要寻取一个对象，就必须有这个对象的hash，因此是不可模糊的。
Kadamila是eMule所用的服务，很多BT中也使用了兼容协议。
另外顺便在此提出一个P2P流的思想。传统的P2P下载是基于块的，简单来说就是文件。现在很多P2P技术可以基于流，就是可以在允许一定延时的情况下，将延时允许区域内的数据作为一个块来传送。这种技术对于P2P的要求更高，但是应用范围更加广阔。例如用于视频流播放，广播，股票数据传输等等。现在的流技术都是针对特定协议来展开的，例如视频流点播就用PPstream。我们可以将P2P流封装成一个独立服务，从发起端上连接一个接口，到客户端上监听一个接口，中间过程透明化。简单来说，发送端上运行一个服务，客户端上运行一个服务。发送端上的服务连接到一个特定端口来获得数据，然后通过P2P流来传输给客户端，客户端的P2P服务再监听到一个端口上，向所有(或者有限)连接上的接口提供数据。除去只能接受数据，并且存在一定延迟和丢包外。整个过程就被掩盖在了单纯的网络传输下面。这样很多协议可以在不修改协议(但是至少要可以对抗错包丢包等等网络状况)的情况下直接P2P流化。当然，P2P流在实时性，安全性上的要求会更加高。
顺便说一下网状模型的一个修改吧，几年前的东西了，可惜一直弄不出算法来。当前的网状模型是一个节点传输给其他节点，然后层级传递。理论上应该将发起节点最近的和提供带宽最高的节点放在顶层，以减少网的层数。不过将底层的节点带宽废弃还是可惜了点。我们可以将一个流分成两个部分(如果先天就可以分离最好，例如视频和音频，不过他们不对等)，然后组成两颗树。这样网络中的底层节点就可以在另外一颗树中被定义为次层节点。如此会对带宽利用更加彻底，当然，程序也会更加复杂。
参考和引用:
1.P2P网络的拓扑结构:http://www.intsci.ac.cn/users/luojw/P2P/ch02.html
 2.Kademlia协议:http://www.itslife.net/blog/?p=132  :http://blog.csdn.net/colinchan/archive/2006/05/08/712760.aspx
3.Gnutella协议:http://www9.limewire.com/developer/gnutella_protocol_0.4.pdf
4.Napster官方网站:http://www.napster.com/
5.Pastry 工程:http://research.microsoft.com/~antr/PAST/pastry.pdf
6.Chord 工程:http://pdos.csail.mit.edu/chord/
7.对等网络中主流分布式哈希算法比较分析:http://www.p2psky.com/tech/article1274.html
8.细说 Kademlia:http://www.vshj.com/Article/2005/200512/Article_18386.shtml</description>
    </item>
    
    <item>
      <title>上海电信ADSL宽带测试报告</title>
      <link>http://blog.shell909090.org/blog/archives/329/</link>
      <pubDate>Wed, 25 Oct 2006 19:33:50 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/329/</guid>
      <description>总算把该死的有线通换成ADSL了——现在我们看看电信的宽带质量。
我做了几项测试，因为时间关系(我要吃饭了——)，没有做的很足，回头补个详细的。
1.tcp连接丢包率
根据我的测试，有一次出现了4%的丢包率，其余时间是0。
2.网络时延测试
www.google.com的测试结果是 平均/抖动=295.3&amp;frasl;591.7
www.sina.com.cn的测试接过是 平均/抖动=435.1&amp;frasl;714.3
3.TTL状态
平均TTL大约在12-18左右，略略好于有线通1-2个路由器。
4.动态丢包测试
P2P/HTTP混合实际使用下1分钟8863个包，丢包2.7%。
5.网络压力测试
未进行。
从以上参数中可以看出，电信的质量略略好于有线通的。但是网络时延大，带有数据丢包。这个要去检查是否是信号线上的问题。
下午仔细检测了ADSL的详细状况，然后得出了一个更详细的表，附录如下：
1.tcp连接丢包率&amp;amp;网络时延测试
#hping -p 80 www.sina.com.cn #hping -p 80 www.google.com  2.TTL状态
NTOP测定，平均TTL大约在12-18左右，略略好于有线通1-2个路由器。
3.动态丢包测试
wireshark测定。
1.无网络压力状态下测试
双机器自然负荷，仅仅开启MSN等IM软件。
--- www.google.com hping statistic --- 96 packets transmitted, 95 packets received, 2% packet loss round-trip min/avg/max = 36.1/39.3/57.6 ms  平均/抖动=39.3&amp;frasl;21.5
--- www.sina.com.cn hping statistic --- 96 packets transmitted, 96 packets received, 0% packet loss round-trip min/avg/max = 10.</description>
    </item>
    
    <item>
      <title>网络性能测试和标准</title>
      <link>http://blog.shell909090.org/blog/archives/324/</link>
      <pubDate>Sat, 30 Sep 2006 22:46:28 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/324/</guid>
      <description>前两天弄有线通的事情弄的郁闷了，所以就研究了网络性能测试。以后不用也是浪费，大家需要就看看吧。
1.目标
测试目的往往是测试清楚几个值，包括:IP包传输往返时延(RTT)，IP包时延变化(抖动)，IP包丢失率(Lost rate)，IP业务可用性，还有带宽(Bandwidth)。
2.适用标准
RFC 1242， RFC1944， RFC2285， RFC2432。
** 中华人民共和国信息产业部令第36号(http://www.chinanetcom.com.cn/mj/dxsc.asp?Unid=3810)
** IP网络技术要求&amp;ndash; 网络性能参数与指标(YD/T 1171-2001)
3.测试平台和工具
我们假定基于POSIX兼容平台测试，演示用的例子来自Debian Etch/Kernel 2.6.17-2-686。Windows下所需要工具可以参考移植工具。
iperf 网络带宽测试工具
paratrace 被动路由测试工具
hping2 网络联通和时延测试工具
wireshark(ethereal) 抓包分析工具
p0f 被动指纹分析工具
4.测试对象，方法，和结果分析
以下为实例测试，参数需要根据具体情况变化。
4.1.测试网络带宽
在服务器端运行iperf -s。
在客户端运行iperf -c 192.168.0.2
100Mbps网络环境下，得到结果为92.6Mbps，折合为11.5MB/s。即数据极限传输速度。
4.2.测试网络IP包传输往返时延(RTT)和IP包时延变化(抖动)
分主动被动方法，被动方法用wireshark抓包分析。下面主要介绍主动方法：
运行hping2 www.google.com -p 80。得到
56 packets transmitted, 56 packets received, 0% packet loss round-trip min/avg/max = 242.5/269.9/381.1 ms  即在主动建立的到www.google.com的TCP连接中(默认为TCP，可以使用UDP，ICMP，IP，具体请看hping2 &amp;ndash;help)，丢包率为0。平均传输延迟为269.9，抖动为138.6。
注：按照《中华人民共和国信息产业部令第36号》，往返时延平均值≤200毫秒，时延变化平均值≤80毫秒。此处已经超标。但因为测试环境和适用条件不完全吻合，因此无法作为有效证据。
4.3.IP包丢失率(Lost rate)
也分主动方法和被动方法，主动方法见上。被动方法是用wireshark抓包后，通过tpc.analysis.lost_segment标志分析丢包数量和总体数量。具体为。
用wireshark抓包。
用( tcp.srcport == 7007 || tcp.</description>
    </item>
    
    <item>
      <title>从踢牙老奶奶到火星文，从火星文到人工智能</title>
      <link>http://blog.shell909090.org/blog/archives/323/</link>
      <pubDate>Sat, 30 Sep 2006 07:19:07 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/323/</guid>
      <description>先复制一个小的密码——
£³¨Ç£ê£±£¬£µ¨É¨Ù¨Ó¡££±¨Ð¨Ç¨Í£¬£±¨Ð£ä¨Ê¡£
¨×£²£ä£´£¬¨ß¨Ç¨Ñ¨È¡£¨ÙYA¨È£ã£¬£ê£±£´¨Ø¡£
£´¨Ñ£´£õ£¬£â£ã£â¨Ó¡££±£ã£±¨É£¬¨Í¨Ø£´¨Ó¡£
看的出来的——请和火星总部联系。
很多朋友可能不知道一个事情，不过不少人应该听说过无冬城之夜。台湾版的无冬城之夜本地化(l10n)中有一个重大bug。俗称踢牙老奶奶。
原文是：我看到一位老奶奶慈祥的脸——我抓住她的手，但是她竟然一脚踢到我的牙齿。
估计所谓踢牙，应当是英文kicked my teeth in，指漠视。最后应当是她竟然无视我。这是典型的一个翻译错误，而且估计可能是机器辅助翻译没有修润的结果。这个错误和当年大菠萝的温暖骷髅情况不一样，没有任何一个电脑会把蠕虫骷髅(wormskull)错成温暖骷髅(warmskull)。
由此肇因产生了很多火星文，例如说：这个游戏里面到处是踢牙老奶奶。
不过，无论是机器翻译不完善造成的火星文，还是人造的火星文。其实都是一个核心问题，NLP。
机器可以理解形式化的编程语言，并且转换为机器代码。是因为语言是具备一定的形式(form)的，或者叫做范式(pattern)。而例如说可以借助符号来做唯一分割(语法树的生成，或者说波兰树的生成)，符号的唯一性。(所谓重载，是用将参数等重载辨识元素附加在名字里面，导致名字的定义仍旧唯一，详细大家可以看有做对象导出的库的导出符号表)然而自然语言本身分割未必唯一，符号也是和上下文相关的。例如最有名的例子，中国队大败美国队获得冠军。(中国队大败美国队获得冠军。和中国队大败美国队获得冠军。前一句中的败是动词，后一个应当是使动用法)这句同时出现了非唯一分割和符号歧义，即使对于人来说，也是具备歧义句特征的。只有在特定的语境中，歧义才会消除。例如如果在表扬中国队表现的文章中，那应当是后面一个解释。
对于自然语言的理解，人工智能中叫做NLP问题(Nature Language Precess)。首先要处理的就是断词和消除歧义。其中涉及的问题到不繁复，但是很庞大。最关键就在于数据量上。
断句的话，一般简单的都采用HMM算法，这就需要有前后词或者词组的衔接概率作为基础。中文又具备一个恶心的特性，就是假借。尤其在口语和古语方言一类的东西里面，倒置使动频繁。所以单纯做HMM还不完全解决问题。现在有很多分词软件，是基于HMM的。拿古文上去试试就知道是不是了，例如：古之人诚不余欺也。
至于消除歧义，更是麻烦的要死的东西。要消除歧义，只有把所有歧义可能全部列举出来。然后查看上下文中相关词汇出现的频率，选择比较高的一个。然而对于上面那个使动用法的例子，两者相关词汇的频率应当差不多。而电脑又不会像人一样判断语境，因此要误判就不奇怪了。
还有一个就是上面踢牙老奶奶出现的原因，俗语(idiom)或者叫俚语。例如百口莫辩，如果不加处理，至少也是can&amp;rsquo;t argue with one hundred mouth(people)。事实上比较恰当的翻译应当是unable to give a convincing explanation for self-defense。当然，NLP的目的未必是翻译，因此可能出现别的错误。不过错误的原因是一样的，就是俗语不了解。这个问题人也会出现，只是人的智能就比电脑高一些。百口莫辩不知道典故错误翻译过去还算难免，买椟还珠这种东西即使知道椟怎么翻译，在真的翻译前也会问问典故的吧。</description>
    </item>
    
    <item>
      <title>玉女穿梭</title>
      <link>http://blog.shell909090.org/blog/archives/322/</link>
      <pubDate>Wed, 27 Sep 2006 06:26:55 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/322/</guid>
      <description>今天弄了一个好玩的东西，esound4win。
现在在我的linux和windows上面有一堆穿来穿去的协议，大家看看实现方法，然后头晕不头晕。
首先是VNC，在windows上面安装RealVNC，启动服务。然后用linux的xvncviewer访问，就可以无缝在linux上面访问windows。
然后是Xming，这个是Cygwin的一个部分。可以在windows上启动X服务，这样我们可以运行一个远程跨平台的图形界面。在我的Debian上面是这样的。
用一个tty登录进去，然后
$export DISPLAY=192.168.0.X:0 $/etc/X11/Xsession &amp;amp;  这样就完成了完整的一个界面，界面控制是在windows下，但是程序是在linux下跑。和VNC不一样的是，windows的前端在操作的时候，其他的前端可以同步操作。
再然后是esound，这也是Cygwin的一个部分。可以在windows上开启一个esound daemon。方法是运行。
esound -tcp -public  在linux下面，esound可以跨站传输，方法是设定。
$export ESPEAKER=192.168.0.X:16001  当然，监听端口可以自行设定。
这样，就完成了从linux上将声音输出到windows听的功能。
最后，我讲讲我的实现。我先开了一个VNC穿到windows上操作，然后启动Xming。按F8退出到本地，用Ctrl+Atl+F2切换到tty登录，并且连接上Xming的前台X。然后Atl+F7返回GUI，F8返回VNC全屏模式。在Xming里面，开了个term。export了参数后启动xmms，并且切换到esound输出。再在windows下面运行esound4win，插上耳机。最后我点了下VNC中的Xming中的xmms的播放，声音出来了——世界多么奇妙？</description>
    </item>
    
    <item>
      <title>电脑程度测试</title>
      <link>http://blog.shell909090.org/blog/archives/321/</link>
      <pubDate>Tue, 26 Sep 2006 05:58:34 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/321/</guid>
      <description>随便写了点问题玩玩——大家开心就好哦——
1.电脑开机和关机一样简单 2.会按照标准流程关机 3.非常习惯的在关机的时候点关机去 4.电脑不经常关机 5.为啥要关机？ 1.不知道啥叫重装系统 2.定期找人重装系统 3.会自己重装系统 4.用过windows以外的系统 5.用的是自己定制的系统 1.从来都只在网络上听歌而不下载 2.没有用过CMD窗口下的命令 3.会按照网络上的说明调整系统 4.中了木马会手工查找 5.经常在自己的论坛或者wiki上写东西 1.看到弹出一个对话框就习惯的按回车 2.删除错误了去回收站里面找 3.文件按照分类摆放 4.经常写两个脚本用用 5.经常猜到将来会流行什么类型的软件 1.电脑里的软件都是中文的 2.可以用一些英文软件 3.偶尔自己装几个软件试用一下 4.经常试用各种软件 5.一般只用自己熟悉的软件 1.出现异常的时候手足无措 2.出现异常时候的反应是，中病毒了 3.出现异常会去论坛上提问 4.出现异常会提交报告 5.出现异常会条件反应出出错的原因  评：
5-8分：您是标准的电脑白痴，除非有人帮忙，否则电脑就是废物。 9-12分:您刚刚学会用电脑，不过还不是很熟练 13-16分：您的电脑还算不错 17-20分：已经算是个高手了 21-25分：对您来说，用电脑和呼吸一样自然，你是神吗？  </description>
    </item>
    
    <item>
      <title>上海有线通网络封锁解析</title>
      <link>http://blog.shell909090.org/blog/archives/320/</link>
      <pubDate>Tue, 12 Sep 2006 09:01:16 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/320/</guid>
      <description>OK，今天贝壳稍微辛苦了点。给用有线通的朋友们准备了份礼物。
贝壳今天解析了有线通的抓包，发现了有线通限制P2P的方法，那就是，丢包。
TCP传输的时候，会有一定几率的丢失部分或者全部传输的数据，对方会根据你的SEQ和checksum来分析是否接收到了所有的包，并且返回一个包，告诉你报文状况。一般来说，丢包率都是很小的，大约是0.1%以下。丢包太多往往意味着各种网络异常，例如抢占MAC的sniffer方式就会有大量的丢包。这里是丢包率的详细解释。
贝壳刚刚截取了32秒的数据，总共传输3082个，丢包率是ED数据丢失119个，其余总共丢失2个，总丢包率3.9%。图片内有相应的截图，并且贝壳可以提供多次的抓包分析证明。
贝壳又做了一次分析，这次贝壳从skycn.com上面下载directx9c，同时保持ED通信。ED是7K上传40K下载的样子，HTTP是15K的样子。在60秒内总共是16763个包，其中ED相关丢包321个，非ED相关丢包13个，丢包率1.99%。
通过这个就可以证明，即使不说有线通封锁P2P的问题，有线通的网络服务质量也存在硬性问题。</description>
    </item>
    
    <item>
      <title>有线通封锁变通办法</title>
      <link>http://blog.shell909090.org/blog/archives/317/</link>
      <pubDate>Sat, 09 Sep 2006 05:27:34 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/317/</guid>
      <description>虽然决定不用有线通了，但是还是要熬到年费结束。所以稍微研究了有线通的封锁方法，看看有没有变通方案。根据我上面的研究，有线通浦东地区封锁的是协议。所以我实验打开了BT和ED两个协议。结果证实，这两个协议同时打开对于单个协议的速度稍微有影响，估计是TCP的优先相应问题。不过总体速度比单个协议高了很多。昨天打开的时候，ED是30下载5上传，没有BT。今天同时打开的结果是BT45下载10上传，ED17下载10上传。总体来说有62下载20上传左右，高了很多。
其中针对BT说一句。之所以有这么高的速度，主要因为打开了BT中的加密协议头优先。这样在某些传输中就被当作HTTP连接，这个速度就是赚到的。不过现在不多，因此也没有太高的提升。不过总体下来不无小补，所以提供给继续要受到有线通荼毒的人士用用。
另外，有线通对HTTP下载不限速。大家可以把HTTP下载速度降低到不影响P2P连接的水平(例如用flashget的限制速度功能)，慢慢下。这样你的总体平均流速是最大的，同时对于有线通的杀伤也是最大的。</description>
    </item>
    
    <item>
      <title>上海有线通，不爽</title>
      <link>http://blog.shell909090.org/blog/archives/315/</link>
      <pubDate>Tue, 05 Sep 2006 22:07:46 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/315/</guid>
      <description>最近贝壳要换ISP了。大家知道，贝壳用了5年多的上海有线通。虽然速度不快，偶尔还有降到半速的现象，但是总体来说还是不错的。TTL跃点主要在12到16上下(经过12-16个路由器)，极限上传一般在55K/s上下。虽然说和标称有一定区别，不过考虑IP封包头问题，也还可以。只是最近有线通不怎么像话，封了P2P不说，还不告知。去询问，又不承认。幸好贝壳两个月后包年到期，到时就跑了结束。
开始(8.30左右)贝壳的ED速度突然从50K/s持续上传下跌到7K/s持续上传。贝壳以为是电信故障维修，造成数个连线失效，路由重生成后形成瓶颈。这现象照理不会在电信这种大公司发生。不过按照莫菲定律，什么坏事都可能发生。就随他去了。24小时以后，贝壳打电话到96877报修。对方开始说会不会是系统问题，windows新出病毒云云。贝壳两台电脑，平台不一样(Intel和AMD64)，系统不一样(WindowsXP和Debian/GNU Linux)，所用软件不一样(eMuleVC，BC0.70和aMule)。不会都是出这个问题吧？再说windows出病毒，关linux啥事情？
维修人员看看没法说的通，换了口风。说这种问题不能算是问题，他需要“提交”一下。OK，你本身做维护的，还向谁提交问题？我也不管他，这几天忙，没空和他唠叨。说好好，你提交下看看。
过两天空了，看问题照旧，贝壳坐不住了。莫非我碰到了P2P封锁？贝壳先查看了网络上的评论，说上海有线通有这问题，已经有人在315网上提交了抱怨。贝壳下面做了几个测试。
首先将eMule复制一份，保留原先的配置。然后关闭所有共享，只共享一个文件。名字起的奇怪点，这样就没有别的下载客户了。然后找一个朋友来做下载，速度是5K上下，而且一般有下没上。
然后贝壳打开apache2，共享同一个文件，打开端口映射(ED等软件的端口映射也是做好的，经EtherReal核查没有问题)。下载速度是50K上下，一般有上没下。
再打开BT，勾选其中“加密数据包头”为“优先”。然后在传输测试中，多数客户的速度是2K-3K，但是一个也是BC0.70的客户，本地发起连接，速度高达50K。后面偶尔也会出现这样的客户，估计是因为不是所有BT客户端全支持加密数据包头的。
最后，测试Debian/GNU Linux从ftp.linuxforum.net下载更新的速度。这是ftp和http混用协议，一般在70K以上，最高甚至达到120K。
至此，基本可以下结论，有线通封锁了P2P类软件的使用。
最可笑的是，我再次打电话过去。他们的服务人员开始还跟我念叨机器问题等等。然后我把测试方法一说，他们立刻改口，说从不保证任何P2P类软件的稳定。只保证Http协议的传输速度。什么时候宽带还有条款，说只能保证Http协议的速度了？如果说只衡量HTTP协议速度，那条款应该重新修订。如果说网络速度，一般都是指IP封包的传输速度。或者放松说，底层网络封包的传输速度。有线通此举就是明显的侵权。上述电话可以向有线通查询的，工号7061。
任何愿意起诉有线通的同志，贝壳这里免费提供技术支持，提供有线通的网络数据统计(ntop统计结果)。大家高兴起诉的，贝壳提供声援和支持。并且贝壳郑重表示，有生之年，见到用有线通的就游说用别的宽带，即使他道歉并且解除封锁也不例外。自10月底有线通到期后，贝壳即抽空银行资金，签订解约协议，改用ADSL。</description>
    </item>
    
    <item>
      <title>新版MSN试用报告</title>
      <link>http://blog.shell909090.org/blog/archives/312/</link>
      <pubDate>Sun, 30 Jul 2006 20:43:37 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/312/</guid>
      <description>最近MSN又更新了，出乎我的意料，这次是stella同学率先跟进的。结果伊在刚刚用的时候发现好友全部消失了，正在惊惶的时候，偶撞上去打招呼，结果被伊捉来拷问。最后恢复是恢复了，不过还欠下新版MSN的论文一篇。
虽然不知道伊何时对MSN的机制感兴趣了，不过偶还是写了一个blog来分析新MSN的战略意义和运行机制。
免责声明，以下内容尚没有经过严密测试。如有偏差，作者不负任何责任。
copyright
itten by Shell.E.Xu, public under GPL.
abstract
新版MSN的功能和工作原理。
keywords
N，安全，兼容，分布式
context
我们先分析what&amp;rsquo;s new上面提到的两个新功能，语音通讯和共享文件夹。
1.语音通讯
这东西很老啦，我测试的情况下是直接连接，连对方的IP都暴了出来，而且还不稳定。不知道为啥微软拿来宣传。
2.共享文件夹
共享文件夹的功能不是MSN的独创，但是MSN的共享文件夹思路很特殊，是针对每个人共享的。这不同于设置共享文件夹权限的做法，针对每个人的共享在正常来看差不多就是文件传输。通常IM的文件共享都是共享一个文件集，然后设置不同人的访问权限。这个时候IM宿主的功能就好像一个文件服务器。但是MSN的做法使得管理者不是单个IM宿主，而是两个。而且IM宿主不必在线，也可以修改文件。对此我跟踪了下整个实现过程，发现是这样的。
MSN使用了%ROOT%Local SettingsApplication
DataMicrosoftMessenger%EMAIL%目录来保存和共享有关的东西，对每个人的共享内容都会保存在SharedFolder下面的Email下。每个人只保存自己共享出去的，对方的内容在联机的时候同步。这里要提到一个概念，硬连接和软连接。假定文件内容相同，连接能减小空间损耗。NTFS虽然在理论上支持了硬连接，但是却没有在platform
API里面导出相关函数。何况FAT根本不支持硬连接。所以MSN使用硬连接的可能为0。至于软连接，同样，FAT根本不支持。所以使用软连接的可能也不大。因此，假定你一个文件要共享给所有人，使用MSN的话你要重复拖曳，并且多次保存。（短期试用，还不知道是否真的必须这样）这样共享文件根本不经济。更何况每次上线都要进行同步，取得别人的更新，这样对网络也非常浪费。同时还存在下载染毒文件的风险（当然不会有运行的风险）。不知道微软存了啥心思。
3.Windows Live Safely Scanner
微软在共享文件夹里面配套提倡的，就是Windows Live Safely
Scanner。其他厂商为了增大合作空间，一般在查毒功能上都是利用外包方式，只要你提供一个杀毒软件主程序的路径，就可以利用%PATH%
%FILE%的方式查毒。微软就在MSN内推荐使用本公司的产品。由此看出微软准备借助IM的优势，向安全领域进军。
4.联系人列表加密
这个是本人最不齿的功能，如果要加密了联系人列表，那么gaim一类的东西就全成了废物。微软如果真的有这个心思，完全是本着把开放协议搞成封闭协议的精神在做事了。如此无异于步QQ的后尘。
5.其他特征
新版MSN登录时间一般比较长，估计是在做功能通讯。有得有失，大家就别计较了吧。不过如果你登录过，速度就比较快了。MSN新版的稳定性还是不行，stella小姐被吓个半死，我这里是分组丢失。不过伊重新登录就恢复了，偶拿gaim登录也正常了。</description>
    </item>
    
    <item>
      <title>BOINC分布式计算</title>
      <link>http://blog.shell909090.org/blog/archives/311/</link>
      <pubDate>Thu, 27 Jul 2006 08:11:44 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/311/</guid>
      <description>嘿嘿，贝壳我现在正式参加了BONIC的两个项目，SETI＠home和Einstein＠home。这两个项目是通过个人电脑的剩余CPU能力来计算大规模运算项目。SETI是寻找外星人的存在。通过个人电脑来计算美国航天局射电望远镜的信号，来分析外星文明的存在可能。Einstein是在2005世界物理年发起的计算引力波的项目。
个人觉得计算来说，PII以上的计算机就可以参与计算，以下的就算了吧。因为您算出来的时候已经超时了。运算是在后台进行，除了系统指示上CPU基本全是满的以外没有什么异常。电影照看网络照上，就是CPU温度可能高了点。不过相对人为和意外来说，这点造成的寿命问题完全可以忽略。
BOINC还有很多有意思的项目，包括计算蛋白质折叠，计算病毒分子情况（以上的都是用来寻找疫苗的），还有大气环流（这个是预报自然灾害和预测人类行为影响的），计算防疫药品最有效分布，计算最大质数，分解大质因数等等。很多都有相当的科学意义。
BOINC的安装相当简单。下载程序，安装，在计算主页上注册，在软件上登录。然后你就不用管了，只要定期看看有多少分就好了。可以用多个计算机算一个项目，也可以一个计算机算多个项目。建议每个计算机算两个项目，这样一般不会超时，而且也不会没的算。
如果您有兴趣，可以参看。
伯克利开放式网络计算平台
Berkeley Open Infrastructure for Network Computing
如果决定参加的话，最好再加入中文站点上面列出的项目小组，为世界做贡献的同时为中国添光彩。
SETI@China , Einstein@China , LHC@China , Predictor@China , Rosetta@China , CPDN@China</description>
    </item>
    
    <item>
      <title>删除无赖</title>
      <link>http://blog.shell909090.org/blog/archives/309/</link>
      <pubDate>Fri, 14 Jul 2006 01:34:54 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/309/</guid>
      <description>大家知道，从3721首开记录后，很多软件都有卸不掉的情况。多数是插一个dll到explorer里面，让你无法UnloadLib，也不能kill。然后保护一堆文件不能删除，再放注册表项目。3721还加了一个驱动，这样就是神仙也删不掉。
骂人不多骂了，方法两个。http://www.sysinternals.com/Utilities/PendMoves.html有一个项目，可以延迟删除。换句话说就是在启动的时候，讨厌的流氓加载前让内核做删除动作。很方便，重起下就没了。至于怎么找这些流氓的位置。http://www.sysinternals.com/Utilities/Autoruns.html同样公司，这个项目可以将开机所有自动加载的模块全部找出来。IE的插入组件也可以找出来。
不过这个办法虽然好，可是还是会有破绽。万一连这两个软件运行都屏蔽呢？这个时候可以用linux live+ntfs r/w modules，这样删除任何东西的时候，神仙也挡不住。
BTW,做live的时候，千万记得放一个ntfsfix在盘里面。贝壳的/dev/hda1有个logfile没有clean，结果死活不能写挂载……</description>
    </item>
    
    <item>
      <title>Google earth</title>
      <link>http://blog.shell909090.org/blog/archives/305/</link>
      <pubDate>Sat, 01 Jul 2006 05:35:56 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/305/</guid>
      <description>google earth很多人已经用过了，不过google earth有linux的bata版了。下载解压，解压界面非常漂亮，很容易上手。运行来看，是QT的界面。不愧是google阿。</description>
    </item>
    
    <item>
      <title>整死人</title>
      <link>http://blog.shell909090.org/blog/archives/296/</link>
      <pubDate>Sat, 01 Apr 2006 07:23:25 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/296/</guid>
      <description>我在编译mplayer1.0的时候需要xf86vmode.h文件，这应该是安装某个dev包。根据packages的结果，是xlibs-static-dev。不过系统还提示找不到，事实上，他在libxxf86vm-dev。</description>
    </item>
    
    <item>
      <title>分布式软件构架的变革</title>
      <link>http://blog.shell909090.org/blog/archives/289/</link>
      <pubDate>Wed, 22 Feb 2006 03:34:53 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/289/</guid>
      <description>分布式软件构架由来已久，从最初的并行计算到现在的大规模网络并行计算，再发展到网格计算。这代表了分布软件的一个变革，而另外一个变革则是从数据-程序-界面合一的构架转换到数据-程序-界面分离的构架。MVC大家都很熟悉吧。现在软件界的三大困扰是什么？安全，效率，可复用。其中程序从界面层剥离开造成了当前你用出bug的程序可以对别人施加影响，而程序和数据层间的紧密结合更加剧了这个问题。还有程序到界面的接口是最影响成本和收益的地方，因为界面和程序的可复用是最能降低成本的。
我们现在流行的一种模式是使用网页界面的B/S模式，诚然，这种模式比C/S模式有更大的优点。客户端与系统无关，这样客户端的可复用性非常好。但是这种模式的缺点也是明显的。网络传输效率低（这个现在没有多少人计较了），构架不合理（人家HTTP本来是传输文件的说），而且不安全。
我们相信将来的软件设计模式是基于分布的，那么可能如何分布呢？我个人认为有两种主要模式，一种是平台抽象式分布，一种是组件抽象式分布。
平台抽象式分布是指软件的运行在一个网络平台上，其具体运行在哪个电脑上，如何协调对象，并不是软件关心的内容。平台负责抽象了机器，平衡了性能，增加了效率，但是对于机器间的传输实时性要求比较高。适用于企业内部的发展方向，以多台电脑平衡性能。均衡性能需求峰值，降低硬件成本，并且可以充分利用旧机器。用于这种分布的基础是分布式操作系统，在系统运行后即无条件陷入分布系统的接管中。前台的模拟为纯终端，后台模拟为纯资源。然后终端向资源登陆。这种模式的近似产品是win2k中的AD，不过AD只提供了资源的访问指向和访问控制，还有权限分散管理模型。而没有提供最核心的内存共享和锁定，还有线程分布和游离运行。
组件抽象式的分布其核心是将一个软件分离到不同的组件中，不同的组件在不同的机器上运行。这种模型更适合于自由的广域环境，当然前提是能成功解决组件通讯的问题。现在这种模型相对前种有更广的发展。这种模型和现在的B/S模式中最大的差异是，B/S模式的用户接口是浏览器和服务器程序共同完成的。从来没有人听说过有页面直接驱动后台组件的吧。如果我们可以用一种抽离语言（JAVA的显示效率太低了）来完成前台的接口部分模块，那么我们应该试图用这种方式来发布软件的前台端。这样软件的抽象更为简单明确，而且可复用性更高。</description>
    </item>
    
    <item>
      <title>第三代博客的兴起</title>
      <link>http://blog.shell909090.org/blog/archives/287/</link>
      <pubDate>Tue, 21 Feb 2006 06:48:01 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/287/</guid>
      <description>第一代博客是少数人的博客，这种博客文化好比前几年的个人主页一般。参与的是少数，出名的也是少数。这种文化好比DHT网络研究中的深度节点模式。不熟悉的朋友也不用看了，大概上讲，信息扩散的拓扑网络有两种主要分类。一种是每个节点的链数目差不多，链接长度也差不多。这种模式传播抗突变和崩溃很好，而且节点的要求也不高。缺点是信息传递路径长，容易变形，而且传播不稳定。还有一种模式是有一些节点的链接数目大，而且长度方差大。这种模式信息传递快而且稳定。但是抗突变能力查，而且节点要求高。目前DHT的努力方向就是以后种模式为骨干的结合两者优点。而“深度博客”文化，或者叫“个人博客”文化。主要是将某些人作为博客的卖点，进而推动博客的发展。如果没有名人，没有卖点，一个博客再稳定强大都没用。而第二代博客是大众化的文字博客。这种博客类似DHT中的分布节点模式，主旨是推行每个人独立的创造博客，最终通过程序链合聚集。在我看来，博客的日志功能只是辅助，其交换，聚集，索引才是核心实质。这种博客是以稳定和强大为基础的，具备很强大的客户粘着性。如果用户的blog某日丢失了，那名人再多也无法挽回局面。
而第三代博客是以媒体为基础的博客。任何媒体，任何形式，都是从文字开始，然后到多媒体。从专业化开始，然后渗入生活。从集成开始，然后嵌入。我们可以仔细观察现在的HTML规范，还有常见的HTML语言，然后和1994年的欧洲核物理研究中心创立的追初的HTML规范对比。我们可以很容易发现，现在的HTML语言更趋近于媒体使用而不是文字，并且现在的HTTP协议更倾向于在网络上交互事件和数据而不是传递文件。后者恐怕我还要专门撰文评价，而前者则是网络界从文字向媒体转换的明证。
我们现在的每个blog理论上都有关键字，所有饮用有通过RSS协议。这是我们得以开放式交换链接，并且实现追踪搜索的根本。如果我们在媒体上类似的处理，我们也可以制作类似的媒体blog。届时我们每天的blog内容更新可以是通过录像而不是打字，这不仅仅是效率的增加，而且是方式的变革。相对来说，当前的blog中加入图片根本是小孩子的玩具。
相信这个问题不是没有人想过，但是实现上有个巨大的难度。当前的第二代blog的栖身之所是巨型的服务器集群，这样才可以负担千万级的用户。如果要在其上传输媒体，未免太强人所难。这个问题可以回到当初我们的DHT网络上去。DHT本质来说是什么？应该是知识网格。通过一些方式将你的知识和信息散布到网络上去，然后别人可以找到。这本不是难事，但是我们现在的主要实现方式是集成数据库！这意味着如果没有核心服务器，我们无法交换信息。而我们交换信息越频繁，核心服务器越大。这当然的限制了交换的发展。DHT是将信息冗余分布在网络上的方法。同样，我们可以将媒体通过一些P2P方式封装，浏览过的人将为将来的人提供上载，这样可以相当的解决第三代blog最严重的带宽问题。
不过其中解决一个问题的同时带来了另外一个问题，公众的公德心，上传的问题。这个问题的解决恐怕要依赖于P2P软件中的补偿机制的完善了。</description>
    </item>
    
    <item>
      <title>英雄传说VI存档修改</title>
      <link>http://blog.shell909090.org/blog/archives/285/</link>
      <pubDate>Wed, 01 Feb 2006 06:15:01 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/285/</guid>
      <description>存档文件都会找吧，HEX编辑器都会用吧。不会还想修改，一头撞死去吧。相对来说游戏还是比较好修改的，继承了FALCOM存档的一致风格。（汗……这个……）和大宇一样白痴兮兮一点加密都没有，差分分析就搞定了……不像某些游戏的存档，居然用RSA加密！（再汗……）不过更夸张的是，游戏的资料全是zip压缩的可读可编辑资源，连对话都可以随便改……（庐山瀑布汗，晕倒。）
下面是地址和数据，除了物品代码和个数是WORD以外，剩下都是DWORD。下面物品不全，有部分我忘记了，还有就是懒。多数情况是够用了，不过晶石是缺的，料理也不全。如果有哪位搞定了全部数据，请和我给我留言……
0x25C88 金钱
0x25C90 七耀石
0x23E64 Js经验
0x23E98 Es经验
0x266B4 战斗次数
0x25C8C BP
0x266B6 战斗不能次数
0x266B8 战斗胜利次数
0x24C8A 物品
0011 太极棍
0030 黑千鸟.白千鸟
0041 九尾
0062 王权之光
0080 水晶剑
009D 狂战士巨刃
00BA 高能量粒子炮
00D9 代达罗斯护腕
00FD 皇家骑士铠甲
00FE 女武神铠甲
0119 天神之鞋
011A 风神之鞋
012D 银耳环
012E 打火机
012F 幻影戒指
0130 黑色手镯
0131 魅惑项圈
0132 光明背带
0133 珍珠耳环
0134 百合项链
0135 羽毛胸针
0136 骷髅项链
0137 活性脚镯
0138 魔力鸟冠
0139 神圣挂链</description>
    </item>
    
    <item>
      <title>IE屏蔽方法</title>
      <link>http://blog.shell909090.org/blog/archives/282/</link>
      <pubDate>Sat, 21 Jan 2006 17:47:02 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/282/</guid>
      <description>IE这个东西讨人喜欢讨人嫌，很多时候没有它不行，有了又容易中各种东西。下面的研究就是怎么样来控制IE的各种行为。首先是屏蔽IE的开启
cacls &amp;quot;C:\Program Files\Internet Explorer&amp;quot; /P admini:N /E  这条语句的目的是屏蔽administrator对浏览器目录的访问权限，访问权限都没了，浏览器自然开不了了。不过这只适合于用户手工开启浏览器，如果系统自动弹出，浏览器还是照样开的。例如我们亲爱的MSN，所以还要加下面这条。
cacls &amp;quot;C:\WINNT\system32\BROWSEUI.DLL&amp;quot; /P admini:N /E  这条屏蔽的是IE的界面（UI），所以凡用IE界面的东西全部弹不出来。像刚刚我就差点无法写新的日志。所以用这两条语句重新开启访问权限。
cacls &amp;quot;C:\WINNT\system32\BROWSEUI.DLL&amp;quot; /P admini:F /E cacls &amp;quot;C:\Program Files\Internet Explorer&amp;quot; /P admini:F /E  这里要特别说明下，admini在我的机器上指administrator，而我机器上的administrator则是一个连guest权限都没有的空账户，专门用来诱骗攻击的。各种账户的情况大家可以根据自己机器自行修改。
上面屏蔽了IE的UI，但是内核还是可以访问的，所以在FireFox里面用IE插件可以载入IE的解释系统，外壳则是FireFox的。如果要真正保证安全就使用这个语句。
cacls &amp;quot;C:\WINNT\system32\MSHTML.DLL&amp;quot; /P admini:N /E  这个语句屏蔽的是IE内核入口，所以下面所有的IE行为全部都会变成下载。有啥网页也全都是下载而不是解释出来显示在网页上。至于解除代码，自己想吧。</description>
    </item>
    
    <item>
      <title>杀虫方法</title>
      <link>http://blog.shell909090.org/blog/archives/281/</link>
      <pubDate>Tue, 10 Jan 2006 01:13:21 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/281/</guid>
      <description>3721，YiSou，等等这些东西让人烦死了……所以我决定正式开始研究杀除方法。
预防方法：
1.先建立一个和对方目标目录一样的目录，然后删除所有权限……
2.编辑C:WINNTsystem32driversetchosts文件，将混帐们的网站重定向到127.0.0.1。
3.IE的安全设置到最高，然后平时用FireFox。再把混蛋们的网站加入受限制站点。
4.偏执狂的做法，新建一个受限制的系统用户，然后去访问网站。
杀除方法：
1.找到正确的位置，然后用ERD或者linux启动系统，删除。再正常进入系统扫描无用的COM。
2.利用ProcessExplorer找DLL的注入宿主（一般是IE或者是Explorer）。然后找正确的DLL位置。启动CMD，输入删除宿主的命令，然后用ProcessExplorer关闭垃圾进程，留下核心，然后运行CMD的命令。
3.将DLL删除命令放到autoexec.bat里面，这个东西在winNT下也会执行。可以用&amp;gt;c:/rslt.txt察看是否成功。
一点建议，谁可以研究下linux光盘引导方法，做一个NTFS支持的引导光盘，自动搜索所有垃圾的位置，然后清理？</description>
    </item>
    
    <item>
      <title>服务器，好漂亮</title>
      <link>http://blog.shell909090.org/blog/archives/274/</link>
      <pubDate>Sat, 17 Dec 2005 05:35:34 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/274/</guid>
      <description>今天偶终于见识到了传说中的服务器是如何组装的。话说我们公司准备用台Linux服务器来做发布。偶就负责了服务器的采购大业。最终抱回来的是一个如下配置的大怪兽：
Xeon x2 KSTDDR2 1G Registed ECC x4 MT 73G SCSI x3Adpetec 2120S RAID Card Hatekey 550W Power SuperMicro&amp;hellip;.(I forgot it, but it&amp;rsquo;s E7320MCH)
从昨天下午开始，我们就坐在店里面死等服务器组件到。结果服务器组件姗姗来迟。等掉了三个钟头，逛了两圈，遇到四个熟人，聊了不知道多少时间天。还让我知道IDE居然可以插根线用USB口拖，上帝阿……我的旧硬盘有救了。
昨天下午服务器组件到货后我们就开始组装，具体请看贝壳上传的图片。不过看着闪闪发光的两个大纯铜风扇，真是让没见过啥好货的贝壳流口水阿。本来贝壳还对着SuperMicro的板子留口水，然后一个人看不过去，带去看了看顶尖主板。然后贝壳口水不流了，眼睛掉出来了，知道自己孤陋寡闻了。
时间跳阿跳，直接到今天。搞定所有部件，将最后的SCSI线插上去后。OK，开机正常了。大家不要听过程简单，其实很麻烦的。最关键是机箱，只要配合上有点错误，就装不上去了。整个过程就像在螺丝壳里做道场。真不知道1U的机箱怎么混的……麻烦装机器的师傅了。
Adpetec卡还不错，真的不错。上去后驱动没装就认出来了，省却我很多麻烦。否则我先要重编译一个合适的内核，然后上驱动，再放到安装盘里面刻录一个新的，以这个内核为基础的安装盘。这样才认的出来，然后可以安装。只要基础系统出的来，剩下的东西就好办了。装好系统直接上了一个ProE1000的驱动，居然上去了……厉害的。然后Copy下所有需要安装的，再下面就和服务器无关了……</description>
    </item>
    
    <item>
      <title>电信机房参观</title>
      <link>http://blog.shell909090.org/blog/archives/268/</link>
      <pubDate>Wed, 30 Nov 2005 04:12:43 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/268/</guid>
      <description>今天偶跑到上海电信机房去参观了，看里面的机器感觉真是爽阿。很多都是品牌机，拼装机都看着非常专业。绝对不是我们公司里面那种破烂机器能比的上的。问代理商，代理商说这是电信的1G光纤分流到户，每个机柜100M带宽，20个机器去分，每个用户不限制流量。因为我们用的那个机柜都是小流量的机器，所以保证我们10M没有问题。如果以后流量太大，也可以换一个接入，用专用的100M口。
偶们在公司里面估算过，假定一个页面调入，不计算图片等媒体，需要50K的网络数据传输。（这也是公司一般页面设计的大小）调入非媒体的时间假定在五秒不会让用户感觉到慢。这样一个用户连接就需要保持10K的带宽。10个用户就是100K，换成bps就是大约合0.8Mbps。图片一般都是静态的，所以只要跑一次，后面IE会自动看缓存。所以每次会耗用KeepAlive的Session大约250字节的数据，基本可以忽略。只是如果带宽空余点首次跑图片的时候比较快，如果不空就比较慢。到后面访问几乎没有差异。
按照供应商的数据，我们有可以至少支持125个页面并发。假定平均一个用户同时开启的页面是两个（有的人开新窗口来用的，还有部分是我们需要弹出或者页面内引用页面），那么就是支持60个用户并发左右，貌似够了。因为60个用户并发，假定每个用户等待加操作需要10秒/页面，而读取的速度是5秒/页面。那样峰值用户数就是120人。平均来说可以支撑最少1000个用户。
问题在于问题在于，杨总设计的业务流程中大量的使用了内嵌的office文件。经常要上传下载office文件。那么我们要把这部分的流量抽离开来使用。一个office文件平均100K，而用户静态数据区大小是100M。按照单次使用不超过总容量1/10的原则来计算，一次用户操作的最大空间就是10M合100个office文件。实际到是没有这么多，一般是5个上下。这样算来，用户需要在五分钟内上下传500K的额外数据。运气好的话只有两个的客户在做这个东西，那么就是6Mbps的速度要求！
我们在假定了两个客户同步做上下传的前提下，还得到这种惨淡的结果。要我们支撑120个同步用户至少需要20Mbps以上带宽。不知道这个系统在后面还怎么经营下去……
算了，那个也不关我事，至少目前不关。到是服务商的收费理由让我感到很有趣。他说他收费贵是因为机房建立的比较好。电池是专门的在线UPS，大楼有备用的发电设备，灭火器是干粉的，大厦是抗震的，所以比较贵点。这些理由怎么样不说啦，至少让我开了眼界……
回来的时候碰到件妖怪的事情。我不知道怎么回去，正好和陈工的981顺路，所以一起回去。结果车等了很久，上去人很多。开了没多久，发现熄火。司机关掉机器再开，启动不了。然后狂踩离合器，汽车居然跑的动了。虽然速度奇慢，不过让我觉得很神奇……</description>
    </item>
    
    <item>
      <title>C&#43;&#43;语言跨系统编程</title>
      <link>http://blog.shell909090.org/blog/archives/263/</link>
      <pubDate>Wed, 23 Nov 2005 03:38:06 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/263/</guid>
      <description>首先我们给这个话题增加一个基础，就是您的C++代码没有用到native的部分。具体哪些部分我会列出让你慢慢检查的，不过用到了还想跨平台，你做梦去吧……
我们假定你代码是在windows的VC++下面写的，因为VC++的转换过去有点麻烦，反向的转换基本可以自动生成。
首先请检查你的头文件依赖性，如果是引用了标准的头文件，那么不需要额外的设定。一般g++的设置中都会自动设定标准的头文件和库。如果引用了某个自己写的文件，那么请检查相对路径是否正确。尤其请着重检查大小写。因为windows不会管大小写的，但是却会将大小写带入*nix。
另外VC++中有一个头文件预编译的加速选项，默认是开启的。将stdafx.cpp(which is empty)预编译次，就得到了stdafx.h的编译结果。在*nix里面我目前还不知道怎么支持，所以stdafx.cpp可以不用理会。
然后请检查标准函数，部分VC++声明在STDLIB.H中的函数其实是VC自带的。用这种函数的结果就是编译100%的失败。遇到这种函数可以自己写一个代替，反正一般都不是特别麻烦。
另外一般不需要关心数据类型和端点型，多数库文件中都会自动处理。不过两种情况需要手工干预。一个是程序中使用了windows特有类型例如DWORD或者linux特有类型le32。这样用typedef重新定义就好了。还有就是跨平台的时候连同芯片类别一起跨过去。这样就要手工确定所有库文件会自动处理数据类型，并且人工定义一组会使用的数据类型扩展宏来处理跨平台的问题。最明显的例子就是int在不同平台的大小问题，对此还有一个特殊的建议就是使用char short long来代替，这三者在所有系统上的长度是相同的。
下面是使用sh脚本来编译代码。其实可以使用make文件来做的，不过俺不会。所以用sh来做好了，反正一般跨平台的程序都不会过于复杂，凑合下就过去了。
g++的编译对象一般是cpp文件，如果是一般的可执行文件，那么编译的指令是g++ *.cpp -o oufile。我这次编译的对象是共享库，所以指令是g++ -shared*.cpp -o outfile。
g++处理extren的比较特殊。如果extren在编译成目标文件时还没有指定链接到哪个符号，那么g++就自动将这个定义为从动态库中引入。不过多数情况下，这应该会出错的。所以要多个cpp文件一起编译，或者使用-c编译到.o文件后再ld起来。否则单个cpp的编译结果根本无法使用。
如果需要使用少量native的方法，也可以按下面说的方法跨平台。
在VC++中定义一个win.cpp，其中将native的方法封装成函数。在主程序中使用C++标准函数和这些函数。
在linux中定义一个linux.cpp，然后用linux的native函数实现对应的函数。在编译的时候略过win.cpp。
VC++中工程引入的时候不要加入linux.cpp。
这样可以保证在两个系统下分别对应不同的函数，当然更好的方法是使用平台相关宏。
附录1，windows下的专有编程技巧：
使用了nativeAPI的绝对无法移植，它们有的甚至无法跨越2000/XP的差异。
使用windowsAPI的，一般不可以移植。这类API多数声明在windows.h中。
使用winsock的没有希望啦，要用socket2才可以。winsock的特征是WSAStartup。
使用了__try{的无法移植，而try{可以。前者是SEH的捕获模块，后者是C++异常捕获模块，在windows下异常捕获是用SEH实现的，不过linux下面不是。linux根本没有SEH。
使用了windows或者VC专用宏的无法移植。
使用C++库和std库的可以移植，包括cout。
使用STL可以移植，不过注意平台差异性。
附录2，linux项目在VC++中引入的方法。
新建一个工程，然后copy所有源代码到工程下面。再然后添加文件到工程，然后F7编译。over</description>
    </item>
    
    <item>
      <title>SrouceForge</title>
      <link>http://blog.shell909090.org/blog/archives/258/</link>
      <pubDate>Mon, 14 Nov 2005 05:33:26 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/258/</guid>
      <description>今天去看了开源代码区，www.SrouceForge.net。总体来说不错，只是慢了点。里面有很多有趣的软件，我还在试他们。刚刚发现一个好东西，truecrypt。
truecrypt是一个加密软件，姑且算吧。用hash和对称加密算法来做加解密，速度非常了得。不过最惊人的地方不是加密的部分，而是实现方法。它先生成一个加密文件，然后在上面加密码（或者密码文件）。然后将这个文件挂载到某个windows没有使用的驱动器上，就好像插入一个加密U盘一样。这个对文件系统完全透明，就我所知，是要写IFS驱动的。但是我在里面没有看到IFS驱动，也可能是封装在程序内部去释放他了，或者是因为扩展名是dll。因为有个主dll啥导出都没有。
总之这个软件我是大力推荐的，如果你打算要一个强加密的系统。使用方便，绿色无污染。使用的时候也没有加解密过程。那么就用它吧。它最合适的地方是放U盘，上面放个文件系统，然后分出点空间来做加密。运行软件后任何系统上（这年头没兄弟还是98了吧）都可以做透明操作，就仿佛你有一个非加密U盘和加密U盘。</description>
    </item>
    
    <item>
      <title>U盘数据隐藏原理和密码系统</title>
      <link>http://blog.shell909090.org/blog/archives/255/</link>
      <pubDate>Mon, 07 Nov 2005 17:25:13 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/255/</guid>
      <description>U盘在windows下有个很好玩的特性。除非不能分区，否则一旦经过分区，windows永远只认第一个分区。也就是说如果U盘映射到sda，那么windows只认sda1。很多隐藏数据或者特殊功能就是利用这个特点来实现的。
现在我们要自己用这个特性，那么就需要自己去操作U盘的数据。也许很多人会想到U盘驱动或者IFS上去。没措，通过那个你可以使用U盘所有特性。但是要操作分区根本不需要这么复杂。根据我的测试，U盘接入后会成为PDn。例如我这里就是PD2，PD0是启动盘，PD1是第二硬盘。利用CreateFile的文件读写机制就可以直接读写U盘的底层数据。
通过这个特性，U盘在我们眼里就变成了一个文件。然后就是如何编辑分区表的问题了。这个嘛，写个程序吧，让他可以通过这种形式来编辑特定分区表，filedisk &amp;ldquo;.PhysiceDiskn&amp;rdquo;，就如同linux下的fdisk命令形式，fdisk /dev/sda一样。
下面就是格式化磁盘，给我们自己的盘一个特殊的类型标示，然后通过我们自己程序的直接读写来定位和操作这个分区。为了保证安全性，我们最好还利用某种方式来进行加密。一般来说我推荐使用PD0（这个肯定存在）的SN和用户键入的密码形成密钥块。</description>
    </item>
    
    <item>
      <title>表达式解析算法</title>
      <link>http://blog.shell909090.org/blog/archives/241/</link>
      <pubDate>Thu, 20 Oct 2005 03:31:13 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/241/</guid>
      <description>表达式解析的本质是什么？是树的构造和消解。其他算法本质上都是树算法。
首先，我们使用Token算法来获得一个Token和Object混合的列表。然后我们将列表展开成为一颗树。这个树符合以下条件。
 树的所有叶子都是Object，无论是数据还是变量。 树的节点上都是算符或函数，其分支数目和算符目或函数参数相等。 单根，无()。  那么我提出一种构造方法。我们假定一种算符passby，然后用Token算法切分表达式并且转换成合适的对象，放置在passby上面。然后我们根据(,,)的规则将整个列表递归表达成同级树。树的每层都是同级的。而后每层都根据优先级从高到低的顺序来计算结果，反馈到上层。由此我们可以得到有效的结果。
但是我没有按照上述方法写解析器。原因是太麻烦，运算时间长，不容易看懂。代码大，维护困难。我问一个同学，你是喜欢精致小巧但是有瑕疵的东西呢？还是庞大严谨没有错误的东西。结果回答说是精致小巧的。好，这就是解析器算法来源。我用了数据结构中的堆栈算法。这种算法在解析正确的式子的时候没有问题，但是精心构造的“看起来”不正确“的式子也可以解析。而且不容易检查堆栈问题。但是谁管呢？喜欢就好。</description>
    </item>
    
    <item>
      <title>Windows Installer修复记录</title>
      <link>http://blog.shell909090.org/blog/archives/240/</link>
      <pubDate>Thu, 20 Oct 2005 01:00:19 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/240/</guid>
      <description>贝壳遇到邪门事了，msiexec的服务死活起不来。这个东西服务态啊，又不好做跟踪的。贝壳无奈只好求助于google。结果找到一个解决办法，适用于windowsXPWindows
Installer服务启动即关闭症状的解决。
Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINESYSTEMCurrentControlSetSevicesMS IServer] &amp;quot;ImagePath&amp;quot;=- &amp;quot;ImagePath&amp;quot;=hex(2):25,00,53,00,79,00,73,00,74,00,65,00,6d,00,52,00,6f, 00,6f,00,74,00,25,00,5c,00,53,00,79,00,73,00,74,00,65,00,6d,00,33,00,32, 00,5c00,6d,73,00,69,00,65,00,78,00,65,00,63,00,2e,00,65,00,78,00,65,00, 20,00,2f,00,56,00,00,00  注意最后是两个回车。
特存留念，方便自己和大家以后使用。</description>
    </item>
    
    <item>
      <title>语言和人</title>
      <link>http://blog.shell909090.org/blog/archives/239/</link>
      <pubDate>Wed, 19 Oct 2005 22:49:41 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/239/</guid>
      <description>GiGi和Nancy先表激动，偶语言暴差，不是你们脑子里面想的那种语言啦。
今天用java，忽然想到以前有趣的比喻，自己也来写一个。
C/C++：黑客的语言。外人根本看不懂。
JAVA：大学教授的语言。逻辑性超强，但是太过理想化太空洞。
ASM：文学家的语言。每个人说出来另外一个人都有另外的理解。
BASIC：傻瓜的语言。拣最简单的说。
DELPHI：神的语言。快要绝迹了……
SQL：我们的语言。就是英语吧……
UML：哑巴的语言。……
XML：全世界的语言。</description>
    </item>
    
    <item>
      <title>IE内嵌对象提取方法</title>
      <link>http://blog.shell909090.org/blog/archives/237/</link>
      <pubDate>Wed, 19 Oct 2005 03:49:29 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/237/</guid>
      <description>我发现很多MM喜欢在blog里面嵌入各种对象，例如flash或者music。例如光MM的光良的歌，功MM的如果的事。一般来说要将这些内嵌对象保存下来是比较麻烦的。因为内嵌对象直接播放，没有引用和连接，那么用连接跟踪器就分析不出结果。
通常来说URL是通过阅读代码来获得的，但是有的时候网页是通过javascript来引用的。这个时候代码分析和代码分析器（例如Mozilla内嵌的那个）就无效了。一般来说是用sniffer来解决问题的，贝壳以前用的是iris。后来出现了种种的特种sniffer分析器（其实分析cap抓包文件就好了），所以这个问题看似就解决了。但是恶搞是没有境界的，还有别的解决方法吗？
贝壳首先想到的是COM分析和跟踪，跟踪COM的dll载入过程和接口参数。这样当然可以获得对象，问题是成本太高了。然后贝壳又设想了文件钩子，在向缓存区域写入特定文件的时候hook到。然后导出这个文件。但是文件确定的问题太困难了，假如同时有1000个内嵌的mid，这个方法等于没用。这个还不是最严重的问题，最严重的问题是这个解决方案可不比特种sniffer简单。
后来贝壳在用ProcExp（www.sysinternal.com出品）的时候发现这个软件可以跟踪进程的句柄。这样的话IE内嵌对象必定在缓存区缓存，COM在打开的时候肯定使用了句柄。我们只要跟踪所有文件句柄，其中不会有很多的。（其实这个方法和前面的方法一样，要确定文件名是个困难的事情。）然后将文件的路径复制到console里面，运行下copy指令，文件就出来了。这个是我想的到的最简单的IE内嵌对象提取方法了。</description>
    </item>
    
    <item>
      <title>可信任路径计算</title>
      <link>http://blog.shell909090.org/blog/archives/223/</link>
      <pubDate>Sat, 08 Oct 2005 02:29:20 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/223/</guid>
      <description>可信任路径计算，其实只是图管理的一个应用而已。不过可以结合计算方法，来精确度量过程的安全程度。
下面提到实体，指以下三种可能。一，法律人。二，计算机。三，协议对象。
以下提到连接，指以下两种可能。一，物理联系。二，逻辑联系。
我们假定用户实体要产生活动，则必须信任某些实体。例如要存钱必须信任银行，要买书必须信任出版商和作者。如果用户要做某项活动，必须信任某种实体，那么用户的活动安全度，则于所信任实体和连接方式，以及连接评估实体相关。
我们假定所有连接都会产生一个权，这个权由某个信任实体直接给出。
我们假定用户对自己的信任是1。
我们假定连接存在以下五种类型：
 请求。有向关系。 应答。有向关系。 依赖/依存。有向/无向关系。 包含于，有向关系。 互斥，无向关系。  利用以上假定，我们可以计算某个系统行为模式对某个用户的潜在风向。
先停止写，去看UML建模。根据分析结果，计算和信息的相关程序有相当关系。</description>
    </item>
    
    <item>
      <title>剥离管理模型</title>
      <link>http://blog.shell909090.org/blog/archives/221/</link>
      <pubDate>Sat, 08 Oct 2005 01:07:27 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/221/</guid>
      <description>有一就有二，老人家脑子不好，大家多多见谅。
剥离管理模型，分三个层面。对象层，数据容器，应用层。
对象层来说，分三组对象，本人，电脑，第三方。分析安全特性时候可以加上攻击者。本人指每个管理的主体，电脑泛指所有可用的电脑对象，每个电脑对象区分安全级别。第三方泛指所有和本人相关的合作者，包括电脑和个人。攻击者分为电脑和个人。
数据容器层来说，区分的是数据的类型和安全类型。以个人来说，具备全局配置，软件配置，安全区域三个部分。以机器来说，包括本地数据，本地配置和本地程序三个部分。第三方的合作关系放置在安全区域和本地配置中。
应用层是关系建立的模式，具体来说就是路径信任计算。回头专门写吧。
一个机器运行的应该是和机器和用户无关的本地程序，根据本地配置来运行具体程序参数，个人软件配置覆盖本地配置。
……脑子乱了，回头慢慢来写吧……头痛啊……还有个可计算信任路径的问题呢……
先停止写，去看UML了。</description>
    </item>
    
    <item>
      <title>核心集合理论（最小集合）</title>
      <link>http://blog.shell909090.org/blog/archives/220/</link>
      <pubDate>Fri, 07 Oct 2005 20:40:40 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/220/</guid>
      <description>本来北京游记都写不完了，中间插一个技术论点很不伦不类。但是老了，脑子不大好，不记下来就忘记了。大家姑且原谅吧。
编译器理论中有中叫做核心构造和自构造。首先通过A语言写出B语言的初次编译器，然后通过初次编译器编译用B语言写的B语言编译器本身，形成二次编译器。逐步叠代，形成稳定的核心编译器，然后通过核心编译器编译层次1，通过编译器和层次1编译层次2，逐步递推，形成最终release的集成编译器。最出名的产品就是IBM公司的Pascal语言。（还有多少人在学……世代更替啊）
同样在离散数学的数理逻辑算符体系中也有一个最小构造集合。通过最小构造集合的有限次叠代可以产生全集合的等效结果。所以又被称为核心集合。
大家可能会认为比较无聊，不过不才贝壳我现在搬到语言上套用，看看这种理论是否可行。
 首先通过单词表等等对比的形式教会最小的单词集合。 然后通过标准语法格式教会最小的语法集合。 通过标准语法集合解释扩展单词和语法集合1。 逐次叠代教会大多数的单词和语法。 着重解释如何学习新的单词和语法。  按照我们使用中文的习惯，还有我使用计算机的经验。我们不是什么都知道的。很多人不知道二进制(binary)是什么意思，但是他们可以很快的学会。如果我们不知道二进制的英文，我们很习惯是通过中文词表的方式来获得其中的意思。但是真正英语好的人都是通过交互的解释来获得意思的，这样的好处是具备非常好的动态性能。因为很多英文单词没有贴切的中文解释，语法更是天地之别。通过英语本身获得英语知识的能力可以让一个人不但具备英语能力，而且可以根据不同环境变化自己的英语。
通常来说，一个人学习语言的最初是模仿，通过学习周围人的发音和对应的可能意义来分辨词素的音和意。至于形来说，符号文字一般都具备相当的音形对应性，象形文字则是意形对应性。这个可以通过后天的刻意学习获得，而且也无关人的交流。毕竟在美国也不是完全没有文盲的。然后音意的对应性存在一个问题，就是循环解释。我们可以通过一个基础的词意去解释另外一个，但是语言是唯一无法用语言来解释的东西。一个词的解释最后永远涉及他的自身。所以我们通过一个最小单词和语法的构造集合来解决这个问题。毕竟发展出自我独立的语言体系结构是我们小时候做的事情，现在完全没有必要这么麻烦。</description>
    </item>
    
    <item>
      <title>椭圆曲线算法</title>
      <link>http://blog.shell909090.org/blog/archives/212/</link>
      <pubDate>Wed, 28 Sep 2005 15:22:17 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/212/</guid>
      <description>frist of all, today is google&amp;rsquo;s 7th brithday. Happy brithday.
这篇是接上篇windows版本论的，主要讲述windows的SN算法和椭圆曲线算法。
windows的SN长度是25位，大家都知道了。但是大家可能不知道，windows的SN是base24的
UUCode算法的结果，所以里面应该只有以下字符BCDFGHJKMPQRTVWXY2346789。如果有别的就不用试了，肯定假的。在UUDecode后应该有114bit的数据，其中只有31bit的有效数据，我们称为data。
具体椭圆曲线密码体系就不说了，大致来说，和RSA一样，是属于非对称密钥体系。RSA是利用大质数分解构造的陷门函数，椭圆曲线利用的是二次方程的整数解。应用方法说明如下：
先利用data和private key经过SHA-1算法hash出一个hsah，取28位。
利用data和private key经过椭圆曲线算法得到sign，55位。
将(data, hash, sign)三元组UUCode出SN。
SN上面算法如下：
用SN做UUDecode得到(data, hash, sign)三元组。
利用sign和hash可以求出private key。（贝壳这里有点看不懂） 利用data和private key经过SHA-1算法hash出一个hsah，取28位。
效验private key。
我们的破解程序很明显在根据public key求private key，正好是要算死的那种。幸好微软为了考虑用户输入SN的麻烦，所以sign才55位。否则我们这辈子休想算出一个号来。</description>
    </item>
    
    <item>
      <title>今天累死了</title>
      <link>http://blog.shell909090.org/blog/archives/207/</link>
      <pubDate>Wed, 14 Sep 2005 03:39:42 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/207/</guid>
      <description>今天做javabean的第一个例子，累了个半死。先去DiabloII，等等再写。
OK,大致来说，今天算一个不错的日子。先是jsp示例跑起来了，还有整个的环境基本也熟悉了。用起来比较方便。（注意我说比较，因为混蛋tomcat经常要重起）。而且用户管理系统作为例子也可以使用了。先恭喜下。
不过今天累了个半死，到最后全是接口不严谨导致的错误。大小写，拼写错误，空格，转义符。搞到最后完全在拼debug能力。痛苦的要死。回家的时候还遇到杨浦大桥堵车，结果……堵了半个多钟头。</description>
    </item>
    
    <item>
      <title>Excel财务统计</title>
      <link>http://blog.shell909090.org/blog/archives/206/</link>
      <pubDate>Mon, 05 Sep 2005 05:44:41 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/206/</guid>
      <description>最近自己赚钱了，所以要管理自己的开销了。用Excel做了一个财务统计系统，比不上专业的财会，不过至少蛮好用的。有兴趣的可以留个话，我Copy你份，保证好上手。
主要分两个部分，一个是财务明细，一个是财务报表。只要在明细里面填写上每笔收入支出的日期和类型，并且再填写用途和备注。报表中的宏就会自动统计所有类型的收支，自动算出每月收支，并且计算累积资金。（就是你现在手里应该有多少钱啦）然后还会自动计算支出的模式（例如消费多少比例，再投资用于学习多少比例等等），和收支比。最后就可以看出自己的钱是怎么花出去的，还有手头是否比较紧，或者是否可以考虑多花点钱或者把活钱存银行等等。
目前偶的平均每月收支比是0.6，而其中用于学习的开销只有一成……</description>
    </item>
    
    <item>
      <title>列一下我要学的东西</title>
      <link>http://blog.shell909090.org/blog/archives/205/</link>
      <pubDate>Sun, 04 Sep 2005 10:31:40 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/205/</guid>
      <description>到了单位也不能固步自封，要学的东西太多，让我列个表然后慢慢学吧。
1.java编程技术，单位里面的吃饭家伙。
2.UML建模和模式，也是吃饭家伙。
3.linux使用维护，服务器组建要用的。
4.linux bash脚本编程，深入linux的台阶。
5.COM接口编程，算是一个漏洞吧。
6.项目管理，以后的大方向。
7.linux软件编程，兴趣吧。
8.linux内核分析，含金最高的东西，对了，还有minix。
9..net编程构架，多个路子。
上帝，我领悟学海无涯的意思了……</description>
    </item>
    
    <item>
      <title>IBM开发者大会</title>
      <link>http://blog.shell909090.org/blog/archives/204/</link>
      <pubDate>Fri, 26 Aug 2005 21:44:18 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/204/</guid>
      <description>因为某个时间表上无法预料的意外，公司让我出席了IBM开发者大会。具体来说是这样的，Boss和Professor钱was surposed 2 attended the meeting。但是Professor钱临时出席了另外一个由Collage driver的meeting。所以公司内部就剩下了一个技术人员，不幸那就是小弟me。
总体来说，这个会议很无聊。头天早上是入场和checkin。每个人领了一个小本本，
which IBM call them 胸卡。it&amp;rsquo;s sounds string, isn&amp;rsquo;t it？里面有整天的安排，先是致辞，然后是两个大人物上去分别解释管理和技术的总理念。总的来说，这次等于是Rational系列产品的宣讲会。里面充斥了Rational系列产品解决问题的案例，无聊。中午的午餐在恒隆，咖哩羊肉，很好吃。可惜速度慢了点，可能是人太多了，造成瞬时响应延迟。然后下午是重头。讲解RSA的三个层面。我开始还当是RSA加密算法，后来发现不是。而是一个Rational家族的产品，构架平台吧，好像。听的我困的要死，不过主要思想明白了。大致来说就是两点，一个是逐步精化，追求可变的循环开发过程。一个是由顶至底，层层西分的构架模型。而IBM提供的就是自动化工具。
简单来说，首先由需求分析出业务模型，然后由模型建立UML的计算无关模型。再下去就是平台无关模型，加入了业务中的细节和计算。然后是平台相关模型，由转换师协同IBMRSA转换成一个平台（例如java或者net）相关模型。最后编译器转化成代码（这个也是当做模型的）。最后利用工具做黑盒和白盒测试，得到性能参数和业务吻合评价，再次调整业务模型，重复流程。这样在两个协调人员的帮助下，由eclipse贯穿，经由系统分析师，建模人员，转换师，测试工程师（还有一个我忘记了）叠代循环，得到最终的代码。
最后节课是电子商务的，我看是中级课程，没去。直接跑去楼下的上机区去玩linux，IBM用的是Redhat或者SuSE，看别人修系统密码结果被VMware虚拟出来的sda1弄的乱没办法。好玩。不过收获蛮多的。然后直接跑去了太平洋八百伴那里的分店，去买电脑，公司采购。CIV2.4D533CPU，KM512MDDR533RAM，ASUSP4S865-XMainBoard，GeForce4FX5200 128M128bits，ST7200.80G2M，嘿嘿，不错吧。4000，带送货。
然后今天起太早了，本来有来就不错了。我先去了一个UML2.0的讲解会议，总体来说就是元素建模嘛。然后是.net framework下面RSA的支持，不过不知道怎么讲着讲着变成黑盒白盒测试了。最后是软件工程和软件关系工程，不过怎么听都在宣传他们的某个产品RPM，完全和理论实践无关阿……无奈。
中午吃午饭，还是老地方，咖哩羊肉，这次速度快了。然后换手杨总进去听管理，我下午跑到公司，安装系统去。结果我和小马统统down在了installnation of winXPSP2VLK上海政府版上面。后来发现联想OEM的是好的，我Ft。连通了交换机，上网加了N多东西，最后基本全部完成了部署，就是死在了VmWare的安装上面。真见鬼，明天用自己用的版本上去试试。</description>
    </item>
    
    <item>
      <title>链式网络协议封装</title>
      <link>http://blog.shell909090.org/blog/archives/202/</link>
      <pubDate>Fri, 12 Aug 2005 22:51:47 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/202/</guid>
      <description>今天设计了一个通讯接口，准备运行在TCP/IP上。实现反扫描，反通讯分析，反IDS，反嗅探。其中反扫描需要使用Sniffer来做侦听诱导或者是反穿诱导（我更倾向后者），反通讯分析需要封装整个协议到ICMP层或者一些比较不容易被察觉很跟踪的协议层上去，还要兼顾反IDS的行为分析。最后反嗅探需要数据加密。这些能力还要能动态叠加和消除，这样只有设计一个动态的通讯接口了。
我先设计了一个虚基类，保证用于每个子类继承后可以自动产生链。通过链式规则，我们从上层将数据层层递推。任何层都可以发出数据，并且终止链的递推。基类有六个虚方法，链接，监听，发送，接收，判断数据进入，关闭。构造函数可以接收一个基类指针作为参数，并且传递给基类构造函数。基类构造函数将会自动产生链，并且加以管理。每次我们调用某个方法时，虚方法会自动按照链的结构依次被调用。同时基类的管理作用也作用于缓冲区，使得所有子类构成链后共享同一个缓冲。当我们设定缓冲并且发送时，最上层的发送函数就被调用，然后处理缓冲内容（如果这个子类是反嗅探用的话）。然后调用下个链上的节点，下个节点继续处理。每个节点都可以决定是否要终止调用链。
我正在编写并且测试整个系统，如果运行良好的话，我准备将虚基类的代码和部分的实现代码公开。可能数据加密方法不会公开（我可能会使用一些比较巧妙而非严谨的方法来保证安全）。使用者可以利用整个接口来收发数据（即使不是网络通讯），并且自行扩展能力。当然，作为普通的网络通讯接口，这个东西也是比较好用的。</description>
    </item>
    
    <item>
      <title>ViaVoice初步试用评估</title>
      <link>http://blog.shell909090.org/blog/archives/200/</link>
      <pubDate>Mon, 08 Aug 2005 23:20:10 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/200/</guid>
      <description>今天Boss打字累了，准备在公司内部加个加速输入的方法。说实在我对此没有啥想法，对于我来说打字说不定还比说话快。但是总不能因此就和Boss说以后我来打字吧。所以大致想下来有三个方案，一个是ViaVoice，一个是扫描笔，一个是写字板。
扫描笔看来是最好用的一个，只要不是手写体，一扫全部搞定，没有要动脑子的部分。但是也只能用于一般印刷体，手写体花体啥的都不行的。成本也是最高的。
其次就是写字板，不过这个东西纯属鸡肋。写字的话一般人还不如打字，只有老头老太这种学不会打字的人才考虑写字板。虽然还有签名画画的辅助功能，不过有多少机会能用到呢。
最后就是ViaVoice了，成本可高可低。（IBM原装USB话筒啥价钱啊）一般来说是最廉价的快速输入方法。不过就是还要费心念字，而且要经过语音训练。公司鉴于经济价值上的考虑，决定使用ViaVoice。（说明白就是便宜啦，毕竟不好用当二十白花还可以换别的。要用了扫描笔不好用也得用了） 家里用ED下了一个ViaVoice9.1Pro的光盘版，然后安装，现场就有一个高级话筒。经过将近一个钟头的测试，试用和训练。我总算掌握了成功让ViaVoice识别九成以上文字的方法。简单来说，就是说话要靠近话筒！每次我嘴向后移动一厘米，识别率立刻降低两成，我Ft……在离话筒一厘米左右，说话可以直接拾音但是气流又不直接接触话筒的时候效果是最好的。在良好的拾音条件和阅读速度基础上，识别率还是令人满意的。不过我很奇怪，ViaVoice的低系统耗用识别非常差，高耗用也没有增加多少耗用，为啥IBM还这么定位呢？尤其是默认还是低系统耗用……
总的来说，ViaVoice的试用结果还是让人满意的。如果正确使用，周岚的输入速度说不定尤在我上。但是如果运气不好，恐怕就……难说了。对于我们这种打字像吃饭一般的人来说，这种东西只是减轻负担的辅助工具，毕竟天天打字手还是会累的。（虽然念东西多了也会累，尤其是念那个训练文本的时候。）对于输入速度比较慢的人来说，这个不啻为一个非常好的输入手段。可惜他和扫描一样，要求你至少会一点的输入法。否则一旦出现根本不搭边的错误就无法修改了。而手写板就可以避免这点，理论上说手写板是不会遇到无法识别的东西的，除非你写的东西我都不认识。</description>
    </item>
    
    <item>
      <title>网络实施</title>
      <link>http://blog.shell909090.org/blog/archives/199/</link>
      <pubDate>Wed, 03 Aug 2005 21:11:02 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/199/</guid>
      <description>最近上班了，实在很懒。回来没事做，上班没做事，累嘛累的要死，天天跑来跑去。为了拿钱阿……
很久没写过blog了，最近也没有时间研究啥技术的。就把在单位里面实施的一个网络系统描述下，权当技术文好咯。
首先是原来状况。一个路由连接外面，路由密码没有更改（太扯淡了）。内部一个10M的大HUB（还不是交换机，我可以嗅探的哦），九台机器，其中两台本本，不定量的本本随时接入。台式win2k，本本XP，结构很干净，不过补丁一个没打（汗……）。有一个服务器，主要打印使用，别的也用。OK，下面着手实施整体网络。
首先别的不说，路由密码我会放着就是白痴了。然后是一个个打补丁（还要看人家机器空不空，头痛阿）。然后用SSS扫描内部，果然漏洞少了。下面修改每个机器的配置，禁止SMB连接中的不严格现象（里面开了SMB文件共享哦，贝壳改成了允许的话使用加密形式），然后禁止客户机器的空连接和guest用户。打印服务器要打印，关闭了guest管理不大方便。这样客户上面基本没有漏洞了。
然后主机上面转换一个空盘到NTFS，实施大共享，做成文件服务器。给每个客户机做一个映射，这样基本可以将零散的文件共享集中到主机上，方便共享和备份。然后主机上面做一个FTP，路由上面开启部分路由映射进来，这样做成了远程FTP。严格来说，这样的FTP是瑕疵的，因为贝壳没有申请外网域名映射。FTP在被动方式时候发送的连接字符中IP是内网IP。如果FTP软件严格照来的话是连接不上的。但是FlashFXP等软件在PASV模式的时候只要返回数据中的端口部分，这个被映射了，所以可以正常使用。
然后在集中共享上放了很多软件，声明要装软件能从这里拿就必须从这里拿。找不到的下载安装后要放这里备份。这样削弱了软件后门的隐患。同时推荐了Mozllia，防止网页木马。使用Iris检测网络，防止内部攻击。其实这里应该放IDS的，而且应该更换成交换机，增快速度，防止嗅探。基本实施就结束了，等大家把文件整理到集成共享中，就可以备份刻盘出来了。</description>
    </item>
    
    <item>
      <title>病毒编年史-当代</title>
      <link>http://blog.shell909090.org/blog/archives/193/</link>
      <pubDate>Thu, 14 Jul 2005 00:15:35 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/193/</guid>
      <description>现代病毒的最大特征是混合化，商业化。可能同时具备文件病毒，木马，蠕虫的特征，很难界定其归属。也可能具备多种传播途径，在多方向传播。同时可能具备多个部分分别载入。病毒的意义也渐渐从无明确的多种意义渐渐转向商业化。
AD 2001.9.18，混合代码出现，代表作 W32.Nimda，作者未知。
蠕虫通过电子邮件发送自己，搜索开放的网络共享，试图将自己复制到未打补丁的或已经有漏洞的 Microsoft IIS 网站服务器上，是一种既影响本地文件又影响远程网络共享文件的病毒。
贝壳评论：
可以看出，蠕虫同时具备了邮件蠕虫，漏洞蠕虫，社会工程蠕虫三者的特征。并且蠕虫会在系统中留下一个后门，这又具备了木马的特征。这正是现代病毒非常明显的特征。
AD 2002.5，蠕虫中的病毒，W32.Klez中的W95.CIH.1049。上面曾经说BackOrifice2000感染过CIH，这次CIH又感染了W32.Klez蠕虫，W32.Klez的大规模流行使得CIH卷土重来。这是首次由大规模蠕虫引起的病毒流行。
AD 2003，IM混合型病毒大规模流行，代表作 QQ尾巴。
贝壳评论：
QQ尾巴是比较有趣的混合型IM病毒（虽然很多人不这么认为……）。通过IM传递一个消息，驱动你去某个网站访问，然后通过IE漏洞使你中毒。结合了IM传递，AcitveX或者脚本病毒，蠕虫三者的特征。这表明现代的病毒正逐渐融合各种技术，各个有害代码的严格分界线正在渐渐消失。
IM病毒有很多有趣的分支，无论技术如何变革。其核心都在IM传递的语言如何驱动人获得病毒。最近有直接发送病毒文件的例子，还有通过URL用户名结合的特定传染的（http://www.sina.com.cn:80@18.com/1.scr）。甚至有你回复是否中毒时对方自动应答没有啊的例子。这个过程中一般用的是社会工程攻击的知识，通过人的心理去驱动人。
AD 2003.2，W32.SQLExp.Worm SQL注入病毒，相信众多网管一定感触多多。
AD 2003.8，W32.Blaster.Worm 史上赫赫有名的“冲击波”病毒。步了红码的后尘，也是一个蠕虫。不过2K/XP双溢出的特性加上2K中一分钟重起的“有趣”特性造就了它的名声。曾经有人说病毒自动设计了一分钟重起，防止更新补丁。根据贝壳的分析，这个应该是溢出失败导致系统进程关闭，而后系统自行决定重起的。这种防止下补丁的方法既不实用风险也大，而且对于病毒传播没有贡献。只有呆子才用他。
AD 2003，“无法删除”的3721。3721是一家公司的网络实名解决方案。为了防止软件被删除，该公司使用底层驱动阻止核心文件和注册表键值被删除，导致系统效率低下。
老实说我对诸多解决方案没有啥兴趣，严格来说左解决右解决就是为了抢实名到底谁用的问题。但是这个事情引申出来一个问题，无法删除是否是恶意代码。如果说非恶意吧，他确实的违背了用户的意志。要说恶意吧，谁能说防删除就是恶意呢？如果这么说，防修改的保护卡是否是恶意呢？同时，这个技术也为诸多病毒提供了借鉴。可以想见将来的诸多病毒左右删不掉的场景，届时恐怕就头痛多多了。
另外贝壳插句话，谁写个linux引导专门对付3721之类的东西阿？我已经被问的脑袋大死了。这个东西DOS下删不了，上NTFS4DOS是ReadOnly的。linux支持了NTFS的RW挂载恐怕内核在软盘上已经放不下了，那就是说要光引导或者是USB引导咯……多软件也可以考虑。哪位大大，出一个吧。
PS.后记，病毒编年史的更新曾经一度中断。最后贝壳偶尔想起是否是文字中的某些病毒特征码导致的呢？结果果然如此，哎……此天意也（旁：又开始打太极了）。</description>
    </item>
    
    <item>
      <title>病毒编年史-近代</title>
      <link>http://blog.shell909090.org/blog/archives/192/</link>
      <pubDate>Thu, 14 Jul 2005 00:05:58 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/192/</guid>
      <description>近代病毒的特征是多样化，结合化，跨平台。对社会工程的依赖大于对技术问题的依赖，传播中对于网络的依赖大于对软盘的依赖。种种病毒多数是通过社会工程方法或者漏洞来传播的。此时也大规模的兴起了后门运动。满世界飞的后门造就了很多Cracker，有害代码的破坏力展露无疑。
AD 1998，木马后门首次为大众所知，代表作 Back Orifice，作者 死牛崇拜(Cult Dead Cow)。
贝壳评论：
1998年真是电脑界风云之年，win98出世，BO发布，CIH流行，java病毒出现，到处充满了生机（如果这个算是生机的话）。BO作为木马，不是最早的一个。但是作为近代木马的鼻祖，BO当之无愧。木马自Unix产生以来就出现了，最早是管理员用来方便自己进出的后门，或者诱骗套取密码用。BO发布的木马可以在win9X系统上开个洞，使得别人任意操控机器。当今世界九成以上的破坏性代码（或者说恶意代码），均结合了这个特点，在侵入别人的机器后会留下后门方便作者进出，或者窃取用户各类密码。
说到死牛崇拜，还有个好笑的事情。在美国拉斯维加斯第七届“黑客”周年大会上，黑客组织“死牛崇拜” 推出特洛伊木马型黑客软件Back Orifice 2000。然而15日“死牛帮”证实其推出的正式版“BackOrifice2000”软件光盘确实感染了CIH病毒……
AD 1999，中国木马兴起，代表作 glacier，作者 西安电子科技大学 黄鑫。
冰河为国内相当优秀的木马，即使在国际上也非常有名。现今很多出名的黑客都是利用冰河迈向通往黑客道路的第一步的。黄鑫的冰河让很多人体会了做黑客的快感，更让很多人了解了网络安全的重要性。此人目前为网站“安全焦点” 的工作人员，水平极高。在安焦论坛上经常可以见到，大家不妨去过把名人瘾，要两个签名来留念……
AD 1999，Millenniu蠕虫出现，作者未知。这是迄今为止最没有名气的一种病毒，只有一个人报告受到感染。因此此病毒入选最没有名气病毒奖……
AD 1999，邮件蠕虫兴起，代表作 W97M/Melissa，作者 David L.
Smith。不要被骗了哦，W97M中指的是win97。时间大约是99年（贝壳在symantec的安全响应中心99年才找到它的资料）。
AD 2000.5，邮件蠕虫和脚本病毒的结合，代表作 VBS.LoveLetter，作者未知。
AD 2000.10，嵌入式系统病毒出现，代表作 Palm.Phage.Dropper，作者未知。这是一个感染PlamOS的病毒，感染能力很小。但是代表嵌入设备病毒首次出现。
AD 2000.11，PHP网页病毒出现，代表作 PHP.Pirus，作者未知。
AD 2000，史上最出名的本地漏洞出现，代表作 win2000，作者Bill.Gates。
贝壳评论：
windows2000的输入法漏洞可以号称是计算机史上最出名的漏洞了，直到去年还出现了一种新的表现形式。输入法漏洞以其简洁有效，立竿见影而著称。任何人都可以轻易学会，从而进入不是自己的系统里面去。漏洞总共有三种表现形式。一个是登陆时使用输入法，察看帮助，Internet属性。一个是登陆是等待，直到KV系列杀毒软件跳出来（怎么又是你）。一个是在特定输入法中按特定键序列，导致缓冲溢出。（这个去年才出来） AD 2001，史上最出名网络漏洞，UNICODE绕回漏洞出现，代表作 IIS5，作者Bill.Gates，发现者NSFOCUS。
贝壳评论：
这个漏洞是下面的红码的基础，红码在窜入新的机器前就扫描此漏洞。并且在远程下载病毒执行。漏洞简单来说就是在UNICODE解码的时候检验不严格，导致可以执行任何一个同盘上的文件。严格来说，如果在IIS或者NTFS安全属性上设置过的话，或者使用了安全策略和IPSEC，漏洞都不会作用。但是漏洞之所以出名就是因为连IIS都是大家糊里糊涂装上去的……
其攻击形式大致如下： （此处省略，否则无法发表） 想当年我的IIS上面一半都是这种扫描代码。虽然我开了各种安全配置，而且上了补丁，上了IISLock。不过机器不停跑这种东西还是非常讨厌的，最终导致了贝壳的个人网站的倒站（太麻烦了）。
AD 2001.8，新一代蠕虫，红色代码II出现。
贝壳评论：
红色代码不同于以往蠕虫的是，它不使用感染文件的方法驻留在系统内部，因此可以简单的通过重起解除感染。但是问题在于，如果没有打补丁，重起后会重新感染病毒。这点和Blaster很像，但是Blaster还会定时重起，导致无法下载补丁。由于很多默认安装的个人win2000系统安装了没有必要的IIS组件，导致了该病毒大量感染。其声势不在Morris之下。
AD 2001.9，反蠕虫蠕虫，W32.BlueCode.Worm出现。此病毒的目的是为了解除红码的流行。在利用和红码相同的漏洞入侵系统后，此病毒会去下载补丁并且清除红码。而后寻找下个中毒机器，并且消灭自身。作为反蠕虫蠕虫，早在磁芯大战(Core War)的年代就出来过了。不过其合法和有效性一直没有得到肯定。
近代的结束年月并无法详细划定，不过我将其定为2001年9月。因为此时出现了一种混合型的病毒，结合了蠕虫，后门，病毒的特征。此后的有害代码正向混合化的方向发展。</description>
    </item>
    
    <item>
      <title>代码和数据</title>
      <link>http://blog.shell909090.org/blog/archives/187/</link>
      <pubDate>Sat, 09 Jul 2005 23:14:42 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/187/</guid>
      <description>从某种意义上说，代码即数据，数据即代码。不仅仅是因为无论何种代码，何种系统，什么格式，什么CPU，代码都是以数据方式存储的。更重要的是，设计良好的数据会自动驱动程序的运行。使得精简的代码发挥意外的功能。最出名的例子有XML，MFC的MessageRoute。或者从某个意义讲，所以代码都是数据驱动的。
现在的所有数据结构都是基于三个内容，数据，列表，指针。数据，即内容本身，也可以认为是某个数字。毕竟电脑是按数字方式编码所有数据的。列表，指某个定长数据区域。指针，即使用某种方式指向的另外一个数据。例如寻址编码。按这三种内容，可以构建出多数的结构来。例如树，图，列表，等等。
如果基于另外的数据方式，是否能构建出另外的数据结构呢？这种结构是否能更好的驱动程序的运行，或者使得程序更智能化的运行呢？我不知道，不过按照我的预感，遗传算法可能是其中的突破口。</description>
    </item>
    
    <item>
      <title>纪念偶可怜的硬盘</title>
      <link>http://blog.shell909090.org/blog/archives/183/</link>
      <pubDate>Mon, 27 Jun 2005 06:47:26 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/183/</guid>
      <description>今天偶的硬盘坏了，感觉是……终于坏了阿。嘿嘿……
偶的硬盘从两年前就开始不好了。其实也没啥好奇怪的，一天二十四小时工作，工作量奇大，天天拖BT。而且还没有好位置，都是用电源线悬挂利于散热（偶用双硬盘的）。能好的了才奇怪了。
不过这个硬盘也算比较奇怪的了，我在服务器上工作的硬盘还没有坏，他先去了。按说服务器上的硬盘无论工时还是工量都比较大，但是却坚持不坏。工作站养护的还算不错，但是又死机又坏硬盘的……看来下次这家DIY公司不能去。（还去啥，都关门了）
两年前，偶的硬盘经常可以听到敲击声，伴随服务器假死状态（整体挂在这个点状态上了）。同时某些部分的数据有CRC错误，读取这个数据时就会引发上述状态。于是偶按照坏区处理，先将整个硬盘格FAT32，重格NTFS，然后重分。将最容易引发的地方分离，然后Copy中等文件，将引发错误的文件保留。于是整理出一个还可以用的硬盘，勉强度日两年。
就在前些日子，偶机器从学校永久的带回家来。由于容易引发死机，所以整个机器经常就裸露在外，利于散热。恐怕加速了硬盘的老化。在一次Copy了大量的ED数据上去准备做压缩的时候（偶好容易从ED上拖下来的阿），硬盘突然狂响。重起后继续响，并且兰屏，再重起……没有了。硬盘整个从系统里面消失了，BIOS都找不到硬盘。看来是硬件电路一起废物了，彻底没救了。
算了算了，反正最近下ED+BT，下的我的硬盘小的要死，正想换个新的。新买个120G的得了。原来我是两个40G分别在两个电脑上，后来貌似就因为这个硬盘不稳定，所以买了个新的硬盘放在WorkStation上。然后Server为了扩容，又添加了一个80G。于是形成了惊人的双电脑双硬盘。然后今天在WorkStation上报废了一个SecondaryDisk40G。所以我买了一个希捷120G放到了Server上面，将原来最初40G的SecondaryDisk（最初是Server的PrimeryDisk）上面的数据移动过去，重新组织了下。和新的80G组成200G服务器双硬盘组，两个都是新的。WorkStation上面换上一个原来的40G作为SecondaryDisk，重新形成80G双硬盘。这样两边都比较稳定，没有大变动。
然后两边都是数据狂移动（40G的数据换位花了我两个钟头，平均数据传输速度是6M/s，实在慢了点，用我自己写的高速移动程序又不放心，嘿嘿，还没有测试完呢）。又重新整理所有硬盘（总算有空间了），打系统补丁（老死机），升级杀毒，整理系统。整整忙了一个晚上，总算将整个系统稳定了下来。
哎，好久没做系统维护的动作了，真的很不适应。八百伴电脑商场搬地方了，新的商家愣是没找到。维护上也头痛的要死……都记不起来了。最头痛的是我多了700的外债，目前已经达到2200，足足是将来三个月的薪水（当然，要吃饭先的）。不过无论怎么叹，硬盘也是回不来了，就像过去一般。所谓永恒和稳定只是虚无的东西，谨以此文纪念我的硬盘。
呜呼，尚觞。</description>
    </item>
    
    <item>
      <title>blogs</title>
      <link>http://blog.shell909090.org/blog/archives/179/</link>
      <pubDate>Sat, 18 Jun 2005 20:18:52 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/179/</guid>
      <description>今天觉得MSNSpace还不错，呃，我没有在做广告。刚刚发现上面可以加入音乐列表和图书列表……虽然这些都需要外置空间的支持，不过，it&amp;rsquo;s better then nothing。今天加了五首动漫曲和六首吉他曲。回头再改。我实在无法在更改IP的时候更换太多的URL的IP。也许我真的应该申请一个虚拟域名了。
OK，最近还不错，除了昨天晚上发神经的和real抱怨了通中国的软件业，还有和Gigi抱怨了通女人和结婚。其余一切OK，在此谢谢Gigi和real。
另外，最近开始分析NTFS格式了，看了MFT的说明，不过好头晕。现在下了一个linux内核中附带的NTFS解析部分在看。呵呵，也许我应该先吧前面的想法搞定，不是吗？不过现在不管这些了。反正我只是在玩电脑，快乐就好。也许几年后，连我自己都会忘记曾经有这么天，我在小小的房间里面，独自研究着NTFS。不过谁在意呢，千百年后，我们中的多少还能留下名字？与其将生命浪费在无谓的虚妄中，我更宁可做点现在就可以快乐的事情。而电脑，就是其中之一。
今天下了BitComet0.59用，终于支持用户列表交换和DHT了。感觉真好。不能不说，BC是目前国产软件中最有活力的一个。不是说推出的速度和宣传，而是各个软件的方面。例如支持XML，支持多语言扩展，各种新技术（像UDP内网穿越），广告，内嵌浏览器，内核定制和重用。让我想起以前的netant，winamp等等软件，充满了活力。也许软件维持活力和生命的关键，在于不断引入新鲜血液，并且加入市场来活化它。可能在几年后，现在BC的缔造者会成为将来的网络新贵。不过现在一切都还未知。</description>
    </item>
    
    <item>
      <title>babylon</title>
      <link>http://blog.shell909090.org/blog/archives/177/</link>
      <pubDate>Wed, 08 Jun 2005 00:40:42 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/177/</guid>
      <description>真TMD麻烦，从网络上下了一个babylon。上了破解补丁，然后发现不能安装词库。安装词库就会出现授权无效，然后八天一过就用不了了。毛主席说，自己动手，丰衣足食。拿出OllyDbg拆开研究看看。反正补丁的类型是文件改写型，不用担心太麻烦。
不过我还是低估了babylon的难度，从昨天晚上到今天下午，经过将近一天的努力，我还是绕在babylon里面出不来。关键是我找到了显示判别无效的代码，但是在附近没有找到判别代码。NND原来他的判别代码在很久以前执行的，然后放在全局变量里面。害的我好找。然后发现判别代码分了两部分，一个是判断是否有效，一个是判断是否过期。经过一天的修改，还是没有发现过期代码的识别。不过幸好后来想到有一个现成的key，只是因为词典安装太多给识别成无效。这个好解决的很，前面的判别自动判断为有效就好了。然后跟踪后发现修改一个字节就可以暂时解决这个问题。不错不错。
然后是写补丁的问题，我上了一个原来的补丁壳子。发现这个补丁壳子实在奇怪，明明写的是8，却按照B去编译，结果修改地址错误了，导致破解失败。更倒霉的是程序把备份文件的名字起的和网络上的补丁一样，结果按照补丁规则默认覆盖了。闹的我连原始文件都没有了……不得以只好将现在的程序备份重新安装，然后提取出一个主文件来。看来不重新写一个补丁壳子不行了，这次写的完美点……</description>
    </item>
    
    <item>
      <title>郁闷，发不了了……</title>
      <link>http://blog.shell909090.org/blog/archives/176/</link>
      <pubDate>Mon, 06 Jun 2005 18:50:11 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/176/</guid>
      <description>病毒编年史已经写好了，不过奇怪的是空间不能用。怎么都发不上来。莫非是我东西太大，导致微软对我的抵制？
今天去参加讨论，得知毕设答辩如果在七月进行肯定没好分数。而且答辩如果过了七月中旬没有结束就直接结业没有毕业。老师还不紧不慢的和我说你不用着急……我快崩溃了。软件写好了就在家天天呆着闲闲没事干，这样如何能不着急。
算了算了，还是不说了。昨天破解了CCProxy6.0，很好的一个软件。不准备发出去，毕竟人家是软件公司，不能坏人家生意。不过挺高兴，软件破解技术终于可以搞点实际的东西了。破解的时候挺痛苦的，重起N次。
然后还发现一个木马蠕虫。通过LSASS的某个后门运行tftp下载代码，结果给天网截获了。然后用ProcessExplorer查出来，下载文件来分析。貌似被压缩过分析不出来，司机的在线引擎给的结果是Rbot。反正我不管这么多了，能下载就让我一身冷汗，本来还以为系统挺安全的。赶快下LSASS的补丁打上，然后又下了一个SSS扫描本身的系统。发现了五个严重漏洞，一个中等漏洞。那个中等是匿名ftp，不用理他。一个是winamp漏洞，要升级到最新。去，最新的winamp又大又难用，我才不干。还有一个是jet漏洞，上补丁后解决了。最后三个FTP绕回漏洞，现在在想办法……
真的是好久不玩安全技术了，居然被人打到家门口才发现。要不是这个服务器配置比较严格，就会被入侵了。我在想能不能开个公司，专门写程序检验你的系统和上面的软件，软件的版本。发现某个版本的软件就查漏洞数据库，找漏洞检验程序。然后扫描没有打的补丁，再专门下载补丁打。这样可以分担网管大部分的工作。不过在中国是否可行还是未知，毕竟中国的网管观念里面，出了问题再解决才能显得自己的重要。漏洞全让你自动打光了，我吃什么？</description>
    </item>
    
    <item>
      <title>病毒编年史-近古</title>
      <link>http://blog.shell909090.org/blog/archives/175/</link>
      <pubDate>Sat, 04 Jun 2005 23:24:18 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/175/</guid>
      <description>近古时代是以win9X的兴起为代表的，这个时期后，人们对于保护模式编程有了相当的积累。更换系统变化的是系统结构，而保护模式的各个易于错漏之处一直保留到现在。同时病毒也开始向跨平台和多样化发展了。难倒病毒编写者也感受到了平台变换的阵痛？
AD 1995，宏病毒出现，代表作 Word Concept，作者未知。 贝壳评论：
这个病毒的意义是打破了人们对于非可执行文件不会中毒的认识。使得非可执行文件也成为了病毒的媒介。并且降低了病毒的技术门槛，使得病毒技术从生僻技术变成了人人都可以接受和理解的技术。制作者从必须懂得各种计算机内部机理变成只需要了解Word宏的编写，从客观上加速了病毒制造的普及。
同时这个也是典型的一个概念型病毒，病毒并不具备破坏性。更多程度上是和Fred Cohen一样为了证明自己的观点而做的。其症状是Word的Normal模板中会出现两个名字为AAAZAO和AAAZFS 的宏命令。另外还有一个PayLoad宏，该宏只包含一句话“这足以证明我的观点（That’s enough to prove my point.）”，而不做其他事情。
AD 1997.6.24，KV300L++事件。某种意义上说，KV300L++事件不是病毒。不过，这个事件在病毒技术，反病毒理念，反盗版理念上造成极大冲击。关于事件我摘录如下：
1997年6月24日王江民先生在其主页上发布了kv300l++版，内含逻辑炸弹。凡是在mk300v4制作的仿真盘（盗版盘）上执行kv300l++的用户硬盘数据均被破坏，同时硬盘被锁，软硬盘皆不能启动。从网上的求救信息可以看到，包括在校大学生的毕业论文被破坏，kv300的代理商的电脑遭到破坏，求救的人不计其数（网上的求救信息并不能作为证据，因为不能排除有人误判断及有假消息）。从常规上可做推断：kv300当时至少有几十万正版用户，盗版用户可能远远大于这一数字，可见此逻辑炸弹的影响之大。首先王江民不是执法者，无权对盗版用户进行打击，另外，被打击对象也不应该是用户，而应该是制作盗版的厂商。1997年9月8日，公安部门认定kv300L++事件违反计算机安全保护条例之23条,对其做出罚款3000元的决定！
另外还有这个事件的一个评论：http://www.chinabyte.com/20011224/1428573.shtml
贝壳评论：
原理上说，KV300L++逻辑炸弹是通过修改硬盘MBR区中分区表导致逻辑死锁所致。属于系统漏洞的一种应用，解法可以使用修改过的IO.sys等等，在此不赘言。就理论上说，KV300L++是严格的恶意代码，关于逻辑锁的解释根本不能成立。假如逻辑炸弹造成损失可以通过技术途径修复，那么就都不叫逻辑炸弹了？并且就行为上说。中国计算机保护条例中打击的范围是制作，传播，销售盗版。江民公司通过打击用户的方式制衡盗版。无论有无效果，客观上打击了客户。就角色上说就更离谱了，江民公司根本不是执法者，连直接打击盗版商的权利都没有，充其量就是能够起诉盗版商而已。最恶心人的是，江民公司在事先一字未提，其原因为何不说，本身绝对侵犯了消费者知情权。后期的很多评论各有偏向，不排除江民公司和对手在做商业宣传的可能。在此引出的问题是，软件保护究竟如何做？
AD 1998，java病毒出现，代表作 StrangeBrew，作者未知。 贝壳评论：
此种病毒代表病毒编写由平台相关迈向了平台无关。从某种意义上说，此种病毒和上面的宏病毒都属于源码病毒，更严格来说是脚本病毒。依靠脚本来传播，因此编写非常简单。当今流行的多数病毒都多少带有这种特征。
AD 1998.6，9X时代巅峰之作 CIH，作者 台湾大同工学院 陈盈豪。 贝壳评论：
说起此君真当是病毒史上又一传奇人物。CIH小小一个病毒，大小约1K，连续创下四个世界之最。最早的大规模硬件破坏病毒，最早的windows核心态感染病毒，流行事件最长，破坏最强。而且这个病毒本身不变形不加密，仅仅通过windows的段机制拆分重组来破坏特征扫描。堪称病毒史上的经典作品。其源码公开，有兴趣做windows核心研究的一定要下一个来看看。不过这个病毒的设定还有点搞笑，CIH取自作者的姓名台湾拼音，病毒发作的时间之所以定在4月26日，因为那是他的高中座号，也是他的绰号。
同时此病毒的解毒方法也成传奇了，五花八门的解毒方法另人瞠目结舌。因为病毒破坏了硬件，所以所有软件解毒方案全成了空话一句，反到是各种偏方效用非常。例如热插拔法就是在此时风行的。很多用户也首次接触了编程器和刷新BIOS的概念。BIOS刷新中的防刷死（BlackBlock方法）成为必备条件。硬盘数据恢复中常用的种种数据修复工具和数据修复方法也是从此时开始流行的。
就贝壳查找的资料显示，作者陈盈豪在99年4月曾经入狱，2000年被发展Linux操作系统的美商网虎公司聘请为工程师，负责硬件事业部门的研究工作。
近古时代就此终结，就传统意义上的种种病毒来说。至今尚无超过CIH的。</description>
    </item>
    
    <item>
      <title>病毒编年史-中古</title>
      <link>http://blog.shell909090.org/blog/archives/174/</link>
      <pubDate>Sat, 04 Jun 2005 23:20:25 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/174/</guid>
      <description>1991年DOS盛行以来被划为中古时代，这个时代的各种病毒主要在dos和win3X上面折腾，win9X和保护模式还是未来的概念。贝壳就经历了这个时代。当时要杀解某种病毒基本是要用户手工去DeBug的。还有专门的小册子指导人怎么做。不过即使现在，能Debug方式杀毒的人又有多少呢？幸好现在有了反毒程序。
贝壳评论：
所谓反毒程序，其实就是感冒药。你吃了感冒药敢去流行性感冒的流行区吗？所以，防毒还是要靠自己小心。
AD 1991，首个多态病毒出现（好快），代表作 Tequila（龙舌兰），作者未知。
贝壳评论：
所谓多态，就是指同个东西的多个表现形式。在C++来讲，就是同个基类的多个行为。在病毒来讲，就是一个动作的多种代码写法。也可以称为变性病毒。基本原理是利用可替代代码，用不同的代码表达一个内容。或者利用变性子，变更病毒的形态，并且执行的时候动态变换回来。其中在DOS时代的皎皎者就是Natas，无穷变形。
插句话，前面所描述的病毒，经历了概念型，游戏型等等非经典形态。在Brain（小球）后才真正是破坏病毒。基本来说分为三个类型，开始的引导型，后来的文件型，和系统型蠕虫。前者出来不久就没了，连作者都没有赶上（赶这个干吗啊？），后者在当代还屡屡出现，生命力超强。最后者直到近年才在windows上广泛出现，由此可见Morris的远见。还有很多是以上的复合型病毒，真正DOS病毒的巅峰之作当数DirII（后文有述）。
AD 199X，Jerusalem病毒出现，又名黑色星期五。在十三号又是星期五的日子，这个病毒就会发作。
AD 1994，恶作剧邮件出现（重复一次，这不是病毒），作者未知。感觉上说，这个很像一个古老的循环。下面的信请在XX天内发给XX人，如果发了你会OOOO，如果没有则会XXXX。其实这个东西（姑且叫东西吧），思想绝对先进。他通过一个信件，发送一个病毒警告给用户，提醒他们小心病毒，并且要求你发送这个信件给所有你认识的人。大家感觉是不是很像邮件蠕虫病毒啊？不过这里并没有真正的病毒，信中提及提及的病毒在其后两年内没有人中过……
AD 199X年，防毒卡终结，DirII横空出世。代表作 DirII，作者未知。
这个病毒贝壳我在DOS病毒中着重描述，为什么呢？因为他有数个特点。首先是他将自身加入了DOS的设备驱动链，合法的修改了系统，导致硬件防毒的一蹶不振。详细请看《信息安全半世纪—一个程序员的简单回顾》江海客（http://netsafe.ayinfo.ha.cn/software/virus/article/teach/teach_25.htm）
贝壳曾经在防毒技术资料上看过病毒分析，非常佩服。同时这个病毒客观上也造成了文件系统格式的变化。当今这种变化可以被用来防御各种本地进攻。
DirII的出世也标志着中古时代的结束，此后的病毒就向win9X平台上迈进了。</description>
    </item>
    
    <item>
      <title>病毒编年史-上古</title>
      <link>http://blog.shell909090.org/blog/archives/173/</link>
      <pubDate>Fri, 03 Jun 2005 17:46:54 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/173/</guid>
      <description>所谓病毒编年史-上古，指的是自AT&amp;amp;T的Unix出现后到BG的DOS刚刚冒出来的这段时间。这个时间里面我都没有出生，所以所有资料均举自网络。如果有抄袭重复还请见谅……毕竟要我说自己出生前的历史想不背书都不行…… AD1949 ，病毒概念诞生，代表作无，作者John Von Neumann。大家表和我说不知道这个人。冯。诺伊曼结构知道吧，近代计算机理论奠基人。 贝壳评论： 话说具体时间嘛，也不确定是1949年，这年恰也是计算机元年。据说同年John Von Neumann提出一篇论文，描述了病毒的机理和存在，不过没有实际代码，也没人信。但是鉴于病毒的基础理论已经出来了，我们同样定这年为“病毒元年”。而后大约十年的时间内在美国电脑电话电报公司(AT&amp;amp;T)的贝尔(Bell)实验室中，出现了磁芯大战。磁芯大战这个游戏现在还有模拟器可以跑，具体情况可以下载来看看，模拟器访问 http://www.xfocus.net 。里面有中文教程和下载，在此不再赘言。 AD 1959（大约） ，远古病毒诞生，代表作 磁芯大战(Core War) ，作者AT&amp;amp;T Bell 的Douglas Mcllroy、Victor Vysottsky以及Robert T.Morris 。最后一个人大家记住了，这个人是后来非常出名的Morris蠕虫的作者的老爸，当时正好掌管整个ARPANET网络，给儿子闹了个灰头土脸。 同时我要特别提到他的公开者。磁芯大战本来是在程序员间秘密流传的，不过1983年（嘿嘿，我诞生的年头） Ken Thompson在一项杰出电脑奖的颁奖典礼上，他作了一个演讲，不但公开地证实了电脑病毒的存在，而且还告诉所有听众怎样去写自己的病毒程序。这个Ken Thompson，如果我没有记忆错误的话，系Unix的缔造者之一。（致以无上敬意……）另外，Ken Thompson与Dennis Ritchie是唯一两位获得Turing Award(图灵奖，电脑界的诺贝尔)的工程师(其他都是学者)，后者是C的缔造者。 AD 1981，苹果病毒1 2 3诞生，近代公开病毒首例，作者未知，传播是通过一个得克萨斯州的盗版游戏传播的…… AD 1983，概念型病毒（不是病毒概念哦），首例病毒研究论文发表，病毒正式定名，作者Fred Cohen。 贝壳评论： 话说此君在南加州大学念书的时候，着重研究了一种导致系统死机的程序。（windows？）结果得不到某些教授的认同。于是此君愤怒之下，直接公开了论文和示例代码。其指导教授Len Adleman将其定名为病毒（virus），Cohen的程序，让电脑病毒具备破坏性的概念具体成形。 BTW，喜欢看近代密码学的人是否觉得哪里很眼熟啊？嘿嘿，Len Adleman的A和RSA加密算法的A是一个A哦…… AD 1986，引导型病毒出现，代表作 小球（巴基斯坦），作者 Basit Amjad兄弟。这个病毒的目的是为了防止盗版游戏。 贝壳评论： 某种意义上说，这个才是近代病毒第一人。笔者曾经研究过这个病毒，感觉非常远古。头部居然还有病毒作者的声明和地址（CIH的前辈啊……）。通过更改系统的BOOT区（0面0道1扇区）来获得系统权限，减小内存总量并且驻留，而后再次载入原始BOOT。目前此种病毒已经失传，原因是因为linux和windows抢MBR区抢的太凶，导致所有BOOT型病毒殃及池鱼……（玩笑……） 为了防止盗版而植入恶意代码的事情后来反复出现，现在形成了一个专门的问题。能否以暴易暴？ AD 1987 文件型病毒出现，代表作 Lehigh（这个是Pennsylvania宾夕法尼亚州东部的一个小镇），作者未知，感染对象是command.com。 AD 1988.11.2 ，蠕虫传播，病毒首次发威，代表作 Morris蠕虫，作者是 在康乃尔 (Cornell) 大学攻读学位的研究生，Robert T.Morris Jr，当年23岁（厉害哦，比我大一点而已……）。 1988年11月2日，Morris 蠕虫[8～12]发作，几天之内6000台以上的Internet服务器被感染，损失超过一千万美元。它造成的影响是如此之大，使它在后来的10几年里，被反病毒厂商作为经典病毒案例，虽然它是蠕虫而非病毒；1990年，Morris蠕虫的编写者Robert T. Morris被判有罪并处以3年缓刑、1万美元罚金和400小时的社区义务劳动。Morris蠕虫通过fingerd、sendmail、 rexec/rsh三种系统服务中存在漏洞进行传播。他的主要思路是通过构造缓冲区溢出获得远程管理员权限，并且载入一段引导代码（boot），下载远程的病毒主体并且编译连接，重复感染系统。 AD 1990，出现了首个大型公司的反毒程序，代表作 Norton AntiVirus，作者 Symantec。这个标志着病毒和反毒已经成为商业化的斗争。 远古时代大致到这里就结束了，其中涵盖了多个系统上的各种病毒。提供了最初的各种病毒理念。</description>
    </item>
    
    <item>
      <title>病毒编年史-前言</title>
      <link>http://blog.shell909090.org/blog/archives/172/</link>
      <pubDate>Fri, 03 Jun 2005 17:18:39 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/172/</guid>
      <description>最近和人聊天，讲到病毒和系统，人家问我要资料了解下历史。我说貌似以前有个大牛人写过一个OS演义，详举了种种系统的历史。病毒就貌似没有了。想想有趣，决定跑回来写个病毒编年史，举各种史上出名的病毒，并且加以评论。不过史上出名四字极难担当。就病毒数目而言，尚远在系统数目之上。其中精品之作汗牛充栋，在此仅仅能分析一二。而且资料不全，有遗漏处还请告知。至于评论更是一家之言，姑且听之，莫笑莫笑……</description>
    </item>
    
    <item>
      <title>Bittorrent</title>
      <link>http://blog.shell909090.org/blog/archives/169/</link>
      <pubDate>Tue, 31 May 2005 21:34:32 +0800</pubDate>
      
      <guid>http://blog.shell909090.org/blog/archives/169/</guid>
      <description>关于纯粹的BT技术，并没有啥好说的。BT的迅猛发展表明了这个技术的生命力。不过BT还要面对几个问题。首先，也是最大的一个，就是Copyright的问题。
嗯，先回顾下网络文件发布的方式和版权追究的历史。最开始的互联网是bbs形式的，而且比firebird一类的telnet形式还要落后。这种情况下要么是通过bbs交换文件，要么就是ftp。多数是大学在用，很少有追究版权的，而且多数东西用于研究时可以藐视版权法。所以这个时期根本没有所谓版权的问题。
然后就是欧洲某个研究所（似乎是欧洲核物理研究所）搞出的html协议，到今天成为了xml协议的基础。这个协议可以在客户端灵活的使用各种媒体对象表示，而不用管对方是啥系统。今天的xml可以保存和创建各种内存对象也不用管是啥系统，从某个意义上说，这是一脉相承的重大进步……呃，好像扯远了。这个时候出现的各种文档基本都是本人发布或者转载，多数也是大学使用，没有版权问题。
后来我们的网络渐渐转向民用，这个时候微软也搅合了进来，发布了IE。然后很多网站就搞了个人主页服务。还有部分小型网站根本就是大流量的个人主页。为了吸引访问量，经常东抄抄西搬搬。这个时候就有了盗版的概念，不过盗版的多数是文字，也经过修改。这个时期的后期渐渐演变成了盗版歌曲，Mp3格式之争由此而来，相信大家非常熟悉了。
网页毕竟比较好处理，盗版的人虽然多，不过稍成气候就可以一个警告让ISP关闭服务。唱片公司们虽然头痛还比较好处理。（当然，他们可能认为这已经是比较严重的问题了。但是和后来的境况相比，他们的却还没有见到啥大场面。）而后出现了分布式的歌曲共享系统和搜索引擎，这让各个公司大大的头痛了。两者的结合使得免费的歌曲在网络上满天飞，整个唱片行业据说损失惨重。唱片公司们为此甚至将歌曲共享先锋的Netisper（貌似这个名字，偶忘记了）告倒了。不过倒了一个人，起来千万个。反正目前来说，唱片公司已经放弃封杀所有免费歌曲流行的可能。改成授权下载了。用非常低廉的价格销售所谓“授权正版Copy”。老实说对于这个我非常的佩服，不但宣传了自己，减少了盗版损失。对于我们来说，合理合法，支持了自己喜欢的歌手，而且还方便查找。这手算是诸公司们非常成功的举措。
然后就是近代，Edonkey和Bittorrent为代表的两种DFS横空出世（其实ED是个老家伙了）。满世界乱飞的盗版根本没法解决，而且盗版的范畴从主要是音乐和文字扩展到了各个领域。从游戏到电影，啥都有。甚至严重的打击了盗版商，将中国多年未竟的反盗版销售的事业推向了顶点。一个卖盗版的朋友是这么评价的：“以后我们只卖三种软件光盘，系统，office，大众软件”。我今年的所有电视和电影都是从网络上下载的。由此可见我们的盗版正式进入了战国时代。
为盗版而生想必不是P2P软件的本意，不过去除盗版后P2P恐怕没啥明天可言。不信你可以上bt.btchina.net数数到底多少共享是有授权的，包括shareware，XXX授课录像Live这种就算授权过好了。照样是盗版比非盗版多。但是P2P极大的刺激了网络的发展，并且可能成为将来的一个核心技术。
当然我相信，立个法禁止P2P软件简单。但是，这是倒退，而不是进步。P2P软件现在逐渐分布化，BT可以自我组件平台，并且透网络运行，凡可上网处皆可BT。如此优良的技术弃而不用，岂非倒行逆施？但是相对，BT也无法参照歌曲运营的模式来个网络授权正版。如此一来，BT被告上法庭的机会就非常高。要是真的禁止了BT，相信会有新的共享软件应需求而生，状况非但没有好转，反而恶化。绝对不是立法禁了就解决的了的。
目前来说，寻求一种共享中盈利的模式是当务之急。不但是各个损失惨重的公司，而且是众多的BTFans。如果公司倒了，我们还能BT啥呢？
另外一个就是BT的共享方式。BT的算法仅仅可以用于静态文件，这点另我非常不齿。目前最需要分布运行的多数都是动态数据，例如电视广播，股票数据等等。BT不可以用于动态数据的原因我比较清楚，因为我曾经就算法设计问过运筹的老师。不过有分流比没有分流好，仔细看看当今诸多股票提供上捉襟见肘的状况就可以知道了。如果BT2.0协议提供包括动态数据流和认证下载，网络穿越在内的一系列能力，相信会非常具备竞争力的。这个我早在一年前就考虑过，不过奇怪的是，我预计一年可以实现，现在都快一年半了……根本没有声音。</description>
    </item>
    
  </channel>
</rss>