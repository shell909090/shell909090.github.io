<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Database on Shell&#39;s Home</title>
    <link>//blog.shell909090.org/tags/database/</link>
    <description>Recent content in Database on Shell&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>CC-BY-SA4.0</copyright>
    <lastBuildDate>Fri, 11 Nov 2011 16:18:45 +0800</lastBuildDate>
    
	<atom:link href="//blog.shell909090.org/tags/database/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于网站架构的几封邮件摘抄</title>
      <link>//blog.shell909090.org/blog/archives/1978/</link>
      <pubDate>Fri, 11 Nov 2011 16:18:45 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/1978/</guid>
      <description>Shell.Xu &amp;lt;shell909090@gmail.com&amp;gt;:
我知道，我自己写过一个greenlet + epoll的实验性框架。
http://code.google.com/p/py-web-server
最主要的问题是，写到后来我发现，这东西对用户的要求太高了。要用好这种框架，用户必须具备系统经验，知道阻塞操作实际上是由非阻塞操作和上下文调度去模拟的，知道代码处处无阻塞（其实是不能有无调度的阻塞），能够想像系统是如何运行的。
这种人不会太多。在cpyug里面不算少，抓10个20个肯定能抓出来，抓上100个也不是没希望。但是实际在操作的时候，平摊到上海这么个地方，会python的也就见过那么不到100人，有这种要求的几乎可以一个个数出来。而且大多数已经在一个不错的公司里面有个不错的职位，你没法指望招个人来做事。
这也是为什么很多公司凡python必django的原因，毕竟用了django，虽然罕见，但是可以招人。用了tornado，能招的范围就少了很多。我自己做的这个实验性的玩意，风险大不说，HR角度来说，可选程序员只有一个。一旦在上面做了系统，不废弃系统的前提下，你压根没法谈判工资。。。
从语言角度来说，我更倾向于lisp，那个比较优美一些，而且也有编译成C的选项，速度不慢，天然的fp。问题是lisp从语义的自然可理解性来说非常差劲，那个传说中某AI实验室源码最后一页全是)并非空穴来风。对于新手入门而言，lisp成本更加高，使用lisp做系统，HR执行的难度也更高。haskell我并不懂，不过从语言理解来说，大概介于lisp和python之间吧。
协程型框架和进程/线程型框架相比，最大的好处就是减少了锁的问题。因为上下文切换的位置都是已知的，是否需要锁很容易考虑。很多时候甚至不需要严格锁定，只要置标志位就好，速度很快。使用fp，也可以大幅减少锁的问题，但绝对不是避免。目前的系统架构设计，已经越来越多的把锁的问题扔到了数据库层。
例如，我在操作一条记录的时候，一定会发生行级锁，否则就是不安全的。而在添加一条记录的时候，必然会修改这个表上关联的索引。而修改索引的瞬间，就会发生瞬时的锁定和解锁，否则也是不安全的。这个过程虽然对用户不可见，但是并非不存在。诚然，数据库访问是基于网络的，而基于网络的read是一个阻塞操作，在架构级别一定会调度到别的上下文执行。但是没意义阿，大规模的用户访问，除掉可以缓存的部分外，都被压到了数据库上进行读写。这些访问，在表级频繁的发生冲突，被各种锁序列化成顺序访问。到最后，我们不断的向系统中添加机器，来换取性能增长的时候，应用服务器实际上变成了问题最小的一个——小到用也许bash去写cgi都可以满足。与此同时，我们的数据库问题越来越大，还没法拆分——你没办法像应用服务器负载均衡那样把数据库拆到多个机器上去，然后让他们的写入性能成倍数增加。
无论是mongo，redis，还是mysql，都没有本质上的解决锁，尤其是写入锁的问题。mongo的读取性能可以上到15kreq/s，但是写入只有5kreq/s，而且好像还不能由sheding做加速——至少不是成倍级别的加速。mysql目前比较成熟的方案还是单写多读。当然，还有所谓水平拆分和垂直拆分的方法。垂直拆分对业务有要求，水平拆分只解决了大规模数据吞吐分布到多个存储媒体的问题，不解决索引访问的问题。redis压根没有自己的分布方案，你必须自己来做。
k-v受到热捧的原因之一，在它给了你一个从某个层面绕过这个问题的方法。目前写入锁最严重的点在于索引。无论是插入还是修改记录都需要在数据库上变更索引，而索引的变更就必然会发生锁。K-V的要点在于不允许在记录上做索引——所以mongo不是k-v数据库——从而允许用户将庞大的写操作分布到数十乃至数百台机器上的同时，获得倍数级别的性能增长。我们先不考虑添加/删除——这个是一致性哈希的目标，也不考虑可用性——这个是冗余的目标。仅从这点来说，k-v数据库受到热捧是有原因的。
问题是，这也不是解决问题，这只是绕过问题。相信使用k-v的人应该有所感受，这玩意根本没法替代常规数据库来用。没有事务，没有一致性隔离就算了。连索引都没有，这TMD的怎么用阿。目前来说，更加实际的使用还是用k-v来存储一些确实没必要进行索引的东西——例如大量小规模图片，用户的属性数据。
Zoom.Quiet &amp;lt;zoom.quiet@gmail.com&amp;gt;:
 那么这样的话,可以考虑用 Erlang ,这货天然就是为了大分布高迸发服务发明的
 而且从语义行文角度看也很好理解
 更加要命的是 erl
  提供了丰富到变态的动态调试工具,风骚无比的热部署无缝回滚&amp;hellip;
 只是,摧悲的是 erl 对于计算无爱&amp;hellip;
 不过,反过来想一下:
 现在 web2.0
  的世界,以及在爆发中的移动互联应用中,有什么是非要复杂关系查询的?!
 通过业务的良好统计,可以从业务角度就异步化
 那么,不论什么语言来开发,都没有阻塞问题存在了哈&amp;hellip;
 这也是为毛 K/V 数据库得以商业应用的主要原因
 另外,前述有人说 git 作存儲的思路也是个方向:
 既然分布式写入锁是个难题
 那么就直接只进行本地操作好了
 仅在必要时,进行分布式合并,这方面,各种版本控制系统都作得很好
 如果 redis 的bilog 文本对 git
  合并是可耐受的,那不就是个山寨的分布异步安全锁了?
Shell.Xu &amp;lt;shell909090@gmail.com&amp;gt;:</description>
    </item>
    
    <item>
      <title>财务数据库</title>
      <link>//blog.shell909090.org/blog/archives/424/</link>
      <pubDate>Fri, 25 Jan 2008 21:15:26 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/424/</guid>
      <description>贝壳最近工作繁忙，一般都是晚上十一点到家睡觉，第二天早上继续上班的那种，所以blog基本没怎么动。现在放篇财务数据库的原型，大家参考一下吧。当然，是对程序员而言。像六牙四皂小姐这种下面估计是压根看不懂的，而且也不会有那种变态的资金准度要求。
首先建立一个账户表。
DROP TABLE IF EXISTS `accont_info`; CREATE TABLE `accont_info` ( `id` int(11) NOT NULL auto_increment, `username` varchar(40) NOT NULL, `accont` varchar(40) NOT NULL, `accont_type` int(11) NOT NULL default &#39;0&#39;, PRIMARY KEY (`id`), UNIQUE KEY `username` (`username`,`accont`) ) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=gbk;  输入用户名，账户名和账户类型，例如&amp;rdquo;许智翔&amp;rdquo;,&amp;ldquo;招行账户&amp;rdquo;,2。账户类型中规定1是现金，2是存款，3是信用卡，4以上不计算。这样可以使用多个现金账户，存款账户和信用卡账户。然后利用子查询把所有类型间的相互行为统计出来。
然后是类型表。
DROP TABLE IF EXISTS `type_info`; CREATE TABLE `type_info` ( `id` int(11) NOT NULL auto_increment, `type` varchar(40) NOT NULL, `subtype` varchar(40) default NULL, PRIMARY KEY (`id`), UNIQUE KEY `type` (`type`,`subtype`) ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=gbk;  最后是资金流动数据表，accont_id中填写出户账户名，to_accont中填写入户账户名。如果是外部(例如从别人那里拿钱或者给别人钱)，则写0。happen_time上填写发生时间，money上写金额，message上写备忘。</description>
    </item>
    
    <item>
      <title>惊魂记</title>
      <link>//blog.shell909090.org/blog/archives/355/</link>
      <pubDate>Mon, 29 Jan 2007 19:07:01 +0800</pubDate>
      
      <guid>//blog.shell909090.org/blog/archives/355/</guid>
      <description>大家知道贝壳的财务是通过自己写的程序进行跟踪合计的。以前是excel表单上面加VBA宏，后来移动到了Mysql数据库。因为数据存储量大，运行稳定，使用方便，所以贝壳一直很得意。
昨天贝壳发现自己的财务怎么也算不对，因为单位的工资发到了浦发的卡上，而程序里面是没有浦发的账户的。本质上是由于程序中使用硬编码导致程序对数据库存在非合理依赖(有点专业，听不懂就算了)。所以从理论上说，我需要修改表结构。
于是贝壳就先备份了表结构(悲惨啊，大家后来就知道了)，然后修改了账户的表结构。然后贝壳发现财务表里面没有使用UNIQ限定，于是又对财务表修改了结构。但是无法通过，原因是因为现有数据中有的不符合UNIQ限定。于是贝壳又合并数据，做了半个小时多的操作，好算添加了UNIQ限定。这时候，贝壳送了口气。处于不可告人的怪癖，贝壳运行了自己写的核算程序，上面赫然写着，当前现金，-1034。
不用说，一定是合并数据的时候出现了错误，问题是错误在哪里呢？不知道，贝壳只有删除了UNIQ限定，然后恢复数据——shit，没备份。
开始的时候，贝壳只需要修改表结构，于是就只备份了表结构，数据还是上个月的备份。OMG，怎么办？怎么办？怎么办？
于是贝壳就开始了悲惨的修复经历。
首先我确定合并的数据都是在上个月备份以内的。就是说，这个月新添加的数据都是没有经过合并操作的。于是贝壳导出当前错误的数据，并且从中截取出这个月新的数据，这部分数据一定是正确的。然后和上个月的备份合并到一起，放到新的文件里面导入数据库。运行财务核算程序，OK，当前现金380.89。
贝壳又一次低估了上帝的决心，高高兴兴的删除了临时文件。然后导出新数据，准备关闭程序睡觉去。然而运气的是，贝壳在关闭前看了眼数据。啥？注释是乱码？
财务软件并不使用注释字段，那个是被贝壳用的，所以财务软件不会报错。可是注释乱糟糟，等于一半的功能被砍掉了。贝壳赶快想怎么解决。当前数据和备份都是错误的，上个月的备份还在，可是少一个月数据。就是说贝壳丢失了一个月的数据！
没办法，贝壳紧急安装修复软件。但是超级RP的是，贝壳上次Uninstall了一个东东还没reset(这是贝壳的一个坏习惯，Uninstall了以后不reset，等系统自然需要reset)。FinalData的Installer在Uninstall事件没有完成前不能运行。我靠～～～贝壳顿时怒了——上网找了半天，找到一个免安装绿色修复软件，Recover4all。运行，找到了上次导出的数据。
吃一堑长一智，贝壳先完美的备份了这个文件(包括扔到了U盘上一份)。然后将这个和上月的备份重新合并，切换编码，重新导入——蓝了——
靠——上帝的决心是无止境的——比客户的变态还无止境——当导入超长的时候，居然诱发了XP64的溢出。由用户输入诱发溢出，我还真是伟大。
贝壳重启，重新合并，然后切分成两次，切换编码，分次导入。总算数据正常了。然后运行财务核算程序，也正常。去手工看表，也正常。不过贝壳的几个新修改和半小时的合并工作就作废了。
忙碌两个小时快，总算让数据库恢复到了以前的状态。还真是——
不说啥了——</description>
    </item>
    
  </channel>
</rss>