<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Shell&#39;s Home</title>
    <link>http://shell909090.org/tags/linux/</link>
    <description>Recent content in Linux on Shell&#39;s Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>CC-BY-SA4.0</copyright>
    <lastBuildDate>Thu, 20 Nov 2014 10:38:30 +0800</lastBuildDate>
    
	<atom:link href="http://shell909090.org/tags/linux/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>上下文切换技术</title>
      <link>http://shell909090.org/blog/archives/2703/</link>
      <pubDate>Thu, 20 Nov 2014 10:38:30 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2703/</guid>
      <description>上下文切换技术 简述 在进一步之前，让我们先回顾一下各种上下文切换技术。
不过首先说明一点术语。当我们说“上下文”的时候，指的是程序在执行中的一个状态。通常我们会用调用栈来表示这个状态——栈记载了每个调用层级执行到哪里，还有执行时的环境情况等所有有关的信息。
当我们说“上下文切换”的时候，表达的是一种从一个上下文切换到另一个上下文执行的技术。而“调度”指的是决定哪个上下文可以获得接下去的CPU时间的方法。
进程 进程是一种古老而典型的上下文系统，每个进程有独立的地址空间，资源句柄，他们互相之间不发生干扰。
每个进程在内核中会有一个数据结构进行描述，我们称其为进程描述符。这些描述符包含了系统管理进程所需的信息，并且放在一个叫做任务队列的队列里面。
很显然，当新建进程时，我们需要分配新的进程描述符，并且分配新的地址空间(和父地址空间的映射保持一致，但是两者同时进入COW状态)。这些过程需要一定的开销。
进程状态 忽略去linux内核复杂的状态转移表，我们实际上可以把进程状态归结为三个最主要的状态：就绪态，运行态，睡眠态。这就是任何一本系统书上都有的三态转换图。
就绪和执行可以互相转换，基本这就是调度的过程。而当执行态程序需要等待某些条件(最典型就是IO)时，就会陷入睡眠态。而条件达成后，一般会自动进入就绪。
阻塞 当进程需要在某个文件句柄上做IO，这个fd又没有数据给他的时候，就会发生阻塞。具体来说，就是记录XX进程阻塞在了XX fd上，然后将进程标记为睡眠态，并调度出去。当fd上有数据时(例如对端发送的数据到达)，就会唤醒阻塞在fd上的进程。进程会随后进入就绪队列，等待合适的时间被调度。
阻塞后的唤醒也是一个很有意思的话题。当多个上下文阻塞在一个fd上(虽然不多见，但是后面可以看到一个例子)，而且fd就绪时，应该唤醒多少个上下文呢？传统上应当唤醒所有上下文，因为如果仅唤醒一个，而这个上下文又不能消费所有数据时，就会使得其他上下文处于无谓的死锁中。
但是有个著名的例子——accept，也是使用读就绪来表示收到的。如果试图用多个线程来accept会发生什么？当有新连接时，所有上下文都会就绪，但是只有第一个可以实际获得fd，其他的被调度后又立刻阻塞。这就是惊群问题thundering herd problem。
现代linux内核已经解决了这个问题，方法惊人的简单——accept方法加锁。(inet_connection_sock.c:inet_csk_wait_for_connect)
线程 线程是一种轻量进程，实际上在linux内核中，两者几乎没有差别，除了一点——线程并不产生新的地址空间和资源描述符表，而是复用父进程的。
但是无论如何，线程的调度和进程一样，必须陷入内核态。
传统网络服务模型 进程模型 为每个客户分配一个进程。优点是业务隔离，在一个进程中出现的错误不至于影响整个系统，甚至其他进程。Oracle传统上就是进程模型。
缺点是进程的分配和释放有非常高的成本。因此Oracle需要连接池来保持连接减少新建和释放，同时尽量复用连接而不是随意的新建连接。
线程模型 为每客户分配一个线程。优点是更轻量，建立和释放速度更快，而且多个上下文间的通讯速度非常快。
缺点是一个线程出现问题容易将整个系统搞崩溃。
一个例子 py_http_fork_thread.py
在这个例子中，线程模式和进程模式可以轻易的互换。
如何工作的  父进程监听服务端口 在有新连接建立的时候，父进程执行fork，产生一个子进程副本 如果子进程需要的话，可以exec(例如CGI) 父进程执行(理论上应当先执行子进程，因为exec执行的快可以避免COW)到accept后，发生阻塞 上下文调度，内核调度器选择下一个上下文，如无意外，应当就是刚刚派生的子进程 子进程进程进入读取处理状态，阻塞在read调用上，所有上下文均进入睡眠态 随着SYN或者数据报文到来，CPU会唤醒对应fd上阻塞的上下文(wait_queue)，切换到就绪态，并加入调度队列 上下文继续执行到下一个阻塞调用，或者因为时间片耗尽被挂起  关于更多细节，可以看这里。这篇文章里还介绍了epoll的工作细节。
评价  同步模型，编写自然，每个上下文可以当作其他上下文不存在一样的操作，每次读取数据可以当作必然能读取到。 进程模型自然的隔离了连接。即使程序复杂且易崩溃，也只影响一个连接而不是在整个系统。 生成和释放开销很大(效率测试的进程fork和线程模式开销测试)，需要考虑复用。 进程模式的多客户通讯比较麻烦，尤其在共享大量数据的时候。  C10K问题 描述 当同时连接数在10K左右时，传统模型就不再适用。实际上在效率测试报告的线程切换开销一节可以看到，超过1K后性能就差的一塌糊涂了。
更细节描述，可以看这里。
进程模型的问题 在C10K的时候，启动和关闭这么多进程是不可接受的开销。事实上单纯的进程fork模型在C1K时就应当抛弃了。
Apache的prefork模型，是使用预先分配(pre)的进程池。这些进程是被复用的。但即便是复用，本文所描述的很多问题仍不可避免。
线程模式的问题 从任何测试都可以表明，线程模式比进程模式更耐久一些，性能更好。但是在面对C10K还是力不从心的。问题是，线程模式的问题出在哪里呢？
内存？ 有些人可能认为线程模型的失败首先在于内存。如果你这么认为，一定是因为你查阅了非常老的资料，并且没仔细思考过。
你可能看到资料说，一个线程栈会消耗8M内存(linux默认值，ulimit可以看到)，512个线程栈就会消耗4G内存，而10K个线程就是80G。所以首先要考虑调整栈深度，并考虑爆栈问题。
听起来很有道理，问题是——linux的栈是通过缺页来分配内存的(How does stack allocation work in Linux?</description>
    </item>
    
    <item>
      <title>上下文切换测试总结报告</title>
      <link>http://shell909090.org/blog/archives/2700/</link>
      <pubDate>Tue, 18 Nov 2014 16:15:16 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2700/</guid>
      <description>效率测试 测试环境  Intel&amp;reg; Pentium&amp;reg; CPU G2030 @ 3.00GHz 8G内存 debian jessie Linux 3.16-2-amd64 2014年10月27日  附注一下，该CPU有2核心，无HT，1ns3个时钟周期。
测试方法 测试代码如下：
time -f &amp;quot;%e,%S,%c,%r,%s,%K,%P&amp;quot; ./perf_fork  数据的意义分别为: 总时间，内核CPU时间，context switch次数，读/写次数，内存耗用，CPU使用百分比。
数据处理方法如下：
import numpy as np p = lambda s: [float(line.strip().split(&#39;,&#39;)[0]) for line in s.splitlines()] q = lambda s: [float(line.strip().split(&#39;,&#39;)[1]) for line in s.splitlines()] np.array(p(s)).mean() np.array(p(s)).var() np.array(q(s)).mean() np.array(q(s)).var()  基础开销测试 函数调用开销 使用s_call来测试性能，循环1G次。
2.35,0.00,17,0,0,0,99% 2.34,0.00,13,0,0,0,99% 2.34,0.00,10,0,0,0,100% 2.35,0.00,10,0,0,0,99% 2.34,0.00,14,0,0,0,99% 2.34,0.00,6,0,0,0,99%  统计结果如下：
 time mean = 2.</description>
    </item>
    
    <item>
      <title>context切换测试——线程创建有关部分请求review</title>
      <link>http://shell909090.org/blog/archives/2693/</link>
      <pubDate>Fri, 31 Oct 2014 14:49:09 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2693/</guid>
      <description>线程模式开销 使用t_thread程序，循环1M次，重复6次，原始数据如下：
9.57,8.22,21098,0,0,0,104% 9.77,8.40,29704,0,0,0,104% 9.36,8.17,10390,0,0,0,106% 9.56,8.50,14514,0,0,0,107% 9.35,8.34,7244,0,0,0,108% 9.57,8.43,26351,0,0,0,106%  统计结果如下：
 time mean = 9.53 time var = 0.02 kernel mean = 8.34 kernel var = 0.013  解读数据可以看到，thread模式的开销为9530ns(已经降到纳秒级了)，CPU将为8340ns，精确级别在20ns级别。粗略换算一下每次create的开销大约是30k个时钟周期。简单对比可以看出，thread模式比fork模式大约快了5倍。</description>
    </item>
    
    <item>
      <title>context切换测试——进程有关部分请求review</title>
      <link>http://shell909090.org/blog/archives/2682/</link>
      <pubDate>Tue, 28 Oct 2014 12:57:04 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2682/</guid>
      <description>测试环境  Intel&amp;reg; Pentium&amp;reg; CPU G2030 @ 3.00GHz 8G内存 debian jessie Linux 3.16-2-amd64 2014年10月27日  附注一下，该CPU有2核心，无HT，1ns3个时钟周期。
测试方法 测试代码如下：
time -f &amp;quot;%e,%S,%c,%r,%s,%K,%P&amp;quot; ./perf_fork  数据的意义分别为: 总时间，占用CPU时间，context switch次数，读/写次数，内存耗用，CPU使用百分比。
数据处理方法如下：
import numpy as np p = lambda s: [float(line.strip().split(&#39;,&#39;)[0]) for line in s.splitlines()] q = lambda s: [float(line.strip().split(&#39;,&#39;)[1]) for line in s.splitlines()] np.array(p(s)).mean() np.array(p(s)).var() np.array(q(s)).mean() np.array(q(s)).var()  进程fork开销 使用s_fork程序(注释语句关闭模式)，粒度1M次，重复6次，原始数据如下：
49.04,26.83,29784,0,0,0,55% 51.53,26.38,32057,0,0,0,52% 49.88,26.02,30892,0,0,0,53% 51.39,27.13,37573,0,0,0,54% 52.89,28.12,37924,0,0,0,54% 51.19,27.02,35880,0,0,0,54%  统计结果如下：
 time mean = 50.98 time var = 1.</description>
    </item>
    
    <item>
      <title>bash严重漏洞</title>
      <link>http://shell909090.org/blog/archives/2680/</link>
      <pubDate>Thu, 25 Sep 2014 14:36:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2680/</guid>
      <description>今天估计各大消息都在报这个漏洞，可能有些人看到有修复就放松了。目前来看，事情没那么简单。
CVE-2014-6271 第一个漏洞，编号为CVE-2014-6271。相应的dsa和usn。
具体的文章可以看这里。
简单来说，当bash执行时看到有变量定义了一个函数，函数尾部又剩余了部分代码。会直接把剩余代码执行了。导致简单的变量定义动作有机会执行任意代码。
对于未修补的系统，执行以下代码出现以下提示：
$ env x=&#39;() { :;}; echo vulnerable&#39; bash -c &amp;quot;echo this is a test&amp;quot; vulnerable this is a test  注意echo vulnerable应当不被执行的。
修复的系统则是以下表现：
$ env x=&#39;() { :;}; echo vulnerable&#39; bash -c &amp;quot;echo this is a test&amp;quot; bash: warning: x: ignoring function definition attempt bash: error importing function definition for `x&#39; this is a test  CVE-2014-7169 第二个漏洞，编号为CVE-2014-7169。
这个漏洞是第一个漏洞没有修复完全导致的，最麻烦的是，这个漏洞没有修复，细节却满天飞了。
表现如下：
$ env X=&#39;() { (a)=&amp;gt;\&#39; sh -c &amp;quot;echo date&amp;quot;; cat echo sh: X: line 1: syntax error near unexpected token `=&#39; sh: X: line 1: `&#39; sh: error importing function definition for `X&#39; Wed Sep 24 23:25:58 PDT 2014  结论和建议 尽量不要暴露bash，能关就关，不行的自求多福吧。</description>
    </item>
    
    <item>
      <title>服务器操作系统的选择</title>
      <link>http://shell909090.org/blog/archives/2671/</link>
      <pubDate>Thu, 14 Aug 2014 16:25:32 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2671/</guid>
      <description>今天被LTN问了一下怎么看一个知乎问题：
服务器操作系统应该选择 Debian/Ubuntu 还是CentOS？
其实我觉得他的大部分说法都没有错。如果你需要装一个服务器，确实首选是RH系的。
但是。。。
选用RH系的主要理由 其实你把回复从头看到尾，主要论点就一点：
哪个发行版，可以在长达7-10年的时间里，始终保持硬件稳定性的同时，又持续的升级补丁？
结论当然是RH！这是RH的主要卖点。
我们真的需要长达7年的硬件稳定性支持？ 咳咳，今年上半年，蔽厂的运维碰到了这么一件尴尬事。
他们进货，去机房装系统，配置网络结构，加入运维管理系统，添加监控，交付。除去采购外，整个一套流程大概是一周。
我们在机房里面原本大约有10个机柜，那么一般扩充的时候，一次扩充一个机柜。
结果今年上半年的某一段时间，一周一个机柜的事情持续了两个月。运维同学辛辛苦苦装好一个机柜，周末打算轻松一下。被老大通知，又来客户了，机柜又不够用了，下周继续。
是的，我们现在20个机柜不止。机房有多少机柜我不知道，不过照这个趋势来看，我们快把机房包下来了。现在我们的带宽已经没有限制了，每个月月底按照合同秋后算账。
我们有一些有三年历史的服务器，台数不多。现在来看，性能已经远远不够。CPU不够快，也没有SSD，硬盘读写次数也太多。这些机器的下场，多数会被换下来折旧卖掉，或者作为测试服务器，搬去测试机房。而现在机房里面大半机器，都是两年以下历史的。而且至少一半服务器历史不超过半年（。。。）。从现状上看，把老服务器留在机房，其性价比并不合算。因为机房有机架密度问题，限制着我们的单机房极限，这相当于变相的租金。
如果考虑到这点，我们的线上服务器生命周期大概也就三年。最多。很多时候甚至还不到。
比我们更极端的是页游。他们的一组服务器生命周期一般是半年。半年内，要赚钱的也赚完了，不赚钱的也死完了。所以他们甚至不会新采购硬件服务器，而是直接使用虚拟机。
当然，虚拟机内的系统，支持时间是一年还是十年，对他们一点意义都没有。
为什么我们不喜欢三年以上的系统？ RH系的提供10年级别的维护性，我换个说法，也就是最近的软件在RH的官方库里面找不到。当然，装最新的RH是有的，但是在安装了三年的一个系统上？肯定没戏。
怎么办？编译呗。
这大概就是国内谈到RH必编译的由来。
可是，我引用文内的一段话。
如果我今天告诉大家，我要做一个 http 的服务器，我不用 apache 不用 nginx， 为了性能我要用 xxx 为基础重写一套出来。我相信绝大多数人会问同样的问题， “你觉得你写的能比 ng 好么？” 再回头看看那时候你们自己吧。  同样，自己编译的软件，补丁维护速度，能和新系统比么？而且我们还得扔一个人下去搞补丁维护。
所以，正解是什么？
装一套新的，把数据导过去用呗。
我们的”数据“，都是装载在磁盘上的。而换”系统“并不需要更新这些数据，只要把系统盘擦掉重部署一遍，然后配置好deploy系统就OK。在开发之初，”环境“，”程序“和”数据“分离，就是一项基本原则。而且即使是”数据“，丢掉一台机器上的所有”数据“也不会构成问题。这应当是运维基础中的基础。只有少数几台服务器，既不能直接更换也不能停机。这些机器我们做特别的管理。
为什么蔽厂使用Ubuntu？ 很简单。因为最初的开发希望在Linux上进行。直接在Linux上开发和测试，对于startup的快速开发是非常重要的。而开发用什么版本，服务器跟什么版本，这是最省事和好办的。如果你硬要和我争，说开发在Mac上，跑在Linux上一点事都没有。或者说开发一个发行，服务器一个发行也OK。
我至少得说这对于golang和python都不是事实。除非不用cgo，也不用python的C扩展。
先不提Mac下和Linux下的差异。我们今年在升14.04的时候就发现，12.04和14.04的编译互不通行。所以现在12.04的编译可以程序员自己编译了本地测，14.04的就必须在测试环境里干。一帮程序员远程tcpdump出结果，拷回本地wireshark一把。。。
看看就蛋疼。
当然，这也有个问题。就是上面”我们不喜欢三年以上的系统“。所以呢。明年我们的系统大概会轮换重装，14.04。。。
也很蛋疼。
Debian系的补丁不靠谱么？ 那要看和谁比。这里有HeartBleed事件的统计。虽然不普遍，但是我觉得这种大漏洞比较有代表性。
CVE-2014-0160 - OpenSSL安全漏洞的非技術事件
我引用他的重点整理：
RedHat 修復的速度比 OpenSSL 官方還快。 RedHat 派系的修復時間，除了 RedHat 外都算慢，如 Fedora 及 CentOS、Scentific， 他們都比 RedHat 慢 16 小時以上。 Debian 派系的修復時間，如 Debian 及 Ubuntu，都比 RedHat 慢上至少 12 小時以上。 Scentific 是列表中修復最慢的。 若以資安黃金 6 小時來說，Fedora、CentOS、OpenSUSE、Gentoo 及 Scentific 都不及格。  如果和RH比，Debian的修复速度是不及格，但是和CentOS比。。。怎么说呢？6个小时对10个小时，有种五十步笑百步的味道？</description>
    </item>
    
    <item>
      <title>docker的原理和类比</title>
      <link>http://shell909090.org/blog/archives/2650/</link>
      <pubDate>Mon, 30 Jun 2014 12:32:08 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2650/</guid>
      <description> 从虚拟化的种类和层级说起  cpu虚拟化：可以模拟不同CPU，例如bochs 完全虚拟化：只能模拟同样CPU，但是可以执行不同系统，例如vmware 半虚拟化：guest必须打补丁，例如Xen 硬件虚拟化：可以当作获得硬件加速的完全虚拟化 系统虚拟化：host和guest共享一样的内核，例如Openvz 语言沙盒：只能在语言的范围内使用  虚拟化的级别越偏底层，速度越慢，用户越难察觉到虚拟化的存在。 虚拟化的级别越偏上层，速度越快，用户越容易感知。
 cpu虚拟化和完全虚拟化时，用户几乎可以不察觉到虚拟化的存在 半虚拟化时，guest内核必须存在补丁 系统虚拟化时，用户不能控制自己的内核 语言沙盒时，用户没有使用api的自由  docker的实现结构  docker  lxc namespace: 仅沙盒隔离，不限制资源。 cgroup: 仅限制资源，不沙盒隔离。 aufs image管理   当然，还有很多细节的东西，里面就不一一列举了。例如veth。
docker不是虚拟机 docker不是虚拟机，因为lxc已经是虚拟机。如果两者功能一样，那么docker就没有存在的必要。
你可以把docker当虚拟机用，但是当虚拟机用的话，他的完备程度远远不及现在的种种虚拟机。相比之下，就会觉得很不好用。这不是docker的错，只能说被不正确的使用了。
docker是什么 docker就是环境。
docker实际上只做了一件事情——镜像管理。负责将可执行的镜像导入导出，在不同设备上迁移。
原本我们发布软件有两种方法，源码发布和二进制发布。二进制发布又有两种方案，静态链接和动态链接。最早的时候，我们发布软件都喜欢动态链接，因为小。但是随着网络和存储的升级，软件越来越喜欢静态链接，或者把动态库打包到发布里。因为系统情况越来越复杂，依赖关系一旦出错，系统就无法启动。
将这个思路推到极限，就是虚拟机发布。早些年有人发过一些Oracle的linux安装镜像，算的上是先驱。因为Oracle早些年的安装程序很难用，对系统的依赖复杂。公司做测试用装一套Oracle还不够麻烦的。相比起来，下载一个虚拟机直接跑起来就可以用就方便了很多。即使性能差一些，测试而已也不是特别在意。
docker再进了一步。不但提供一个镜像，可以在系统间方便的迁移。而且连镜像的升级都能做掉。更爽的是，升级只用传输差量数据。当然，有好处就有牺牲。
docker的镜像是只读的 其实不是，docker的镜像当然可以写入。但是写的时候有几个问题。
 如果对镜像进行写入，aufs会将原始文件复制一次，再进行写入。这样性能比较低。 更直接的问题是，一旦对镜像做了写入，就无法从docker这里获得更新支持——docker不能将你的写入和上游的更新合并。因此，整个系统就退化成了一个完全的虚拟机。  所以，我个人认为，docker的镜像本身应当是只读的——如同EC2里面一样。数据的写入应当通过远程文件系统或者数据库服务来解决。
vagrant 提到镜像管理，我们可以提一下同样属于镜像管理的一个软件——vagrant。
 可以将vbox的镜像打包导入导出 提供了一个cloud，允许镜像的分享/更新  为什么vagrant不如docker出名  快，系统级虚拟化使得docker的虚拟化开销降低到百分级别以下。 可以在虚拟机内使用的虚拟机，例如云主机内。 资源调度灵活，不需要将资源预先划定给不同的实例，在不同资源的机器上也不用调整参数。  成功案例 编译系统/打包系统/集成测试环境 典型的搭建一次，执行一次，销毁一次。不需要对image做更改（准确说的需要做更改，但是不需要保存）。
公司内部应用 在IaaS的比拼中，以Openvz为代表的系统化虚拟化方案几乎完败于完全虚拟化/半虚拟化系列技术。就我和朋友的讨论，这里面最主要的因素在于。完全虚拟化技术可以比较好的隔离实例和实例间的资源使用，而系统虚拟化技术更偏向于将资源充分利用。这使得系统虚拟化更容易超售。
然而，在公司内部应用中，这一缺陷就变成了优势。企业的诸多系统，只要在同一个优先级，其可用性应当是一致的。几个联动系统中，一个资源不足陷于濒死的情况下，保持其他几个系统资源充足并无意义。而且总资源是否足够应当是得到充分保证的事情，企业自己“超售”自己的资源，使得业务系统陷入运行缓慢的境地一点意义都没有。
因此，系统虚拟化可以为企业级云计算提供可以灵活调度的资源，和非常低的额外开销。
当然，云计算在企业化中原本就面临一些问题。原本提供软-硬件统一解决方案的集成商，需要如何重新组织解决方案。如何协调节约资源和高性能，高可用。云计算在企业级应用中还有很长的路要走。
短板  太新。目前成功案例还是不足，而且围绕docker的工具链还不完备。 适用范围比较窄。需求需要集中在“环境迁移”领域，而且image本身不应被写入。 生不逢时。rvm和virtualenv已经在前面了。  </description>
    </item>
    
    <item>
      <title>cgroup限定内存</title>
      <link>http://shell909090.org/blog/archives/2642/</link>
      <pubDate>Fri, 06 Jun 2014 14:34:45 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2642/</guid>
      <description>机器配置 ubuntu 12.04
内核版本：3.11.0-20-generic
ulimit的限制效果  ulimit -m 8192 当内存突破8M时，什么事情都没有发生。直到38M都没任何反应。
 ulimit -v 65536 python抛出MemoryError
  cgroup的限制效果  echo 8388608 &amp;gt; memory.limit_in_bytes  大小不对，cgroup的内存量计算方法和ps/status不一致。因此限制计数需要根据具体情况调整。
内核计数 /proc/[pid]/statm size (1) total program size (same as VmSize in /proc/[pid]/status) resident (2) resident set size (same as VmRSS in /proc/[pid]/status) share (3) shared pages (i.e., backed by a file) text (4) text (code) lib (5) library (unused in Linux 2.6) data (6) data + stack dt (7) dirty pages (unused in Linux 2.</description>
    </item>
    
    <item>
      <title>为什么running不高但是load很高</title>
      <link>http://shell909090.org/blog/archives/2640/</link>
      <pubDate>Tue, 03 Jun 2014 14:43:11 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2640/</guid>
      <description>很多初学者会混淆几个概念。CPU繁忙程度，load。两者的区别在于，一个秘书是真的忙着抄抄写写，另一个么，反正领导只检查桌子上堆的文件数。只要桌子上准备一堆文件，在文件里换来换去就好了，没必要真的很忙。当然，大多数时候桌子上堆着很多文件的理由还是因为秘书手不够了，不过少数时候也有例外。例如fork boom，CPU很空但是load奇高。
我们就遇到了一个例外的例外。
症状是这样的。系统经常出现偶发性的load过高。例如有那么几分钟，load会高到100-200，然后就快速下降。但是检查后发现，即使在load极高的时候，cpu占用率也并不高，大概在10-20左右。磁盘吞吐也一般。那么load为什么会这么高呢？
我的第一怀疑当然是超多数量的小线程，在那里搞切换调度。所以我第一反应就是看了/proc/loadavg的当前活跃线程数——结果居然只有1-5。为了确认，我特意的持续观察了数次，在我观测期间load的1分钟计数还升高了——这说明当前实际队列比1分钟平均还要高，而活跃线程却是3。
怎么可能？交通系统报警说北三环大赛车，平均堵塞长度500辆。去一辆警车到现场回报说只看到塞了两辆，再去一辆说算上我们自己三辆。去了十多次都如此。任何脑子清楚的人都会毫无疑问的喊出——黑箱政治，政府不作为，我们要占领国会——不好意思，我们好像没有这个东西。
OK，言归正转。为了解释这个疑惑，我特意的去看了一下内核源码——我擦，loadavg的平均值计算中，是把uninterruptible算在一起的。而活跃上下文中，只算了nr_running！
——你丫敢再精神分裂点么？
为了确认，我还特意man proc，结果发现里面确实有说，平均值是R和D两者去算的。但是在活跃上下文那里，只说了the number of currently runnable kernel scheduling entities——看看清楚，这里可从没有说有D。脑子清楚的仔细想想就知道，D是不可调度的。
——问题是咱脑子不清不楚的就没想这差异，而且咱连man proc都没查。。。
另外顺便说一句，内核也告诉了我们一点东西——load计算的时候是连内核线程一起算的。
清楚这点差异后，问题的原因也很清楚了——肯定是哪里有很高的D。用ps -e Hl | grep -e R -e D扫了一下，再用wc -l做了一下统计。214个线程在D(或者R，或者只是不小心被grep到，但是实际上大部分都是D)。系统当前的loadavg正好长这样：
214.12 156.63 82.25 7/4629 10027  7个执行中线程&amp;reg;，207个uninterruptible。
——所有的谜都解开了。</description>
    </item>
    
    <item>
      <title>系统内存有富裕但是syslog中持续报告内存耗尽</title>
      <link>http://shell909090.org/blog/archives/2594/</link>
      <pubDate>Mon, 17 Mar 2014 14:01:13 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2594/</guid>
      <description>现象 ubuntu12.04，3.5.0-23的内核。在syslog里面持续看到内存耗尽，用free去查看却是内存还有80G左右。检查系统没有cgroup或者ulimit限制。log如下:
Mar 11 14:45:34 nb81 kernel: [7352493.081026] swapper/0: page allocation failure: order:4, mode:0x4020 Mar 11 14:45:34 nb81 kernel: [7352493.081035] Pid: 0, comm: swapper/0 Tainted: G W 3.5.0-23-generic #35~precise1-Ubuntu Mar 11 14:45:34 nb81 kernel: [7352493.081038] Call Trace: Mar 11 14:45:34 nb81 kernel: [7352493.081040] &amp;lt;IRQ&amp;gt; [&amp;lt;ffffffff8112d1b6&amp;gt;] warn_alloc_failed+0xf6/0x150 Mar 11 14:45:34 nb81 kernel: [7352493.081065] [&amp;lt;ffffffff81139a51&amp;gt;] ? wakeup_kswapd+0x101/0x160 Mar 11 14:45:34 nb81 kernel: [7352493.081071] [&amp;lt;ffffffff81130ffb&amp;gt;] __alloc_pages_nodemask+0x6db/0x930 Mar 11 14:45:34 nb81 kernel: [7352493.081079] [&amp;lt;ffffffff815c80df&amp;gt;] ?</description>
    </item>
    
    <item>
      <title>利用cgroups隔离多个进程资源消耗的尝试</title>
      <link>http://shell909090.org/blog/archives/2561/</link>
      <pubDate>Wed, 19 Feb 2014 10:14:23 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2561/</guid>
      <description>setup Add to /etc/fstab.
cgroup /sys/fs/cgroup cgroup defaults 0 2  Then sudo mount -a.
Change directory to /sys/fs/cgroup/. Use mkdir to create a new group, and initalize it like those.
echo 0-3 &amp;gt;&amp;gt; cpuset.cpus echo 0 &amp;gt; cpuset.mems  Without those two step, next operator will failure.
echo 0 &amp;gt; memory.swappiness echo 52428800 &amp;gt; memory.limit_in_bytes  Set memory limit 50M, and forbidden swap.
python test code import os, sys, time, random, string def main(): l = [] random.</description>
    </item>
    
    <item>
      <title>openvpn auth with google authentication</title>
      <link>http://shell909090.org/blog/archives/2545/</link>
      <pubDate>Fri, 24 Jan 2014 12:33:39 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2545/</guid>
      <description>client config # base config client dev tun proto udp remote 192.168.1.122 1194 nobind user nobody group nogroup persist-key persist-tun mute-replay-warnings comp-lzo # authentication config ca ca.crt cert shell.crt key shell.key ns-cert-type server tls-auth ta.key 1 auth-user-pass  Group should be nogroup, not nobody in debian.
auth-user-pass is needed for google auth.
pam config account [success=2 new_authtok_reqd=done default=ignore] pam_unix.so account [success=1 new_authtok_reqd=done default=ignore] pam_winbind.so account requisite pam_deny.so account required pam_permit.</description>
    </item>
    
    <item>
      <title>lxc和virtualbox和物理机的简单性能测试和对比</title>
      <link>http://shell909090.org/blog/archives/2542/</link>
      <pubDate>Thu, 23 Jan 2014 11:04:34 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2542/</guid>
      <description>说明 测试各种虚拟化系统下的虚拟机性能。
测试使用sysbench。
CPU采用如下指令测试。
sysbench --test=cpu --num-threads=2 --cpu-max-prime=50000 run  文件IO采用如下指令测试。
sysbench --test=fileio --file-total-size=10G prepare sysbench --test=fileio --file-total-size=10G --file-test-mode=rndrw --init-rng=on --max-time=300 --max-requests=0 run  内存采用如下指令测试。
sysbench --test=memory --num-threads=2 --memory-access-mode=seq run sysbench --test=memory --num-threads=2 --memory-access-mode=rnd run  线程采用如下指令。
sysbench --test=threads --num-threads=2 run sysbench --test=mutex --num-threads=2 --mutex-locks=1000000 run  裸硬盘测试采用如下指令。
hdparm -tT &amp;lt;dev&amp;gt;  物理机上有三个文件系统，ext4/xfs/btrfs，前两者仅做fileio测试以对比性能。
另外做两个特殊文件系统对比，aufs带复制和aufs无复制。前者在只读层上准备好测试文件，而后进行随机读写测试。其中就附带了文件复制开销。后者在aufs建立后初始化测试文件，因此消除了文件复制开销。
所有测试都是测试数次，取最高者（因为低者可能受到各种干扰）。一般是2-3次。
物理机是一台DELL Intel 64位桌面系统，支持硬件虚拟化，有4G内存。系统采用debian jessie，测试于2014年1月17日-20日执行，内核3.12.6-2 (2013-12-29) x86_64。
虚拟机lxc是使用lxc切分的一台虚拟机，没有做资源限制。
虚拟机vbox是使用virtualbox切分的一台虚拟机，分配了所有CPU，打开了硬件虚拟化，分配了1G内存。
文件系统 ext4 Operations performed: 21311 Read, 14207 Write, 45440 Other = 80958 Total Read 332.</description>
    </item>
    
    <item>
      <title>lxc简单介绍</title>
      <link>http://shell909090.org/blog/archives/2533/</link>
      <pubDate>Thu, 02 Jan 2014 12:48:17 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2533/</guid>
      <description>基本安装 安装lxc包。
注意修改/bin/sh，链接到/bin/bash。lxc在某些版本上有一个bug，声明为/bin/sh却使用bash语法，导致不如此链接会出现错误。
 lxc on debian wiki  镜像和设定 使用lxc-create -n name -t template生成镜像。
在/usr/share/lxc/templates可以看到可用的模板。
在/var/cache/lxc/debian会缓存生成过程的临时文件。
生成的镜像需要在镜像内安装lxc，否则无法使用lxc-execute。
资源限制 在config文件内，写入cgroup限定规则。注意，使用内存限定的话，需要在内核参数中加入cgroup_enable=memory。
在debian下，可以修改/etc/default/grub文件，使用update-grub重新生成规则。
GRUB_CMDLINE_LINUX_DEFAULT=&amp;quot;cgroup_enable=memory quiet&amp;quot;  在config文件中可以如下限定。
lxc.cgroup.memory.limit_in_bytes = 512M # 限定内存 lxc.cgroup.cpuset.cpus = 0 # 限定可以使用的核 lxc.cgroup.blkio.throttle.read_bps_device = 8:0 100 # 读取速率限定 lxc.cgroup.blkio.throttle.write_bps_device = 8:0 100 # 写入速率限定 lxc.cgroup.blkio.throttle.read_iops_device = 8:0 100 # 读取频率限定 lxc.cgroup.blkio.throttle.write_iops_device = 8:0 100 # 写入频率限定   cgroups blkio-controller cpusets memory  执行 lxc-start -n name /bin/echo hello  还可以用以下指令，在已经启动的container里执行进程。</description>
    </item>
    
    <item>
      <title>lxc的double NAT模式无法使用dnsmasq的分析</title>
      <link>http://shell909090.org/blog/archives/2517/</link>
      <pubDate>Mon, 25 Nov 2013 16:40:01 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2517/</guid>
      <description>系统debian testing，lxc-0.9。
在笔记本上做lxc，网络是wifi，AP会drop不同MAC发出的报文，所以无法做网桥。一个办法是用ebtables做规则，我嫌麻烦。另一个是配置多头主机，double NAT。当然，还有路由器模式。不过大多数网络环境中我搞不到default gateway的权限来添加子网的路由规则。所以就选了double NAT。
问题出在dnsmasq作为dhcp和dns服务器上。整个网络都搭好了，通的。完了我在host上启动dnsmasq，在guest里就是硬生生无法获得IP。
首先host上vi /var/log/syslog，看到dnsmasq把dhcp offer发出去了。在guest里tcpdump，看到有报文收到。那就奇怪该死的dhclient不工作了。dhclient版本4.2.4，和主系统一致。网桥环境中这个版本可以工作。
所以把网桥环境中的报文也tcpdump了一遍，加上刚刚不成功的dumpout一起看——什么都看不出来。
偶然dhclient -v -d -4 eth0了一下，看到bad udp checksums，顿时一愣。跑到wireshark下面看了一下——还真是没有计算checksum。打开checksum计算可以看到double NAT里的checksum算错了。提示是maybe checksum offload。
我找到这个链接：http://www.wireshark.org/docs/wsug_html_chunked/ChAdvChecksums.html
里面提到，checksum可能是由网卡或驱动计算的。这就难怪——没问题的dhcp offer的udp checksum是由openwrt的网卡发出，而有问题的则是由bridge和virtual ethernet发出。
那见鬼，别人是怎么成功的？
一番搜索，看来lxc还不是第一个中招的：http://lists.xen.org/archives/html/xen-devel/2011-12/msg01770.html
dhcp-4.2.2可以打这个补丁，使得dhcp-client不去校验udp checksum：http://pkgs.fedoraproject.org/cgit/dhcp.git/plain/dhcp-4.2.2-xen-checksum.patch?id2=HEAD
当然，也有各种坑爹补丁（例如这个：http://marc.info/?l=kvm&amp;amp;m=121882968407525&amp;amp;w=2 ）来修复虚拟驱动上的问题，计算出正确的checksum。
在debian下，他被报为bts671707(http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=671707)。已经报了一年半，尚未处理。
网上很多教程能够跑通的原因，大概是因为他们的guest基于08年以后的rh系系统。rh在08年就对dhclient出了一个补丁（4.2.2那个），用于暂时修复这个问题。
所有基于debian系的系统都无法从offloading不处理的系统上获得dhcp offer。</description>
    </item>
    
    <item>
      <title>nagios配置</title>
      <link>http://shell909090.org/blog/archives/2427/</link>
      <pubDate>Sat, 08 Jun 2013 09:32:28 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2427/</guid>
      <description>nagios的结构 nagios的结构其实很简单，一个监视系统，一个web展现系统，一个remote服务器，没了。
监视系统是根本，在debian中，需要安装的包是nagios3。在安装这个包之后，会启动一个监视进程，负责检查所有的服务是否OK。不OK就触发事件。
检查的时候，nagios会去调一些“插件”。这些插件其实都在/etc/nagios-plugins/config下面注册过的。每个插件配置都是name!v1!v2&amp;hellip;的格式。在注册里面，可以看到这个command_name，对应一个command_line。你很容易看到这就将一个定义转换为了一个命令行。
直接执行这个命令行，你可以看到一个标准输出。nagios就是解析这个标准输出，得到值是否在一个合法的范围内的。所以从原理上说，你可以自己写插件，对任何事情做nagios的监控。
对于某些远程可以获得的信息，目标设备上可以什么都不动，例如ping连通性，或者是端口连通性等。而对于其他信息，例如磁盘空间剩余值，靠远程可能没法获得，就需要在目标设备上装nrpe，Nagios Remote Plugin Executor Server。在debian中，就是nagios-nrpe-server这个包。如果获得本地信息，不需要这个包。
最后，cgi会将本地的信息暴露给web查询，这就构成了完整的nagios体系。在debian中，这是nagios3-cgi这个包。
nagios页面在nginx上的配置 这个过程比较繁琐，因为apache会自动配置，而nginx没有宿主进程，也没有cgi。因此实际上需要运行两个宿主进程。
首先，你需要安装php-fpm宿主进程，这个是nginx搭配php执行的最佳宿主。在nagios中有用到php，所以你需要php执行能力。
其次，安装fcgiwrap这个包。这是cgi执行宿主，以fastcgi协议暴露。这里需要注意。如果你的nginx和nagios的宿主不在同一个设备上（例如像贝壳这样执行了虚拟化的），那么实际上只要在nagios的宿主上执行fcgiwrap即可。php-fpm和nginx可以执行在其他不同设备上，没有关系。只是前者必须有nagios的cgi代码，后两者必须有nagios的网页和php代码。而这三者又都在nagios3-cgi包里面。因此几台机器都需要安装nagios3-cgi包。
最后，配置nginx。
location /nagios3 { index index.html index.htm index.php; } location /nagios3/stylesheets { root /etc; }  第一个映射是nagios的基础目录，在根目录中，我其实配置了nagios3 -&amp;gt; /usr/share/nagios3/htdocs/（debian中的链接位置）。第二个映射是样式表配置，我用系统缺省的。
location ~ ^/nagios3/.*.php$ { include fastcgi_params; fastcgi_pass unix:/var/run/php5-fpm.sock; }  这个是nagios的php解析代码。我的php-fpm执行在同一台机器上，因此直接如此配置即可。
location /cgi-bin/nagios3 { root /usr/lib; include fastcgi_params; fastcgi_param REMOTE_USER $remote_user; fastcgi_pass dev:port; }  最后是cgi暴露的配置。由于我的nagios宿主并不在web服务器上，因此fastcgi是个远程地址。而且注意REMOTE_USER，传递这个才能让远程认到你的用户basic auth。由于nagios的cgi通过这个工作，因此没有这个会直接导致对方始终认为你是无权限用户。
nagios的简单配置 我们首先认清一点，nagios并不负责管理机器的维护。他的设计目标是“可用性”。因此目标是否可达，服务是否可用，是nagios的关心重点。至于磁盘，负载，只是顺便监控而已。所以你可以看到，nagios并没有直接的插件来监控CPU或者内存。他只有snmp插件可以查询到这些数据。
所以，我们开心一点。最低限度，我们将所有需要监控的设备和服务端口加入列表。当这些设备不可达时，nagios会发出告警（有邮件）。而如果运气好，我们是可以监控到这台机器是否有apt包需要升级，磁盘空间是否够的。作为建议，其实你只需要监控load和磁盘空间利用率就够了。其余的东西一般不大需要。当内存或者CPU发生问题的时候，你的query其实也拿不到返回。相对的，目标端口很快失去响应进而引发告警才是我们的预期。
OK，在这个基础之上，让我们看看有什么可以配置的。
服务器添加 首先，你可以定义一些机器。localhost_nagios2.cfg里面有例子，大致是这个样子。
define host{ use generic-host ; Name of host template to use host_name host alias host address IP }  我建议你专门弄个文件来管理这些自己的设备，例如我这里叫hosts.</description>
    </item>
    
    <item>
      <title>lxc路由模式</title>
      <link>http://shell909090.org/blog/archives/2404/</link>
      <pubDate>Fri, 24 May 2013 09:25:36 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2404/</guid>
      <description> 为什么使用路由模式 lxc默认使用的是桥模式，这也是我在家里和公司里部署的模式。在这种模式下，lxc虚拟机可以直接和真实网络中的机器互相访问，就如同一台真的机器一样。路由模式则没有这个便利性。
但是桥模式有个缺陷，必须能够做出桥来。我们有做不出桥来的时候么？有，如果你用笔记本，大部分AP会拒绝第二个MAC地址的包。导致网桥可以组建，却永远无法正常使用。
第一种路由模式，双重NAT简版 双重NAT可以用于几乎所有场景，并且不会带来后遗症。然而，双重NAT的问题在于，物理网络不能直接访问虚拟机。对于很多设备来说，这就失去了价值。另外说一点，之所以叫做双重NAT，是因为多数时候物理网络接到外网还需要一次NAT。
lxc的双重NAT可以视为两步，建立NAT连接的虚拟网络，将lxc连接到虚拟网络。
第一步比较复杂，我们先从br0的建立开始说起。首先，你需要为虚拟网络分配一个不同的保留内网网段。如果使用同样的内网网段，在ARP查询的时候会从一个端口发出超过一个的MAC回应，这就退回了桥模式。
然后我们需要建立一个br0网桥作为配置的起点，对这个网桥赋予IP，配置路由和防火墙，并启动dnsmasq以便于dhcp和dns。这个模式之所以叫做简版，是因为我们先不讨论dnsmasq。
假如你的lxc内网网段是192.168.66.0/24，那么你大致可以如下配置：
brctl addbr br0 ifconfig br0 192.168.66.1 route add -net 192.168.66.0/24 dev br0 iptables -A INPUT -s 192.168.66.0/24 -j ACCEPT iptables -t nat -A POSTROUTING -s 192.168.66.0/24 -j MASQUERADE  实际上，对于任何一种网口设备，将其配置为NAT的过程都是一样的。
第二步非常容易，在lxc的config文件内，指定网桥为br0就OK了。当然，作为略去dnsmasq的代价，你需要手工配置每台机器的IP地址和DNS服务器。
第二种路由模式，双重NAT 双重NAT的完整版需要在内网网口上启动dns，作为dns缓存代理和dhcp服务器。其余和第一种模式没有区别，只是你不需要手工指定IP和DNS服务器了。
当然，其实任何一种网口的NAT配置都是一样的。
第三种路由模式，双边交互路由 第三种路由模式的效果最好，虚拟机和真实机可以互相访问。但是这种模式需要能够修改物理网络网关的路由表。这种模式使用主机作为路由器，中转真实网络和虚拟网络。
我略去如何创造br以及如何将lxc连接到上面，这些前面有叙述。下面我简述一下双边路由最关键的几点。
 最重要的重点，就是在真实网络的网关上，将你的真实物理机在外网的IP，配置为虚拟网络的下一跳网关。例如，对于上面的例子，我们应当在网关上如此配置。
route add -net 192.168.66.0/24 gw 192.168.1.4
  如果不进行如此配置，物理网络所发出的包在到达网关后就不知道应当如何转发了。
 在物理机上允许双边网络的所有包透过。你的包当然不能被防火墙挡掉。 虚拟网络的dhcp是不会传递到外网的，因此如果打算使用dhcp，还是需要开dnsmasq。  </description>
    </item>
    
    <item>
      <title>什么叫做网桥</title>
      <link>http://shell909090.org/blog/archives/2362/</link>
      <pubDate>Mon, 08 Apr 2013 11:18:57 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2362/</guid>
      <description>下面简述的只是linux下的brctl创建出来的玩意，和网桥的学术定义什么的没有关系。
想像你有一块网卡，接上网线，OK，能上网了。
现在，你有一台物理的机器，和一台虚拟机，都需要上网。但是网卡和网线只有一块，怎么办？
如果你能够物理的触摸到虚拟机，你也许会这么干。
找一个交换机来，把物理设备的网卡用网线连接到上面，把虚拟机的网卡连接到上面，再把外网网线接上去，OK，齐活了。
brctl创立出来的网桥就是这么工作的。
你原本的物理网卡，例如eth0，我们直接为他分配IP，进行通讯。结构大概是这个样子的。
system -- eth0 -- network  接入网桥这个假的交换机后，eth0依然负责向外通讯，但是没有自己的IP了。网桥和宿主所在的机器的连接叫做br0（或者br1，以此类推）。
system -- br0 -- eth0 -- network  然后，我们可以为这个交换机接入很多的设备。
system -- br0 -- eth0 -- network | vethXX | virtual -- eth0 /  其中，eth0和vethXX是一对设备。一个在宿主里，一个在虚拟机里。互相连通。
所以，当虚拟机发生通讯时，eth0上可以看到数据流，但是br0上看不到。而如果虚拟机和宿主通讯时，eth0看不到数据流，br0上可以。</description>
    </item>
    
    <item>
      <title>lxc的文件共享映射和严重安全隐患</title>
      <link>http://shell909090.org/blog/archives/2334/</link>
      <pubDate>Sat, 09 Feb 2013 01:18:31 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2334/</guid>
      <description>在lxc中，可以利用mount bind指定guest可以访问某些host的路径。例如：
lxc.mount.entry = /home/shell /var/lib/lxc/{vmname}/rootfs/home/shell none defaults,bind 0 0  注意，/home/shell是你希望共享的主机路径，/var/lib&amp;hellip;/shell是映射到的目标路径。
这个工作的基础原理，是在虚拟机启动的时候，自动执行mount，添加一条bind映射，将host的路径挂到guest可以访问的路径里去。
由此，我发现了一个lxc在文件共享时的严重bug。
user@guest:~$ mkdir -p ttt/123 user@guest:~$ cd ttt/123 user@host:~$ mv /var/lib/lxc/{vmname}/rootfs/home/user/ttt/123 . user@guest:~/ttt/123$ cd .. user@guest:(unreachable)/user$ ls -l  好了，现在guest在host的~user/目录下，host上本来不应当被看到的东西全被看光光了。
更严重的是，如果此时sudo成root，在host中可以以root的身份做任何事情。
结论：暂时来说，不要在host和guest之间直接共享任何数据。</description>
    </item>
    
    <item>
      <title>fork两问</title>
      <link>http://shell909090.org/blog/archives/2332/</link>
      <pubDate>Fri, 01 Feb 2013 10:44:23 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2332/</guid>
      <description>问题1 以下代码。
int main() { fork(); fork(); fork(); printf(&amp;quot;---n&amp;quot;); return 0; }  编译后执行./a.out | wc -l，输出多少？
问题2 以下代码。
int main() { fork(); printf(&amp;quot;b&amp;quot;); if (fork() == 0) { write(1, &amp;quot;a&amp;quot;, 1); }else{ write(1, &amp;quot;c&amp;quot;, 1); } return 0; }  编译后执行./a.out，输出多少？
答案 第一个是8，因为pipe会继承。
第二个是cabcbbab，结果不恒定，原因比较复杂。至少应当能看懂2个a2个c4个b，c先出ab后出最后一个是b。</description>
    </item>
    
    <item>
      <title>修正问题，让debian testing使用lxc</title>
      <link>http://shell909090.org/blog/archives/2329/</link>
      <pubDate>Wed, 23 Jan 2013 16:57:03 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2329/</guid>
      <description>目前debian testing里面的lxc是无法运作的。原因是live-debconfig这个包只在sid中存在，而lxc是借助这个包来做系统初始化设定的。没有设定就结束初始化会挂掉系统。
解决方法如下：
dget -x http://ftp.de.debian.org/debian/pool/main/l/lxc/lxc_0.9.0~alpha2-4.dsc  可能因为没有key而无法解压，用dpkg-source -x解压开内容即可。
aptitude install autotools-dev docbook2x libapparmor-dev libcap-dev linux-libc-dev  然后进入目录，dpkg-buildpackage -rfakeroot -d进行编译。
退出目录，dpkg -i lxc&amp;hellip;进行安装。
到/usr/share/lxc/packages/，wget http://ftp.cn.debian.org/debian/pool/main/l/live-debconfig/live-debconfig_4.0~a15-1_all.deb。
然后再执行常规操作。
lxc-create -n vm0 -t debian lxc-start -n vm0  启动正常了。
在debian wheezy 3.2.0-4-686-pae下测试通过。</description>
    </item>
    
    <item>
      <title>选择哪个linux发行</title>
      <link>http://shell909090.org/blog/archives/2242/</link>
      <pubDate>Thu, 27 Sep 2012 14:07:46 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2242/</guid>
      <description>选择哪个linux发行 很多人问我，哪个linux发行版更好。这不是个伪命题，而是个蠢命题。哪个发行版更好取决于你要做什么。我们首先把linux发行版分为四大类，deb家族，rpm家族，源码家族，其他。
假如你要稳定部署 所谓稳定部署，就是你没什么机会对系统升级打补丁。听上去很傻X，系统不打补丁？实际上这样的系统非常多。大型跨国公司的ERP，托管在企业封闭机房内的核心业务系统。这些系统的升级成本是非常惊人的，一次升级动辄数天策划，弄一套备用系统来放着，然后再顶着XX的损失停机几个小时。
这种级别的系统，建议你直接上RHEL。不要怕花钱，出问题的损失远远比RHEL的服务费高的多。
假如你要持续更新 对于持续更新的系统，你可以选择debian/ubuntu。这两个系统都具有很强的滚动更新能力。虽然RH系统可以通过yum进行升级，然而RH的追求稳定策略，使得仓库的升级频率要比deb系小的多。
deb的系统有非常简单的配置和升级方案，而且大多保持稳定。ubuntu的策略比debian激进很多，所以软件有更多的新特性——当然，也有更多的死机。
假如你要高度定制 高度定制的系统只有使用源码安装，任何发行版都不会帮你把每个开关组合全部编译一遍。
源码家族中最出名的两个是gentoo和lfs，不过除非你的蛋在燃烧，否则一般是不会用lfs作为自己的应用系统的。大多是使用gentoo来做支持。
假如你只是自己想用用 你是一个彻底的新手 我建议你从debian家族的knoppix开始，或者ubuntu livecd也不错。这两个都是livecd系列，就是可以直接从光盘启动系统并使用，不需要在硬盘上安装，也不需要虚拟机。相反，他们自带虚拟机，可以虚拟一个windows出来供你偶尔用一下。
你是一个有过一定经验的人 那你熟悉什么就用什么。
不过作为一般性使用，我推荐ubuntu。他们针对桌面用户做了很多定制，打造了一个非常不错的环境。在我所知的发行版中，ubuntu的桌面用户是最多的，针对新手的答疑也是最友善的。
当然，文档最好的还是gentoo。
你是一个专家 很感谢你看完这篇文章，你太无聊了。</description>
    </item>
    
    <item>
      <title>卖vpn咯</title>
      <link>http://shell909090.org/blog/archives/2223/</link>
      <pubDate>Mon, 13 Aug 2012 02:46:03 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2223/</guid>
      <description>提供pptp, l2tp, openvpn, ssh,
socks5五种协议支持。如果需要的人比较多，其他协议也可以逐步实验，例如iodine。其中pptp,l2tp和socks5依赖于客户端和网络环境，因此不能保证每个点每次都连接正常，请自行测试，有问题联系我，看看是否是已知问题。
美国机房（应该是西海岸，不过我不确定），不限速，不限流量。原则上一个vps大概放10个vpn帐号，保持成本就行，不会太慢。但是不得使用p2p，也请不要超过12小时连续满速使用vpn。如果发现连续满速使用造成其他用户投诉，暂封帐号，您来找我。只要不是病毒造成的，您继续用。如果发现使用p2p，头次警告，第二次封号不退款。（因为被版权部门发现使用p2p会造成vps被封，所以，抱歉）
一个帐号10元一月，100一年，试用期一周。你可以先联系我开账户，然后试用一周，一周内你可以实验账户和各种环境的匹配性。一周后付款（这一周也是计入费用的），支持支付宝，银行汇款，面付（限上海）。
如果碰到问题，邮件联系我。
开通账户：
你需要给我你的用户名和密码，以及需要开通的服务。如果开通ssh，最好由你来生成密钥，并给我key。如果你懒得给，那么就由我来随机生成了。
完成后，我会邮件给你你的用户名，密码（如果可能的话，key），服务器设定。
一般来说，android手机推荐pptp/l2tp，ios系统只能用l2tp。windows和linux推荐openvpn，在外使用时推荐ssh。
注意，无论用哪种vpn方式，必须将你的dns修改为境外dns，例如8.8.8.8。ssh的话需要客户端支持从socks中进行地址解析。
pptp设定：
http://www.maizidi.com/howto-configure-windows-xp-win7-pptp-l2tp-client/
pptp和l2tp协议需要你的路由器支持。普通的tplink设定中就有是否开启pptp协议通过的选项，请务必打开这个选项，否则无法工作。
如果你的网络接入供应商封锁pptp，那么也是无法正常使用的。你可以再试试l2tp。如果也不行，那么请换别的协议。
ssh：
ssh一般用于pptp和l2tp都无法穿越的地方，例如机场或者酒店的网络。具体设定可以看这里：
http://hi.baidu.com/x%CE%B4%D6%AA%B7%E7x/blog/item/6e6eaf1ff55f641a203f2efc.html
autoproxy的目的，是为了自动检测域名是否需要进行代理。如果你不需要这一检测，可以不用autoproxy。
在身份验证选项那里，应当有一项是使用key。你需要将自己的key在user keypair
manager里面导入(import)，最后再使用。如果是我邮件给你，你需要将key的内容保存为一个文本文件。
openvpn：
http://blog.felixc.at/2010/11/openvpn-win/
我会为你准备好配置，可以直接使用。但是
，你必须在这里下载，不要直接去首页下载，那是openvpn官方提供的服务的定制版：
http://openvpn.net/index.php/open-source/downloads.html
配置文件默认是.conf，在windows下也许需要修改为.ovpn。默认是会打开智能路由的，这会导致加载速度比较慢。如果是win7，你需要以管理员身份运行openvpn-gui-1.0.3.exe，否则会出现权限问题。
MacOsX的教程在这里：
http://cn.giganews.com/vyprvpn/setup/mac/openvpn.html
你可以在这里下载：
http://code.google.com/p/tunnelblick/
至于linux用户，你直接sudo openvpn xxx.conf就好了，没有任何难处。
另外，最近gfw开始升级。openvpn的稳定性会比原来差很多，即使连接上，也可能丢包。这点对不同的接入和不同的机房情况不一样，我们还在进一步确认中。如果你有类似困难，可以向我反映。</description>
    </item>
    
    <item>
      <title>debian wheezy下以uwsgi安装graphite</title>
      <link>http://shell909090.org/blog/archives/2200/</link>
      <pubDate>Mon, 09 Jul 2012 08:45:28 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2200/</guid>
      <description>abstract graphite是一个python写的性能监控系统。这个系统是由多个分离的部分组成的。
 graphite-web: 由django写的web界面系统。 carbon: 数据收集的守护进程。 whisper: 一种python写的数据库，类似rrd，便于大量的性能日志数据收集和处理。上两个组件会调用这个库。 collectd: 数据收集守护进程，向carbon中喂数据的数据源。  另外，有一点黑色幽默的就是，graphite的意思是石墨，是炭(carbon)的一种同素异形体。因此在graphite项目中，多次出现carbon这个名字。当然，另两个同素异形体是钻石(diamond)和足球烯(footballene)，你就暂时别指望看到他们的身影了。
另一个用python写的，以元素命名的著名软件是mercurial。化学元素中的汞，俗称水银，符号hg。因此mercurial的命令行简写才是hg。
以上几个的结构大概是这样的：
collectd(source) -network-&amp;gt; carbon -&amp;gt; writing-&amp;gt; whisper
database -&amp;gt; reading-&amp;gt; graphite-web
下文描述了在debian wheezy下，以nginx+uwsgi模式安装graphite的过程。之所以用这个模式，是因为我的大部分系统都是python写的，同样安装在uwsgi下面。一事不烦二主。
carbon carbon有对应的debian包，可以很简单的安装。
sudo aptitude install graphite-carbon  默认的数据端口是2003，默认的数据路径是/var/lib/graphite/，这个在下文需要用到。
graphite virtual graphite有部分需要安装到系统中，因此最好用virtualenv进行安装。
cd /var/web/ sudo aptitude install python-virtualenv virtualenv --system-site-packages graphite  我假定你的安装路径是/var/web/graphite，这个在下面要反复用到。
install 在安装路径下，执行以下内容
source bin/activite pip install graphite-web --install-option=&amp;quot;--prefix=/var/web/graphite&amp;quot; --install-option=&amp;quot;--install-lib=/var/web/graphite/webapp&amp;quot;  注意，/var/web/graphite需要根据上面的设定自行修改，webapp是你的django基础路径。
configure 在/var/web/graphite/webapp/graphite下面，执行以下内容
cp local_settings.py.example local_settings.py  然后编辑local_settings.py
GRAPHITE_ROOT = &#39;/var/web/graphite&#39; WHISPER_DIR = &#39;/var/lib/graphite/whisper&#39; DATABASES = .</description>
    </item>
    
    <item>
      <title>multiseat简说</title>
      <link>http://shell909090.org/blog/archives/2192/</link>
      <pubDate>Mon, 11 Jun 2012 03:19:54 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2192/</guid>
      <description> 简述 这篇文章说的是如何实现multiseat，必须的条件和步骤等等。
首先简介一下multiseat。multiseat又叫做多座电脑，和瘦客户端(thinclient)一样，是一种降低电脑平均使用成本的方案。基本思路是，买一台稍好的物理机，然后买两个显示器和键盘鼠标，让两个(或者多个)人同时使用一台电脑。和瘦客户端一样，multiseat一般只用于对电脑计算能力要求不高的场合，打游戏的一般就别考虑了。和瘦客户端不同的是，multiseat的处理都在近程，所以在体验上会略好一些，部署时也不依赖于中心化网络。不过这些年网络设备都在改善，相差也不多。
硬件解说 显示系统 显示系统通常分为显卡和显示器两部分。multiseat至少需要两个显示器，但是两台显示器输出有多种情况。
 单卡单核心双输出。一块显卡，一块核心，pci上就一个物理设备，但是可以输出到两台显示器上。例如笔记本，一个输出到本子上，一个输出到投影上。大部分机器都是这种情况。 单卡双核心单输出。又叫做单卡双核心交火。交火是一个ati术语，在nv那里叫做sli。是指用两块显卡为同一个显示进行加速，达到比一块显卡更快的情况。这一般是顶级显卡。 单卡双核心双输出。在单卡双核心单输出的卡上，一般都有两个输出。如果接入两个设备，那就是双核心双输出了。 双卡双核心单输出。又叫做双卡交火，在pci上有两个物理设备。同样是为了游戏而生的电脑。 双卡双核心双输出，两个pci-e。在上面的基础上，多接一台显示器。 双卡双核心双输出，一个pci。很少见，一般都是图形工作站。  之所以在这个问题上说这么细，是因为多X方案必须工作在两个以上核心上，每个核心分别输出一路。也就是说，上文中的3, 5, 6三种情况。我们最常见的1是不可以用多X方案的。而方案5, 6，是这么分的。一般的显卡都是pci-e的，而一块主板上只有一个pci-e插槽。所以普通主板是配不上两块普通显卡的。也不要考虑板载显卡和外接显卡的问题，卖电脑的说，大部分主板上都做了自动屏蔽。外接显卡一插上去，板载显卡自动屏蔽。
键盘和鼠标 multiseat至少两套键盘和鼠标，这是常识。
声音和外设 做的好的multiseat，尤其是搭配硬件卖的商业方案，一般都会做声音和外设隔离。你接上去的u盘不会出现在另一个人的电脑里。不过有些方案的隔离就不是那么完美，有可能只有主座有声音拉，或者是声音不能用拉。或者是自己指定声音输出到哪个设备，然后再抢耳机拉，或者是干脆多装一块声卡拉。这个问题自己留心。
windows windows下可以用softxpand[2]或者betwin[3]，俗称拖机软件，不过两者的破解都不是很好找，尤其是win7可用的。windows下拖机的后果可能是，D3D加速有问题，两个人同时用的时候CPU使用率升高，其中一个人没有声音等。具体情况你设法下到试试再说。
linux 以下linux，没特别说明的话都是指debian，默认的发行版本是wheezy。
多X方案 所谓多X，就是开启两个以上的X，每个显卡一个X。这样形成的multiseat保留了原生的一切能力，包括3D加速。只要你原生显卡支持，都可以做到。多X方案的第一个显卡可以看到console，第二个只能看到图形界面，不能通过C-M-F1切换到console。
但是多X的条件也非常严格，上面列的情况1是没戏的。大部分人的电脑都被划到了这种情况。即使你有幸，弄到了3, 5, 6三种情况中的一个，也要注意，两块显卡必须是同一厂家，最好是同一型号。这点尤其对pci显卡更需要注意，pci显卡和pci-e显卡显然不能是同一型号，但是*必须是同一厂家*。
这个方案最鸡肋的地方在于，3, 5两种情况只有在针对游戏特别配置的电脑上才有效，而这种电脑本身是非常昂贵的。这和降低系统成本的初衷相违背。
Xephyr方案 Xephry是一个X的模块，他的目的是使用内存作为X的输出设备。因此Xephry做出来的X可以将显示内容再显示到其他地方，例如作为其他X中的一个窗口出现，等等。
利用这个特点来做multiseat的思路基本是这样的。首先我们将两个显示器合并成一个虚桌面，如同我们常规做的那样，左边的窗口拖一下可以到右边。然后再开两个Xephry，每个里面包含一个标准的X，包括display manager，session，window manager等等。最后每个X分别用一套键盘/鼠标。这样出现的效果和multiseat是完全一样的。
这个方案的优点是，支持众多的机器，尤其是我们最常见的1情况。但是，其缺点和优点一样明显。由于我们操作的是Xephry，而不是实际的显卡，因此会缺少一些X扩展，例如3D。而且相比原生设备，Xephry方案会有少量延迟。贝壳做过实际测量，至少在播放普通视频的时候，60Hz的刷新率没什么问题，播放无卡顿。
这个方案有一个封装好的实现，帮你做了整个过程。(不过我没有测试)叫做MDM[4]。
虚拟化拖机 无论是windows还是linux，都有一个不算方案的方案。安装一套vmware，然后将vmware在其中一个显示器全屏，再把其中一个鼠标和键盘指定给这台虚拟机。这样也可以做到multiseat的效果。使用Virtualbox/Vitrual
PC也是完全一样的原理。
vmware中原生是不可以将鼠标/键盘指定给虚拟机的。关于这点，文档[6]给出了完整的解决方案。在.vmx中加入下面一行即可。
usb.generic.allowHID = &amp;quot;TRUE&amp;quot;  参考  Multiseat Documentation in x.org Softxpand BeTwin Multiseat Display Manager ourbetwin VMware拖机方法  </description>
    </item>
    
    <item>
      <title>首次bsp日记</title>
      <link>http://shell909090.org/blog/archives/2158/</link>
      <pubDate>Wed, 02 May 2012 03:09:03 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2158/</guid>
      <description>第一次参加BSP，还不错拉。因为以前没参加过，所以等搞明白了这个是干吗的再和大家说。
BSP是bug squeeze party的简称，简单来说就是修错会。debian马上要发行7了，在此之前有很多的bug没有修复。其中有一种是RC bug，即运行就会出大问题的bug，或者干脆没法编译。无论哪个，都会导致这个包不能进入最新的发布。有些bug很麻烦，需要maintainer和author沟通，这个没有办法。但是有些问题解决起来很简单，只是因为后果很严重，作者又暂时没空处理，导致包无法进入stable，实在很无谓。BSP的目的，主要是以非维护者上传(non-maintainer upload)的方式修复这类bug。因为包不是自己的，所以礼貌上，只修复半个月以上的rc级别bug，其他的留给maintainer来处理。
BSP的主要目的，就是这么一个苦力会。没有挂名，最多只有一条changelog记录，还要大量寻找和修复bug。不过BSP相当重要，因为很多maintainer往往有一段一段的不活跃时间。这时候即使再简单的问题也不会处理。按照debian的规则，别人也不会帮他处理。除了BSP，很少有一批人会专门找这种简单的Bug来修正。如果没有BSP，debian stable发布的时候一做RC冻结，就要少掉很多有用的包。BSP更大的目的是，交流和传授debian打包和除错的经验，唤起人们的关注。也许在会后，如果有人看到一些简单bug，会使用nmu的方法给与修正。不过BSP到确实是有一个额外加成的好处——基本变成了签名会。昨天估计是中国大陆地区首次DD数量接近其他人数量，我一下弄到了5个签名，2个DD一个Ubuntu员工。加上原来就有的zigo签名，我就有3个DD签名了。
本地BSP是在thomas的公司举行，欧特家博士匹萨厂商赞助了我们两天的午餐——微波食品匹萨。第一天来的人比较多，很多都是纯新手，大概有20多人。Zigo倒是在网络上说会帮助新手，但是纯新手看到debian打包系统根本无从下手，所谓指导什么的也无从说起。很多人一天一个bug都修不掉，甚至都看不懂，很有挫折感，估计有不少有热情的人在第二天就这么默默退散了，第二天只来了15个左右。
我主要是以修复自己的问题为主，python-snappy和python-formalchemy都升级到了最高级，并且修复了自己以前打包的一个问题。至于RC bug么，我修了一个。两个包在python中命名冲突了，所以在debian中需要声明为conflicts。另外我评审了一下，最终还是决定关闭了python-libmemcached的ITP。虽然对douban很不好意思，还让他们修了一下。但是python-libmemcached依赖于libmemcached，而后者已经逐步升级到了1.0.X版本，但是douban为了稳定使用，是sticky在0.4版上的。因此当更新的debian发行时，实际上python-libmemcached和系统中的libmemcached不是一回事。因此，我不能依赖libmemcached的维护者，而是需要自己去维护后者——没办法，我就是怂了。python-libmemcached的爱用者，还是自己打包吧。我倒是可以公开打包文档。
另外，我在想是否要集合一批python/debian的用户，来做投票。例如，python的一个容器——flup，在debian中实际上已经orphon了。如果有足够的人投票，我愿意为flup做接手维护工作。不过目前debian下问下来的结果，大家对flup没什么太大兴趣。</description>
    </item>
    
    <item>
      <title>vps上应当装什么</title>
      <link>http://shell909090.org/blog/archives/2144/</link>
      <pubDate>Tue, 17 Apr 2012 07:00:21 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2144/</guid>
      <description>假定你有一台debian vps，上面需要装一些东西来——你懂。你应该装一些什么呢？
基础部分 ssh 没啥好多说，没有ssh，你甚至无法管理机器。不过注意，安全的ssh方式应当只允许使用key登录，禁止一切密码登录。而且对于没必要登录的某些用户，需要在/etc/passwd中将shell改为/bin/false。至于端口改不改，这个不重要，看你心情。
vim debian默认装的是vim-tiny，很不好用。建议改为vim，改配置的时候让自己舒服点。
安全部分 iptables-persistent 这是debian内用于iptables规则持久化的工具，你可以编辑/etc/iptables/rules.v4来修改防火墙规则。注意，目前debian stable(squeeze)中的版本还没有4/6区分，你可以弄一个testing(wheezy)中的来装。
一般来说，你的规则中至少要包含以下内容：
-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -i tun+ -j ACCEPT -A INPUT -i ppp+ -j ACCEPT -A INPUT -p tcp -m multiport --dport 22,xxx,xxx,xxx -j ACCEPT -A INPUT -p udp -m multiport --dport xxx,xxx,xxx -j ACCEPT  而且强烈建议，先保存一个没问题的iptables，然后直接修改iptables，再保存。这样的好处是，当你脑残改错了导致你自己都无法管理的时候，只要重启就可以恢复vps工作，而不用更麻烦的动作。
denyhosts 这是ssh的连接防御进程，用python编写。如果有人试图尝试你的ssh密码，这个程序就会踢掉他的ip。
如果你已经用了我说的，通过key的连接方式，你可以一次就直接踢掉对方ip。
管理部分 ifstat ifstat是用于网络流量管理的工具，可以告诉你网络目标的流量是多少。
dnsutils dnsutils里面包含了不少用于管理dns的工具，包括我们常用的nslookup，还有相对少用的dig。
mtr-tiny mtr是一个traceroute工具，比后者好用很多。这个工具可以快速跟踪路由。</description>
    </item>
    
    <item>
      <title>mirrors.geekbone.org软件仓库镜像站将于4月中旬下线</title>
      <link>http://shell909090.org/blog/archives/2140/</link>
      <pubDate>Fri, 13 Apr 2012 01:38:56 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2140/</guid>
      <description>原文在此我用了5年多的cn99和geekbone两大镜像终于全部下线。
需要通告的一点关键问题即是, 由于tux下线早于新一个版本的debian发行,
因此目前mirrors.geekbone.org还是已经发行的debian安装盘的官方源之一.
请大家在安装debian6的时候不要再选择geekbone, 并请通告其他debian用户.
在09年加入shlug之初，就知道当年用了很久的geekbone服务器是shlug管理维护的。当时就很惊讶，以捐助方式运作一台镜像服务器，这个是相当不容易的。包括募集，管理，账目，在中国要做整套过程需要相当心力。而且geekbone还是在debian有注册的镜像站之一。可以看Debian 全球鏡像站。
大约在11年，中科大的ustc服务器上线后。在一次和lightning的闲聊中，lightning就谈到了tux服务器的问题。当时tux的服务器硬盘已经不足，最多在数月后就会满额。lightning删除了部分上面的无用数据，让服务器可以稍稍多工作一些时日。我当时就建议不要全面镜像所有的debian镜像，毕竟当时中国已经有anheng和ustc两个全面源，其中ustc还在申请大陆一级源(他们的资源投入确实不错，镜像速度相当快)。tux毕竟是老服务器，可以转做i386和amd64两个主要镜像。国内大部分人用的都是这两个arch，sohu的部分镜像也是针对这部分的。lightning表示看看再说。
今天，看到了shlug通告，tux服务器准备下线。想想也的却是，tux已经在超期服役，而国内已经有了ustc, anheng, sohu, bjtu四个镜像.
再进行一次募捐让tux恢复服役看来是没什么必要了.
在此, 感谢一下shlug服务器维护团队, 谢谢你们的努力让我五年来得以享用快速的源服务. 祝tux一路走好, 愿电脑诸神与它同在, enter.
另外, 提一点我们和欧美的工业水准差距. 我曾经撰文说过, 中国要追赶美国还有很长的路要走. 当时列举的证据就是dd和debian mirror lists. 当时我们也是4个源, 目前加入了bjtu, tux退出, 还是4个源.
相比美国那个深不见底, 鼠标滚轮滚好几下都没看到头的列表, 实在是太差距了.
这个差距不仅体现在源少, 更体现在用户少. 用户少就是源少的原因.
如果用户增长一个数量级, 目前这些源肯定会发生不足, 然后吵着让各个大学再开一两个镜像出来. 我倒是觉得这样不错, 至少sjtu有机会露个脸.
其实sjtu也是有自己的源的](http://ftp.sjtu.edu.cn/debian/)%E7%9A%84), 只是没有对普通网络用户开放, 访问速度缓慢而已.</description>
    </item>
    
    <item>
      <title>如何用tabbar插件做emacs的tab定位切换</title>
      <link>http://shell909090.org/blog/archives/2134/</link>
      <pubDate>Tue, 10 Apr 2012 06:50:56 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2134/</guid>
      <description>说明一下，定位切换的意思，是像chromium那样，用Atl-1-9直接切换tab。而不是用上一个下一个慢慢换。另外，是切换buffer，不是切换frame。
以下是实现部分：
;; 全部的buffer都分一组，否则这个修改是没任何意思的 (setq tabbar-buffer-groups-function (lambda () (list &amp;quot;All Buffers&amp;quot;))) ;; 去掉emacs自带的几个buffer (setq tabbar-buffer-list-function (lambda () (remove-if (lambda(buffer) (find (aref (buffer-name buffer) 0) &amp;quot; *&amp;quot;)) (buffer-list)))) ;; 切换到第N个buffer，1为第一个，负数表示从后数，注意0会出错，这里就不处理了 (defun switch-tabbar (num) (let* ((tabs (tabbar-tabs (tabbar-get-tabset &amp;quot;All Buffers&amp;quot;))) (tab (nth (if (&amp;gt; num 0) (- num 1) (+ (length tabs) num)) tabs))) (if tab (switch-to-buffer (car tab))))) ;; 不说废话，绑热键 (global-set-key [(meta 1)] (lambda () (interactive) (switch-tabbar 1))) (global-set-key [(meta 2)] (lambda () (interactive) (switch-tabbar 2))) (global-set-key [(meta 3)] (lambda () (interactive) (switch-tabbar 3))) (global-set-key [(meta 4)] (lambda () (interactive) (switch-tabbar 4))) (global-set-key [(meta 5)] (lambda () (interactive) (switch-tabbar 5))) (global-set-key [(meta 6)] (lambda () (interactive) (switch-tabbar 6))) (global-set-key [(meta 7)] (lambda () (interactive) (switch-tabbar 7))) (global-set-key [(meta 8)] (lambda () (interactive) (switch-tabbar 8))) (global-set-key [(meta 9)] (lambda () (interactive) (switch-tabbar 9))) (global-set-key [(meta )] (lambda () (interactive) (switch-tabbar -1)))  </description>
    </item>
    
    <item>
      <title>empathy的无聊问题——记一次排错</title>
      <link>http://shell909090.org/blog/archives/2132/</link>
      <pubDate>Mon, 09 Apr 2012 03:55:40 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2132/</guid>
      <description>废话不说，debian testing，装了empathy后没法用account，等于废物。
先看bug report，开reportbug，看empathy的bug，有一个“Accounts window does not open”，估计就是我要的。
在浏览器中打开，http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=594945&amp;amp;archived=False&amp;amp;mbox=no，里面说了大致情况，和我这里非常类似。
第一个意见，killall -9 empathy-account，无效。
第二个意见，需要装CM。
跑去看看，一个都没装。跟着看说明，应该在recommand里面的。OK，我这里有这个配置。
shell-deb:\~\# cat /etc/apt/apt.conf.d/20norecommanded APT { Install-Recommends 0; };  这是对付很多无聊包把recommand当作suggest用的，结果这次中标。其实这次的recommand应当放入dep里面的。
OK，完事。
PS.虽说如此，记得把telepathy重启一下，否则jabber协议看的到但是无效。</description>
    </item>
    
    <item>
      <title>redis的rdb和aof模式性能对比</title>
      <link>http://shell909090.org/blog/archives/2128/</link>
      <pubDate>Fri, 30 Mar 2012 04:10:30 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2128/</guid>
      <description>由于是同一台机器，进行相对对比，我就不列配置了。系统是debian testing，kernel 3.2 686。redis 2.4.8。
测试方法是用python写的脚本对redis数据库进行写入，看写入速度。
100000/300000/1000000是数据量，插入的都是string。第一个数据是最小时间，第二个是平均，第三个是数据大小。
100000:
dbmode: 4.8, 5.1, 1477792
aofmode: 9.1, 9.3, 3677803
300000:
dbmode: 16.5, 17.6, 4877792
aofmode: 21.1, 21.4, 11477803
1000000:
dbmode: 61, 65, 16777792
aofmode: 77, 85, 38777849
从简单分析来看，aof比rdb慢25-80%，但是大规模数据都比较支持慢25%这端。估计在低数据量下，rdb模式更加占优势。数据规模增长时，速率比接近于4:5。aof的数据比rdb数据大150%（2.5倍上下），这点随着数据增长基本不变。
从读性能分析来看，两者差异不大。同样，数据分别是最小时间和平均时间。
dbmode: 55, 60
aofmode: 62, 63
差异在10%以内，甚至比最小-平均差异还弱。基本可以视为一致。</description>
    </item>
    
    <item>
      <title>kvm虚拟化的性能对比</title>
      <link>http://shell909090.org/blog/archives/2118/</link>
      <pubDate>Mon, 19 Mar 2012 07:09:38 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2118/</guid>
      <description>废话不多说，4G的机器，debian testing，amd64内核32位环境。用kvm切出一个768m的机器，debian testing，64位内核64位环境。对比起来有点不公平，不过基本说明问题。
用lmbench对比两者的性能，报告我就不贴了。基本结论如下：
1.纯计算: kvm内比真机还快，或者至少性能相当。估计是32位环境的关系。
2.syscall, read, write, select: 都是kvm快。
3.Protection fault,AF_UNIX sock stream latency,fork+exit,fork+execve: 真机比kvm快至少4倍，最多可达6倍。
4.文件读写api: 真机比kvm快3倍以上。
5.socket性能: pipe是kvm快，unix file是真机快。
6.iozone: 两者吞吐性能几乎一致，有时kvm比真机还快。可能和真机的ext3上面堆满碎片结构有关。
基本结论，kvm在计算和io上都没什么太大问题，主要问题在于各种涉及ring0指令的内核调用方面（好像这也是虚拟化的通病）。在虚拟化系统中，尽量避免大量的内核调用，尽量减少碎片调用，增大IO块。</description>
    </item>
    
    <item>
      <title>有一种错误，叫做太常见了以至于视而不见</title>
      <link>http://shell909090.org/blog/archives/2098/</link>
      <pubDate>Mon, 20 Feb 2012 06:19:51 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2098/</guid>
      <description>最近整XEN，出了一个奇怪的错误。
ERROR (SrvDaemon:355) Exception starting xend((22, &#39;Invalid argument&#39;)) Traceback (most recent call last): File &amp;quot;/usr/lib/xen-4.0/lib/python/xen/xend/server/SrvDaemon.py&amp;quot;, line 335, in run xinfo = xc.xeninfo() Error: (22, &#39;Invalid argument&#39;)  根据网络上的内容，首先排除没有xen模块——有了，然后是/proc/xen目录是否mount——有了，然后是/sys/hypervisor/下面的一堆属性——有了，然后是版本——不对。xen-utils-4.1是4.1.2版本，而xen-tools是4.2版本。不过xen-utils并不依赖xen-tools，没有后者应当也可以运行这些玩意。hypervisor和xen-utils的版本是一致的。那问题是什么？
出错的文件是/usr/lib/xen-4.1/lib/python/xen/lowlevel/xc.so里面发生的异常，下载xen的源码检查，这个函数主要是检查属性。属性检查会出什么错？
正在一头雾水的时候，突然想起一个问题。我安装的是xen-hypervisor-4.1-amd64，因为kernel是linux-image-3.1.0-1-amd64。然而，我这个系统有一个非常大的特殊——在64位CPU上运行的32位系统。因此，实际上xen-utils是32位的。行了行了，下面的事情用膝盖都能想到。
叹气，这世界上，真的有种错误，叫做太常见了以至于视而不见。不要认为自己不会犯。</description>
    </item>
    
    <item>
      <title>最新一期的freenas测试报告</title>
      <link>http://shell909090.org/blog/archives/2096/</link>
      <pubDate>Fri, 17 Feb 2012 03:57:59 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2096/</guid>
      <description>去年我写过一篇freenas和解决方案，今年我又测试了一下，发现这玩意更加完善了，更企业化了，也更不适合玩玩了。今天写一下大概的步骤，供需要的参考一下。
freenas提供以下几种服务，afp，活动目录(AD)，CIFS(windows共享)，动态DNS(绑定域名到动态IP)，FTP，LDAP，NFS，Rsync，SNMP，Ssh，tftp，iSCSI。基本涵盖了非IT企业常见需要的所有服务（除了邮件服务）。目前镜像的大版本已经升级到8，所以我下到的是8.0.3，大概100M多点。
新版和旧版最大的区别在于，新版本去掉了bt下载，upnp，iTunes和http这四个家庭常用服务（实话说，http还是企业常用的）。加入了远程同步，snapshot，10G网卡等功能。内存要求也更加高，从7的256M-512M，变成了4-6G。对比起来更加企业化和专业化，但是更不适合随便玩玩。
首先，你需要准备合适的硬件。一台老式的机器，或者atom平台的mini-itx板子都是很不错的。即使是新的atom板子，便宜点的400也能弄到手，加上一条2G的内存，除掉硬盘大概也就1000。故障毕竟比较少，而且省电。存储需要一块硬盘和一个U盘，注意，两者不是或的关系。因为FreeNAS安装到某个物理设备后，会强制使用设备的全部空间，因此这个设备无法再用来存储数据。整个FreeNAS才500M，4GU盘绰绰有余，读取速度也不慢。除了升级和改配置外，没有什么太大写入，很节约。
然后，你需要去官网下载最新的iso镜像，用这个iso启动系统（注意，此时最好不要接上数据硬盘，只挂U盘）。当然，要省事的可以在windows下用vmware来装，不过对非IT专业人士来说，有点困难。启动后，在出现的选择中选择1，安装到硬盘上。在出现的安装目标选项中选择U盘（如果只挂U盘，这里就一个选项），然后等。最多两分钟，安装就完成了，选3重启系统。
去掉光盘（甚至可以去掉光驱），使用U盘和数据硬盘启动系统，并且将系统设定为从U盘启动（这点很重要，因为硬盘一般比较优先，但是硬盘上没有系统）。进去后什么都不干，会自动识别你的网卡，并且dhcp到一个ip。你可以在系统启动完成后使用选项1来重新配置ip，或者在dhcp上干脆给这个mac指定一个ip。对于使用路由器的小型公司来说，这点并不困难。
用浏览器访问这个ip，你可以看到freenas的控制界面。作为中国用户，先去setting里面改为中文，保存。然后关闭浏览器页面，重新打开（这点很重要），后面的设定都是中文了。然后，在存储，卷下面，新建一个卷。你现在可以把数据硬盘挂起来用了。
然后，再去服务里面把你需要的服务全部启动起来，并且配置合适的用户。这些就按照自己的高兴配了，界面都是中文的，应该不用我教吧。
如果无法启动服务，重启再试。你也可以参考这篇（http://www.c-dd.org/post/214/）。写的很详细，不过他安装的版本稍旧，是7。</description>
    </item>
    
    <item>
      <title>简易debian livecd打造手册</title>
      <link>http://shell909090.org/blog/archives/2094/</link>
      <pubDate>Thu, 16 Feb 2012 01:10:21 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2094/</guid>
      <description>废话不说，上干货。先装一下syslinux，genisoimage，kvm，debootstrap，squashfs-tools。
$ mkdir debcd $ cd debcd $ mkdir isoroot $ cp/usr/lib/syslinux/isolinux.bin isoroot/ $cat &amp;gt; isoroot/isolinux.cfg &amp;lt;&amp;lt; &amp;quot;EOF&amp;quot; prompt 0 default linux label linux kernel vmlinuz append initrd=initrd.img EOF $ cp /boot/vmlinuz-3.2.0-1-amd64 isoroot/vmlinuz  完成上述步骤后，你就准备好了一个基础的iso镜像文件系统，并有了一个基础的引导模块和内核。现在，我们尝试把这玩意烧到iso上，并且测试一下。
$genisoimage -o output.iso -b isolinux.bin -c boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table isoroot/ $ sudo kvm -cdrom output.iso -m 512  如果没法装kvm，换成qemu。屏幕会停在内核引导过程中——因为你没有initrd.img，所以在isolinux.cfg中指定的initrd就不正确。下面我们会设法弄一个initrd.img。
$ cp -a /etc/initramfs-tools/ initramfs $ mkinitramfs -d initramfs -o isoroot/initrd.img $genisoimage -o output.iso -b isolinux.</description>
    </item>
    
    <item>
      <title>Progress Linux</title>
      <link>http://shell909090.org/blog/archives/2092/</link>
      <pubDate>Mon, 13 Feb 2012 01:56:41 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2092/</guid>
      <description>别紧张，我不是要progressLinux，这是一种新的distribution（算是吧）。http://progress-linux.org，是一个基于Debian的dist。
为什么要有这个dist？其实严格意义上说，这不是一个完整的dist。不同于Ubuntu，这个dist可以完全的寄生在Debianstable(squeeze)上面。你不需要真的去官网上下载一个ISO，然后安装。只需要安装Debianstable，然后加入
Progress-Linux的source就好了。如果你胆敢在Ubuntu上这么干，只会把系统弄的一团糟。当然，直接下载Progress-Linux的安装ISO也是可以的，这个ISO基于Debian Live，作者(Daniel Baumann)本人也是DD，是Debian Live的主要作者之一。
为什么要这样？因为Debian是以严谨到变态而闻名的系统。例如，mdadm这个包有一个很小的不便。每个月当检查RAID的时候，会发一封mail。如果你有一堆电脑需要管理，这件事情就非常烦人了。要修正这个问题，只需要在其中一个脚本中加入参数-q。但是Debian修这个bug修了9个月。因为具体的包维护者并不是很关心这个事情（低优先级），而Release
Term需要确保这个bug必须先在Sid中修复，确认没事了（基本是没问题的，只加一个-q而已），再修复testing的，最后修复stable的。于是，你的邮箱要被一堆垃圾持续淹没9个月。
Progress-Linux就快多了。
但是为什么要做成dist呢？
Debian的模式设计，是方便fork，而严格控制release的。Debian的版本库更新要很多条件，例如符合DSFG（也就意味着符合一系列的开源授权协议），更新的时候首先作用于SID，Release
Term说了算等等。DD也没有权利要求更新Debian
stable中的包，他必须申请Release
Term批准。想想也能明白，如果真的每个DD都能直接更新包，那才天下大乱了。我们不能绕过Release
Term去解决问题，也不想让这些问题留着。
那么怎么办？只有自己做一个仓库。Debian鼓励这么做（有很多dist就是这么做的），但是这时就不能用Debian的名字，因此作者才做了一个新的dist。DSFG这时变成了一个优势，Debian的所有包，都满足DSFG的第8条，“不仅仅对Debian授权”，可以直接应用。
因此，其实Progress-Linux是一个基于Debian的改进。更快的bug
fix，更多的backport，更少考虑版权问题。当然，限于作者关心的包。另一个激动人心的特点是，
Progress-Linux的包和backport包不会碰撞，因此使得stable可以简单的安装很多新的包。如果你喜欢，可以在安装系统后加入他的source，作为系统的改进。但是不要指望有什么实质性变化，都是一些细节改进而已。如果你希望知道几个例子，可以看这个页面（http://www.progress-linux.org/project/about/）。
也许你希望使用一个中国区的mirror来做这个事情（这样更快，也省去中间的一些其他麻烦），http://mirrors.ustc.edu.cn是debian中国区域的主镜像(即http://ftp.cn.debian.org)，这个节点已经完成Progress-Linux的镜像。
Relax, I don&amp;rsquo;t mean to progress Linux, it&amp;rsquo;s a new distribution (kind of). http://progress-linux.org, a new dist based on Debian.
Why people made this dist? Technically, it is no a fully dist. Unlike Ubuntu, this dist can totally on the top of Debian stable(squeeze). You don&amp;rsquo;t need to download a ISO from website and install.</description>
    </item>
    
    <item>
      <title>lfs under debian注记</title>
      <link>http://shell909090.org/blog/archives/2088/</link>
      <pubDate>Thu, 09 Feb 2012 07:04:06 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2088/</guid>
      <description>1.严格按照说明做，少看一点无关内容后面就一堆err了。
2.新分区大点，4G不够的，最小用8G。我用了20G的，硬盘不值钱。另外说一句，并不是4G不能够做到，而是你可能被迫删除不少有用东西，或者是移到其他位置，增加复杂度。
3.每次你进入一个section，以前针对这个包进行解压，打补丁，并修改的source都作废了。直接删除它们，然后重新解压。lfs不依赖于以前解开的源码，在任何一节的开始都不需要翻以前怎么处理（解压，打补丁，修改）源码的。你在任何一节都可以（并且必须）独立操作源码。
4.mawk会出错，装一个gawk。
5.yacc没有的时候，装bison，it&amp;rsquo;s works。
6.如果碰到见鬼的tar.xz，用tar Jxf。或者更简单的，现代tar都支持xf直接解压，不用再自己选择zjJ。
7.chapter5的流程？先用系统的编译器编译了binutils，gcc和glibc，然后再用刚刚编译好的再编译这三个，这样编译系统就统统连接到了/tools上。然后用/tools的连接编译了一堆编译用工具，bash啦，make啦。这样，就完成了编译环境的建立，/tools是一个独立于主系统的，完整而可用的编译系统。用这个编译系统编译任何东西的结果应当是相对可控的。
8.如果我是你，在chapter5完成的时候会tar czf ~/tools.tar.gz /tools。这样会让你在chapter6中犯错的时候不至于血本无归。
9.chapter6的流程？用chapter5的编译系统，编译了新系统的编译系统。当然，这个不容易，因为刚刚的编译系统所有指向都是/tools。所以lfs指导你做了不少patch。然后重复chapter5的过程，逐步把源码编译安装到正式系统中。
10.lfs真TMD的辛苦，连source code的typo都需要在书中指出和fix。。。而且lfs自己还有errata。
11.lfs的56两章看起来像是两个人写的，风格习惯不一致。chapter5用``，chapter6用\$()。还有gcc-pass2的时候，cp -v XXX{,.tmp}; sed XXX.tmp &amp;hellip; &amp;gt; XXX。而chapter6的binutils则是sed -i.bak。当然，有可能是因为有些系统的sed不支持-i，例如redhat的系统始终不支持netstat -nlp46，I hate it。BTW，我喜欢sed -i。
12.编译过程真心傻X，大部分都是解开源码，configure &amp;ndash;prefix=&amp;hellip; &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make check &amp;amp;&amp;amp; make install。这些过程好像可以用一个不知道啥脚本来简化，建议不要手工干这堆事情，没意思的。相反，倒是很多调整有些意思。</description>
    </item>
    
    <item>
      <title>如何写基于google code的watch file</title>
      <link>http://shell909090.org/blog/archives/2078/</link>
      <pubDate>Wed, 01 Feb 2012 04:06:39 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2078/</guid>
      <description>google code很好用，可是他的下载页面很恶心，很难跟，而且还改过一次。debian打包党要做watch file的时候，估计会很郁闷。
去http://googlecode.debian.net/，然后提交你的包名，你会得到一个url（其实自己猜也可以猜到）。每次访问这个url的时候，他会代你解析google code，告诉你有没有更新。</description>
    </item>
    
    <item>
      <title>PXE模式使用openwrt网络安装debian</title>
      <link>http://shell909090.org/blog/archives/2076/</link>
      <pubDate>Tue, 31 Jan 2012 03:14:14 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2076/</guid>
      <description>废话不说，上干货。
首先，禁用arptables。当然，如果你没开这个防火墙，那么没必要。其次，注意你的openwrt必须有udisk，否则空间相差太多，根本没有实现的可能。
然后，如果你用的是新版的rom，应该在/etc/init.d/dnsmasq里面看到，dnsmasq()这个函数里面有。
append_parm &amp;quot;$cfg&amp;quot; &amp;quot;tftp_root&amp;quot; &amp;quot;--tftp-root&amp;quot; append_parm &amp;quot;$cfg&amp;quot; &amp;quot;dhcp_boot&amp;quot; &amp;quot;--dhcp-boot&amp;quot;  如果没有，加一下，有的话说明原生支持。下面可以直接修改。
dnsmasq是一个dhcp/dns双重服务器，而pxe引导的第一步就是支持bootp协议。这个选项在/etc/config/dhcp里面。config
dnsmasq一节上，增加。
option &#39;dhcp_boot&#39; &#39;pxelinux.0&#39;  重启dnsmasq，完成bootp准备。
然后，安装tftpd-hpa，opkg update，opkg install
tftpd-hpa。这是一个tftp服务器，默认不启动。如果你打算让pxe引导模式持久化，那么就改为默认启动，同时永久关闭arp防火墙。在/var/tftpd-hpa里面，可以看到tftpd的根路径。从参考3的的连接里面，你可以找到合适的一个下载路径，下载netboot.tar.gz到这个文件。解压后，可以看到pxelinux.0，这个和上面的pxelinux.0相对应。这是pxelinux的组件，隶属于syslinux项目，可以用来完成启动。
这样，就完成了安装的所有准备工作。你可以找一个设备实验一下，应当可以完成网络安装的步骤。
另外，如果需要启动选择amd64或者是i386，或者更进一步定制。那么需要下载其他镜像，自己生成pxelinux.cfg这个目录中的内容。
 PXEhttp://wiki.debian.org/PXE
 NetbootPXEhttp://wiki.debian.org/DebianInstaller/NetbootPXE
 netinsthttp://www.debian.org/distrib/netinst
 配置pxe，安装debian和ubuntuhttp://my.unix-center.net/~whtbie/wordpress/?p=290
  </description>
    </item>
    
    <item>
      <title>小米手机入手体验</title>
      <link>http://shell909090.org/blog/archives/2026/</link>
      <pubDate>Wed, 21 Dec 2011 09:48:05 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2026/</guid>
      <description>很好很强大
LTN和我说的时候，开头用的词就是，我的小米不打算卖你了。既然前面有“我的”两字，可见东西差不到哪里去的。入手之后感觉很好，起码比g2强多了(233)。我把一些直观体验说一下吧。
手感不错，性能优异 机器的手感沉实，屏幕贴上膜后手感流畅，g2上的光膜也很滑，但是偶尔沾水就阻力大了。小米的膜很少出现这种现象，而且触感很灵敏——当然，太灵敏了也是个问题，经常手不小心碰到返回键，然后程序就没了。
程序滑动很流畅，不愧是双核的。内存足够大，ROM也够了。我完全不折腾app2sd之类的问题，也不管内存回收，每个程序都跑的很流畅。这种表现让人用着很省心。
周边齐全 我到小米的官网上，看到了后盖，保护壳，贴膜，背贴，耳机，数据卡的官方销售。虽然和小米2000元的价位比，这些周边并不便宜，但是他们很方便。作为智能机爱好者，往往会买一些国外的水货机，这时你就知道我在说什么了。往往表面膜坏了，只能买第三方的膜，偶尔尺寸还不匹配。还有的时候线控坏了，买一个很贵，还不知道好不好用，有时候还没地方买。后盖摔坏了，也没地方配，只能去店里花大价钱修。这些问题，每个都不大，但是解决起来很麻烦，不解决很恶心。
一些问题 屏幕偶尔会卡死，大约三秒后恢复。猜测是双核cpu全部耗尽，导致失去响应。更进一步猜测，还可能内存耗尽——虽然看起来不大可能。
原配膜为了保证使用，尺寸精度相当精确，只要错一点，就没法贴上去。我自己贴了半个小时，结果满脸青春痘。没办法，只能出钱找了个专业人士。其实卖的时候，完全可以让客户选择贴好了发出来。
ROM版本控制的隐患 在一周的周期上，说这个并不合适。不过我入手后，ROM自动升级。然后就出现了有时突然没有信号的问题，只能重启。
我肯定这个问题不是真的没信号了。将手机切入飞行模式，返回后有一瞬间信号是恢复的，过三秒左右信号就没了。而且手机状态中有信号数据，但是手机打不通。这个问题反复出现，经常是在某处没有信号，重新恢复信号后就出bug，死活保持无信号状态。
按照我前一个手机的经验(G2)，这个往往和手机的ROM或者基带有关。我前一个手机的所有ROM中，有两个有这个问题的，有两个没有。而按照网络上一个帖子的说法，楼主在降级后问题也消失。反复印证下来，推测很可能是因为最新升级的ROM有这个问题，而我升级后就出现了问题。
这个属于ROM版本控制和测试的不严密，在一周不到的时间内我无法确认这点。但是我希望不是，因为一旦是ROM版本控制问题，将来后续问题还会层出不穷。个个都是莫名其妙的出现，没有精力一个个的跟。</description>
    </item>
    
    <item>
      <title>linux tty部分源码阅读</title>
      <link>http://shell909090.org/blog/archives/2020/</link>
      <pubDate>Mon, 19 Dec 2011 16:08:11 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2020/</guid>
      <description>1.事情从file开始 file的定义在include/linux/fs.h中，其中有两个field，一个叫file_operations
*f_op，一个叫void *private_data。file_operations定义了所有file能够进行的操作，在tty这个层面而言，drivers/tty/tty_io.c能看到有个叫做file_operations tty_fops的东西，下面有个叫console_fops的东西。两者区别不大，就是write函数进行了一下包装而已。从这里可以看出，系统将某个file的读写操作，转包给了tty_io.c这个文件。这个转包的手法非常类似虚函数。如果将tty_io.c里面的函数看作一个类的所有成员，那么tty_fops就是虚函数表，而f_op就是虚函数指针_v_ptr。
2.tty_io的二转包 tty_io做了什么？他直接转包给了ldisc来处理这个事情。从tty_struct的结构我们能够看到，有这么一个field，tty_ldisc *ldisc。而tty_ldisc.h文件里面，我们能看到这个结构又有这么一个成员，tty_ldisc_ops *ops。同样手法，第二次使用。目标是tty/下面很多n_开始的文件，例如n_gsm，估计是处理手机的。我们的目标看起来像是n_tty.c中的tty_ldisc_ops tty_ldisc_N_TTY对象。
3.n_tty做了些什么 n_tty也做了很多转包，例如对于n_tty_write而言，他使用了tty-&amp;gt;ops-&amp;gt;write这个函数。我们从struct tty_struct中可以看到这个field，tty_operations *ops。目标是谁？看起来像是pty.c，他里面有很多定义，例如tty_operations master_pty_ops_bsd，tty_operations slave_pty_ops_bsd，tty_operations ptm_unix98_ops，tty_operations pty_unix98_ops。
4.pty总不转包了吧 以write而言，pty.c做的很简单，就是tty_insert_flip_string而已。不过之后调用了tty_flip_buffer_push，这个又会调用flush_to_ldisc，这个里面会调用ldisc-&amp;gt;ops。从上文中我们知道，这个函数的实体在n_tty.c的n_tty_receive_buf。
5.n_tty_receive_buf做了些什么 这个函数对每个字符依次处理，如果是普通字符，就调用n_tty_receive_char。这个函数会调用put_tty_queue，经过两次转手，最终，这个字符进入了read_buf。这是一个循环队列。</description>
    </item>
    
    <item>
      <title>android几个常识</title>
      <link>http://shell909090.org/blog/archives/2018/</link>
      <pubDate>Fri, 16 Dec 2011 10:41:28 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2018/</guid>
      <description>内存问题 首先，总内存量需要被各种CPU划出部分使用，剩余才是系统可用内存。这个概念差不多相当于电脑上的共享显存，系统对划走的内存是没有管理能力的，因此在/proc/meminfo中找不到这部分内存。这部分内存既不能优化也不能使用，因此其实是不可使用内存。厂家出厂内存（标称内存）和可使用内存一定存在差，具体多少看各种机型。htcg2是288m标称191m可用，p81hd是512m标称288m可用。
可用内存是linux kernel能管理的内存，这部分再会被划出一些供系统使用/服务使用/常驻程序使用。这部分是可以优化的，少编译一些ko模块，少开一些服务，少一些常驻程序，内存就会节约一点。
最后，剩下来的内存才是程序实际能用的量，htcg2和p81hd都在100-150M上下。不过程序退出时，内存并不交还给系统。而是当系统内存不足时(memory threshold，通常24m)，由系统分析目前内存中，使用频率最少的一块，然后去释放这个内存。通常而言，你在系统中开了三五个程序，然后按Home退出到桌面，再进入时程序还处于退出当时所处的状态，这就是因为还在内存中没有释放的缘故。而当你开的程序比较多，例如十多个程序，也是由Home退出到桌面，再进入最老的一个程序时，程序已经处于初始的状态。这就是因为内存不足，系统帮你杀了这个程序的缘故。如果用Back键退出，程序会直接关闭，内存释放，这个无关系统是否有空余内存。
所以，对android而言，内存只代表两件事情。一个是所能运行的最大的程序。如果总内存不足，一些一次性需要内存比较大的程序就会无法运行，特征是一运行就退出，系统没有提示错误。另一个是同时在内存中不关闭的程序的数量。内存越大，在机器中就可以保持越多的程序处于打开状态。对于新打开程序（此时内存请求较多），或者程序突然申请大量内存，系统就开始释放其他程序，此时系统会稍慢。但是在考虑是否需要使用内存优化软件的时候，不妨这么想。内存优化软件运行的时间，一般比直接kill进程还长呢。
如果觉得自己内存不足，想要优化的话，需要非常注意系统中的服务。系统中一般会有很多服务在运行，很多都是消息通知类的，例如fackbook的新消息，twitter的新消息通知，google plus的消息通知，还有微信，等等。这些消息通知每个大概都是5-10m内存不等。有的时候，如果你不需要消息通知，关闭消息通知可以有效关闭服务，例如ubersocial的消息通知是可以关闭的，而google plus和facebook就没有这个选项。如果你觉得这两个的消息浪费内存，那只有卸载他们。至于微信，你可以使用程序中的退出功能关闭微信。一旦关闭，通知服务会自动关闭。
内核模块问题 一般而言，系统内核会编译进很多东西，但是也有不少东西是不编译进去的。这些可以动态载入的东西，就叫内核模块。对android而言，其实普通用户没必要在意到底机器内的某个模块是模块形式还是编译进入了内核，所以下面统称内核功能。无论是模块还是内核形态，只要能用，就称这个功能打开。
内核常用的几个功能有，cifs，tun。
cifs是用于smb挂载的内核模块，如果内核中有这个东西，你就可以把你的某个samba服务器当作机器本地的sd卡来用。samba服务器可能听起来很陌生，不过windows文件共享就是一种samba服务器。也就是说，拥有cifs，可以将windows下面的文件当作机器的本地sd卡来随意读写。这对于家庭内使用android是个很方便的事情。
不过cifs现在用的比较少，因为ES文件管理器有个功能，可以把远程文件转换成一个http流。视频之类可以以http流模式工作的文件就可以直接远程打开。
tun是一个很重要的内核模块，因为openvpn/anyvpn都需要使用这个东西来工作。没有tun模块，这两个程序将无法工作。
存储形态问题 任何一个android设备都一定会搭配一块存储。这块存储会被切分为多个区域，模拟成一个硬盘的多个分区来使用。我们来看一个内核的启动参数，以下数据来自我的P81HD。
console=ttyS1,115200n8n androidboot.console=ttyS1 init=/init initrd=0x62000000,0x800000 mtdparts=rk29xxnand:0x00002000@0x00002000(misc),0x00004000@0x00004000(kernel),0x00008000@0x00008000(boot),0x00008000@0x00010000(recovery),0x00078000@0x00018000(backup),0x0003a000@0x00090000(cache),0x00100000@0x000ca000(userdata),0x00002000@0x001ca000(kpanic),0x00080000@0x001cc000(system),-@0x0024c000(user) bootver=2011-08-05\#2.06 firmware\_ver=0.2.3  能明显看出，存储使用的是nand，编译是针对rk29xx的，所以模块叫做rk29xxnand。mtdparts里面规定了rk29xxnand的分区特性，每组三个数据，第一个是大小，第二个是起始位置，第三个是分区名。其中userdata实际大小256m，表上面写的是1m，因此1相当于256字节。下面可以再看一下mount表。
/dev/block/mtdblock8 on /system type ext3 (ro,noatime,nodiratime,data=ordered) /dev/block/mtdblock6 on /data type ext3 (rw,nosuid,nodev,noatime,nodiratime,errors=continue,data=ordered) /dev/block/mtdblock5 on /cache type ext3 (rw,nosuid,nodev,noatime,nodiratime,errors=continue,data=ordered)  可以看出存储编号是从0开始的。分区后，存储的内容即是以ext3格式存储。
系统组织问题 android的系统组织很有意思，并不是按照FHS来组织的，却部分兼容于FHS。
android最基础的一个分区是system，这个分区被mount到/system。/etc一般都是直接link到了/system/etc下面，由此可见这个分区的重要性。这个分区一般存放所有系统内置的，不能更改的程序和数据。例如系统的内置app，framework，java基础库，so库，系统程序，等等。一般的刷机包里面，都是以zip格式打包了system的新内容。一旦这个内容被替换，系统就有了新特性。一般一个system的大小是200m-500m，不会全部用满，会留出一些方便后续的升级改造。
data里面是系统内置的存储区域，这个区域常常被误叫为手机内存。实际上内存是ram，这块类似于rom。一般是500m上下，程序安装后就是装到了这个，包括数据也保存在这里。如果这个区域不足，系统就不能安装新程序。因此有些人想出了app2sd的把戏，说白了，就是通过bind，把sd卡上的一块区域映射到这个区域的某个目录下，使得某个app的数据可以存储到sd卡上。当然，这个能够转移过去的只限于数据，代码好像是不能转移的。而且，mount需要时间，sd的读取一般也比rom更加慢和麻烦。因此app2sd后，系统启动速度会变慢，程序运行也会变慢。
一个更好的扩充data的方案（当然，也更危险）是，通过修改刷机包，将上面kernel参数改变掉，并且重新分区nand。这样，data区的大小可以增加到1g左右，而user区的大小会减小相应的量。这样处理后，手机上可以安装更多的程序，而且没有什么后遗症。
cache里面是缓存，这个直观感受并不多，也很少用满，所以不解释。程序里面一般会列出，使用多少缓存，就是指的这个区域。
权限管理问题 android手机的权限很有意思。和macbook有点类似，但不完全相同。
android手机的每个程序，都有一个权限和他相关。规定的事情可以做，不规定的不能做。估计是给程序新建了一个身份，可以做的事情做成组，然后对身份加组。但是其中，有一类特殊的权限，正常情况下是任何程序都无法申请的，即是sid权限。学过linux的应当知道，就是可以切换成root身份的权限。
android的root，基本方法都是通过某种方法将/system改成可读写，然后用自己做的su替换/system/bin/su文件。自己做的程序，会以一些方法验证某个程序是否具有su的权限（一般是弹出对话框确认），然后让他们可以拥有最高权限。可以su的程序，他们的权限表就没有意义了。
adhoc问题 adhoc是一种常见的wifi形态，特征是没有一个ap（常见的路由器即是一种ap），全部由普通的客户端电脑来进行网络连接。
android的wpa_supplicant文件做过一些修改，过滤了adhoc网络的essid。所以，如果你使用adhoc模式共享了网络，你的android设备将无法使用。
但是android是可以做出adhoc的。这是很悖论的一个事情，android自己做出的网络分享，另一台android是无法使用的。</description>
    </item>
    
    <item>
      <title>从python-support改为dh_python2的方法</title>
      <link>http://shell909090.org/blog/archives/2016/</link>
      <pubDate>Thu, 15 Dec 2011 11:00:46 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2016/</guid>
      <description>在debian/rules里面，将这个：
%: dh $@  改为这个：
%: dh $@ --with python2  其余看这里。</description>
    </item>
    
    <item>
      <title>拨号的几个简化</title>
      <link>http://shell909090.org/blog/archives/2004/</link>
      <pubDate>Tue, 06 Dec 2011 11:41:59 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/2004/</guid>
      <description>1.pptp client
安装pptp-linux，使用pptpsetup，按照man来。使用pon configname启动，poff关闭，plog看日志。
2.3g网卡拨号
应当使用usb_modeswitch进行编码转换，然后用wvdial拨号。MF190而言，至少我这里modeswitch会自动转换的。后者直接编辑/etc/wvdial.conf，然后输入wvdial开始拨号。wvdial有个包装叫做gnome-ppp，依赖很少，在其他桌面也可以用。我还没有研究出来怎么玩。
附，MF190使用的usb_modeswitch配置（debian自带）:
######################################################## # ZTE devices DefaultVendor= 0x19d2 DefaultProduct= 0x2000 TargetVendor= 0x19d2 TargetProductList=&amp;quot;0001,0002,0015,0016,0017,0031,0037,0052,0055,0063,0064,0066,0091,0108,0117,0128,2002&amp;quot; MessageContent=&amp;quot;5553424312345678000000000000061e000000000000000000000000000000&amp;quot; MessageContent2=&amp;quot;5553424312345679000000000000061b000000020000000000000000000000&amp;quot; MessageContent3=&amp;quot;55534243123456702000000080000c85010101180101010101000000000000&amp;quot; NeedResponse=1 CheckSuccess=20  附，MF190可用的wvdial.conf:
[Dialer Defaults] Modem = /dev/ttyUSB2 Init1 = ATZ Init3 = ATE0V1 Init5 = ATS0=0 Init6 = AT+CGDCONT=1,&amp;quot;IP&amp;quot;,&amp;quot;uninet&amp;quot; Init7 = AT+CFUN=1 Modem Type = USB Modem Baud = 460800 New PPPD = yes ISDN = 0 Phone = *99# Password = any Username = any Stupid Mode = 1  3.</description>
    </item>
    
    <item>
      <title>openwrt配置——自动重启openvpn</title>
      <link>http://shell909090.org/blog/archives/1976/</link>
      <pubDate>Thu, 10 Nov 2011 15:55:20 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1976/</guid>
      <description>还记得如何配置openvpn么？手工配置有个问题，当我ppp0连接断掉，需要重启路由器的时候，网络会短暂的断开。然后，openvpn就失效了，导致各种混乱后果。为了解决这个问题，我测试了一下，做了以下设置。
-----/etc/hotplug.d/iface/30-openvpn----- #!/bin/sh [ &amp;quot;$ACTION&amp;quot; = &amp;quot;ifup&amp;quot; -a &amp;quot;$INTERFACE&amp;quot; = &amp;quot;wan&amp;quot; ] &amp;amp;&amp;amp; [ -z &amp;quot;`/sbin/ifconfig tun0 2&amp;gt;&amp;amp;1 | grep inet`&amp;quot; ] &amp;amp;&amp;amp; { /etc/init.d/openvpn start } [ &amp;quot;$ACTION&amp;quot; = &amp;quot;ifdown&amp;quot; -a &amp;quot;$INTERFACE&amp;quot; = &amp;quot;wan&amp;quot; ] &amp;amp;&amp;amp; [ -n &amp;quot;`/sbin/ifconfig tun0 2&amp;gt;&amp;amp;1 | grep inet`&amp;quot; ] &amp;amp;&amp;amp; { /etc/init.d/openvpn stop } -----end files-----  好了，你重启外网连接的时候，就会自动连接openvpn。
参考：
OpenWRT下的动态DNS(用3322.org的服务)</description>
    </item>
    
    <item>
      <title>SHLUG Summit 2011</title>
      <link>http://shell909090.org/blog/archives/1969/</link>
      <pubDate>Thu, 03 Nov 2011 10:38:05 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1969/</guid>
      <description>这次有我的演讲，转一下转一下，大家来捧场。
&amp;mdash;&amp;mdash;&amp;mdash;- Forwarded message &amp;mdash;&amp;mdash;&amp;mdash;-
From: ghosTM55 &amp;lt;ghosthomas@gmail.com&amp;gt;
Date: 2011/11/2
Subject: [shlug] [公告]SHLUG Summit 2011
To: shlug &amp;lt;shlug@googlegroups.com&amp;gt;
Hi all,我们SHLUG的2011年年度大会来了!
作为惯例，我们的年会会面向Linux新手以及初学者来进行Linux的宣传与知识普及，这次也不例外 这次我们将会来到松江大学城，在东华大学进行一场200人规模的交流会，欢迎有时间和兴趣的朋友一同前去参加 时间: 2011年11月6日(周日) 下午2点 地点: 东华大学 松江大学城校区 报名: 不需要 入场费用: 不需要 演讲主题:
 如何成为一名黑客
 Debian GNU/Linux介绍
 实战Linux网络部署
  隐藏关卡:
 Ubuntu 11.10 Release Party  和去年一样，在这里我需要:
 一些朋友能够来帮助到我们运维好本次SHLUG的年会(拍照，摄影，现场话筒传递，入场引导等)
 SHLUG的朋友在参与活动的时候尽可能坐在教室后排并请勿在演讲过程中大声讨论问题
 大家对于此次活动的线上以及线下的帮忙宣传
  在这里需要感谢东华大学开源社区的同学们的积极配合与帮助，为我们奔波于松江大学城各高校进行宣传 并且为我们找到了能够容纳200人的教室(具体教室号码尚未确定，我会在列表以及blog中进行更新，请持续关注) 欢迎各位参与本次年会并向我提出建议，谢谢</description>
    </item>
    
    <item>
      <title>P81HD，以及任意一种Android的翻墙</title>
      <link>http://shell909090.org/blog/archives/1965/</link>
      <pubDate>Mon, 31 Oct 2011 14:24:50 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1965/</guid>
      <description>假如，你有一台Android，不能刷机（厂家没提供ROM，也没有源码，而且可能锁了bootloader），没有ip_gre模块，没有tun模块，连iptables_filter模块都没有，那怎么办呢？没有第一个，就无法使用pptp/l2tp的内置VPN，没有第二个，就无法使用openvpn，没有第三个，就无法使用sshtunnel。如果你运气不好，这个东西连root都没有，肿末办？
很简单，你得先弄到Opera，注意Opera Mini没有测试过，据说不行。然后准备一台vps，上面不但要开ssh，而且必须在机器上有个代理。然后在地址里面输入opera:config，看到设定了？下面有一项proxy。按照参考[1]的方法设定代理，地址设定为127.0.0.1:1984。注意不要写成localhost:1984，后者不一定认。代理服务器用sshtunnel，注意不要用Socks5翻墙，必须用http模式。打开看看？是不是可以了？
原理很简单，sshtunnel使用redsocks来执行的全局翻墙。根据参考[3]，redsocks是通过iptables规则来将所有连接重定向到自身，然后包装成代理的。由于iptables_filter模块缺失，或者干脆没有root，这个路子走不通。但是启动sshtunnel后1984端口的翻墙链是好的，只是程序都不使用而已。Opear又给了我们一个自行设定代理的能力。因此，结合使用两种方法，能让你在没有模块，没有root的情况下，自行拥有翻墙能力。由于Opera只支持HTTP代理，因此你必须满足http代理翻墙要求（远程服务器上有代理，不启用socks5模式）。
参考：
1.Android下使用Opera实现Wifi代理上网
2.Android 平台的 SSH Tunnel 应用
3.redsocks on android指南</description>
    </item>
    
    <item>
      <title>lxde使用观感</title>
      <link>http://shell909090.org/blog/archives/1927/</link>
      <pubDate>Sun, 02 Oct 2011 14:56:46 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1927/</guid>
      <description>前一段时间，雨苍问我有没有功夫参加台湾的lxde开发，做志愿者。不巧今年结婚装修，事情比较多。除了给debian贡献几个包练习一下，没有什么别的计划，就给推了。不过推归推，当时就看到了lxde的桌面，还挺不错的。
前几天，xfce又一次大升级，整个系统加了N多功能出来，顿时感觉太庞大臃肿了。贝壳喜欢的是精简有效的桌面，不是庞大的怪物——否则我不会用gnome/kde阿？尤其是贝壳的三台纯linux，一台上网本，一台atom的低功耗机，都是低资源量的。其余系统都是虚拟机。于是就策划换掉xfce4。替代品有两个，一个是lxde，还有一个是enlightenment，两个都是以轻量级而出名的桌面。不过杯具的是，enlightenment在做vnc测试的时候总是死机，所以压根没法用。所以目前的系统就花落lxde了。
关于enlightenment，有几点补充说明。一个是，这个东西在debian下的包叫做e17，不要直接找enlightenment。另外，他的bug是，在vnc下面可以用，但是如果进行setup，就会找不到模块，然后SEG FAULT。我试过用bugreport去汇报错误，但是邮件发不出去，现在还在找为什么。
好吧，题归正传，lxde做桌面，至少有以下几点好处。
轻量。我看到的内存消耗是20M，CPU消耗很低。简洁。整个系统没有太多废物组件，也没有满天飞的各种插件。除了有限的几个组件外，其余都是自己配置的。可变。目前我用terminator替代lxterminal作为标准term，用的挺好。
OK，下面简单说一下lxde使用过程中的几个心得。
pcmanfm不支持树形目录结构。这个太坑爹了。据说版本库中的已经改出来了，debian testing还得等等。所以我觉得还可以观望一下。lxlauncher不起作用。不过幸好我也不需要这个。这个据说是为了平板或上网本做的启动系统。我现在用的是launchy，是为键盘控设计的，挺不错。快捷键不支持编辑。需要你手工修改~/.config/openbox/lxde-rc.xml。具体可以参考这个。他里面提到的两个连接是openbox的wiki，分别是Bindings和Actions。注意，wiki上有些资料是错的！下面我会讲一下哪些需要修正。没有mail notification。我自己装了一个mail-notification，还不错。可惜没有邮件的时候，托盘区图标经常失踪，不知道为啥。反正来了邮件是会出现的。自动启动不自动。可以把desktop文件放入~/.config/autostart中。也可以在~/.config/lxsession/LXDE/autostart中写，每行一个程序名，不用&amp;amp;结尾，不是bash脚本。我用的是后者。
下面是快捷键的一些错误。
ToggleMaximize应当写成ToggleMaximizeFull。Desktop指令下面的to标签应当是desktop标签。</description>
    </item>
    
    <item>
      <title>debian打包的一些细节补充</title>
      <link>http://shell909090.org/blog/archives/1895/</link>
      <pubDate>Fri, 26 Aug 2011 15:52:30 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1895/</guid>
      <description>如果前面有人接手了，你最好和前任联系一下，看看是否可以获得他的帮助，或者跟着他的思路继续做下去。
debian有一个比较变态的规定，你的打包内容，必须遵循FHS。有些程序写的数据放到了程序路径下面，你需要进行人工分离（这个花了我整整两天）。
求RFS比ITP难多了&amp;hellip;
&amp;hellip;.
&amp;hellip;&amp;hellip;.
求RFS。</description>
    </item>
    
    <item>
      <title>第一个debian官方包请求出来</title>
      <link>http://shell909090.org/blog/archives/1891/</link>
      <pubDate>Tue, 23 Aug 2011 16:47:24 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1891/</guid>
      <description>贝壳的第一个为debian官方贡献的包出炉了，地址在这里。之前也发过一个ITP，结果发现莫名其妙有人在做了。不知道为什么没有在wnpp中发现，结果弄的好不尴尬。
大概说一下，为debian官方贡献打包，你需要了解这个包的基本情况。例如用哪种语言写的，有什么依赖关系，是什么授权，等等。尤其是授权，debian有所谓的dsfg方针（不知道的看这里，这里，这里）。如果你打出来的包包含dsfg不许可的内容，你的包会被紧急移除，直到修复这个问题。尤其值得注意的是，debian要求文件级的授权，就是说，即使有一个文件不符合授权要求，整个包也会不通过，哪怕包本身声明为开源授权。之前ibus还是fctix，因为用了拼音加加的词库，就享受了一把这个待遇。另外，如果可以的话，最好征求一下上游维护者的意见（一般就是作者）。因为debian的bug系统中的问题是你需要解决的，而这些问题通常没有上游维护者是很难搞定的。当然，如果你觉得自己搞的定，或者可以出了问题再联系，那也可以。
当你搞明白这些问题后，通常需要先发一个ITP（Intent To Adoption）出来，表示你要打包，别人不要抢。通常是用reportbug来进行提交，汇报wnpp（Work-Needing and Prospective Packages）这个包的bug。然后程序会问你确定？确定的话，会要求你选择是哪种报告，其中就有ITP。当你的ITP通过后，你会收到一个bugnumber，这个bugnumber会在changelog中用到。
另外说明一下bts(bug tracking system)的基本用法。你需要给control@bugs.debian.org发送一封邮件，内容是bts的控制指令，每行一条。碰到无法识别的指令时，bts停止解析。通常习惯在最后写一个thanks来停止解析，也表示礼貌。指令系统可以参考[3]。
然后开始干活。干活的方法参考Debian 新维护人员手册。其中注意在changelog中填入你刚刚申请到的ITP，这样当包通过后，会自动关闭你的ITP。提交的包需要是lintian clean的，即自动检查程序没有发现错误。通常你可以在本地系统安装lintian进行检查。
当你完成打包工作（没法详述，太复杂了，自己看文档吧），你需要上传到mentors系统，然后让DD审查你的包。你首先要在http://mentors.debian.net拥有一个账户，这个账户的email将来会用于给你发送bug通知之类的东西。当你完成账户创建，你会在页面上看到要求上传一个gpgkey。gpg创建key都会吧？记得做4096位密钥。另外填写姓名的时候，用最好真实姓名作为名称，网名进nickname，尤其是大部分中国人都有一个拼音姓名和一个英文姓名的时候。。。
然后，你的主页上有一个说明，会让你复制一些数据到你的~/.dput.cf中。dput是用来上传源码包的工具。如果你按照说明去复制，那么你就可以用dput debexpo.changes来上传你的包。其中有几点需要注意的，一个是debexpo不能丢，否则会默认传到ftp.debian.org上去，然后失败。另外changes和dsc必须经过你上传那个公钥对应的私钥的签署，否则签名验证失败，你的包上传行为就会失败。如果你的系统中有多个private key，那么dpkg-buildpackage会不知道如何打包。用-k参数加上你的私钥id，就可以指定使用哪个私钥进行签署。
当你的包完成上传后，你可以在my packages下面看到。注意服务器检查结果，本地通过lintian的包在远程还是可能爆出错误，所以再检查一下。
如果一切都没有问题。你可以将package中的Needs a sponsor改为Yes，然后等DD注意到你的包。当然，还可以向debian-mentors@lists.debian.org发送一封RFS（Request For Sponsor）的邮件，提醒DD的关注。具体的内容模板在成功上传的邮件中会提示你，一般是http://mentors.debian.net/package/rfs/[package name]这种格式。打开url，里面就是你的RFS邮件规范的目标地址，标题，还有内容。
OK，最后总结一下，整个过程中我们用到了三个系统。第一个是debian bts，通过提起bug来表示你准备打包。第二个是mentors.debian.net，通过注册来上传包。第三个是debian-mentors@lists.debian.org，通过maillist来提醒DD检查你的包。过程有一点小繁琐，不过熟悉之后还不算繁琐。如果真的觉得繁琐，debian在包检测和打包过程中的一堆事情更是会烦死人的。
Reference: [1].Debian 缩略语http://www.cnblogs.com/lidaobing/archive/2010/05/21/1740508.html
[2].软件如何进入 Debianhttp://www.cnblogs.com/lidaobing/archive/2010/05/02/1726138.html
[3].Introduction to the bug control and manipulation mailserverhttp://www.debian.org/Bugs/server-control</description>
    </item>
    
    <item>
      <title>一次系统和数据迁移</title>
      <link>http://shell909090.org/blog/archives/1889/</link>
      <pubDate>Thu, 18 Aug 2011 15:42:49 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1889/</guid>
      <description>在文件系统选型后，贝壳骤然发现用ext3保存媒体文件是一件很傻的事情。耗费空间多，性能差，安全性低。根据文章结论，其实最好的文件系统是xfs。同时，贝壳的mini-itx空间基本满了(/home分区75-80%)。所以，贝壳准备买一块新的硬盘，然后将数据迁移过去。
硬件选择上，贝壳询问了熟悉的硬件商。他说日立没货，WD的盘问题比较多，推荐希捷的。而且只有绿盘，具体型号是ST2000DL003-9VT166，SataIII，常规转速5900。ST的2T盘入手后，贝壳做了一下基础测试，hdparm分数是，原本的WD硬盘90M/s，新的ST硬盘70M/s，公司的硬盘99M/s。看来硬盘性能还是WD的比较好一点，当然，也可能是因为新硬盘本身就是低档硬盘。
贝壳的第一选择，是按照原本的U盘安装设置，安装debian系统。不过前后两次都可耻的失败了，主要原因是mini-itx对U盘启动的支持并不是很好。被迫，用新买的大型电脑安装，又失败。原因是6.0的安装镜像对boot.img.gz方式的U盘启动支持不良。算了，先装5.0升级。没想到，这个原因直接导致了贝壳两次系统安装完毕后无法引导升级。为什么？因为硬盘的尺寸刚刚好比2T大了点。gurb升级到grub2的时候，为了让你支持全部空间，很好心的帮你升级到了gpt。然而gpt需要一个分区来保存一些信息，新多出来的空间又刚好不足以保存这个数据。因此，grub-pc就升级失败，而且救都没法救——因为没空间了。
两次折腾下来，贝壳基本搞明白了为什么。然而要解决这个问题，就要手工分区，计算大小，产生lvm，设定，然后debootstrap，再设定。或者就直接使用debian
6.0的安装镜像。这个时候，悲崔的事情来了——U盘安装那篇文章的上一节，就说明了如何直接使用usb启动iso，直接cat iso &amp;gt; /dev/sdX就可以了。早知道这么简单，何必折腾那么一大套呢，哎。
debian 6.0的安装系统比5.0的好了很多，磁盘分区支持gpt，直接就生成了bios_grub分区。lvm2的支持增加了vg级别的控制，而不仅仅只能控制lv的生成和删除。同时增加了软raid的支持。这就很好的解决了贝壳当前的问题。
贝壳的分区方案是，gpt分区表，一个bios_grub分区，一个ext2的boot分区，一个lvm分区。lvm上面分8G的root，ext4格式。4G的swap，可以适应当前内存和升级到4G的内存(linux swap推荐是，4G以下两倍于内存，4G以上和内存一致)。1.7T的home，xfs格式。剩余268G。为什么要剩余？因为xfs只能扩展不能缩小，如果我需要扩展root和swap，或者需要产生新的lv来做虚拟机，不留下一定空间会出问题的。如果home不足，我再扩展150G基本可以解决问题。
分区和安装都很顺利，然而approx对新的系统基本没有缓冲作用。我略微想了一下，大概明白了为什么——原有系统是用i386架构和amd64内核，而新系统则是架构内核都是amd64。或者通俗来说，原系统是64位内核下的32位混合系统，而新系统是彻底的64位系统。32位的包对64位的系统一点用都没有，所以approx原有的包都白缓存了。
好吧，瑕不掩瑜，这次升级基本还是成功的。安装对应软件包，复制数据（推荐首次cp -a，速度快，后面用rsync保证同步），修改属主（否则很多程序无法启动）。尤其需要注意，mldonkey在downloads.ini中，不但保存了以哪个用户启动，同时也保存了用户id。新系统中用户名和id对应关系会发生变化，因此要修改正确。基本——事情就完了。
一个小细节是，uwsgi由于amd64升级，所以无法使用。贝壳解决了一下问题，重新编译这个包。另外，debian官方的包出来了，目前处于sid状态，大家可以等着什么时候进入testing状态了。</description>
    </item>
    
    <item>
      <title>linux下的文件系统选型</title>
      <link>http://shell909090.org/blog/archives/1883/</link>
      <pubDate>Mon, 15 Aug 2011 10:07:03 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1883/</guid>
      <description>贝壳原来一直认为文件系统可以随便选，结果最近吃了两次苦头。一个是btrfs对虚拟机支持不良，另一个是特定情况下xfs性能比ext3高20倍。痛定思痛，打算列一下文件系统选型的方法和依据，欢迎拍砖。 
 下面我列一下纳入参考的文件系统，当然，ntfs就不要出来搞基了，玩嵌入式/光盘live之类的朋友也不要来凑热闹了阿。btrfs(简介), ext3, ext4(简介), jfs(简介), reiserfs, xfs，基本涵盖常用文件系统。最下面加入ntfs和zfs对比，实际上不参与选型。以下进制换算为1024，大小依次为KB,MB,GB,TB,PB,EB,ZB。

 --------------- --------- -------------- ---------------- ---------------- ---------------- ------------------ --------- ----------- ------------ 文件系统 btrfs ext3 ext4 jfs reiserfs reiser4 xfs ntfs zfs 最大卷容量 16 EB 32 TB 1 EB (16TB) 32 PB 16 TB ?? 16 EB 256 TB 16 EB 最大文件容量 16 EB 2 TB 16 TB 4 PB 8TB 8TB 8 EB 16 TB 16 EB 目录结构 B tree list/tree list/Htree B tree B+ tree dancing B\* tree B+ tree B+ tree hash table 文件分配 extents bitmap/table bitmap/extents bitmap/extents bitmap ?</description>
    </item>
    
    <item>
      <title>linux下多种文件系统在小规模追加写下的性能</title>
      <link>http://shell909090.org/blog/archives/1877/</link>
      <pubDate>Tue, 09 Aug 2011 16:56:06 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1877/</guid>
      <description>因为公司需要，所以贝壳最近做了一个比较。多种文件系统，在小规模写下的性能。
首先要说明的一点是，贝壳的blog为了保持便于传播，因此惯例是不贴图。这次的图，全部在blog同空间的相册上，通过引用方式放原始连接，可以保持原味查看。我知道中国不少站长复制粘帖大法厉害，不过大家手下留情，可以的话自己找个图床，贝壳可以提供所有原始图片。万一相册过载，blog也会跟着挂掉，谢谢谢谢。
这次的内容，对于有些类型的应用很有价值，具体哪些——懂行的自然了解，就不多嘴了。测试的目标，是测试在同样的环境下，不同文件系统对于散碎的写文件的支撑能力。测试方法如下。
首先，贝壳写了一个程序，可以开N个子进程。每个进程打开4个文件，分别写出16, 32, 64, 256字节大小的块。间隔m秒写一次。当磁盘吞吐耗尽的时候，大量的线程会排队在iowait上，因此造成iowait和loadavg快速上升。当loadavg明显超过CPU数时，宣告文件系统压力达到极限。具体测试方法，使用自己设计的压力系统对磁盘造成压力，然后通过压力读取系统读取系统参数，输出到文件。通过一个filter重新组织文件，计算移动平均数等。最后通过gnuplot输出图像。由于具体有些涉及公司业务，贝壳避嫌，就不贴出源码了。draw.plot的代码在最后。
这个业务情况的核心问题是，对同一个文件，在一段时间内会写多次。正常情况下，这些数据会堆积在系统的Dirty区域，直到dirty_ratio的限制到了，或者dirty_expire_centisecs的限制到了，系统才会开始强制写出。否则每隔dirty_writeback_centisecs的时间，系统会写出部分数据。虽然理论上说，一个磁盘的IOPS应当在每秒600-700次上下，但是实际上并不是只能支撑150个并发的。然而设计的好的文件系统，支撑并发数会比设计的差的文件系统明显高。
这个测试环境和实际的另一个差异，在于读写平衡上。这个业务和大部分的日志系统是很类似的（其实我们系统的业务就是日志）。但是商业用日志系统的特点是在高散碎文件写的情况下还有高随机读。这点在测试中并没有涉及，测试是单纯的大量文件追加写，请读者自行注意。
首先是400进程，间隔1秒写出，测试对象是ext3, ext4, ntfs, jfs, xfs, btrfs，基本涵盖常见的linux文件系统。ntfs不属于常见的linux文件系统，本轮只做对比测试。首先可以看到的是ext3糟糕到吐血的表现，磁盘写io只有500上下，400个进程最多有280多个在排队。这货不是坑爹呢么。ext4的结果就正常很多，io在100上下，开始的高开是因为前一个测试的静默时间不足。jfs的结果很搞笑，队列load倒是不高，可是Dirty缓存一路上涨，让人不禁怀疑到底有没有写出。xfs的表现中规中矩，半分钟一次写出，和贝壳机器上的dirty_expire_centisecs相吻合，Dirty也不高。btrfs和jfs的情况类似。
上一轮中，筛掉ntfs和ext3，其余进行1000进程，间隔1秒写出测试。测试对象是，ext4, [jfs](), xfs, btrfs。这次ext4也表现出了坑爹的一面，Dirty最高250M多，load也明显超过了2，写io大约在700上下，就此出局。btrfs这次的Dirty控制还不错，在25-40M徘徊，写出也不多。看似情况略好，实际上暴露出btrfs一个非常大的弱点，突发响应能力差，服务不稳定。一次集中写出，就能让排队数飞速上涨。jfs虽然曲线类似，但是队列可从没有超过1。综合考虑，后期平均load也明显超过了2，一样出局。xfs还是一样中规中矩的写出，非常低的io和Dirty。jfs依然是高速上涨的Dirty和超级低的io。
测试到这里，只剩下了jfs和xfs。jfs的特点是大量使用Dirty，平均io很低。xfs的特点是Dirty使用比较低，io输出比较平均。不过我们的服务器内核对xfs的支持比jfs要好一点，所以使用xfs已成定局，下面就是测试两者的极限性能而已。
第三轮的参数是2000个进程，0.75秒间隔。jfs和xfs表现非常相似，让贝壳差点怀疑自己是测试错了东西。核查之后，确实没有。所以就下狠手，测试了一把高压力的。
第四轮的参数是3200个进程，0.5秒间隔。从绝对量上，大概是基础测试的16倍。在jfs测试开始后的三分钟内，load上升到了60，宣告出局，因此贝壳这里没有jfs的图像。但是xfs还是完美的顶住了压力。Dirty已经上涨到了80-120M，平均io也到了300。然而平均load只有1左右，最高load也只有1.4。
最终测试的参数是4000个进程，0.5秒间隔，基础测试的20倍。xfs的表现万分惊艳，平均io300-400，Dirty100-160M，平均load大约是1，最高也只有2。也就是说，到最后贝壳还是没有测试出xfs的最高压力。
另外，贝壳也通过iozone对两者进行了测试，结论是，xfs在读写性能上比ext3高一些，但是在随机读写上大幅低于ext3。无论哪个数据，都无法出现这种20倍以上差距的现象。因此贝壳又对文件系统选择发生了兴趣，具体写在下一篇blog上。
从最终结论上说，我们确定了xfs比ext3的巨大提升（20倍以上），并准备对xfs进行可用性测试。如果您有什么经验，欢迎和我联系。
-------------draw.plot------------- set terminal png size 1920,1080 set output &amp;quot;out.png&amp;quot; set xdata time set timefmt &amp;quot;%H:%M:%S&amp;quot; set y2tics set origin 0,0 set size 1,1 set multiplot set origin 0,0.5 set size 1,0.5 plot &#39;out.dat&#39; using 1:2 with lines title &#39;Buffer&#39;, &#39;out.dat&#39; using 1:3 with lines title &#39;Cached&#39;, &#39;out.</description>
    </item>
    
    <item>
      <title>重分区和lvm</title>
      <link>http://shell909090.org/blog/archives/1859/</link>
      <pubDate>Wed, 20 Jul 2011 14:15:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1859/</guid>
      <description>上篇btrfs会导致虚拟机慢死的blog都看到了吧？看到了就不多解释。
首先，删除掉cache数据，还有冗余数据，使得数据可备份化。然后执行rsync -av /home /mnt/mdisk/sync，将数据同步到备份的移动硬盘上。之所以用rsync，是因为我在备份的时候还能看看网页什么的。等第一次备份完成，关闭所有X程序，退出shell这个用户的所有进程，然后再次执行rsync，就可以保证同步。同步完成后，注销/etc/fstab下面的/home和swap项目，重启。
系统启动后，先登入root用户，因为此时/home已经恢复到了/下面，所有shell用户的home路径不存在。建立/home/shell目录，并且复制/etc/skel配置，修改owner后，shell就可以登入了。当然，此时是系统默认环境，并没有定制化。没有关系，我们只需要terminal。在terminal中执行gparted，会出现图形的分区管理工具。当然，理论上说，如果你够熟悉，使用fdisk完成全部操作也是可以的，这免除了初始化shell用户和登入图形界面的麻烦。删除原先的/home所在分区和swap所在分区，切割一个ntfs分区用于将来安装windows(回头可以打游戏)，剩余的全部切割，而后开启lvm标记。当然，这一步贝壳当时不知道，而是创立了一个未知分区，再用fdisk调整分区类型为8E。而后系统会提示你，不能保证内核数据结构更新，需要执行kpartx
/dev/sda。无论如何，此时我们已经有了一个lvm分区。
lvm的结构是pv -&amp;gt; pg -&amp;gt; lv，也就是物理卷-&amp;gt;物理组-&amp;gt;逻辑卷。物理的各个分区首先被组织成物理组，再被划分为逻辑卷。这样设计是因为可能有多个磁盘上的空间，被划分为多个逻辑卷。在不改变逻辑的情况下，lvm的默认组织构型是raid0的。不过这对我不是个问题，我只有一个磁盘。
首先创建pv，使用命令pvcreate，没什么好多说的。然后是产生vg，使用vgcreate main /dev/sda7，之所以需要main，是因为需要一个vg命名。而后我们需要从这个vg中创建出一个lv来，执行指令lvcreate -L150G -nhome main，设定lv的名字叫做main-home，大小150G。此时在/dev/mapper/main-home，就产生了一个设备文件，大小150G，可以当作/dev/sda1之类的设备一样使用。不过，这个设备没有经过任何格式化过程，所以还需要mkfs.ext3 /dev/mapper/main-home。在这个指令后，我很习惯的跟了一个tune2fs -c 0 /dev/mapper/main-home来关闭重启检测。使用blkid，发现这个设备已经成功创立，并且有了ID。把UUID复制进（这时就知道X的好处了，console下面比较绕路）/etc/fstab，并且修改刚刚被注释掉的/home一行，更改UUID和分区格式。贝壳当时光记得复制，忘记改分区格式，导致系统进不去。不过也不困难，修改/etc/fstab后mount -a一下就可以了。
此时我们已经建立了有效的逻辑卷，并且正确配置。下面要创建一个交换分区，并且挂上去。废话不多说，lvcreate -L6G -nswap main，mkswap /dev/mapper/main-swap。而后一样blkid和vi /etc/fstab。系统就基本配置好了。验证一下看看。
shell-deb:\~\# pvs PV VG Fmt Attr PSize PFree /dev/sda7 main lvm2 a- 229.19g 73.19g shell-deb:\~\# lvs LV VG Attr LSize Origin Snap% Move Log Copy% Convert home main -wi-ao 150.00g swap main -wi-ao 6.00g  而后就是新系统的启用过程，首先要退出X，注销shell用户的所有进程，然后以root删除/home下的所有数据。如果不删除的话，重启后，这里的数据无法访问，变成垃圾。而后重启，就可以看到正确结果了。不过还不要着急登入shell。首先执行rsync -av /mnt/mdisk/sync/home /home，将备份同步回去。这样我们登入shell的时候就可以看到有效的定制化界面了。另外一点细节是，mdisk使用了ntfs格式，所以导致数据恢复后属性混乱。使用find . -type d -exec chmod 755 {} ;和find .</description>
    </item>
    
    <item>
      <title>btrfs上使用虚拟机效率很差</title>
      <link>http://shell909090.org/blog/archives/1858/</link>
      <pubDate>Tue, 19 Jul 2011 14:38:06 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1858/</guid>
      <description>试图在linux中使用虚拟机的同学请注意，刚刚测试下来的结果，vmware和kvm在btrfs上的IO效率极端的差。
首先是vmware，win2003，512M的实例，开机大约需要40分钟。这种效率已经远远超出了我的预期，于是我改用libvirt管理的kvm。结果依然出乎意料，debian实例的安装需要超过5分钟。由于怀疑是raw格式而非qcow2格式造成的速度差异，因此新建了一个实例，一时偷懒就放在了/下面，这个分区是ext3而非btrfs。结果安装大约在3分钟内结束，这似乎证明了我的猜想。于是我开始使用btrfs下的raw格式进行安装，结果速度依然异常缓慢。由此我怀疑到是btrfs文件系统的问题。
在ext3上创建一个qcow2格式的实例后，证实了我的猜想。问题在于btrfs的某种机制上。在网络上寻找类似问题，并没有发现。因此在blog上提出警告和问题。
有人知道为什么在btrfs上使用虚拟机会导致极端的效率问题么？hdparm和文件读写测试表明btrfs的平均效率并没有问题，磁盘也没有问题。</description>
    </item>
    
    <item>
      <title>社区的准则</title>
      <link>http://shell909090.org/blog/archives/1849/</link>
      <pubDate>Mon, 04 Jul 2011 12:19:51 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1849/</guid>
      <description>今天碰到了一件挺有趣的事情。当然，有趣是对我们这种老社区用户来说的，对于两个当事人，好像受到了严重的侮辱，不怎么有趣的样子。
起因是因为有个朋友，在shlug上求UltraEdit的注册码。马上有用户说不合适，然后有人建议ban掉。下面出来个人，说不要以为谁都是高手，能不能有耐心帮助一下人家，有人要被踢出去了，凭良心讲，这样是不对的，要说一些良心话，至少救他一次。云云。
我想，也别搞的事情太大，就回复了两句。1.lug论坛讨论Windows话题（事实证明，我看错了，他需要的是UltraEdit Linux版）。2.内容涉及盗版。我的态度分两方面，一方面，我们自己手头的版权也不见得干净（我引了自己的一篇blog，地址这里：（ http://shell909090.org/blog/archives/1786/ ）。封了别人，有点“只能做，不能说”的感觉。另一方面，帮楼主说话也不是什么善。严格来说，盗版和偷东西是划为一流的。要说是善，颇有孔乙己“窃书不算偷”的尴尬。
OK，下面说要帮助别人的朋友又出来了。首先指正了我第一条问题，楼主需要的是UltraEdit Linux，这个是我看错了。第二条的回复我摘录如下：
内容设计盗版，这个我不否定，但是请问，你能向我保证您的电脑里面没有盗版软件吗？许多时候我们盗版是被迫无奈的 许多正版软件，在我生活的城市和淘宝网上都是不存在合法的获取途径～ 但是我们是否能够因为一个孩子的一次犯错，就认为他是坏人，然后把它抓起来，永世不得翻身？
看到这里，我就气乐了，心说估计这人要给thomas封掉。下面还有些内容，我们后面讨论。他下文又接了一封邮件，内容摘录如下：
而且如果强词夺理的话，我们甚至可以理解这个标题的含义为！！！
哪位可以给一个Ult​raEdit Linux的注册码 要求邮件列表里面的那位网友提供一套正版的Ult​raEdit 赠送与他 至少这在法律上是说的通的，如果要打官司，他是会无罪释放的，完全抓不到他所要盗版的问题 当然这是题外话，我还是希望大家能互相帮助，才是王道啊～～～～～～～～～ 好吧，我暗自叹口气，决定不和他辩了，这人死定了。
为什么？出了什么问题？
我觉得他在侮辱所有人的智商。
要一个UltraEdit的SN，严格来说不涉及法律，任何角度，任何层面都不。就算你亲手破解了一套软件，依然不涉及法律问题。下载盗版，依然不涉及。法律只要求惩罚传播盗版的人，而不是使用盗版的。就是说，要回答楼主的问题，除非真的如楼下所说，弄一套授权赠与给楼主。否则，楼主没事，论坛麻烦大了。作为论坛管理员，警告乃至封禁是份内事，视而不理才是失职。这点事情，任何一个智力正常，了解版权法律的人都应该能知道。
而且，楼下在讨论的时候，使用了“道德说教”的方法，而且是进攻性的道德说教，咄咄逼人。“你应该如何如何，你自己就没有错么？”这类的言辞。实际上，在被ban之后，还单独发邮件给我，讨论关于thomas的决定。全篇依然是道德说教，我怀疑不止我一个人收到。和hacker打交道，道德说教是一种非常差的选择。hacker们才没功夫听你讨论平等，博爱，神爱世人那一套。对于hacker来说，对和错都是显然的，不显然的事情可以投票。哪怕占领了道德的至高点，对于hacker也没有任何意义。大家都不傻，也不在上幼儿园，不用教怎么过日子。更加奇特的是，对于lug这种组织，讨论技术上如何破解UltraEdit是可以接受的。甚至讨论结束后会兴致勃勃的翻译成英文给作者发过去。然而讨要SN是不可接受的。组织成员都知道这点，并且深信不疑。
然后是楼下帮楼主说话的朋友回复我邮件的后续内容摘录：
第三，请问，您所说的这些规定，有一个具体的邮件列表或者网址，贴出来公示吗？
如果有，我也很希望能看看，至少我现在还没有找到，相信很多人都没有找到，而且显然，这里的规范和网络上大家习以为常的大多数论坛，还是有些许出入的。既然这类公告的东西都非常不好找，请不要随意说ban什么的～～～～～～～ 这是你们自己的职责失职～～～～～～～～～ 这里再补充一个问题，请问邮件列表里面有多少人看到过，这个shlug列表发贴规则与规范的？
这个shlug有几个管理员？
是否你们每个管理员都能单独ban一个人？还是必须所以管理员都通过才能ban？
你们ban一个人的时候，管理员之间是否有讨论过？
能否把这些讨论公开来给大家看看呢？让大家觉得是否做的有道理呢？
这里的许多人不愿意说这些事情，很简单，避免不必要的麻烦与冲突，但是问题始终存在 不回避，直面解决问题，才是值得尊敬的。
我觉得，显然这个人不是在国内日子过傻了，就是在党政机关工作。我们为什么没有贴出一套具体的规定呢？阮一峰翻译过一本叫做《软件随想录》的书，原名joel on software。里面有一段话，大意如下。说joel坐火车，看到火车上的规定列表。一大长串，写着“不能XXXX，否则OOOO”。joel就想，显然，这是没用的。真的会犯事的人，才不在乎你写了什么。会来仔细阅读这些条文的99.99%都是智力正常，不会犯事的人。这些条款，对于他们一点意义都没有，反而显得冷冰冰。
他里面用了一个词，智力正常，我觉得可堪形容lug社区。会来lug社区的，至少是智力正常的人（我不敢用成年，曾见过一个初二学生，现在应当升初三了，长江后浪推前浪阿）。作为一个智力正常的人，你应当知道什么是对的，应当知道我们不应该随地大小便，应当知道不应当盗版。对于任何一个正常的，混过网络的人，都不会误解楼主的意思是要求别人赠予一套正版软件，而是要求提供盗版。也不会认为这是理所当然的，不应当被指责的。对于这种正常人都知道的问题，几个管理员需要讨论，再集体决定。这是侮辱管理员的智商，还是以为这是常委投票呢？
为什么需要集体决定？这通常见于两种情况，一个是意见相左，一个是推卸责任。如果关于一个问题，管理员之间意见不一，就需要讨论，集体决定。对于显然的问题，集体决定的唯一意义是，这个决定是错的，集体责任等于没责任。
为什么需要公示条例？同样常见于两种情况，一个是未达成公识，一个是被投诉时的自我防御措施。如果一个未达成公识的事情，例如餐厅禁烟，要实行就必须明确公示条例。即便我们的智力正常，我们也不可能理所当然的认为餐厅应当禁烟或者应当不禁烟。另一个公示条例的理由就是被投诉时的自我防御，也就是joel看到条文的原因。如果一个组织（例如铁路系统）会被起诉/投诉，那么如果没有公示条例，在某些情况下这个组织会面临败诉的问题。如果公示了条例，组织可以说，我们有规定。这是一种会被投诉的组织的自我防御措施。然而你觉得一个全自发的松散组织，有任何被起诉/投诉的可能么？对于这些组织，唯一的问题是参与人员是否满意，是否得到了他们想要的迦南圣地。
而后更好玩的事情来了。楼主总算出现了，开口就是人身攻击。“首先是有点吃惊，但看着看着不禁笑了出来，原来世界上真的是有很多人，爱装B，爱自诩，爱用言辞抨击别人（现实中会被揍所以不敢）”。他自言曾经在LinuxMint的论坛里面，问如何破解WPA2的WIFI密码，结果得到朋友们的热心帮助。由此得出结果“呵，无需多言。某些人，他就那点素质，就那点眼色，就那一点空间，就知道那一点技术，就不得了了，自己仿佛穿上了圣洁的外衣，其实里面还是破内裤。鲁迅先生笔下的某些丑陋的国人到现在还是存在的。” 楼主还有部分邮件，摘录如下：
这个我得阐明一下，UltraEdit是从Ubuntu软件中心里下载的，我下的时候上面赫然写着“Free”，但我装完之后发现要注册码，我立马想到了来这里，这里是一个Linux论坛，然后这里都是懂Linux的人，这里都是用Linux下软件的人，于是我就来问了。但却遭到一帮人的抨击。我是一个linux菜鸟，开始用linux不到一个月，还不喜欢vim那繁琐的命令，只是在寻找一个图形化的友好的编辑器。但是以后我肯定不会再来这里问任何问题了，我想我也会很快的换回到Windows，因为我还有很多问题搞不清楚，不知道向谁，该怎么求教。但这里的氛围，会让初学者心寒。我之前也发过几个初级帖子，但我发现回复你的人大多都不是帮你解决问题的，而是质疑你和说你这不好那不对的。只希望这不是国内linux社区的一个缩影吧，不然就太悲哀了。
为什么开机会随机出现gnome applet丢失，为什么compiz很不稳定，为什么装独显驱动装不上去等等太多的对于初学者很重要的问题，会影响到很多初学者步入linux殿堂的问题。其中不乏我这则帖子这样的问题。可能那些抨击我的人，是从娘肚子里出来就能玩转vim了，不需要ultraedit这样的东西？这里我想作为一个老资格的Windows开发者，为UE说一句话：UE很好很强大，不比vim差！
我觉得这个人想反了。如果我从Ubuntu软件中心（我是说如果，实际上我觉得这个东西很邪恶）下载一个软件，写着Free，但是却要注册码。我会干啥？大概是卸掉，然后向Ubuntu软件中心投诉“描述与内容不一致”。这和UltraEdit好不好没关系。哪怕当年，胡正的stardict我用了很久了。这家伙突然想到说，辞典可以收费。开玩笑，自己的辞典版权还没有搞定（和金山辞典的质疑），而且很多都是社区整合辞典，还想收钱？
我立刻拆掉stardict，转用dictd和各种客户端，哪怕他后来不收费了。
Don&amp;rsquo;t be evil.
而且LinuxMint那个论坛，我打赌他混的是用户论坛。
hacker们的做法是什么？
首先，还是会回答你怎么做。不过通常不会告诉你，下那个软件，然后上面有个大大的破解，点下去就好了。而是会告诉你，你的网卡是什么型号的，用什么内核驱动，是否支持监听模式。软件选用什么，怎么启用调式模式，调试信息是什么，出了什么问题，等等。
其次，如果你的议题引起了某人的兴趣，hackers会做一些看似无聊但是很酷的事情。例如有人曾经在国外的列表里面问如何在java中将一个数变成负号形式（就是a变成-a），具体的讨论可以看这里（http://www.webgamei.com/club/thread-5028-1-1.html)。%E3%80%82)这个好像还是简化版，我记得那次的恶搞甚至用到了模板编程，以及讨论到模板编程的图灵完备性。
这才是hackers会干的事情。技术，技术，还是TMD技术。hackers才不关心你有没有SN，编辑器好用不好用。如果你打算学习linux，他们会推荐你用vim或者emacs。你表示这个不好用，他们就耸耸肩走开了。除非你说，我打算基于emacs写一个现代编辑器，架构如何如何。内部使用lua语言作为控制，并且做一个elisp到lua的自动译码器。他们会纷纷围上来，看着你干活。如果你干的比较像样，他们会抢着把能干的活干掉，然后合力推出一个1.0版——这大概就是linux怎么出来的。
如果你打算以初学者作为辩护，那是你值得同情的理由，而非必须原谅的理由。如果新手就不应当被惩罚，结果大概是论坛内充斥着新手的叫嚷，“冰天雪地360度裸体跪求，我的显卡不工作了”，“高分求SN，送两个软件SN”。其中大多数人奉行打了跑（hit and run）理念，跑上来跪求一番，搞定问题就潜水，下次还是新手。
他们一辈子会是新手，我们肯定转身就走，离开社区，不再回头。
问问题的时候，你要考虑，我们和你们是一样的。这个陈述包含了数重的意义在里面。你们不会的东西，我们也是慢慢学出来的，为什么要我们无条件的帮助你们？你们是人，我们也是，所以不要害怕权威，认为他的观点一定就是正确的。太理所应当的问题，就要多想想，大家都不是笨蛋。
如果你觉得不习惯，不想学习，可以转回去用Windows。反正这不是lug的损失。
哦，对了，作为结局，楼主也被封了，原因是人身攻击。</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——中文化</title>
      <link>http://shell909090.org/blog/archives/1809/</link>
      <pubDate>Tue, 24 May 2011 10:36:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1809/</guid>
      <description>讲了半天废话，都是在介绍你应该用什么应该用什么，基本没讲到中文用户最关心的一个问题，中文化和输入法。
其实没讲是有原因的，因为debian的中文实在太简单了。在你安装的时候选择中国地区和中文，装出来应该就是中文的。如果不是，或者你安装的时候忘记选择了，可以先运行dpkg-reconfigure locales，出现一个很长的语言列表。其中选择中文的几项，常见的有zh_CN GBK(不推荐18030，多出来的字很少用到，生成时间极长)，zh_CN UTF-8，zh_HK UTF-8(香港地区编码，不用可以不选)，zh_TW BIG5，zh_TW UTF-8(后两者为台湾地区编码，不用可以不选)。选择好后，确定，推荐zh_CN UTF-8为默认编码。然后就是漫长的生成，完事。试试看重启后你的env | grep LANG有没有变成zh_CN.UTF-8？过去就对了，没有的话，手工修改/etc/default/locale加入也一样。其实dpkg-reconfigure locales就是修改了/etc/default/locale和/etc/locale.gen，然后locale-gen一下。
不过这不代表你能正确的使用中文，只是你的满屏看不懂的东西变成了一堆方块而已。因为，你还没装字体。当linux不支持该种语言的时候，出现的是满屏的乱码。如果支持了但是没有字体，则是一个个方块。下面是我常用的一堆字体，保证不含windows，大家可以选择自己喜欢的用。ttf-arphic-bkai00mp，ttf-arphic-bsmi00lp，ttf-arphic-gbsn00lp，ttf-arphic-gkai00mp，ttf-arphic-ukai，ttf-arphic-uming，ttf-wqy-zenhei。其中最后一个就是赫赫有名的文泉驿正黑。安装方法都很简单，aptitude install就好。如果你还不满足，非要自己安装字体。那就在/usr/share/fonts下面新建个目录，把你的字体复制进去（符号链接也可以），然后在这个目录中运行mkfontscale，mkfontdir。全局运行fc-cache。
OK，中文支持快走到最后一步了。你现在应该可以看到满屏的中文，可是，可是——你还什么都输入不进去。恩，没装输入法吧。debian的特点是什么东西都是自己来装，而不是系统帮你装好。所以，你需要自己装输入法。简体中文而言，比较流行的有三种，fcitx（传说中的小企鹅），scim，ibus。下面就要根据你的具体配置选择了。ibus是我用过的比较好的输入法，但是相对比较费cpu，在低端机器（例如netbook）上老是丢字，scim对这种情况略好些。如果你安装了一个以上，可能你还需要im-switch来切换输入法。这个软件会调整/etc/alternatives/xinput-zh_CN的链接指向，这是debian的alternative系统，细节不说。
另外说一句额外的提示，做完上面的步骤，你应当可以阅读和输入中文，但是你看到的软件还是满眼的鸟语，对不对？这是因为软件的语言在软件书写的时候就确定了，他不会随着你的内容改变而改变。但是这并不是说常见软件没有中文版。例如你安装一下iceweasel-l10n-zh-cn这个包，再跑iceweasel (firefox)看看？</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——上网</title>
      <link>http://shell909090.org/blog/archives/1806/</link>
      <pubDate>Fri, 20 May 2011 13:46:38 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1806/</guid>
      <description>上网是linux系统的一大强项，除了那个变态的QQ外。
通常而言，上网指的是网络三大基础应用，浏览器，IM工具，电子邮件。最后一个我们介绍过了，那么我们就集中介绍一下linux的两大杀手级浏览器。firefox和chrome。
firefox是debian内置的，不过用的是开放分支，iceweasel。其实主要就是改个名字换个图标做做兼容性测试打几个下游补丁什么的，内核还是一样的，版本号和firefox都保持一致。目前testing下的firefox还是3，不过估计很快就会升到4。firefox下有很多插件，你可以挑选部分来安装，改善浏览器特性。记得linux是一个多用户系统么？对了，你在firefox下安装的插件(addons)都是针对个人起效的。所以，你老婆安装了一堆插件，对你不会构成任何干扰。如果你打算全局安装，可以用apt-get来安装部分插件。
用firefox的话，你可能疑惑flash插件怎么装。系统会给你默认安装拉，不过那个非常不好用。你需要用non-free版本的flashplugin-nonfree，直接从仓库中可以下到。注意这个组件是x86 only的，如果你用64好像要自己装ia32来做模拟，否则无法生效。如果连这个都说版本太老，就去adobe的网站上弄个最新linux版本回来，for debian或者for ubuntu都可以，自己装。
chrome的安装使用就比firefox简单很多了，直接去这里( http://www.google.com/chrome/ )下载合适的包，安装后，你的系统/etc/apt/sources.list.d/位置下会多出一个google-chrome.list，每次update的时候会检查google的仓库，跟随升级。这点chrome做的非常无缝，你基本没有感觉。
另外就是IM软件的选用。国内装机量最大的是QQ，不过鉴于我对企鹅这厮没什么好感，我强烈不推荐你用QQ。整个开源社区做QQ兼容做了不下三次(QQ for pidgin, luma, eva)，还都是在未公布资料的黑盒情况下做的。每次都被腾讯改协议给封掉。自己出了个linuxqq，做的烂不说，还多年不升级，也不管客户反应。微软就算讨厌开源，也好歹没有封杀开源办公软件兼容他的文件格式。既然这厮不打算支持开源，那么开源也不打算支持他。你非要用，可以用webqq，或者很痛苦的用linuxqq。有不支持的功能，请打电话给腾讯吧。
linux下用的比较多的IM还是gtalk,msn和skype三种。不得不感慨大中华局域网的威力，国内和国外的东西都不一样的。国外好用的东西就是进不来，国内的山寨货大家玩的不亦乐乎。首先是最多的gtalk，这个东西什么都不支持。没有定制表情，不一定能传输文件，没有远程协作。那为什么列为第一推荐IM呢？因为这个东西就是为了随时通讯而生的。支持gmail内置客户端，可以在无客户端的情况下用网页使用（这也就是为什么不一定能传输文件的原因）。支持几乎所有的第三方客户端，支持手机，强安全通讯。（腾讯的另外一个问题是，在同一个网段内的人可能可以获得你的聊天记录）并且，这是我所知唯一能同时在多个地点登录的IM工具。你可以在地铁上通过手机聊天，到了公司后直接登录，不必担心手机和电脑互相提下线的问题。电脑关机，手机持续在线。
MSN是老牌IM，不过微软逐步淡化了这个系统。某个版本后居然需要安装100M+的客户端，我就没在windows下继续使用。但是linux下的pidgin可以同时支持gtalk(协议是jabber)和MSN，开一个软件可同时登录多个账户，也不需要一个超级庞大不知道干了点啥的客户端，非常方便。skype是国外知名的IM工具，特点是音频支持能力，说白了基本当电话来用的，在国内发行的版本有记录聊天记录的问题。linux下要使用skype需要独立下载软件，pidgin-skype这个东西居然要skype在运行才能使用，这不是扯淡么？贝壳的repos里面有skype的安装包，你也可以去下载官网的安装包，应该没什么问题。不过最近这厮被微软收购了，也不知道将来命运如何。</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——办公</title>
      <link>http://shell909090.org/blog/archives/1805/</link>
      <pubDate>Thu, 19 May 2011 09:49:49 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1805/</guid>
      <description>作为一台中国的电脑，最重要的三大功能就是上网，办公和游戏。当然，linux下你需要暂缓考虑游戏。不过最基础的，办公功能应当还得有。
首先要说明的一个问题是，linux下对微软的office系列的支持并不好。这当然不是linux的过错——你让微软打开odp或者tex文件看看？不过鉴于现在office满天飞的现状，你总要支持doc系列文件，否则办公就直接出局。这部分的是为什么只有程序员才用linux的原因——在IT公司里，用office的是异类。我们公司里，老大带头用openoffice。对于没有这种幸运的人，我的建议是安装libreoffice这个包，这个的前身是sun的openoffice，不过开源社区做了一个完全自由的分支。后来sun杯具了，debian下的头号办公系统就是他了。大部分的文件打开，使用和保存都是没问题的。如果光论正常文档，文字的编辑，段落编排，libreoffice的功能都不会和office差太多。不过高阶功能开始，libreoffice就会变的很不顺手。这是当然的，office用户众多，发掘出的用法和资料不知凡几。libreoffice用户不但少，而且多数还是老外。
当然，作为一个linux用户，通常都抱有一个观点。平文本(plain text)比复杂的办公软件好用多了。大多数情况下，这都是对的。当你写毕业论文的时候，内容比你排版技巧更加重要。当你给上司做一份汇报材料的时候，内容比排版技巧更加重要。平文本的简单编排，libreoffice还是可以比较好的兼容掉office的。如果这些工作上，公司的要求是排版技巧更加重要，那你可以考虑换一个公司。有少部分情况下，排版技巧会比内容更加重要。例如客户PPT展示，公司报纸美编，这些工作不要使用办公软件来完成，你应当做的是寻找合适的软件来做到完美，而不是用一个不专业的软件在那里折腾，然后抱怨不好用。记得我们开始说的么？要懒，而且有创造力。
除了office系列，另一个办公上常用的东西是pdf文档。debian下可以用的选择就比较多了，闭源的有foxit reader，开源的有epdfview，mupdf，xpdf，evince等等一堆。个人比较推荐foxit reader，基本可以解决大部分情况下会让你比较烦恼的中文看不见问题。如果要生成和处理pdf，选项更多。linux下大部分办公软件都可以直接输出PDF。即使不可以，也可以像windows那样，装一个虚拟的打印机，然后输出pdf来。
提到PDF不能不提的就是打印，这点上debian做的并不太好，当然，也不算太差。在windows下的行为通常是，连接打印机，安装驱动，在打印机设备中出现新设备，配置打印机，并标记为默认，然后就可以工作了。在debian下需要先安装cups包，启动服务。再安装合适的驱动，例如hplip-cups。连接打印机，然后用浏览器访问http://localhost:631/来访问管理界面。新建打印机，再选择合适的配置。对于不大熟悉的人，通常会在驱动选择和管理界面上花费不少功夫。这里（ http://zh.wikipedia.org/wiki/CUPS ）介绍了常见系统下的管理工具，能减轻一些负担。不过实话说，直接用web管理并不繁琐。
办公中还有一个比较重要的功能就是收发邮件。作为初学者，我建议你用thunderbird开始，debian下需要安装icedove这个包，这是thunderbird的开放分支。基本简单配置后就可以直接收发邮件了，没什么值得好讲的。不过既然你选择了linux，我建议你好好学习一下gnupg和签名技术。你要知道，通常的电子邮件安全性和明信片背后写的祝福大致相当，以这个作为办公基础实在是一件相当危险的事情。</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——安装</title>
      <link>http://shell909090.org/blog/archives/1802/</link>
      <pubDate>Tue, 17 May 2011 10:25:58 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1802/</guid>
      <description>这篇主要讲安装。所以，请去这里（ http://www.debian.org/CD/http-ftp/#stable ）下载一张stable光盘。如果你对testing和unstable比较感兴趣，没问题，装好了可以改的。但是对于初学者，我建议你从stable开始玩起。在选择了合适的架构后，你会被引导到光盘镜像服务器上。作为国内玩家，我建议你别用官方服务器，那个在美国，很慢。个人推荐中科大服务器（ ftp://ftp.cn.debian.org/debian-cd/ ）去下载合适镜像，服务器是电信联通教育网三线路的，无论是学生还是商业人士都很合适。目前而言，我推荐你下载debian-6.0.1a-i386-netinst.iso作为安装镜像。这个镜像只安装最小部分，而且在安装时无须联网，适合大多数场合。注意，如果你的机器只有无线网络，请不要使用这张镜像，因为难度太高了。
好吧，下面我假定你有镜像了，你有三种常见的安装模式，刻录光盘安装，liveusb安装，虚拟机直接使用镜像。刻录光盘没什么好多说的，虚拟机直接使用就看你会不会用虚拟机，liveusb就有点复杂。具体参考我写的这篇文章（ http://shell909090.org/blog/archives/1646 ）。无论从哪里开始，你都必须保证开机启动的是你的debian安装镜像。所以发生例如debian安装时进入了硬盘上的windows这种问题别来问我，直接去google BIOS设定。
很多人经常问的一个问题，是关于如何安装linux和windows共存。其实这种模式并不好，至少我知道的使用这种模式学习linux的人都失败了。因为你平时会经常进入windows，然后懒得出来了。最好的方法是，彻底告别你的windows，然后下定决心用linux解决所有问题。如果你觉得底气不足，可以用虚拟机运行一个小实例，至少我觉得这比共存模式方便。因此，我不会介绍windows和linux共存的有关问题——这些问题太复杂了，虽然技术上说并不难，但是会占用大量篇幅。
单独安装linux也需要划分分区。通常的建议是/ /usr /var /home /tmp swap全部可以考虑分开。不过作为初学者，我建议你用一个分区/就够了。如果内存在1G及其以上，也不一定需要用swap。减少麻烦不是什么值得羞耻的事情，制造麻烦才是。如果你看了半天，搞不懂这段话什么意思，我建议你先看看下一篇《系统管理》中关于linux文件组织结构的介绍。如果你觉得有些不安，常见的方法是/ /home swap。这通常用于大型机器上，分离的home会让你在重装时无须额外的做数据保留操作，swap则提供更高的内存使用率。文件系统的建议是全ext3，这个会减少你很多的管理麻烦。如果你想尝试一些新的文件系统，最好不要在/上面尝试。
安装过程没什么好多说的，安装完成后，才是一系列最艰难的地方。debian-netinst是不带X系统的，所以如果你想使用图形界面，安装完成后的配置才是最关键的。通常你的电脑可以联网，因为安装的时候会自动配置你的网卡。如果你是无线网卡，请先连一根有线。如果不行，那就不是初学者课程了——你需要自行安装wpasupplicant，iw和相关依赖包，然后手工建立config文件。通过config连接合适的ap，再手工dhcp获得地址。总之，这些问题初学者就不要想了，请直接拉一根网线，接上，启动机器（次序不要反），你的机器就联网了。如果不是，找人求助吧。
第一件事，请先去/etc/apt/source.list下面，修改你所选用的镜像。如果你希望用testing或者unstable，直接修改此处就可以了。通常我们需要安装contrib和non-free部分，所以在main后面加上contrib和non-free。这里有些重要的商业程序，例如sun-java，rar/unrar，flashplugin等等。另外就是名称。通常镜像后面的名称是lenny这类的代号，建议改成stable这样的代号。当debian升级，版本切换的时候，你的系统会自动的升上去。当然，商业级别的服务器反之，不要用stable这样的代号，因为会造成稳定性问题。
当你修改完source后，执行aptitude update，然后再执行aptitude install vim slim xfce4。当然，如果你喜欢用gnome，那就是aptitude install vim gdm gnome。然后重启？你的机器应当出现了一个可爱的，花里胡哨的界面。啧啧，简直俗毙了。不过鉴于新手都比较习惯图形界面，我还是继续从图形界面开始介绍吧。</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——系统管理</title>
      <link>http://shell909090.org/blog/archives/1800/</link>
      <pubDate>Mon, 16 May 2011 10:08:01 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1800/</guid>
      <description>装什么系统就要能玩什么，如果你安装的是windows，也需要解决几个最简单的管理工作——文件存放，如何联网，安装软件。不过幸好，用debian的好处是，你暂时不用担心病毒了。
在进行管理工作前，我先说明一个事实。平时你在windows下，可以随便进行的系统管理工作，在debian下面不是谁都能干的。如果linux也像windows那样允许所有用户都修改系统，那早就天下大乱了。为了修改系统关键部分，你需要root权限。如果在命令行下（多数系统管理都是命令行完成的），那么用su-来变成root，或者在执行具体命令的时候在前面加上sudo，如果你已经配置了sudo工具的话。需要特别注意的是，我不建议新手随时都顶着root权限做事，这很危险。在windows下我们很容易修改系统导致出错和崩溃，原因之一就是我们随时都可以拥有系统最高权限。所以，当你需要root权限的时候，开一个root的命令行来管理，不要一直用root命令行做日常工作。
首先是文件存放，这和windows有基础概念区别。windows的文件组织结构继承了DOS的特征，使用A-Z的分区号标示每个物理设备。而linux的文件组织结构继承了unix的特征，所有数据都在一颗单根树下。就是说，系统只有一个根目录。每个物理设备，都被“挂载”在特定的目录下。在windows下，我们把光盘放入光驱，就可以在F盘上面看到一颗目录树。如果在linux下，我们需要将光盘“挂载”在某个目录下。这个目录下的原本内容就消失不见（放心，没有被物理的删除），取而代之的是光盘的目录结构。当然，debian下面通常有自动挂载程序会帮你完成检测到光盘插入后自动挂载的过程。
文件存放的结构也和windows大有不同。windows下的程序安装和文件组织遵循“同包内聚”的结构特征。即是说，只要属于同一个软件，这些文件就被放到一起。大家可以看看programfiles下面一堆堆的目录，每个都属于一个软件。而linux则基于FHS结构，大部分的时候是“功能内聚”，即是说，同类功能的文件被放到一起。例如可执行代码基本放置在/usr/bin和/usr/sbin，前者是普通用户可执行代码，后者是特权用户可执行代码。当你执行ls的时候，其实是调用了/bin/ls。这样的好处是路径设定及其简单，你不信可以对比windows的path设定和linux的path设定。当然，坏处是无法通过直观的文件删除来删除所有包。
这当然不代表debian卸载软件比windows更费力。实际上，是更简单。debian提供了dpkg工具来管理包，和apt工具来管理仓库。你可以很简单的用apt-get install 包名，来安装一个包。用apt-get purge包名来彻底删除包。purge和remove的区别相当于windows中的“是否删除注册表”，如果是purge，是不会保留你自己修改和定制的配置文件的，除非这些数据存在于你的HOME目录下。你可以用aptitude update来追踪系统升级，不过这个不会自动的未你下载最新包。update只是检查服务器上有没有新的包出现，然后通知你，有新东西了。升级是upgrade的事情，不过我建议手工进行升级，具体要多读debian参考手册，也要有几次搞坏系统的准备。
最后一个问题是如何联网。debian是一种很网络化的系统，你的系统升级，使用，都是通过网络的。乃至于我每天用系统的时候，一多半时间都在透过ssh来管理不同的设备。对于这种系统，如何联网是一个很重要的问题。如果你是有线网络，由于不大可能断线，我建议通过/etc/network/interfaces来配置。方法在debian参考手册里面，根据你是dhcp还是static配置好，重启，基本就固定下来不用动了。如果是无线网络，建议直接安装NetworkManager，并且注释掉/etc/network/interfaces中的所有内容。nm的使用很简单，你看着办就好。</description>
    </item>
    
    <item>
      <title>debian中文初学者引导——总论</title>
      <link>http://shell909090.org/blog/archives/1798/</link>
      <pubDate>Fri, 13 May 2011 10:39:45 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1798/</guid>
      <description>上次写了篇debian中文争议问题，结果发现好多人都在搜debian中文，我估计他们对debian中文名没什么兴趣。纯粹想玩玩debian，但是却难于入手。由于此类人中中文使用者居多，对于debian良好的资料无法使用。所以我准备写这篇debian中文初学者引导，来让更多的人可以玩玩这个系统。
在开始玩debian之前，请确定你是适合使用linux的人群。当然，这里并不是说linux只适合程序员。我认识的人里面，使用linux的还有金融工作者，大学教师（非计算机专业），初中学生。他们使用linux完成日常工作，没有什么太大的问题。如果你希望学习linux，首先，你不能是重度游戏爱好者。linux下的游戏无论从数量还是质量，和windows都不在一个级别。其次，你需要一定的英语水准。当然其实不需要太好，贝壳自己连四级都没过。你只需要能认识基础的指令和提示，照抄到网络上即可。如果您是初中未毕业，26个字母尚有困难，建议还是别用了。最后，也是最重要的一点，你需要热爱折腾，总觉得现有软件满足不了自己，但是又没有什么好办法。当然，如果您热爱折腾又有办法，那估计是个程序员。程序员就别废话了，完全没学过linux的程序员不算是完整的程序员。
我的目标是，尽量让你从最简单方式安装一台系统出来，然后普通使用三个月以上，期间基本不用windows。当然，鉴于中国国情，有些网站是永远的IE，所以要用到windows是难免的。实际上，如果你的学习能力不算太差，大约在一周以后，使用linux的不舒服感就会减少，甚至消失，出现问题无法搞定的几率也会降低。大约在一个月后，就会开始自己折腾各种配置。差不多从你开始折腾自己的配置开始，你就会无可救药的爱上linux。
学习linux最重要的几件事情是——合作，创造，懒惰，不满足。
当你学习linux时，最重要的就是和其他人合作，包括看文档和问问题。所以，首先请学会自己查看常见文档，包括man和google，来解决一些简单的问题。例如ls的哪个参数能够列出目录详细信息这种问题就不要问出来。次之，你需要学会《提问的智慧》（http://bbs.csdn.net/IndexPage/SmartQuestion.aspx），请不要问出愚蠢的问题来。其中最愚蠢的就是，为什么linux不能XXX，windows可以。唔，为什么老虎不能拉车呢？驴可以。最后，尽量认识几个linux玩的不错的，又比较有空的人，这对解决你的燃眉之急很有帮助。
作为linux玩家，你必须是懒惰而具有创造力的。通常linux玩家不喜欢太“勤劳”的人。自己辛辛苦苦的在一个文件的所有行头部加上行号是一个很愚蠢的行为——作为一个懒人，你应该想——这个是不是有人做过了，有没有什么比较省力的方法？要能够懒惰，你必须很有创造力。见没见过用光驱不断弹出收入来晃动婴儿床的想法？恩，这家伙很懒，我很欣赏。
作为开始使用linux的基础，请把这个网址（http://www.debian.org/doc/manuals/debian-reference/）收入你的收藏夹。里面说了很多实用的东西，足可引导一个人正常的使用整个系统完成工作。其次，专门准备一台电脑，不用太好，用来安装debian。如果没有，那就用虚拟机。尽量不要多分区混合安装，因为你不会记得去用linux的。现在一台专门的电脑并不贵，一般人家里都有几台很老的电脑，用那个就好，通常还免去了最新硬件无法驱动的烦恼。
如果上面的东西你都看过了，确定自己需要学习使用debian，那么，请慢慢看接下来的文章。</description>
    </item>
    
    <item>
      <title>android常用软件</title>
      <link>http://shell909090.org/blog/archives/1792/</link>
      <pubDate>Fri, 06 May 2011 09:56:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1792/</guid>
      <description>专为职业用户介绍，菜鸟就别看了。
 barnacle wifi tether，将手机变成3G无线路由器，紧急的时候可以拿来让普通笔记本上网。当然，如果你3G带宽或者流量不够，就别考虑了。 comicbricks，漫画阅读器，支持从网络上拖一堆漫画离线慢慢看。 connectbot，功能强大的ssh客户端，支持密钥方式连接服务器，可以做简单的操作。适合在车站，想看看服务器状态的时候用。 es文件浏览器，还算不错，支持ftp和smb方式文件共享。很容易使用windows文件共享进行操作。 gtasks，如果你平时使用google calendar的任务列表管理自己的任务，gtasks就是你需要的东西。 keepassdroid，平时各种密码一大堆，是不是记不住？用keepassdroid，支持linux和windows共享密码文件，记忆一个密码就可以到处用。 openvpn settings，不解释，翻墙必备。倒是自带的pptp客户端连接不上去，很奇怪。 QQ影音，虽说腾讯到处抄，但是QQ影音做的确实不错。功能中规中矩，大部分格式都能放，而且程序体积不大。 realcalc，计算器，不解释。 seesmic，twitter客户端，支持api代理，功能强大，不解释。 sshdroid，ssh服务器端。有了这个东西后，你就不需要连接usb连线并且安装adb这个大家伙了。凡是能操作ssh的机器都能登录操作，支持文件上下传(sftp)，支持密码和密钥。 安全隧道，翻墙必备，不过是走ssh代理的。 大众点评，出门吃饭消费必备。我所知的信息最全的LBS。 静读天下，小型阅读器，可堪一用。体积比ireader小，也没那么多花哨的功能。打开文件的时候有点慢，没有别的缺点。 快图浏览，强烈推荐替代android自己的图库。速度如飞一般，图片瞬间出来。不过仔细看的话，从出来到清晰化大约有一秒的间隔，可见底下还是用模糊运算的。 麦当劳优惠券，打折优惠应用。这类应用都差不多，从网络上下载一段时间的某品牌优惠组合，然后统一显示给你，方便你直接挑合适的组合去。严格来说，麦当劳优惠券不算真的优惠券，只能算优惠组合。当然，有些品牌的产品还是需要看一眼优惠券的，这时候这类应用也提供图片的优惠券。总之，在外面混的时候，带上这个应用，不知道什么时候就有点小折扣。 迷你飞信，不介绍了。比较小巧，消息存储在系统信息里面。和系统自身整合做的不错。 墨迹天气，体积比较大，不过支持多个地区天气，预报比较准（有几个预报误差太大），皮肤不错。 淘宝，什么都不说了，在超市里尤其有用。就是家附近的沃尔玛没信号&amp;hellip;&amp;hellip; 天天动听，播放器，支持网络自动搜索，找封面和歌词。 宜搜小说，自动从网络上找最新的小说来看，追连载的利器。用这个软件连找都不必了，上下班直接看就好。  注意，此处comicbricks和宜搜小说有违反版权的问题，请对版权敏感的人不要用。</description>
    </item>
    
    <item>
      <title>vmware-workstation 7.1.2 source for linux-image 2.6.38</title>
      <link>http://shell909090.org/blog/archives/1781/</link>
      <pubDate>Wed, 20 Apr 2011 09:51:17 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1781/</guid>
      <description>I&amp;rsquo;m running a vmware-workstation under debian testing. Last week I update kernel from 2.6.32 to 2.6.38, then vmware don&amp;rsquo;t work.
Searching for patch with kernel modules, finally I got those.
http://shell909090.org/vmware-source.tar.gz
http://shell909090.org/vmware-7.1.2-2.6.38-1-generic.patch.gz
Source is tested under debian testing, but should work for all dist which use 2.6.38 as kernel. Patch is not tested.
Here is how to make it.
#cd /usr/lib/vmware/modules/source
#for file in *; do tar xvf \$file; done</description>
    </item>
    
    <item>
      <title>论不同系统和客户端的证书管理</title>
      <link>http://shell909090.org/blog/archives/1773/</link>
      <pubDate>Wed, 13 Apr 2011 15:54:41 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1773/</guid>
      <description>上面刚说完x509证书链系统，现在我们说说各种系统和客户端下的证书管理吧。理论上说，系统只要保留一份根证书系统，其余的会自动进行计算。但是杯具的是，不同系统的不同应用，使用的是不同的数据库。这导致你的根证书导入之路漫漫而修远。
windows系统：
1.系统证书管理
在运行中输入certmgr.msc，就可以看到证书管理系统了。根证书管理在“受信任的根证书颁发机构-&amp;gt;证书”下面。对证书文件进行查看，导入，然后导入到这个区域，就可以变成根证书了。要吊销一份证书，删除是不行的，因为会自动加回来。加入“不受信任的证书”好像也无效。我找到的比较实用的方法是右击看属性，“停用这个证书的所有目地”。再试试看？证书应当无效了。
2.firefox
火狐的证书系统是独立于系统证书的，因此在windows中做的修改对firefox无效。需要到“选项-&amp;gt;高级-&amp;gt;加密-&amp;gt;查看证书”中（windows下在工具菜单下），在“证书机构”选项卡，导入证书，而后启用所有用途，让证书生效。如果要吊销，跑到同一个地方，删除证书，或者编辑，取消所有用途。需要注意的是，当你删除证书后，再次查看证书列表时，证书会回来。但是此时编辑证书，可以看到，所有用途都被取消了。
3.chrome
chrome在windows下使用系统证书，因此不要用chrome自身的证书管理系统，直接修改系统证书就可以。
linux系统(debian)：
1.系统证书管理
运行dpkg-reconfigure ca-certificates，会出现让你配置系统证书的界面。这是系统的证书数据库，自动配置的话好像不能添加，只能取消。你反选某个选项后，/etc/ca-certificates.conf中，对应这个选项的行在行首就会出现!。此时系统内就不再认可这份证书。因此推测，如果你需要自己加入一份证书，需要将证书添加到合适位置，编辑/etc/ca-certificates.conf，加入路径，再执行dpkg-reconfigure ca-certificates或者update-ca-certificates进行更新，此时程序会更新/etc/ssl的某些内容，证书就安装上去了。
2.firefox
同样是独立于系统的配置，基本操作和windows差不多，不过linux下面“选项”在“编辑”下面。
3.chrome
linux下面的chrome可以在“首选项-&amp;gt;高级-&amp;gt;证书管理器”中，选择“授权中心”。导入后修改权限即加入。注意需要使用禁用，而非删除对应证书，来阻止某些证书。
这里面说的加入证书，基本是加入自己的证书。至于移除，基本说的是cnnic。cnnic证书有什么危害？目前没有。如果你相信中国的互联网是世界上最开放的互联网，那么下面一堆不看也罢。不过，如果你不相信中国政府颁发出的证书，还是移除的好。在系统内保留一个不受信任的根证书，可能受到证书替换钓鱼。简单来说，你访问一个安全网站的时候，这个网站的证书是如何颁发的，你留心过么？在地址栏网站logo那里右击，查看证书，再找到证书链，你就可以看到，这个证书属于谁，是谁颁发的，这样一个链条。想象一下，你在用gmail的时候，心血来潮看了看域名证书，发现颁发者是CNNIC SSL（google的颁发者是Thawte）。很明显，你访问的网站不是真的gmail，而是一个伪装的网站，将你的请求再转到gmail服务器上。这个网站没有gmail的证书，不过用CNNIC签了一个。于是你的所有请求，收到的邮件内容，发出去的内容，全部被公开了。你也不知道这个替换什么时候进行的，由于安全验证可以通过，系统也没有警告你。是不是有种看到日本恐怖片里面，贞子爬出屏幕的感觉？
当然，这个是一个特例，有点危言耸听。因为对于某些国外CA，证书也是乱发的。基本只要交钱，给一份材料复印件，一样可以通过审查，得到一本CA证书。然而，这种证书通常比较容易被发现，CA也会很快吊销这些证书。如果不是这样，这些CA往往也会被各种系统加入吊销名单。不过对于蓄意产生的CA证书么，就难说的很了。附上一个用于检测CNNIC证书的网站，https://www.enum.cn/。
另一个风险证书则是comodo，早些时候，这个公司被黑客入侵，导致黑客给自己签发了一堆证书。虽然目前这些证书已经被吊销，不过这种安全公司让人一点信任感都没有。最好果断删除。</description>
    </item>
    
    <item>
      <title>twip在LiteSpeed上碰到403问题的解法</title>
      <link>http://shell909090.org/blog/archives/1764/</link>
      <pubDate>Sat, 02 Apr 2011 15:16:09 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1764/</guid>
      <description>这是一个老bug了，具体问题看这里(http://code.google.com/p/twip/issues/detail?id=80 )。
当你使用o模式，到twitter上同意后跳回来，就会撞上403。
不管他，当时你的url应当是http://xxx.com/path/getapi.php?api=http://xxx.com/path/o/username/token。xxx.com是你的域名，path是路径，username是用户名，token是一个随机的数字。
用http://xxx.com/path/o/username/token，直接上去。</description>
    </item>
    
    <item>
      <title>approx无法升级问题的解决</title>
      <link>http://shell909090.org/blog/archives/1749/</link>
      <pubDate>Wed, 23 Mar 2011 09:47:38 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1749/</guid>
      <description>approx最近不知道怎么回事，无法升级。每次aptitude update都无任何升级提示。而直接指向mirrors是可以升级的。
其实，去缓存目录下删除Release和Release.gpg就好了，通常是在/var/cache/approx下面的debian/testing/下面，testing是你的/etc/apt/source.list中指名的发行。</description>
    </item>
    
    <item>
      <title>debian是什么</title>
      <link>http://shell909090.org/blog/archives/1739/</link>
      <pubDate>Sun, 20 Mar 2011 23:19:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1739/</guid>
      <description>debian是一种开源的操作系统，其内核理论上是可变的，主要有linux/freebsd/hurd三种。但是目前为止，主要被采用的都是linux内核，大部分都是基于i386或x86_64编译。
debian系统使用一种被称为deb的打包格式，这种格式中声明了依赖性问题，但是没有解决。所谓依赖，是指一个包内不包含运行所需的所有组件。例如特定版本的lib，辅助配置程序等。将依赖分离有助于多个包共享一份被依赖程序，并且几个组件可以独立升级。windows中通常将依赖包加入安装包内部，但是这样往往不利于被依赖程序的升级。(windows的二进制兼容性做的并不很好)如果没有打入安装包，windows中通常表现为安装一个程序的过程中提示你需要安装某个东西，请去哪里下载。debian的依赖是依靠一套被称为apt的系统解决的。在这套系统中，你可以指定一个源(debian mirror)，或者多个源。apt系统会自动将上面所有软件的目录下载下来供你查阅安装。如果有依赖性问题会自动安装依赖的包。因此，配置好的apt系统相当于一个软件仓库，里面有很多程序。你可以选择其中的一部分，安装使用，而无须忧心安装过程。
apt的更新分为三部分，一部分是这个源中有哪些包，这些包的元信息(meta info)。包括这些包的名字，版本，所依赖程序的版本等。当一个源获得了新的软件的时候，就会更新这个列表，或者叫目录。客户端更新目录后就可以发现，有哪些包需要更新或者下载。而另一部分则是这些包文件本身。最后一部分是以上内容的签名。在元信息上有包文件的校验，而元信息本身则被一个非对称密钥签名。这个签名由apt的管理者签署，从而保证只有受到管理者认可的包会被客户安装，其他恶意插入的包都会被警告。
debian系统默认是没有图形界面的，也没有ssh操作界面，debian的基础系统甚至没有一个可启动的内核。基础系统中只包含了一个文件结构，和被简单配置能够自我管理的apt系统。最精简系统在基础系统之上，安装了内核和引导管理器，从而保证在某个系统上可自启动和自引导。debian的businesscard安装包包含了一个建立其他精简系统所需的所有工具的集合，而netinst安装包则增加了建立最小系统所需的镜像。两者的区别在于，businesscard必须联网以下载最小系统所需的所有安装包，而netinst可以从光盘上获得这些包。
当然，这离一个完整的系统还差很远。作为服务系统，必须安装ssh以便于远程管理。作为桌面系统，需要安装X，WM，还有其他应用程序。甚至，作为网络系统，基础的网络配置组件都是默认不完整安装的。你必须设定网络，设定源，然后更新列表，而后安装合适的程序。这一切对于初学者非常不友好，所以debian还有一种gnome标准安装包，在光盘上放了建立一个标准系统所需的所有包。你可以在不联网的情况下，自动建立起一个标准的桌面。
debian的特性是非常强的自我定制，虽然从根本上说，gentoo的定制方式才是极限。但是长期滚动编译对维护而言是一个非常大的挑战(debian的维护方式都会让很多公司感到不舒服)。debian可以很方便的直接定制一个特制化系统，而跳过编译过程。这对于自己需要一定程度定制的高级linux用户非常有吸引力。</description>
    </item>
    
    <item>
      <title>debian社区争论摘抄</title>
      <link>http://shell909090.org/blog/archives/1731/</link>
      <pubDate>Fri, 18 Mar 2011 21:12:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1731/</guid>
      <description>jobinson &amp;lt;jobinson99@gmail.com&amp;gt;
强烈反对这种所谓的尊重说
1、这是人身攻击，攻击他人人品，不是在认真讨论问题
2、我并没有违规。我的作为，是符合debian维基本身规则的，如果这样你还认为我违反规则，不尊重别人，那么，首先的问题就是你拉大旗扯虎皮，把你的个人观点强加在整个debian社区之上，这才是更大的不尊重社区。
也就是说，在目前维基规则未变的情况下，我并没违规，上面几个认为我不尊重人的人，其实才是真正的违规者。
3、请不要以贡献来论我的对错，这是道德绑架，虽然我对debian目前官方社区的贡献有限，但在其他地方的贡献，请不要在不清楚的情况下肆意抹杀，然后试图以玩道德绑架的方式让我闭嘴。
4、单纯讲翻译问题，debian社区确实太多文档老久了，以至于我都不知道debian中文翻译团队是否活着，这是谁的问题？如果按贡献论，是不是原有社区的人都该被论罪？这显然会激起众怒，如果楼上认为贡献论可行，那么接下来激怒社区的责任楼上要负全责。
5、如果debian是世界性的，那么debian就应该容纳得了中文、英文、德文、日本、西班牙文……，而不是只能使用英文。现在这种情况，连个中文名都起不了，还谈什么世界性，简直就是狭隘英文中心主义。
6、请不要回避问题，老左躲右闪的，以贡献啊、尊重啊、其他更需要啊之类的来搪塞对问题的真正讨论。要不干脆关闭这个讨论，要不就不要躲躲闪闪，认真对待。
还有，就是存在众多莫名其妙的所谓公认规则，结果一认真，才发现不过是个人意见，强加给这个社区的，这样的个人规则，请不要再秀出来，这才是真正对社区其他人的极大不尊重！
其实，我也不想纠结在这些名词上，但如果连这么个名词都容纳不下，我不觉得还能容纳下什么别的东西，我不知道英文社区是否也是如此。
Aron Xu &amp;lt;happyaron.xu@gmail.com&amp;gt;
2011/3/17 jobinson &amp;lt;jobinson99@gmail.com&amp;gt;
&amp;gt;
&amp;gt; 强烈反对这种所谓的尊重说
&amp;gt; 1、这是人身攻击，攻击他人人品，不是在认真讨论问题
也许有些人的话确实说的不怎么恰当，这是说话人的问题，呵呵。
&amp;gt; 2、我并没有违规。我的作为，是符合debian维基本身规则的，如果这样你还认为我违反规则，不尊重别人，那么，首先的问题就是你拉大旗扯虎皮，把你的个人观点强加在整个debian社区之上，这才是更大的不尊重社区。
&amp;gt; 也就是说，在目前维基规则未变的情况下，我并没违规，上面几个认为我不尊重人的人，其实才是真正的违规者。
你的操作没有违反权限（否则没权限你无法编辑），但是违反了在社区活动的一条基本准则：做自己的事不要给别人带来麻烦。现在你私自改了东西就给很多人带来了麻烦。
像项目名称这样重大的决定应该是团队的共同意志，如果你直接不经说明就私自改了，那么你忽略了其他人的意见，这的确是不尊重他人。社区中不是你有权限编辑的地方就可以随意编辑，赋予你权限是对你的信任，相信你能够和其他人好好地合作，共同把项目做好。如果说有了权限就觉得自己什么都可以做，那就辜负了社区对你的信任。
3、请不要以贡献来论我的对错，这是道德绑架，虽然我对debian目前官方社区的贡献有限，但在其他地方的贡献，请不要在不清楚的情况下肆意抹杀，然后试图以玩道德绑架的方式让我闭嘴。
何必把这个问题升级到对与错呢（大家都停止说这个对错，\^_\^）。我觉得只是你做事方法不对，现在不应该在这里讨论这个名字如何如何，而是尊重大家的意见暂时不使用它，并且通过主流媒体做出更正。
昨天我联系 cnbeta.com 等两三个站点删除了文章，LUPA等社区还发了一些更正。希望大家能到 cnbeta 等地方投稿更正这个事情。
4、单纯讲翻译问题，debian社区确实太多文档老久了，以至于我都不知道debian中文翻译团队是否活着，这是谁的问题？如果按贡献论，是不是原有社区的人都该被论罪？这显然会激起众怒，如果楼上认为贡献论可行，那么接下来激怒社区的责任楼上要负全责。
Debian 文档翻译在 Squeeze 周期里没有怎么更新 installation-guide，重译了 maint-guide。网页翻译匆匆地赶出来了一个 release-notes。
如果你要参与，非常欢迎，这个团队现在可以说基本只有个别人做零星贡献。自由软件社区里，每个人都是自由的，行为上第一条是不给别人捣乱，第二条是交接好工作。翻译上一直没人接手，如果谁愿意来可以到这里先询问一下情况——比如你现在问，这个团队是否活着。
5、如果debian是世界性的，那么debian就应该容纳得了中文、英文、德文、日本、西班牙文……，而不是只能使用英文。现在这种情况，连个中文名都起不了，还谈什么世界性，简直就是狭隘英文中心主义。
这种说法有些偏激，和中国中央电视台不能称为CC{T,A}V有一拼了（笑）。当然，Debian和中文名之间并非完全和CCTV那个情况相同。
Debian不是不能有中文名，而是现在还没有让众人觉得确实最好的名称。过去常说的&amp;rdquo;大便&amp;rdquo;显然不雅，&amp;rdquo;蝶变&amp;rdquo;某种意义上讲是个不错的候选，但还是有很大反对的声音。
不管好与不好，想出来的都是&amp;rdquo;候选&amp;rdquo;，不能直接改 Wiki 强迫别人接受你的意志，哪怕你解释说只想做个实验。
这样的实验是不合适的，就好像说某国核电站出了问题，事后说我只想实验它出了问题能有多大影响，这显然不对。
6、请不要回避问题，老左躲右闪的，以贡献啊、尊重啊、其他更需要啊之类的来搪塞对问题的真正讨论。要不干脆关闭这个讨论，要不就不要躲躲闪闪，认真对待。
其实讨论能展开这么久，你回避了最关键的问题。现在是你做得不对，未经讨论滥用了社区赋予的权限，为啥还在说别人呢。
争论的话说多了，谁都可能说出赶劲的话，这时候大家坐下来喝杯茶冷静下，呵呵。
还有，就是存在众多莫名其妙的所谓公认规则，结果一认真，才发现不过是个人意见，强加给这个社区的，这样的个人规则，请不要再秀出来，这才是真正对社区其他人的极大不尊重！
这确实是公认的规则，难道赋予你的权利不是给你的信任吗？如果说，必须要精细地管着你的权限才舒服，那我在这里无话可说。可以随意编辑的分到一类，不可以随意编辑的再分到一类并锁定，我觉得那时候会有人大叫不公平。
其实，我也不想纠结在这些名词上，但如果连这么个名词都容纳不下，我不觉得还能容纳下什么别的东西，我不知道英文社区是否也是如此。
不想纠结就不说这些，赶快把给大家造成的麻烦处理掉。如果你想讨论社区的规则是怎样的，社区怎样才有包容性，再单独发主题，有兴趣的人会愿意和你讨论三百回合。:P
Tao Wang &amp;lt;dancefire@gmail.com&amp;gt;
说你不尊重社区，你还觉得有错了。还什么这论，那主义的，还论罪，我怎么恍惚觉得倒退了几十年，又看到了满眼红色的世界？
真是莫名其妙，看看jobinson都干了些啥：
http://www.udpwork.com/item/4522.html
http://www.freebsdchina.org/forum/topic_51353.html
http://www.freebsdchina.org/forum/topic_51346.html
http://zh.wikipedia.org/w/index.php?title=Debian&amp;amp;diff=15902934&amp;amp;oldid=15830869
http://zh.wikipedia.org/w/index.php?title=Linux&amp;amp;diff=15963993&amp;amp;oldid=15926795</description>
    </item>
    
    <item>
      <title>debian中文名的争议</title>
      <link>http://shell909090.org/blog/archives/1729/</link>
      <pubDate>Tue, 15 Mar 2011 17:31:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1729/</guid>
      <description>最近在debian社区上爆发了关于debian中文名问题的争议，我大致摘录一下，具体可以看debian maillist archive。毕竟这里不是wiki，我就不求全了。
起因是因为Jobinson在社区未达成一致的前提下，将wiki中debian的中文名称改为了&amp;rdquo;蝶变&amp;rdquo;。而后，wenheping告知了LIDaobing。后者是DD。LIDaobing将wiki还原，并且发起了社区讨论。他们之间的原文贴录如下：
(03:37:51 PM) Atlas Jobinson: 我想问你个问题，你是什么时候知道这维基被改的？通过什么途径知道的？ (03:38:01 PM) LI Daobing (李道兵): 很晚 (03:38:11 PM) LI Daobing (李道兵): 因为我没有 subscribe 那个页面 (03:38:22 PM) LI Daobing (李道兵): wenheping 告知的 (03:38:29 PM) Atlas Jobinson: 你可以看看我最早翻译于什么时候 (03:38:37 PM) LI Daobing (李道兵): 看到了 (03:38:40 PM) Atlas Jobinson: 2011-03-04 (03:38:42 PM) LI Daobing (李道兵): 10天前 (03:38:52 PM) Atlas Jobinson: 那说明什么问题？ (03:39:06 PM) LI Daobing (李道兵): 说明你在没有取得社区共识前 (03:39:09 PM) Atlas Jobinson: 还有，那个wenheping，是我在freebsd上得罪他了 (03:39:12 PM) LI Daobing (李道兵): 就修改了 wiki 页 (03:39:23 PM) Atlas Jobinson: 错，说明debian中文的参与者都不关心 (03:39:30 PM) LI Daobing (李道兵): 罗伯特议事法则 (03:39:34 PM) Atlas Jobinson: 连被人改了都不知道 (03:39:38 PM) LI Daobing (李道兵): 不要追究动机 (03:39:47 PM) LI Daobing (李道兵): 我们关心的是 ibus, fcitx, scim 的 bug (03:39:50 PM) LI Daobing (李道兵): 不是这个 (03:40:04 PM) Atlas Jobinson: 是，我也更关心那些 (03:40:27 PM) Atlas Jobinson: 但实际上，这个修改已经过了十天，才有反应，都快两周了 (03:40:35 PM) Atlas Jobinson: 快成既定事实了都 (03:40:44 PM) LI Daobing (李道兵): Debian 的运作不需要 wiki (03:40:45 PM) Atlas Jobinson: 那假设我在其他地方修改呢？ (03:41:05 PM) Atlas Jobinson: 那你还那么看重维基的修改？ (03:41:08 PM) LI Daobing (李道兵): Debian 的核心在于打包人员, DM, DD, ftp-master (03:41:13 PM) Atlas Jobinson: 我知道 (03:41:15 PM) LI Daobing (李道兵): 那是错的 (03:41:17 PM) LI Daobing (李道兵): 我知道了 (03:41:23 PM) LI Daobing (李道兵): 我去纠正他 (03:41:28 PM) LI Daobing (李道兵): 仅仅如此而已 (03:42:02 PM) Atlas Jobinson: 如果两周是个争议期，恐怕这两天我都不会让你安心的，呵呵 (03:42:42 PM) LI Daobing (李道兵): 我真不知道你能跟谁合作 (03:42:53 PM) Atlas Jobinson: 我仅仅是表达意见 (03:43:21 PM) LI Daobing (李道兵): 你为一个社区做贡献是因为你认同这个社区的理念 (03:43:29 PM) Atlas Jobinson: 而且这手段是合理的，并没有在规则外。 (03:43:56 PM) Atlas Jobinson:但谁能说他认同的观点就是该社区的观点呢？比如说debian不需要炒作？ (03:44:03 PM) Atlas Jobinson: 这是光晕效应 (03:44:14 PM) LI Daobing (李道兵):如果你不认同这个社区的理念，个人建议还是创建自己的社区比较好 (03:44:30 PM) Atlas Jobinson:可能你认同其他观点，但这个观点很可能是你个人观点强加给社区的 (03:44:33 PM) LI Daobing (李道兵): 比如在 维基百科 (03:44:55 PM) LI Daobing (李道兵): 如果这个观点有问题，你可以在 maillist 上讨论啊 (03:44:59 PM) LI Daobing (李道兵): 有何不可 (03:44:59 PM) Atlas Jobinson: 因为我没在debian社区中找到这一条 (03:45:14 PM) Atlas Jobinson: 也没人公开宣称这一条 (03:45:21 PM) LI Daobing (李道兵): 如果这个观点有问题，你可以在 maillist 上讨论啊 (03:45:55 PM) Atlas Jobinson: 那么，此条很可能就是你自己过于想当然的想法。 (03:46:08 PM) Atlas Jobinson: 观点是你的，是你应该发起这个讨论，而不是我 (03:46:21 PM) LI Daobing (李道兵): 好的 (03:46:42 PM) LI Daobing (李道兵): 我直接把这些聊天记录发到 maillist 吧 (03:46:46 PM) Atlas Jobinson: 而你不也是没经过讨论就宣称：debian不需要炒作的么？你这不也首先违规在先了？ (03:46:49 PM) LI Daobing (李道兵): 你订阅了 maillist 么？ (03:46:59 PM) Atlas Jobinson: 我刚刚订了 (03:47:02 PM) LI Daobing (李道兵): OK</description>
    </item>
    
    <item>
      <title>linux社区规模估量</title>
      <link>http://shell909090.org/blog/archives/1725/</link>
      <pubDate>Sun, 13 Mar 2011 11:25:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1725/</guid>
      <description>debian是一种重要的linux发行，基于其上有很多衍生，其中最知名的就是ubuntu。debian的包是通过ftp mirrors来进行发布的，因此一个国家的镜像数量，大概能够反映出这个国家debian社区的规模。也大概的，能够说明这个国家开源软件社区的发展。
debian的所有官方镜像有一个列表，具体在这里（http://www.debian.org/mirrors/list）。我利用wget下载了这个镜像，然后写了一个简单的脚本来处理这个文件。文件发布在这里(http://shell909090.org/debmircnt.py)。以下是结果。
United States 48 Germany 32 France 28 Taiwan 13 Australia 12 Japan 11 Great Britain 11 Canada 11 Portugal 9 Italy 9 Russia 8 Sweden 8 Spain 8 Czech Republic 8 Brazil 8 Austria 7 Bulgaria 7 Poland 7 Turkey 7 Netherlands 7 Hungary 5 Greece 5 Ukraine 5 Belgium 5 Thailand 5 Croatia 4 Finland 4 Lithuania 4 South Africa 3 Romania 3 Switzerland 3 Denmark 3 China 3 Korea 3 Slovakia 3 Latvia 2 India 2 Mexico 2 New Zealand 2 Indonesia 2 Chile 2 Slovenia 2 Iceland 2 Belarus 2 Israel 2 Argentina 2 Ireland 2 Nicaragua 1 Colombia 1 Uzbekistan 1 Kazakhstan 1 Estonia 1 Luxembourg 1 Moldova 1 New Caledonia 1 Hong Kong 1 Bosnia and Herzegovina 1 Venezuela 1 El Salvador 1 Singapore 1 Algeria 1 Norway 1 French Polynesia 1 Costa Rica 1 Malta 1 Bangladesh 1 360  这个列表有几个有趣的数据。首先是中国的排名，不算太差，三个镜像，在第30名上下，比香港的一个镜像好多了。不过考虑到香港的人口和中国的人口，让人有点笑不起来。其次是俄罗斯的排名，以8个镜像居于11位。这也不难理解，因为俄罗斯不使用英文，所以在俄罗斯流行的不是常见的英文发行版本。德国比法国多出四个镜像居于第二位，美国是debian的发源地，以48个镜像的惊人数量居于第一。世界全部镜像是360个，光是前三位的镜像数量就占了将近三分之一。台湾地区以13个镜像居于第四，这到让人很是意外，居然比日本还多。</description>
    </item>
    
    <item>
      <title>debian under box</title>
      <link>http://shell909090.org/blog/archives/1719/</link>
      <pubDate>Mon, 07 Mar 2011 09:43:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1719/</guid>
      <description>This is linux tech blog, so&amp;hellip;猫咪和六牙四皂小姐退散。
下面简介一下小型系统组装NAS和服务器的完整攻略。实话说这篇文章写的异常艰难，题目本来叫debian squeeze under EPIA。结果一晃过了一个春节，debian升级了，EPIA挂了。下面前一部分的文章是开始写的，后来发现M10000系列主板只要上sata to ide就会死机，部分IDE硬盘也会死机。所以&amp;hellip;
首先是物理硬件的组成办法。推荐购买VIA EPIA M10000，价格大约在150上下。附带了VIA C3 Eden，只要一条内存就可以工作，非常便宜。不过USB引导有些问题，所以后面用的是其他机器装的Linux，并且给折腾了个半死。贝壳还买了一个小机箱，能够放置3.5&amp;rsquo;硬盘，并且买了1T的硬盘来组装NAS。由于1T的硬盘只有Sata接口，因此还得买一块Sata to IDE，大概是30-40。全部的硬件就是这样，组装起来就可以工作。主板的右下角是主板控制跳线，从左（以CPU和电源所在边为上）到右顺序，引脚如下定义：上排2-3，power sw。上排4-5，reset sw。上排6-7，power led。
首先借助一台大型机，使用USB开始debian系统的安装。另外补充说明一下USB安装debian一文中的一个情况，在boot.img.gz解压开的U盘内复制入netinst也是可以工作的，不一定是businesscard。按照这个估计，复制入完整ISO也是可以的。在分区的时候，贝壳选择了full disk with LVM。/boot分配了228M，最后用了17M。root用LVM中的ext3卷，分配了7G，用了不到1G。全部装好大约有2G吧，安全起见。swap用了2.5G，其实不用这么大，不过我懒得换了。剩下908M，因为1T有一定损耗，还有JS的1000进制算法。。。好吧，全部用ext3放到/home下放数据用。
之所以没用btrfs的原因，一方面是这个是硬盘，不是ssd，也没有高等数据管理要求。另一方面也要求一定的稳定性，btrfs还没有fsck呢。
系统安装并没有什么太大困难，对于熟悉linux系统安装的人，很快就可以完成安装。不过由于是在其他机器上安装，因此注意在迁移后需要修改/etc/udev，把网卡修改为eth0。
下面就是大头了，系统使用grub2引导，但是在booting kernel这里直接挂掉，完全起不来。问过gary后，基本肯定要么是主板坏了，要么是内核坏了。后来我猛然想起，C3是个老CPU了，我用的内核是686内核。改为486内核？顺利引导。
EPIA edin C3 just support i486 Instruction Set, so don&amp;rsquo;t use linux-image-.*-686。
系统启动后，发现速度并不很快。我用samba和windows共享文件，大约只有7M/s的读写速度，消耗了60%的CPU。我使用的是TP-504G+路由器，后面是一个100M的交换机。EPIA是VT6102，10/100M自适应网卡。主机是1G的网卡——不过没任何用。理论上，最高读写速度应该有12M/s的。实际上根据我的测试，瓶颈居然可能在windows上。我在windows复制文件的时候从box上读取数据，居然对复制没有影响的情况下达到了2M的速度。这样的速度远远低于硬盘30M/s的持续读写速率，所以硬盘效率不用顾虑太多，包括碎片问题。
当我发现sata的问题后，使用iozone确认了问题在udma层面上。杯具的是，这问题无解。所以，退了主板换了一块新的。新主板上去后，性能有所升高。硬盘的吞吐到了97M/s，网络共享的读写速度大约是10M/s。其余都很顺利，就不废话了。</description>
    </item>
    
    <item>
      <title>如何建立自己的debian repository</title>
      <link>http://shell909090.org/blog/archives/1710/</link>
      <pubDate>Mon, 28 Feb 2011 16:36:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1710/</guid>
      <description>首先，感谢zigo的大力支持，并且贡献出他的源码，我才得以完成本文。其次，技术文，该散的可以退散了。
很多时候，我们对某些东西比较有兴趣，所以会安装一下。debian系统下最熟悉的安装系统就是dpkg了。作为debian用户，我想用deb包来安装这些东西。这样会有以下的好处：
1.便于在多个系统上重复安装。如果是源码包编译，就必须每台系统安装好环境来configure/make install了。
2.便于拆除。如果是make install，能不能拆就看你的运气了。
3.系统可以管理依赖。包括自动安装缺失的依赖包，以及保持依赖包的固定等。
关于打包，请看debian新维护人员手册（ http://www.debian.org/doc/maint-guide/index.zh-cn.html）。本文主要是说一下如何将这些包变成一个自己的仓库。
变成仓库，你将拥有以下好处。
1.不必自己去复制包，然后手工安装。
2.当仓库更新后，目标机器在update后可以发现。
3.你可以向仓库中加入自己定制编译的，更加新版本的软件。替换掉系统的同名软件，而不改变操作特性（除了没加key会碰到不安全提示）。
其实debian的主系统是一个超级大仓库，通过ftp和rsync同步提供服务。我们的包如果够重要，也会享受到这种待遇。然而debian官方仓库的要求比较严格，你必须在文件级别搞清楚每个文件的授权，并且核对这些授权是否符合dsfg协定。你的包必须足够重要，有可能的潜在用户。多数时候，我们自己写的产品/库还没有这种待遇，因此只有自己做一个仓库了。
zigo提供了他的打包代码，比我的功能全多了，大家可以参考这里（http://git.gplhost.com/gitweb/?p=mgmt-scripts.git;a=blob;f=scripts/scan_archive;h=db7647732b989b35ae7d8a48c80a48ecf67e4612;hb=0ff8fd7d0ba1991d552376f8beca0b46bfaa32e3）。我根据这个脚本，自己实现了一个，放在这里（http://shell909090.3322.org/debian/scan_deb.py）。下面，我简述一下用法和原理。
首先，你需要建立一个pool目录。在其中建立一些release目录。举例来说，wheezy是一种release，testing也是。但是目前testing是wheezy的别名，你用ln -s做链接指向就可以了。在release目录下，你需要建立category目录。例如main是一种category，contrib和non-free也是。
在指定一个deb仓库的时候，release和category是必须指定的，可以被看作是一个仓库地址的一部分。
建立完三级目录后，将你的包放在对应目录下。
全部文件放好后，在根目录下执行python scan_deb.py。如果你需要自动签名，将最后一行的False改为True。在此前请准备好私钥。如果缺少某种架构，请修改脚本architectures一行。
系统的基本原理是，在某个release, category, architecture下，对于pool/release/category目录执行dpkg-scanpackages操作，生成Packages文件到dists目录下，并且再生成一个压缩版本。
对所有目录执行过操作后，使用apt-ftparchive来生成一个Release文件，这个文件指名了有哪些Packages文件，以及他们的MD5各是多少。
客户端获得了Release，就可以知道某种release的特定几个category是否需要更新。更新到了Package，就知道有什么包，他们的meta信息是多少。最后对Release文件进行签名，就可以防止作假了。</description>
    </item>
    
    <item>
      <title>linux下第二声卡的启用</title>
      <link>http://shell909090.org/blog/archives/1706/</link>
      <pubDate>Thu, 24 Feb 2011 11:43:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1706/</guid>
      <description>贝壳用的是debian testing，xfce。最近买了一个usb耳机，在windows下一切正常，但是linux下只有mplayer能工作。因为mplayer可以指定输出声卡，其他程序都是使用默认声卡的。而由于debian移除了alsaconf，因此连调整一下都不知道该怎么做。也许修改/etc/modprobe.d/alsa*可以解决问题，问题是，谁知道哪些资料是神马时候的呢？我最早甚至找到过01年的资料&amp;hellip;
后来，在zigo的建议下，我改用了pulse。zigo在linux下玩音频的，又是DD，怎么也算职业人士，推荐果然很给力。当晚我拿着usb耳机，很顺利的听到了youku视频。那一刻我热泪盈眶，感谢国家，感谢ccav，感谢zigo&amp;hellip;
做法如下：
# aptitude install pulseaudio pavucontrol $ pavucontrol  在输出设备页面，选择你想要的设备为默认。
如果有部分程序还是不认，建立~/.asoundrc或者/etc/asoundrc.conf，内容如下：
pcm.pulse { type pulse } ctl.pulse { type pulse } pcm.!default { type pulse } ctl.!default { type pulse }  完了。
补充一下，pulse的具体资料就不说了。大致上，pulse是一个linux的混音器。用于将多个音源发出的音频流混合成一个音频流播放。严格来说，音频设备属于独占设备，当一个软件发音的时候，其他软件应当不能发音的。这个有点类似于fifo，当两个进程同时打开fifo写数据的时候，目标只能得到碎片。
pulse的作用，是产生一个可以被多次使用的音频设备，类似于unix socket。每一个进程的数据被单独的输入，然后混音，再输出到真实的物理设备上去。由此，多个音源同时发音就变成了可能。
有人也许说，alsa原生也是支持多音源的阿。那是因为alsa内部带了一个很简单的混音器，叫做dmix。当然，pulse比dmix更加专业。</description>
    </item>
    
    <item>
      <title>EPIA主板经常死机问题</title>
      <link>http://shell909090.org/blog/archives/1702/</link>
      <pubDate>Tue, 22 Feb 2011 10:53:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1702/</guid>
      <description>十天死机三次，经过咨询，问题可能在电源或者DMA上。
用iozone来压硬盘，一次没跑完就死机了，问题看来集中在DMA上了。
在BIOS里面把硬盘的高性能模式关掉，再压，两次没死机。
等三天，又死了。
正在换主板。</description>
    </item>
    
    <item>
      <title>linux下使用windows共享打印机打印</title>
      <link>http://shell909090.org/blog/archives/1676/</link>
      <pubDate>Wed, 12 Jan 2011 16:42:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1676/</guid>
      <description>废话不说，上干货，六牙四皂小姐，猫咪退散。
http://www.openprinting.org/printer/HP/HP-LaserJet_1010
这是我的机器型号和驱动
aptitude install cups foomatic-filters smbclient hpijs hplip  访问http://localhost:631/
添加你的设备，并测试。</description>
    </item>
    
    <item>
      <title>linux虚拟化简介</title>
      <link>http://shell909090.org/blog/archives/1670/</link>
      <pubDate>Thu, 06 Jan 2011 10:14:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1670/</guid>
      <description>又是科普文，行家免入。
关于虚拟机的一些比较充分的讲解，可以看这里（http://zh.wikipedia.org/zh-cn/虚拟机比较）。下文是对linux下希望实现虚拟化和被虚拟化的情况提出一些简洁的说明。
1.windows下虚拟出linux。
不在意版权的人可以装个vmware 6.0以上，在意版权的装virtualbox开源版。字符界面通常分配128M内存，512M交换分区。图形界面512M内存，1024M交换分区。硬盘大小视各个发行会有所不同。对于多数工作用的系统，建议使用debian stable安装后升级到testing，稳定好用，最主要是简洁。128M内存512M交换8G的磁盘，足够系统安装和大部分的开发/运行。
2.linux下虚拟windows。
啥都别说，装virtualbox吧。破解vmware是很蛋疼的一件事情，装ESX就更蛋疼了。建议，XP512M内存以上，要稳定使用至少1G。倒是页面文件，只要512M就差不多了。硬盘至少准备16G以上，否则安装程序加运行数据，十有八九会空间不足。
3.linux下虚拟linux。
主要可用方案分为四类，系统虚拟化，半虚拟化，全虚拟化，硬件虚拟化，分别介绍。
4.linux下虚拟一些比较怪的东西。
这是职业玩家了，例如minix，或者freenas。改天写写后者，挺不错的一个创意。
1.全虚拟化
vmware是这种技术的代表。全虚拟化的特征是可以运行完全不同的系统，例如linux下运行windows。virtualbox是开源中做全虚拟化做的比较好的一款软件。当然，即使是全虚拟化，也必须是同一类CPU，例如32位虚拟64位CPU就不给力了。要虚拟不同的CPU，是CPU虚拟化，例如bochs和pearpc。速度大约是真机器的几十分之一，除了调试程序外没别的用途。
全虚拟化比较适合玩玩其他系统，其他可以选用的方案有，vmware，virtualbox，virtual pc，qemu。
2.半虚拟化
Xen是这种技术的代表。通过修改的真机内核和客户机内核来支持虚拟化。优点是效率比全虚拟化高，缺点是客户机必须是可以修改内核的，这将windows排除在外。但是从理论上，可以在linux的xen上运行freebsd系统，两者都是开放内核源码的系统。
半虚拟化技术一般被拿来做VPS比较多，基本没有其他可选用的方案。
3.系统虚拟化
OpenVZ是这种技术的代表。这种技术通过系统内核级别的代码修改来支持虚拟化。优点是效率比半虚拟化更高，缺点是客户机和服务器必须是同一个内核。因此真机和客户机都必须是linux（或者其他相同系统，例如freebsd），但是可以是不同发行（例如真机debian客户机centos），而且客户机不能自由加载内核模块。
系统虚拟化也被用来做VPS，但是这种VPS有强烈的超卖可能，因此不推荐使用。反倒是在同一个公司内，因为某些原因需要将多个程序部署在多台设备上，每台设备所需的资源又不多的时候，比较适合用。其他可选用的方案有jails，vserver，virtuozzo。
4.硬件虚拟化
kvm是这种技术的代表。当然，vmware workstation，virtualbox等也可以支持这种技术。这种技术是未来虚拟化的大趋势。
硬件虚拟化，是使用CPU和其他硬件的特殊设计，辅助虚拟化的进行。通过硬件虚拟化，虚拟机的执行效率往往可以达到和半虚拟化相似甚至超过的地步，而不需要客户系统的特殊配合。从设计理论上说，完整的硬件虚拟化应当可以在客户机上再执行全套的硬件虚拟化，如VM/370。但是目前Intel和AMD的家用CPU系列只支持在真机上创建一系列虚拟机实例，这些虚拟机的内部是不支持硬件虚拟化的。
硬件虚拟化可以用在VPS/机器切分/新系统尝试等各种环境中，其他备选的方案有，vmware workstation，virtualbox，virtual pc，qemu。</description>
    </item>
    
    <item>
      <title>U盘安装debian的技巧</title>
      <link>http://shell909090.org/blog/archives/1646/</link>
      <pubDate>Fri, 10 Dec 2010 10:43:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1646/</guid>
      <description>翻译文，原文看这里。
首先，去一个足够好的镜像（有些二级镜像会没有iso等安装文件的镜像的，具体可以看这里）下载debian/dists/lenny/main/installer-i386/current/images/下面的boot.img.gz文件，然后执行：
zcat boot.img.gz &amp;gt; /dev/sdX  sdX是你的U盘设备。再然后，下一个businesscard文件放到目标盘上，这时候/dev/sdX是一个fat格式的文件系统。重启后，businesscard就会自动运行，如同被刻了一张光盘一样。
简要说一下businesscard，netinst，和完整光盘的区别。businesscard上没有任何安装包，所以你所需的所有安装包必须从网络上抓。这种安装方式下，没有网络就无法安装。netinst上有最小系统所需的安装包，大概100M上下。在无网络的情况下，可以安装出一个字符界面的可联网系统，用于进一步配置。而完整安装光盘把600M多的软件包全打了上去，即使没有网络，你也可以装出一个标准的图形界面可工作系统。2张DVD的那种安装光盘把i386的所有安装包都打了进去，你要装什么都不用上网了。
装大量机器的时候，建议使用businesscard加上缓存代理。</description>
    </item>
    
    <item>
      <title>如何做一个mercurial的http发布</title>
      <link>http://shell909090.org/blog/archives/1618/</link>
      <pubDate>Mon, 22 Nov 2010 09:29:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1618/</guid>
      <description>我假定你了解hg，了解python，理解nginx或者其他cgi/fcgi的配置过程。现在想用http发布自己的mercurial仓库，而且可能发布一群，怎么操作呢？
首先，复制模板文件过来，你可以挑选其中之一。以下是debian的文件位置，其他发布请自行查询。
/usr/share/doc/mercurial-common/examples/hgweb.wsgi /usr/share/doc/mercurial-common/examples/hgweb.fcgi /usr/share/doc/mercurial-common/examples/hgweb.cgi  我使用nginx+fastcgi模式部署，因此复制了hgweb.fcgi。我假定你的仓库在~/hg下面，有很多子仓库。复制hgweb.fcgi到~/hg/下，改名为hgweb.py，并修改以下两行。
config = &amp;quot;/path/to/you/config&amp;quot; WSGIServer(application, bindAddress=&#39;hgweb.sock&#39;).run()  其中bindAddress为你需要监听的unixsocket路径，没有前缀表示在当前目录生成。而后建立配置文件，大概为以下内容。
[web] allow_push = someone push_ssl = false [paths] /hg/proj1=/path/to/proj1 /hg/proj2=/path/to/proj2  以上就完成了hgweb的服务配置，/hg/proj1是你的url映射路径，/path/to/proj1是物理路径。someone是允许进行push的人，而push_ssl是允许http推送。而后，启动服务。
python hgweb.py &amp;amp; chmod 666 hgweb.sock  注意，这里要用screen之类的程序来启动hgweb，否则term关闭后服务进程停止，就没的玩了。修改权限是因为debian下的nginx使用www-data运行，对/home/user/hg没有读写权限，导致无法使用unixsock。
在nginx中做以下配置。
location ^~ /hg/ { limit_except GET { auth_basic &amp;quot;Restricted&amp;quot;; auth_basic_user_file /home/user/hg/users; } fastcgi_pass unix:/home/user/hg/hgweb.sock; include fastcgi_params; }  如果你不需要auth，可以自行参照nginx的配置修改。其他web服务器以此类推。重启服务后，http://domains/hg/proj1 就可以访问到proj1了。
当然，其实最后还要提一句，如果你不需要web界面，可以直接设定将文件内容直接发出去，这样也是可以做pull/push的。
参考： http://mercurial.selenic.com/wiki/PublishingRepositories</description>
    </item>
    
    <item>
      <title>twip在hawkhost上问题的解决</title>
      <link>http://shell909090.org/blog/archives/1604/</link>
      <pubDate>Wed, 03 Nov 2010 17:39:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1604/</guid>
      <description>这两天twip的api不正常，跑上去看看，有个错误。
**Fatal error**: Cannot redeclare class OAuthException in **/home/shellcom/public\_html/apis/include/OAuth.php** on line **8**  这时候，找到include/OAuth.php，改成这样。
#class OAuthException extends Exception { # // pass #}  问题就暂时解决了。
这是因为主机上新装了什么库，这个库自己也定义了OAuthException（会定义这种异常的，估计是OAuth库）。所以，把这个自定义的异常移除，问题就暂时解决了。</description>
    </item>
    
    <item>
      <title>ubuntu release party</title>
      <link>http://shell909090.org/blog/archives/1599/</link>
      <pubDate>Mon, 01 Nov 2010 09:34:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/1599/</guid>
      <description>会开完了，流水帐就不记了，总结几点问题，以后注意。
1.抽奖程序可以当场写，逻辑一定要事先验证。这次抽奖程序的逻辑出现了重大误差，所有值抽完后才去更新命中集合，导致样本空间和总空间相差不大的时候重复中奖。
2.人无任事事不应人。志愿者不知道应该做什么，求助者不知道应该找谁。那天Thomas说他忙不过来，但是其他人又聚堆聊天就是个明证。
看上去找个专门的人进行前台咨询是个很有道理的做法，最好找个MM，问明白求助者的意图后推给合适的志愿者。
3.位置错误。大会上的人基本分成两群，一群是lug里面的，或者在圈子里面的熟人。另一帮则是专门跑过来的新手，还有当地的学生。前者在左侧大门聊天，阻挡后者的视线。大会的基本目地就是增进交流，聚众聊天无可厚非。但是聚集在显示屏前位置很不合适，这主要是因为圈子里的人基本在第一排入座，互相一找就聚在了显示屏前。
这种问题纯是现场场地问题，下次应该找个不干扰的开阔地给圈子里的人扯淡用。
4.秩序混乱。在一等奖领奖的时候，出现了一个人上去拿了东西，发现给错人的状况。
主席还不知道cheng说了一点很要精确的观点，我们没有事先登记。类似大会应当设立前台登记并发放名片卡和编号，这样做有几个好处。首先是组织方获得了潜在的用户名单，其次是大家互相交流的时候比较直接，至少知道对方怎么称呼，最后是抽奖的时候不会出现自行核对号码的难题。这次是按照座位号，没有出现太大混乱只能说受众素质还不算太低，或者我们的奖品他们不感兴趣。否则以中国人的聪明，只要座号相似，大家上去浑水摸鱼主办方也是有口难言。
5.缺乏引导。这个问题最严重，主要是30人的三等奖领取混乱，礼品发放混乱和哄抢。
礼品发放混乱和哄抢和三等奖的领取混乱是类似问题，都是组织者没有合适引导。Thomas认为这是个素质问题，我觉得这应该是组织方问题。任何open party，对应低素质人群是基本预案。中国人的一大毛病是只会听别人口号行事，没人喊口号就不知道该怎么动了。三等奖的时候大家还不错，总算都是从左边上台。虽然情况稍稍有些凌乱，还在可接受的范围内。要是有几个右边上台的，情况就更乱了。而且没人说的话，台上的人也不知道要不要留一下，让下面拍个照什么的，还是直接下去。奖品发放也有类似问题，没人告诉拿奖品的人，奖品数量，怎么排队，怎么退场。就看到半个场子的人一拥而上，Thomas瞬间被淹没了，然后在那里狂喊大家守秩序，有点素质。问题是这时候，谁知道秩序是什么东西呢？通常应当事先告诉拿奖品的，有多少奖品，从右边排队，领取后不要停留，左边快速退场，并且派人规劝。虽然即使这么做了，也不一定保证顺利，但是场面功夫还是要做的。
总结一下几点可改进的要点：
1.事先一定找人发卡片，让用户填写后挂在自己身上。组织方可以自行留录副本。
2.找个专门的，不影响活动的区域给志愿者。
3.找个前台MM，所有问题都找她，她再介绍专家。
4.事先验证抽奖程序的逻辑，这个是我的问题，自行解决。。。
5.除了主持人外，要有适当的人作为台下的协调和引导者。
不过总体来说，这次release party的效果还不错，社区组织发生混乱本来就在意料之中。多来几次组织者有经验就好了。
另外，事后我们集体跑去Thomas(不是台上的鬼鬼小朋友，而是Debian的DD，他的名字是法文，s不发音)家里扯淡吃东西，打德州扑克打到三点。贝壳第一次玩，赢光了其他所有人的钱，哈哈哈哈哈哈哈哈。</description>
    </item>
    
    <item>
      <title>世界上10个最受欢迎的Linux发行</title>
      <link>http://shell909090.org/blog/archives/123/</link>
      <pubDate>Fri, 25 Jun 2010 12:04:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/123/</guid>
      <description>http://blog.sina.com.cn/s/blog_49f7fe790100j0hp.html
个人意见是RHEL(Enterprise use), Debian(Enterprise use), Gentoo(All use), Fedora(Desktop use), Ubuntu(Desktop use), CentOS(Enterprise use), SuSE(Enterprise use), Mandriva, Knoppix, Arch。
按照阵营可以分为Redhat系列(RHEL, Fedora, CentOS, Mandriva), DEB系列(Debian, Ubuntu, Knoppix), Gentoo系列(Gentoo), SuSE系列(SuSE), Arch系列(Arch)。
按照包管理系统可以分为RPM和DEB两大主流系统，Redhat系列和SuSE系列使用RPM，DEB系列使用DEB，Gentoo和Arch是自己的包管理系统。
另外插一句区别。Fedora是Redhat的社区版本，由社区维护，免费使用。当Fedora比较稳定了，就会出RHEL。RHEL是商业版本，由Redhat公司维护，收费的。而CentOS是使用RHEL的源码包（它必须提供）自行重编译的社区版本，和Fedora的区别在于CentOS的稳定度和维护状况更靠近RHEL。Debian和Ubuntu没有关系，Ubuntu使用了Debian的包管理系统不代表他们有关系。Ubuntu有自己的开发/管理计划，通常来说比Debian unstable更加激进，稳定性也不差。不过如果你需要稳定的商业级服务器，还是Debian更加靠谱点。
另外，无论你认为哪个Linux更受欢迎，即使Debian中确实有FreeBSD kernel package，请别把BSD放进最受欢迎的linux发行中来。那个是Unix，Idiot。
&amp;ndash;无能者无所求，饱食而遨游，泛若不系之舟</description>
    </item>
    
    <item>
      <title>小公司在IT上容易犯的几个错误</title>
      <link>http://shell909090.org/blog/archives/115/</link>
      <pubDate>Wed, 19 May 2010 13:25:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/115/</guid>
      <description>很多同学现在自己开公司，或者有开公司的计划。公司都是由小做大的，万事开头难。小公司由于成本和规模的限制，IT上很多问题是不得已的。例如没有自己的网管，没有保密规定等等。然而注意以下几个低级错误，从IT从业人员角度来说，这些是绝不应当发生的低级错误。数数看您那里有几个？
第一，无线不设密码，或使用WEP加密，或公开SSID。
这是任何称职网管的第一禁忌。WEP，公开SSID，相当于弱无线网络。通过嗅探方法，别人很容易获得网络上传递的重要数据。不要以为谁会来关心你的数据，除非你有把握把公司里所有资料晒到网上也没问题，否则还是小心为妙，出问题再补救就太晚了。具体看前面有篇《无线网络安全问题》。
第二，使用hub而非交换机。
技术角度不说了，造成的问题和上文一样。这两个问题，只要请一个称职的网管当顾问，帮你进行一次规划就可以避免。惠而不费，何乐不为。
第三，一个隔间只拉一根网线，或者只有一个电源头。
兄弟，后期搞不好隔间会坐满的。就算没有，万一坏了呢？马上找人修理？起码两个隔间三个插座/网口。一个是方便损坏后替换，同时也方便新添电脑。
第四，雇新手当网管，没有公司内服务器。
相信我，找个靠谱的网管偶尔来几次，其他让行政接手，比找个新手当网管便宜又实用。你需要的是不会出问题，和出了问题能处理的人，而不是价格低廉却在发生问题时手足无措的菜鸟。
同样，让每个员工自己发布共享文件，大家互相访问，打印机在需要的时候搬来搬去。这是最没有管理的公司做的事情。一旦员工多于三人，找台电脑做服务器。共享文件，处理打印，跑个论坛什么的，比扁平而混乱的管理强。
第五，成批购买电脑。
对于大公司而言，一次购买上百台电脑只是公司内的一小部分。如果这些电脑出问题，不会引发大的赔偿问题，也不会造成公司停摆。但是如果一个小公司一次购买同型号的电脑，或者从同一个供应商那里进货太多。那么万一出问题，不说固定资产损耗。公司停摆造成的损失也是惊人的。
第六，弱邮件系统。
如果公司邮箱在发送和接收时没有启用SSL或TLS，会导致员工在其他网络中接受邮件时内容泄密。如果使用webmail，也要注意全过程需要有SSL。最好的办法是让网管尝试嗅探攻击一次，如果拿不到内容，邮件供应商就是过关的。另外，即使电子邮件供应商过关，邮件在传递途中也可能泄密。因此对于极密级的东西，rar加密打包后发送，密码另行传递。
第七，过份信任电子邮件效力。
也许有人不知道，“电子邮件无法篡改”只在公司内被认可，拿着企业电子邮箱和其他公司或离职员工打官司是没有效力的。因此，如果需要无法篡改的内容，请用纸。
第八，太短的员工密钥。
如果您的系统很安全，然而员工设定的密码为1，这等于一个最不安全的系统。因此，强调员工密码的安全性，加上密码设定时弱密钥检查是一个很好的方案。
第九，员工自己持有文档。
文档是企业的重要资产，因此整理和保存文档是公司的责任。让行政部的人跟踪每一个应当保存的文档，不要在员工离职后打电话过去要人帮帮忙看看三年前什么什么文档是否还在。
第十，不分机密级别。
小公司对于机密的规定无法太严格。但除非所有人的机密级别一致，否则一旦区分普通员工和经理，起码将文档划分成涉密和非涉密。不要让普通员工接触涉密文档。
第十一，过分神化IT。
有些小公司过于追求现代化，上班用ERP和OA管理，销售用CRM管理，交流沟通走论坛化。何时采用IT系统管理是一个复杂的问题，但是过早追求IT化会对公司发展造成不利影响。实行IT化是有成本的，仅在你需要的地方进行实施。
第十二，有极密的内容，没有极密的渠道。
回想一下，你们公司的报价是怎么传递给一线员工的？服务器密码呢？公司银行账户呢？对于最高机密的内容，没有合适的传递渠道是不行的。QQ，MSN之类的IM工具机会百分百的会导致泄密，对于嗅探和查看记录他们没有任何抵抗力。短信和电话也是不行的，虽然很困难，但是还是可以窃听的。电子邮件在附件中放一个加密的rar文件，并且提前约定密码，是个很好的方案。</description>
    </item>
    
    <item>
      <title>用android的usb网络共享上网很爽</title>
      <link>http://shell909090.org/blog/archives/111/</link>
      <pubDate>Sat, 10 Apr 2010 15:30:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/111/</guid>
      <description>什么设定都不需要，直接打开usb调试和usb网络共享，然后插上线路。Linux下自动出现了usb网络设备，usb0。然后――没有然后了，随便上网吧。各种分享上网工具可以全扔掉了。</description>
    </item>
    
    <item>
      <title>以nginx作为subversion前端的一些细节</title>
      <link>http://shell909090.org/blog/archives/108/</link>
      <pubDate>Fri, 02 Apr 2010 03:40:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/108/</guid>
      <description>本文系电脑资料，同步到blog上。小黄姐姐不必看了，可以帮我留个言。 nginx性能不错，可惜不支持WebDAV，因此没法拿来作为subversion的http服务。于是考虑开一个nginx作为前端，后端就跑一个apache来作为容器。配置这么写的(节选)： =========/etc/nginx/sites-enabled/default========= server { listen 443; server_name OOXX ssl on; ssl_certificate keys/server.crt; ssl_certificate_key keys/server.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; access_log /var/log/nginx/localhost.access.log; include /etc/nginx/mapping-ssl; error_page 500 502 503 504 /50x.html;
location = /50x.html { root /var/www/nginx-default; } } 打开了一个https的服务，这是当然的，svn传输的数据使用http很危险。 ===========/etc/nginx/mapping-ssl============= location \^~ /svn { proxy_set_header Destination \$http_destination; proxy_pass http://apache_svr; proxy_set_header Host \$host; proxy_set_header X-Real-IP \$remote_addr; proxy_set_header X-Forwarded-Host \$host; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-Server \$host; proxy_set_header X-Forwarded-For</description>
    </item>
    
    <item>
      <title>emacs配置系统</title>
      <link>http://shell909090.org/blog/archives/100/</link>
      <pubDate>Wed, 03 Mar 2010 16:51:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/100/</guid>
      <description>emacs是个超级复杂的程序，尤其在配置问题上。贝壳的emacs要跨越三个环境。环境一，WindowsXP+Emacs23。环境二，Debian Testing + Xfce4。环境三，CentOS + Ssh。而整个的操作方式，个性设定需要保持一致。因此，引出一个问题。配置如何设置，跨平台，同步。
首先解决配置的同步问题，贝壳建立了一个svn仓库，用于存储该配置系统。然后在各个系统中co出这个仓库，当有需要调整时ci就可以保持同步了。Linux下可以使用ln连接文件，Windows下比较麻烦点，NTFS格式(大多都是NTFS格式了吧)可以去sysinternals下一个叫做junction的工具，以建立目录的工具链接，当然，.emacs文件只能手工拷贝了。
然后是配置的切分问题，如果只有一个文件，即使使用了版本控制，意义也不大。同时，将配置切割成不同的部分，控制载入过程，也可以跨平台和加速。以下是贝壳的.emacs文件。
;; .emacs profile, written by shell.xu ;; load other set (add-to-list &#39;load-path &amp;quot;~/.emacs.d/&amp;quot;) (add-to-list &#39;load-path &amp;quot;~/.emacs.d/auto-complete/&amp;quot;) (add-to-list &#39;load-path &amp;quot;~/.emacs.d/plugins/&amp;quot;) (load &amp;quot;emacs-setup&amp;quot;) (load &amp;quot;emacs-redef&amp;quot;) (load &amp;quot;emacs-plugin&amp;quot;) (cond ((not (boundp &#39;initial-window-system)) (load &amp;quot;emacs-console&amp;quot;)) ((memq initial-window-system &#39;(x w32)) (cond ((memq system-type &#39;(windows-nt cygwin)) (load &amp;quot;emacs-win&amp;quot;)) ((memq system-type &#39;(gnu/linux)) (load &amp;quot;emacs-linux&amp;quot;))))) (load &amp;quot;emacs-keymap&amp;quot;)  从上可以看出，我们先设定了.emacs.d作为默认加载路径——大多数文件都是放在这里。plugins是各种第三方程序的安装路径，这样这些程序就无需在各个平台上各自安装一次。而auto-complete单独拆出来纯粹是因为文件太多了。而后，我们加载了setup，这个文件内定义了emacs的基本配置，redef文件内定义了各种自定义函数和变量，plugin内控制了需要加载的各个插件和配置。
下面就有点复杂，简单来说，设定无Windows系统的时候加载emacs-console文件，有Windows的情况下，在windows下加载emacs-win，在linux下加载emacs-linux。这是实现跨平台设置的核心。
最后是keymap，经过上面复杂的设定，按键设置是统一的。
setup文件就不细说了，大家按照自己的习惯设定就好。下面我说几个redef中定义的函数。
(defun switch-windows-buffer () (interactive) (let ((this-buffer (window-buffer))) (switch-to-buffer (window-buffer (next-window (selected-window)))) (switch-to-buffer-other-window this-buffer) (other-window 1)))  这个函数的目标是用热键交换两个窗口的位置。如果你经常用C-x 3分栏，并且在两者间跳来跳去的话，有的时候往往希望两者的位置换一下。通常都是C-x b切换当前的窗口，然后C-x o切到隔壁去再换。这个太繁琐了。</description>
    </item>
    
    <item>
      <title>android历史记录备份和应用三例</title>
      <link>http://shell909090.org/blog/archives/99/</link>
      <pubDate>Tue, 02 Mar 2010 16:10:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/99/</guid>
      <description>有不少不折腾会死星人已经用上andriod了吧？有没有刷机过？有没有怕手机掉过？android的联系人是同步到gmail的，不用怕。但是信息就不同不了。所以，下面介绍几个信息导出的方法。
1.aqq
用adb shell去/data/data/com.android.aqq/databases/下面，把aqq.db复制出来，sqlite3格式，随便看吧。
2.AnFetion
用adb shell去/data/data/&amp;hellip;..AnFetion2/databases/下面，把fetion.DB复制出来。
3.信息
这个是最麻烦的。去信息-&amp;gt;Menu-&amp;gt;设置-&amp;gt;导出短信里面导出。但是别高兴的太早，贝壳发现一个bug。如果你的短信里面有西文引号，会导致xml格式错误，从而无法导入。解决方法是手工删除引号。
应用，使用xsltproc，将xml转换为html来浏览。贝壳用的xslt比较简单，抄在下面。
&amp;lt;?xml version=&#39;1.0&#39; encoding=&amp;quot;GBK&amp;quot;?&amp;gt; &amp;lt;xsl:stylesheet version=&amp;quot;1.0&amp;quot; xmlns:xsl=&amp;quot;&amp;lt;http://www.w3.org/1999/XSL/Transform&amp;gt;&amp;quot;&amp;gt; &amp;lt;xsl:template match=&amp;quot;/&amp;quot;&amp;gt; &amp;lt;html&amp;gt; &amp;lt;body&amp;gt; &amp;lt;xsl:for-each select=&amp;quot;//smss/address&amp;quot;&amp;gt; Phone Number:&amp;lt;xsl:value-of select=&amp;quot;@data&amp;quot;/&amp;gt; &amp;lt;br/&amp;gt; &amp;lt;table border=&amp;quot;0&amp;quot; class=&amp;quot;rev_tab&amp;quot; width=&amp;quot;100%&amp;quot;&amp;gt; &amp;lt;xsl:for-each select=&amp;quot;sms&amp;quot;&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td class=&amp;quot;rev_tab_rev&amp;quot;&amp;gt; &amp;lt;xsl:value-of select=&amp;quot;date/@data&amp;quot;/&amp;gt; &amp;lt;/td&amp;gt; &amp;lt;td class=&amp;quot;rev_tab_rev&amp;quot;&amp;gt; &amp;lt;xsl:choose&amp;gt; &amp;lt;xsl:when test=&amp;quot;read/@data = 1&amp;quot;&amp;gt;read&amp;lt;/xsl:when&amp;gt; &amp;lt;xsl:when test=&amp;quot;read/@data = 0&amp;quot;&amp;gt;unread&amp;lt;/xsl:when&amp;gt; &amp;lt;/xsl:choose&amp;gt; &amp;lt;/td&amp;gt; &amp;lt;td class=&amp;quot;rev_tab_rev&amp;quot;&amp;gt; &amp;lt;xsl:value-of select=&amp;quot;body/@data&amp;quot;/&amp;gt; &amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;/xsl:for-each&amp;gt; &amp;lt;/table&amp;gt; &amp;lt;BR/&amp;gt; &amp;lt;/xsl:for-each&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; &amp;lt;/xsl:template&amp;gt; &amp;lt;/xsl:stylesheet&amp;gt;  为了美观，你还可以修改一下xslt。xsltproc在linux下直接有包，Windows可以来信问贝壳索要移植(其实去官网上就能下到)。</description>
    </item>
    
    <item>
      <title>ext3下小文件的恢复</title>
      <link>http://shell909090.org/blog/archives/94/</link>
      <pubDate>Sun, 21 Feb 2010 10:20:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/94/</guid>
      <description>ext3下如果误删除了文件，恢复起来是异常麻烦的。如果是小文件，其实很多时候不用走常规文件恢复的路子，只要能找到内容就好了。基本思路是从磁盘中直接搜索内容，然后设法复制出来。
恢复条件：
 文件没有被覆盖。如果被覆盖了，那就绝对没有希望了。 文件不大(通常建议在16K以内)。如果很大，下面一个条件就很难满足。 知晓文件内的特定关键字。条件是，文件每4K内，你必须知道至少一个关键字。因为ext3通常将4K内容连续存放，每知道一个关键字，可以恢复4K内容。如果缺少关键字，那就无法恢复了。 文件保存的版本不太多。  满足以上条件后，使用以下方法进行恢复：
# grep -abn &amp;quot;id_insert_stmt_param&amp;quot; /dev/xvda1 4799010:713068605:sql_id_insert_stmt_param = &amp;quot;SELECT NEXTVAL  使用grep对/dev/xvda1磁盘进行搜索，需要管理员权限直接访问设备文件，搜索哪个物理磁盘可以用mount来确定。 713068605是相对偏移地址，如果保存了多个版本，可能有多个偏移地址。 他们的选择和确定是个非常麻烦的问题，所以文件保存的版本不能过多。
$ python &amp;gt;&amp;gt;&amp;gt; (713068605/4096)*4096 713068544 &amp;gt;&amp;gt;&amp;gt; exit ()  以上过程可以在常规权限下操作，使用python(或者其他你高兴的计算器)确定该偏移地址的块首地址。
# dd if=/dev/xvda1 bs=1 count=4k skip=713068544 &amp;gt; 1.tmp  将这个块的内容复制出来，注意磁盘上必须有足够空间，否则搞不好会将原始内容覆盖。
更严谨的方法是将内容dump到其他磁盘设备的挂载点下，做异地磁盘恢复。
以上方法可以恢复一个块的内容。手工恢复所有块后，将内容拼接，就是你要恢复的文件。</description>
    </item>
    
    <item>
      <title>一个远程下载verycd的小技巧</title>
      <link>http://shell909090.org/blog/archives/89/</link>
      <pubDate>Fri, 29 Jan 2010 15:59:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/89/</guid>
      <description>贝壳家里开了emule，天天下载，问题是又不能每次都是晚上添加资源。
怎么办呢？不知道大家知道不知道，emule是可以网络管理的，端口是4711。不过不是https，密码容易泄露。而且贝壳已经有一个nginx服务器了，也懒的再做端口映射，换端口。于是，在nginx中做如下设定。(当然，贝壳是放在https段中的)
location ^~ /emule/ { rewrite ^/emule/(.*)$ /$1 break; proxy_pass &amp;lt;http://hostip:4711&amp;gt;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }  然后，用https://dynname/emule/就可以访问你家里的emule了，记得密码设强点。
接下来，verycd里面曾经有复制所有连接的选项，现在没了。面对几个链接，也就手工复制一下，面对上百个连接，贝壳就无语了。贝壳试验过几个插件，都无法正确识别ed2k的链接获取。那怎么办呢？这时就要请出我们伟大的Linux。
需要准备的工具是lynx，请预先装好，然后如下操作。(范例是个动画^_^)
wget -c &amp;lt;http://www.verycd.com/topics/2779234/&amp;gt; lynx -dump -listonly index.html | grep &amp;quot;ed2k://&amp;quot; | sed &amp;quot;s/.*ed2k/ed2k/g&amp;quot; | grep -v BIG5 &amp;gt; out.txt wc -l out.txt  lynx的-dump选项是将某个网页全部渲染成文本进行展示，这是html2text的好方法，效果还不错哦，不过中文支持好像不是很好。而-listonly则是展示出页面上的所有链接，这就拿到了我们需要的原始数据。
然后，我们取其中的ed2k行，忽略其他链接，再通过sed转换，去除头部的编号和空格，这样就可以得到所有的ed2k链接。
我在下面是用-v BIG5的参数，忽略了其中繁体中文的资源，然后输出到一个文件中。数数行数，52行，大致和文件个数相当(其中好像有两个v2)。那就是可用资源了，复制到emule的控制页面中——出错？
这是因为emule的控制页面使用GET方式传递参数，因此有长度限制。你需要将链接10个一批往里面复制——有个几次就OK了。当然，如果还是多，贝壳回头会写一篇文章，介绍如何使用curl自动干这事情——这还不算太难。
这就是为啥贝壳喜欢Linux的原因了。相比Windows下的两个解决方案，找插件太费劲，自己写程序更费劲。Linux使用现有工具的组合可以轻松完成这一任务。</description>
    </item>
    
    <item>
      <title>手工删除oracle数据库实例的全部文件</title>
      <link>http://shell909090.org/blog/archives/85/</link>
      <pubDate>Mon, 11 Jan 2010 00:37:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/85/</guid>
      <description>今天公司搬家，没啥好写的，简单记录一下前两天删除重建oracle数据库的过程吧。
首先，我重建的是oracle数据库，而不是oracle数据库程序。这几天不知道怎么回事，整个数据库的redo log出问题了，我又懒得去找。加上这个数据库做演示的时候乱糟糟的配置做了一堆，也记不请了，干脆重建。
重建的第一步，需要找到所有程序实例的位置，这个可以看/etc/oraInv什么的一个文件，这里会指向一个目录。这个目录是标准的，里面有各种格式的oracle程序实例的位置。然后，一个程序实例可以运行多个数据库实例，因此，要找出这些数据库实例的配置文件。这个就需要对oracle的数据库基本结构有所了解，这里不赘述oracle数据库的各种基本概念。
oracle的数据库配置文件在一个很怪的位置，/etc/oratab里面。其中有SID到spfile路径的对应关系，通常而言，这个路径位于$ORACLE_HOME/dbs/init$ORACLE_SID。我们首先不要删除这个对应关系和文件，因为启动中其他文件需要通过这个找到。我们首先通过spfile建立pfile，来读取其中的参数。
$ export SID=orcl $ sqlplus / as sysdba &amp;gt; create pfile from spfile &amp;gt; exit  OK，这样我们就建立了pfile，现在可以删除$ORACLE_HOME/dbs目录下所有的SID相关的文件，并且删除oratab中的对应关系。完成这步后，数据库就无法启动，也不存在了。但是我们还需要回首数据库相关的文件，主要是收回空间，同时也免除后患。
首先，数据库有三个control files，还有一个到多个data files，以及多个redo log。在默认设置中，这些文件一般放在一起，你可以通过查看pfile确认这些文件的路径。找到之后，直接删除，没啥好多说的。在完成数据基础文件的删除后，我们还需要删除flash_recovery文件，这个也可以通过pfile确认，位置一般在data文件上两级(就是通常$ORACLE_BASE的位置)下面，flash什么的一个目录，很好找。
最后，我们删除admin目录，具体是在$ORACLE_BASE下面的admin下面，以SID命名的，可以通过pfile确认。至此，oracle数据库的删除完成。不过呢——呵呵——让大家失望的是，其实DBCA也可以完成一样的工作&amp;hellip;
不过，dbca的工作必须通过vnc，绝对不要通过ssh + xming，因为那个会让最后一步执行前的确认无法被确认，导致不能执行。实在是很让人郁闷的一个bug，切记切记。</description>
    </item>
    
    <item>
      <title>软件自由英雄谱</title>
      <link>http://shell909090.org/blog/archives/78/</link>
      <pubDate>Mon, 14 Sep 2009 13:53:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/78/</guid>
      <description>谨以此缅怀那些为了今日软件事业的自由做出贡献的先辈们。(注1:多数人没牺牲，谢谢)(注2: 排名不分先后)(注3: 科普作品，大家别怕)
我在撰写这篇文章的时候，避免使用自由软件这个词，而改为更普遍意义上的软件自由。因为自由软件是RMS提出的一个专有词语，指软件的开源，复制，协作等
特质。而我试图通过软件自由这个词，表达人们在使用软件上的自由，以及使用软件来为我们获取自由。我们拥有知道软件一切内幕的自由，我们拥有修改软件的自由，我们拥有思考的自由，我们拥有挑战老系统的自由，我们拥有拒绝通过软件收费的自由，我们拥有通过软件获得信息的自由，我们拥有不受任何人，包括政府监控的自由。为了这种自由而付出的，不仅是自由程序的拥护者，也有商业程序的拥护者。
 Richard Matthew Stallman  大名鼎鼎的RMS，GNU的核心人物，自由软件的布道者。要是在这个列表上没有他的名字，那我不知道还有谁能留在这张表上。具体可以看这里(http://zh.wikipedia.org/zh-cn/%E7%90%86%E6%9F%A5%E5%BE%B7%C2%B7%E6%96%AF%E6%89%98%E6%9B%BC)。简单来说这家伙最大的几个成就：创立了GNU和FSF，为自由软件的传播奠定了基础。制作了emacs，当今黑客世界两大编辑器之一(另一个是VIM)。制作了GCC，世界上使用最广泛的编译器。
RMS的核心想法是，因为软件而收费是罪恶的，这种人是撒旦(当然，Bill Gates是其中最大的那个)。他认为软件应当自由分享，程序员从中收取的应当是服务费。今天，RedHat正是继承了这一模式。通过免费的软件和收费的服务来进行持续的开发。
2.Linus Benedict Torvalds
常常和RMS并提的一个家伙，具体在这里(http://zh.wikipedia.org/zh-cn/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%89%98%E7%93%A6%E5%85%B9)。
一个低调又火爆的家伙，没有什么太多言论，但经常语出惊人，最有名的是以“一群自慰的猴子”(OpenBSD crowd is a bunch of masturbating monkeys)来形容OpenBSD的团队。最大的成就就是写了个操作系统——没错，就是叫Linux的那个。
3.Donald Ervin Knuth
哈，这个人就不像上两个那么广为人知了。他(可不能叫这家伙，得敬老)有个中文名字，叫高德纳，页面在这里(http://zh.wikipedia.org/zh-cn/%E9%AB%98%E5%BE%B7%E7%BA%B3)。
最大的成就是写了本书，叫做《计算机程序设计艺术》。有意思的是，写到一半的时候，觉得现在(那是上世纪80年代的事情)的排版软件不爽——于是自己下手，写了一个叫做Tex的排版系统——然后再回来继续写书。这本书算起来已经写了30多年了，估计成书时间和《浮士德》有的一拼。而Tex是当今高端排版中最流行的系统(多数都不是直接拿来用，而是用了LaTex之类的包装)，如果有向国际期刊投稿过的应该有印象。Tex也是被誉为最接近完美的程序，它的介绍在这里(http://zh.wikipedia.org/zh-cn/TeX)。%E3%80%82)他的版本号是以圆周率为基准的，头一个版本叫3，后一个叫3.1，以此类推。目前的版本号是3.1415926，刚好是祖冲之的密率。高伯伯曾表示，等他死之后，版本号就改为π，剩下的bug就作为程序的功能放在那里。
有一个未经证实的故事。据说上世纪Internet还没出现的时候，美国军方找人设计了TCP/IP协议，他们希望有人为他们实现基于Unix的TCP/IP协议栈。于是他们花了四千万美金，找人写了一个协议栈，并且拿到高伯伯的学校去用。对此高伯伯非常不满意——别误会，我指的是实现的效果。于是就自己花了点时间写了一个，结果比原版的协议栈更快速而稳定。美国军方觉得非常困惑，问他是怎么做的。高伯伯说，读你们的协议，然后编码。
4.Andrew Stuart Tanenbaum
这个知道的人也不会太多，当然，职业玩家例外。当初AT&amp;amp;T禁止UNIX7的代码公布，因此大学里面都没什么实际产品可以用来教操作系统这门课。
于是，有个叫AST的老师就怒了，你不让我干，我自己干。于是写了一个叫做Minix的系统，并且还写了本书，叫做《操作系统：设计和实现》。后来有个学生，觉得这个系统改改能干别的，于是给AST去信。AST说，改什么改，我写这东西是拿来教书的。于是这个学生就自己写了一个系统——对了，这个学生就是上面的Linus，而那个系统，就是大名鼎鼎的Linux。
时至今日，Minux已经发展到了第三版(他的版本号是跟着书走的，第一版，第二版，第三版&amp;hellip;)，是大多数大学里面教授操作系统基础原理的标准教材。
同时，也在嵌入式系统等领域有非常大的应用。但是，由于AST还是坚持他的教学和精简原则，因此在桌面和服务器领域就别指望了。关于AST，大家可以看这里(http://en.wikipedia.org/wiki/Andrew_S._Tanenbaum)。
5.Ian Murdock
这个人很多人都听过，不过看着名字还是认不出来。他是Debian系统的作者，具体可以看这里(http://en.wikipedia.org/wiki/Ian_Murdock)。
Debian有什么特殊呢？其实就本身来说，Debian并不算特别成功。但是Debian有庞大的衍生系统群，更有Ubuntu这样充满活力的发行。
Linux世界有所谓三大发行，四大包管理系统之说。其中三大发行指三个在世界上最广泛用于服务器的发行版本，即RedHat Enterprise Linux，SuSe，Debian，其中只有Debian是无服务商支持的。而四大包管理系统就是指RH的RPM系统，Debian的APT系统，arch的PCMAN系统，和Gentoo的emerge系统。
6.Ken Thompson
有没有听说过？至少看着眼熟吧。这家伙是贝尔实验室的，最大成就就一个：Unix作者。详细内容请看这里(http://en.wikipedia.org/wiki/Ken_Thompson)。
7.Dennis Ritchie
没听说过？也很眼熟？这家伙和上面那位是朋友，最大成就也就一个：给上面那位提供了基础语言，C语言。详细内容请看这里(http://en.wikipedia.org/wiki/Dennis_Ritchie)。
8.Bjarne Stroustrup
又是一个怎么看怎么眼熟的家伙？那当然。他和上面两位不怎么熟，不过他们都是一路的。他是C++的作者，详细内容请看这里(http://en.wikipedia.org/wiki/Bjarne_Stroustrup)。
9.Phil Katz
这个就很少有人知道了吧，不过大家肯定天天和他打交道。大家用记事本打开任意一个ZIP文件，开始的两个字肯定是PK，这就是Phil Katz，具体请看这里(http://en.wikipedia.org/wiki/Phil_Katz)。
这是一个有点悲剧的人物。在上个世纪的时候，大家还在BBS上混。由于速度有限，因此下载站的资源都是压缩提供的(当然，直到今天肯定还是如此)。最初的压缩格式大多是ACE的，这是一家商业公司，直到今天还活着。由于PK不满意这家公司的压缩软件，压缩率低，速度慢，而且还不断提出高昂的收费。因此他决定自己写一个压缩软件，就是最初的PKZIP。由于软件免费提供使用，压缩率高，解压速度快，因此很多站长自发的将数据格式转换为ZIP。后来PK就干脆开了PKWARE软件公司，免费发行压缩程序代码，同时提供方便使用的图形界面版本。
但是非常可悲的，由于格式开放，因此这个软件有个非常大的竞争者，winzip。我想有些Win95时代的老用户还记得这个软件。PK在软件开发上很有天分，但是在市场策略上却不很成功。WinZip对ZIP格式的熟悉其实比不上PK(那当然，人家是原作者)，然而WinZip却拥有很多用户友好的特性，右键菜单解压，虚拟解压(将压缩包的内容临时虚拟成一个目录，用户可以无缝的使用，XP中集成了这个功能，但是WinZip的虚拟解压很容易撤销)。所以最终PK的软件公司破产了。他本人在2000年4月14日因饮酒过度，在一家小旅馆内死去。
至于WinZip呢？碰到了一个更强大的对手，WinRar。功能类似，但更简洁，最主要是支持大多数流行的压缩格式。因此目前压缩软件领域还是WinRar占据着主流，市场就是这么残酷。
10.Phil Zimmermann
这个人基本没人知道，但是却是这张表里面最典型和突出的一个人。他是PGP的作者，具体可以看这里(http://en.wikipedia.org/wiki/Philip_Zimmermann)。他的成就很难用一句话说明，要阐明他的成就，就必须从美国的国家安全出口管制说起。
在上个世纪，美国政府有一种观点，他们需要能随时随地的窃听任何一个人和其他人的通讯。同时，作为延伸，他们制定了国家安全出口法案，将密码产品作为军用管制品，限制出口。这其实是很荒谬和不合逻辑的，任何公开的算法都可以被多个人独立的实现。只要算法是公开的，即使产品不允许出口，国外也可以没有任何阻碍的实现出来。而如果算法是不公开的，则会出现两个弊端。一个是阻碍密码学的交流和进步，更麻烦的是，根据密码学的内在逻辑，这样的系统，由于验证不完全，因此比公开的系统更加不安全。
在1991年前后，PZ制作了PGP软件，用于保障当时备受争议的电子邮件的安全(小常识:电子邮件默认是明文的，安全程度和你写在明信片背面寄给你父母的句子差不多)。这个软件使用了1980年以来提出的现代密码系统几大密码系统，实现了签名安全和秘密安全。这里我们小小的讲解一下电子邮件的两大安全系统，对此无爱的人自行跳到下一段。签名安全就是指，你收到一个邮件的时候，能够确信，这个信的内容是原始发件人的真实意思表示，而不是被篡改过的。秘密安全就是指，当你收到一个信的时候，你能够确信，除了你没有别人能够偷看到内容。对此，一般采用公钥系统来实现两者的安全。所谓公钥系统是这样一种系统，用公钥加密必须用私钥解密，用私钥加密必须用公钥解密，私钥很容易计算出公钥，公钥非常难计算出私钥。当你要签名安全的时候，将邮件内容用自己的私钥加密再发送一次(实际是将内容hash了再加密的)，接收者解密后对比。由于篡改者只有公钥，因此虽然可以拦截和修改内容，但是无法伪造出一对匹配的内容，用公钥解密后刚好一致。而秘密安全则是用对方的公钥加密。对于更高层级的要求，你的公钥不仅要求公布，而且必须在国家认可的部门公布，这样就由国家认定了你的公钥和你的身份的一致性。当你对一个内容签署的时候，只要能用公钥验证签名，就可以认定内容是你的真实意思表述，并被法律所承认。
当时的PGP当然还没有这么复杂，但是对于当时缺乏任何安全性特征(当时连TLS都没有)的电子邮件来说，是非常必要的补充。可是我们上文说了，美国禁止出口这些产品。于是，PZ免费的将软件的最初版本散发给同事和其他人使用，而这些人又可以免费的分发出去——这和自由模式非常的吻合，除了我找不到具体信息标明当时PZ是否从授权上同意他们做这个事情。法律上说，PZ并没有“出口”密码产品，但是实际上，是他实现并且向全世界推广了高强度的电子邮件安全系统。从某种意义上说，PZ可以说是叛国者。非法散布军用管制品，危害美国的国家安全(这还不像中国那种含糊不清的指控，这里的军用管制品定义是明确的，并且是由国会制定的)。于是，PZ受到了三年的官司和五年的调查，直到96年的时候，克林顿签署了新的法案，放松了密码产品的出口限制。其实也没松多少，从40位到56位——大概就是从5个字符到7个字符的区别。反之，我们改变观点，从世界的角度说，由于他的勇气和决心，我们每个人从中受益匪浅。
EDIT 2016-09-08: 按照我听到的更新消息，PZ当时实际上是出版了一本书，这个书里面就是完整的源码。他虽然没有“出口”这些源码，但是实际上任何人都可以在书店里买一本，然后带去海外，照着源码keyin一遍。美国政府虽然希望禁止这本书的出版，但是禁止个人出版图书违反宪法第一修正案——言论自由。当时政府还不能因为国家安全因素就随意禁止公民出版书籍（这都是911之后的事了），所以只能用官司和调查来整PZ。</description>
    </item>
    
    <item>
      <title>搭建家用的OpenVPN服务器</title>
      <link>http://shell909090.org/blog/archives/76/</link>
      <pubDate>Fri, 04 Sep 2009 14:50:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/76/</guid>
      <description>啥都不说了，贝壳最近搞了一个家用的OpenVPN服务器，任何机器，随时随地可以穿到家里来，很方便。用VPN干啥？这就多了。我可以用vpn操作 Windows上的vnc，使用Windows的共享文件服务，直接向Linux Server放文件(这样别人可以用http下载)，查看摄像头(被网络公布了)。将来如果有其他网络设备(例如冰箱和空调)，也可以一并管理。不过最直 观的——可以很方便的打游戏，我们根本就在一个网络里面。要点是，这些服务要分别开映射端口非常麻烦。而且有的服务从安全起见，根本不能开端口(例如臭名 昭著的Windows文件共享服务)。 具体原理上，贝壳有一台Windows，上面用Vmware搭建了一台Debian Linux，两者使用桥接模式。从概念上看，就是一台通向公网的路由器，里面放了一台Windows和一台Linux。现在，贝壳想通过某种方法，将外部 的一台机器接入内部的局域网中，就如同随身携带着一根通向家里路由器的网线一样。 下面直接上具体配置： &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;filename: /etc/network/interface&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- auto lo iface lo inet loopback iface eth0 inet static address 0.0.0.0 iface tap0 inet static address 0.0.0.0 auto br0 iface br0 inet static bridge_ports eth0 tap0 address 192.168.1.IP netmask 255.255.255.0 network 192.168.1.0 broadcast 192.168.1.255 gateway 192.168.1.1 dns-nameservers 192.168.1.1 dns-search home &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- 使用上述配置的原因是，vpn只能联通你机器上的逻辑网卡和服务器上的逻辑网卡。单就vpn自身而言，是无法让你连到服务器上的内网网卡的。因此，我们需要通过网桥的配置，将eth0和tap0配置成网桥。这样，你的服务器就如同一台交换机一般，联通了两个网段。 而后，我们设定服务器配置。 &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;filename: /etc/openvpn/server.conf&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- local 192.168.1.51 port 1194 proto udp dev tap0 ca /etc/openvpn/keys/ca.crt cert /etc/openvpn/keys/server.crt key /etc/openvpn/keys/server.</description>
    </item>
    
    <item>
      <title>组合翻墙方案</title>
      <link>http://shell909090.org/blog/archives/74/</link>
      <pubDate>Wed, 29 Jul 2009 11:44:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/74/</guid>
      <description>1.墙的存在和原理简述 1.1.墙的存在 在您访问某些网站的时候，经常会发现无法访问。通常来说，这是服务器挂了。但是现在，越来越多正常的服务器出现了无法访问的情况。这些服务器中有一些是因为色情和暴力问题，但是更多则是政治层面的因素，例如google和twitter。对于用户来说，可能不关心政治层面的因素。但是政治自然的关心了你，所以我们需要找一种方法，让我们依然能够使用网络上一些很重要的服务。例如gmail(本文即是在gmail中写成的)。本节中，我将简述国家网络防护工程(简称GFW, Great FireWall)的工作原理，并在下一节给出一些比较成熟的翻墙方案。 1.2.DNS污染 我们通过DNS(Domain Name Service)将域名转换为IP地址。通常而言，我们不会怀疑ISP的DNS服务器的可信性。然而在某些地方，DNS服务器被用来欺骗客户端，达到屏蔽的作用。例如，在上海的某些地方，fanfou.com曾经被指向127.0.0.1。如果机器按照这个地址访问，那么肯定无法获得预想的数据。 这个方案如果控制不当，可能造成全球性的后果。曾经有报道，伊朗将youtube的域名指向了自己的一台蜜罐(Honeypot)服务器。但是由于配置不良，因此DNS错误被扩散到了伊朗以外，导致全世界的youtube访问都被定向到了这台蜜罐。整个过程造成了youtube6小时以上的服务中断。 1.3.DNS替换欺骗 由于DNS污染会被下面2.1节的方法绕过，因此在某些地方针对OpenDNS的数据被进行了替换欺骗。UDP53端口的查询数据包被拦截和替换，其造成的结果就是即使使用了OpenDNS，返回结果和电信服务器的结果仍然一致。 1.4.IP禁止 对于某些IP，防护系统直接禁止了该IP的访问。这种手法一般见于早期，由于经常导致误杀和株连，同时对最普通的proxy都无效，因此现在已经不常使用。 1.5.关键词过滤 防护工程在中国网络的核心路由器上，都放置了一些探头。具体的方法为配置一个核心路由器的镜像端口，将所有通讯数据全部向端口转发一份。该端口指向一套深度包检测集群。如果数据没有异常，则不对通讯进行干扰。如果数据异常，则发送RST包拦截通讯。同时记录双方IP，拦截其后5分钟内的所有TCP SYN包。 这种方法的优势在于，无论多复杂的网络拓扑结构。只要能够开镜像端口，就可以工作。无论多大的规模和多高的流量，只要能添加服务器，就可以支持。同时由于屏蔽效果好，对普通访问的干扰小，因此目前已经成为最主要的屏蔽方式。 这种手法无法针对UDP工作，因为UDP不存在链接断开状态。同时如果双方都屏蔽RST包，则连接不会被中断。然而如果双方都屏蔽RST包，会导致一些主动断线在对方那里变成死连接，因此无法通过拦截RST包来防御。同时，按照当前的测试结果，IPv6的包并没有被拦截。相信这是因为核心路由器支持了IPv6，但包检测集群尚未支持IPv6包检测。 1.6.热点屏蔽 近来发现一种趋势，当某个链接的热度非常高的时候，通向此链接的访问会被屏蔽。由于是接受到RST包，因此不像是服务器超载。这是当前防护系统的新方向，尚没有更多资料。 2.翻墙方法简述 2.1.OpenDNS DNS污染可以通过修改自己的DNS服务器来屏蔽。以Linux为例，当前你的DNS服务器配置可以在/etc/resolv.conf中查看。你可以将其替换为OpenDNS的DNS服务器，而非电信的服务器。OpenDNS是一家商业公司，通过提供DNS服务来收费(不具体解释商业运作)。一般来说，他们的DNS服务还是比较准确的。 通过OpenDNS可以防御DNS污染，但是无法防御其余方式，而且会被DNS替换所干扰。因此建议一般作为常规网络配置，而非专门的翻墙方案。 2.2.hosts hosts的目地和OpenDNS一致，但可以防御DNS替换。其原理是通过将正确的DNS结果写入/etc/hosts文件，在绕过网络解析过程。从而避免DNS出错。 该方式无法防御1.4-1.6的屏蔽。 2.3.proxy和变形 针对DNS欺骗和IIP屏蔽，我们可以通过指定一个国外的代理来访问。由于DNS解析在代理商进行，因此一般不会被欺骗。由于不直接访问IP，因此IP屏蔽也失效。 一般而言，该方法无法屏蔽1.5的屏蔽，但是有一些变形产品(例如Firefox的gladder插件)，通过变形URL请求，使用特殊代理的方式对1.5进行了部分绕过。但此种方式不保证100%成功。 2.4.ssh -D ssh是一种安全的远程命令行工具，具有很多端口转发选项。其中有一种动态端口转发选项，在服务器端开启后，使得ssh可以被作为一个socks5代理服务器使用。 此种方式需要有一个墙外的ssh服务器，一般可以购买墙外的空间，他们会附送一个。此种方式可以绕过全部屏蔽方式，但是由于ssh本身的稳定性，因此经常有掉线的问题。而且有的服务器关闭了动态性转发选项，或者对长期连入的ssh连接进行断线处理。同时，由于很多人接入同一个IP进行翻墙，因此很多网站(例如google)会认为你的访问不可信。 2.5.tor tor是一种分布式代理工具，可以在隐蔽源和目标的情况下访问服务器。该方法可以绕过所有屏蔽方式，但是通常而言，该方法的访问会比较慢。同时也存在访问不可信的问题。 2.6.gae gae是google的个人引擎服务，一般由很多服务器构成，而这些服务器一般位于国外。有人针对这个特点，制作了特殊的python程序，能够将客户的访问转换成特殊的加密包，在服务器上访问目标服务器。因此可以被视为一种特殊的代理协议。该方法可以绕过所有屏蔽方式，但是由于众所周知的原因，gae服务器本身有的时候也会被屏蔽，导致该方法无法工作。而且由于google本身的屏蔽，该方式对于某些网站也是无法访问的。该方式也存在访问不可信的问题。 2.7.vpn vpn是唯一一种能够快速有效，一劳永逸的翻墙方式。使用vpn后，等同于你的机器拉了根线接在国外的网络端口上。因此该方法可以穿越所有屏蔽方式，同时很少有访问不可信的问题。唯一的问题是vpn，尤其是快速的vpn很难得，而且通常很贵。 3.组合翻墙 3.1.问题 纵观全部翻墙方式，每种方式都有一定的缺陷。2.1-2.3并不总有效，ssh不稳定，tor慢，gae看运气，vpn又贵。同时，我们还要借助终端的客户端组件(foxyproxy之类)来区分被屏蔽的网站和普通网站(使得普通网站的访问不使用特殊的方式)。 3.2.目标 本文试图通过某种方法，同时使用2.4-2.6的一种或多种方法。达到访问透明，使用稳定，速度尽量快，流量尽量小的目标。 3.3.架构 我们使用squid和haproxy进行代理调度，达到上述目标。squid是一种老牌的开源代理服务器，其特征是会对代理内容进行缓存，减小访问流量。同时，可以将请求转发到其他代理上。从而会自动检测和管理多种代理服务器。haproxy是一种基于tcp和http的反向代理程序，在此我们需要使用它的TCP代理能力，将多种socks5代理集成为一个。 基本架构图如下： / -&amp;gt; tor web brower -&amp;gt; squid -&amp;gt; privoxy -&amp;gt; haproxy -&amp;gt; sshtunnel -&amp;gt; gappproxy 3.4.优势 相对单层代理，组合方式具有多个优势。 使用squid分离访问线路，并缓存访问数据。对大规模密集访问，可以有效的减小流量。而且对除Firefox外的浏览器，可以根据其访问范围控制代理线路，进一步减小代理流量。(Firefox可以使用AutoProxy或FoxyProxy) 使用haproxy反向代理了socks5服务，因此可以并行使用多个sshtunnel的带宽。同时自动检测这些ssh是否可用，保证了访问的连续，同时也非常容易添加和减少代理。 3.5.劣势 本方法有一个比较明显的问题，即squid无法直接使用socks5代理，因此需要通过privoxy进行转换和保密。但是此时squid只测试privoxy的存活，而不理会socks5的存活。因此当haproxy的后端全部失效的时候，squid仍旧会认为privoxy有效，进而导致出现privoxy的错误页面。 同时，由于haproxy只检测ssh端口是否相应。因此当远程服务器几乎不响应代理请求时，haproxy并不会将这一代理移除出列表。从而导致某些请求需要非常长的时间完成。 3.</description>
    </item>
    
    <item>
      <title>ssh翻墙服务</title>
      <link>http://shell909090.org/blog/archives/71/</link>
      <pubDate>Tue, 07 Jul 2009 22:48:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/71/</guid>
      <description>不多说了，上脚本。
-----------/etc/init.d/sshtunnel------------ #!/bin/bash PATH=/bin:/sbin:/usr/bin:/usr/sbin CONF=&amp;quot;/etc/default/sshtunnel&amp;quot; source $CONF if ! [ -x /usr/bin/ssh ]; then exit 0 fi start () { echo -n &amp;quot;Starting tunnel..&amp;quot; ssh -CNq -D &amp;quot;$PROXYPORT&amp;quot; &amp;quot;$USERNAME@$SSHHOST&amp;quot; -p $SSHPORT -o ServerAliveInterval=30 &amp;amp; echo &amp;quot;done.&amp;quot; } stop () { echo -n &amp;quot;Stopping tunnel..&amp;quot; PID=$(netstat -nlp -4 | grep &amp;quot;:$PROXYPORT&amp;quot;) PID=$(echo $PID | sed &amp;quot;s/.*LISTENs*(.*)/1/&amp;quot; | cut -f1 -d/) kill -9 $PID echo &amp;quot;done.&amp;quot; } case &amp;quot;$1&amp;quot; in start|restart) start ;; stop) stop ;; restart) stop start ;; *) echo &amp;quot;Usage: $0 {start|stop|restart|clear}&amp;quot; exit 1 ;; esac exit 0 -----------------end of file------------------ ---------/etc/default/sshtunnel---------- PROXYPORT=7777 USERNAME=abc SSHHOST=abc SSHPORT=22 -----------------end of file------------------  首先准备一个远程服务器，获得域名端口，用户名密码。而后将上述脚本放置于指定位置，修改/etc/default/sshtunnel的值，即完成配置。但是上述脚本并没有解决自动登录问题，因此，请生成一个没有密码的密钥，将公钥导入远程服务器。</description>
    </item>
    
    <item>
      <title>AMD64下的Google Gears</title>
      <link>http://shell909090.org/blog/archives/65/</link>
      <pubDate>Sun, 24 May 2009 21:49:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/65/</guid>
      <description>到http://dev.laptop.org/~joel/gears/下载了用吧，debian testing下正常。当然，离线还没有测试过——</description>
    </item>
    
    <item>
      <title>Linux的环境</title>
      <link>http://shell909090.org/blog/archives/63/</link>
      <pubDate>Tue, 21 Apr 2009 21:02:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/63/</guid>
      <description>很多专业人士的Linux是万年不换的，贝壳没有这么专业，电脑最近老换来换去的。所以列一下有什么东西是一个Linux必装的，以免忘记。其他东西就算 了，需要了再说。另外说明一下，以下列表是针对日常使用，而不是专业开发。例如python环境中的一些组件，还有一些太基础的系统组件都没有列。贝壳认 为会到这里看这些东西的人这些基础常识都应该有了。
1.firefox + thunderbird。这两个是万年组件，好用跨系统。不多说了，列一下插件。
1.1.Flash Player，adobe的能用就用那个，不能就用swfdec。
1.2.CustomizeGoogle。
1.3.Firebug，要用debian提供的包，否则无法用。
1.4.FoxyProxy，移动系统要修改about:config。
1.5.GMarks。
1.6.Google Gears，x64有定制的安装包
1.7.Google Reader Notifier，Google的产品好多。
1.8.Greasemonkey。
1.9.NoScript。
1.10.Tree Style Tab。
1.11.TwitterFox。
1.12.Update Scanner。
1.13.Session manager。
1.14.QuickText，TB插件，能够使用模板定制信件。
1.15.WebMail，TB插件，能接收Hotmail邮件。
1.16.SendFilter，能够使用发送过滤。
1.17.Enigmail，邮件加密系统。
2.Gnome-do，快速启动程序，很方便。
3.pidgin，万用IM，很强大，最好加上两个插件
3.1.msn-pecan，msn的另类插件，功能比标准的多一些。
3.2.fetion，飞信 for pidgin的插件。
4.mplayer + audacious，经典电影播放器加还不错的音乐播放器。
5.amule，emule的Linux替代品，电驴软件。
6.ibus，很爽的输入法，不过比scim的系统结合程度要差一些，也还在发展中。
7.OpenOffice，想开.doc .docx文件么？装OO3以上。
8.eclipse，很强大的编辑器，唯一问题就是太大太强了。
9.emacs + vim，推荐emacs23，自编译。比22好用太多了。
10.apache2 + mysql，啥都不用说了，日常保存一些东西，共享文件，运行一些网页程序很方便。不过对已有的人是不需要的。
11.mercurial，这恐怕是今天最专业的一个组件了。这个组件的目的是分布式的管理文件版本。对于大多人来说，最大的好处是可以本地化的管理自己的一堆文件，以及处理各个版本。
12.comix，漫画浏览器，也是不错的图片浏览器。
13.cryptkeeper，这个是文件加密软件，内部使用encfs作为加密基础。很不错的。
14.Wine，只要想运行Windows程序，就非装不可。记得字体反虚化，否则会难看死。
15.revelation，密码管理器。
16.tsclient，远程到windows下。
17.dictd + gnome-dictionary，方便的词典系统，比stardict差点，但是不那么让人恶心。</description>
    </item>
    
    <item>
      <title>debian testing下的ibus安装</title>
      <link>http://shell909090.org/blog/archives/62/</link>
      <pubDate>Wed, 08 Apr 2009 23:30:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/62/</guid>
      <description>贝壳经过N个人的宣传，决定试用一下传说中的Ibus，下面是试用安装手记。文章参考了后面的参考1，特此鸣谢。
apt-get install git-core python-gtk2-dev cvs libtool automake python-enchant libgtk2.0-dev libdbus-1-dev libdbus-glib-1-dev python-xdg
在安装以上依赖后，运行。
# 安装ibus git clone git://github.com/phuang/ibus.git ibus cd ibus ./autogen.sh chmod +x debian/rules dpkg-buildpackage # 安装ibus-pinyin git clone git://github.com/phuang/ibus-pinyin.git ibus-pinyin cd ibus-pinyin ./autogen.sh chmod +x debian/rules dpkg-buildpackage  而后，在根目录会生成两个文件。贝壳的是ibus_0.1.1.20080908-1_amd64.deb ibus-pinyin_0.1.1.20080901-1_amd64.deb。名字比较旧，但是查看git log的话，是2009年4月8日的版本。先安装前者，再安装后者(顺序不要弄错)。而后就是设定部分。
设定的话，请不要按照参考文去设定。这是贝壳血的教训，足足弄了4个小时。正确的做法是用root用户im-switch -c。而后选择ibus作为输入法。
而后，稍等，先不要着急重启。在两个包里面还有个bug？？
在ibus包中，有这么一个文件。 /usr/etc/xdg/autostart/ibus.desktop在debian testing中，这个位置的自启动是无效的！ 正确的做法是，cp /usr/etc/xdg/autostart/ibus.desktop /etc/xdg/autostart/ibus.desktop
如果不按照上文修正，结果就是ibus会正确启动，但是没有托盘区和输入条，全凭感觉选字(汗-_-|||)。
其实这应当是一个bug，scim可以在/etc/X11/xinit/xinput.d/scim中设定好守护进程，而后在系统界面出现后自动出现(这也是为什么每次启动的时候scim总是先看到的原因)。而ibus尚不支持界面出现后再去注册托盘区，因此必须试用autostart来启动守护进程。
总体感觉而言，ibus比scim更加漂亮干净，据说对kde的支持也更好。不过试用过程中还是有点问题，主要是以下几个(2009年04月08日列表)：
1.�字没有！我相信，其实是很多字没有！
2.firefox就在贝壳写这篇文章的时候，崩溃了一次。以前贝壳的firefox很稳定的，从来没有崩溃过——
参考： [1].debian 5.0 安装 ibus中文输入法.http://hi.baidu.com/cvwolf/blog/item/3d812b4e8c4fe201b3de0591.html</description>
    </item>
    
    <item>
      <title>要死的磁盘挂载</title>
      <link>http://shell909090.org/blog/archives/55/</link>
      <pubDate>Fri, 20 Mar 2009 16:31:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/55/</guid>
      <description>follow了我推的人应该都看到了，从昨天到今天，贝壳都在狂找U盘挂不上去的原因。贝壳的两个本子，一个T61一个HPmini，明明都装的Debian testing，两边的配置都一样，怎么就是一个可以挂载U盘，一个就是无权限呢？
贝壳首先进行了包检测，是否少装了包，结果没有。然后再进行了配置对比，也没有发现差异。而后，贝壳祭出了绝技，strace和dbg的调试。一跑，贝壳傻眼了。一台机器是AMD64，一台是i386。CPU和内核完全不同，导致整个行为没有一点可对比性。难道无法挂载是因为CPU的问题？
在贝壳长达10多小时的排查后，贝壳无意中打开了HPmini的fstab文件，发现一个让人绝倒的事实。贝壳的HPmini是从u-live上面镜像过来的。因此继承了u-live上面LABEL=live-ntfs /的设置。而亲爱的gnome-mount是会启用这个文件的——
结果，这就是贝壳悲惨世界的原因——</description>
    </item>
    
    <item>
      <title>上网本，UMPC，手机的混血</title>
      <link>http://shell909090.org/blog/archives/54/</link>
      <pubDate>Tue, 17 Mar 2009 23:13:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/54/</guid>
      <description>贝壳最近又手痒想败家了。对象是上网本，UMPC，或者HTC G1。不过以上三者都不怎么完美，要能结合起来就非常有诱惑力了。要是价格低点那就更——
不说瞎想了，就说说上网本，UMPC，G1的概念和对应客户。以及贝壳为什么想要混合以上几个东西。
UMPC是指和电脑具有类似构架，但是更为小型的电脑设备。当然，官方有更严格的规定，例如最低分辨率，触摸屏等等。UMPC和上网本的区别主要就是官方的几个内部规定，满足就是UMPC，不满足则是上网本。但是对贝壳来说，不管这些，好用就好。贝壳希望的机器，具有7寸的触摸屏幕，对应的键盘。这样的话，贝壳可以用键盘来操作电脑(熟悉的人应该记得贝壳的快捷键使用和单手操作电脑的绝技吧)，并且触摸屏可以剩下一个触摸板的空间。
但是，仅仅以上条件却不能让贝壳满意。为什么呢？首先是因为体积。现在的上网本经典大小是230x160x30，这么大的一个家伙，就算带出门也够当板砖用了。其次，这东西不支持SIM卡插槽，这造成了非常麻烦的问题(当然，支持恐怕是更麻烦的问题)。贝壳无法通过这个本来直接上网，打电话，管理电话。
其实，后者的特性主要是针对HTC G1去的。现在的手机基本已经相当的智能，但是却有两个先天的问题。一个是没有能让人用起来很爽的键盘！这样写起程序来非常费劲(旁：汗—— ..-_-||||，手机上还不忘编程，真TMD是程序员)。其次是构架不同于经典的x86构架，扩展和使用程序都非常不方便。
如果一个本子，有200x150x30的大小，0.8kg上下的重量，支持SIM卡插槽，支持触摸屏幕，使用SSD硬盘。还可以标准的安装debian，使用linux下的各种程序。那基本就是贝壳梦想中的本子。当然，如果价格能在3000以下更好&amp;hellip;.贝壳可以拿这个本子到处跑(虽然体积还是个问题)，到处写程序看电影看小说都不成问题。还可以打手机(那可以直接从thunderbird中拨出阿～～)，GPRS上网(TMD混蛋中国移动，现在 3G还没出来呢)。
当然，现在很多手机基本也可以实现上面的功能，除了一个标准尺寸的键盘外。但是可惜的是，这些手机的系统都不是标准的系统，一般用户是无法重写和定制的。如果按照刚刚的方案来定制，那么整个机器上跑的就是一个完整的系统，甚至可以跑一个XP起来。稍微定制一下就可以当手机专用系统用了。像贝壳这样的编程人员更可以方便的给手机编程，来扩展手机的功能。
还有更好的一个方案，就是将手机回归原始。使得整个手机除了电话和短信外，什么功能都没有。而后给手机指定一个标准接口，在需要进行复杂应用的时候，直接插在上网本的外面当外接设备使用。这样手机的屏幕和键盘都可以极度精简，体积小巧方便使用。接入电脑后，非常方便的可以浏览网页，观看电影等等。其实本质上就是一个强大的手机(当然，要用经典构架)外接一个大型(相对大型)的显示器和键盘系统。</description>
    </item>
    
    <item>
      <title>磁盘对倒迁移</title>
      <link>http://shell909090.org/blog/archives/52/</link>
      <pubDate>Thu, 12 Feb 2009 15:40:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/52/</guid>
      <description>贝壳的本本坏了。
Acer的质量真不怎么的，只是正常使用而已，买来不到一个月就返修。费时费力不说，还差点因为IWT的问题无法修理而要付钱。结果刚刚过保半年，总共买了一年半后，坏了。
趁机问老板要了一台ThinkPad，虽说联想的做工不如IBM，不过依旧非常舒服，不愧是商务王者。但是，贝壳原来在笔记本上配置的复杂到死的系统，要是在新机器上一一重装的话，费力先不说，项目肯定是无法按期完工了。
贝壳修旧机器的时候，拆下了硬盘和电池。这里顺便提醒送修笔记本的同志们，记得拆下硬盘和电池。硬盘是你机要数据的所在，将来要恢复系统就全靠他了。而电池——到时候要是发现电量少了，这种东西谁都说不清楚。所以还是拆下来的好。那么，最低限度的，要从旧硬盘上读出数据，否则很多东西完全无法运作了。所以——贝壳找人借了一个移动硬盘盒。嘿嘿，这种东西可以将笔记本的SATA转换成USB使用，从而在新电脑上直接读取旧电脑数据。
为了不重装电脑，贝壳决定在新电脑上直接使用旧电脑的系统。将旧电脑的数据整个复制到新电脑上，就是俗称的磁盘对倒。下面是一个关键的问题，是重建文件系统，然后复制数据好呢？还是直接镜像整个系统？如果是复制数据，相对的数据清晰干净，但是容易发生一些莫名其妙的错误。如果是整个镜像，对了错一并带入新系统。贝壳在这里选择比较保守的方案，镜像整个磁盘。
首先贝壳从U盘启动(刚刚做了U live debian，冲着拯救去的系统，不知道是说幸运呢，还是乌鸦嘴呢)，而后删除原有磁盘的所有分区，输入dd if=/dev/sdc of=/dev/sda，将整个磁盘复制到新电脑上。这里注意，贝壳没有设定区块大小，因此速度比较慢，正确的设定大小有助于加速复制。贝壳的数据是 120G(因此向公司申请的电脑最低是120G硬盘)，复制速度是10M/s多一点，复制时间大约是3小时15分钟。从晚上9点一刻一直到晚上12点半。在完成复制后，直接重启，从硬盘启动Linux，成功！
在几乎没有任何干预的情况下，Linux就可以开机成功，不得不说这给了我很大信心。然后我去启动windows——不动。
贝壳被迫回到了Linux，仔细调试驱动，设法最快的弄出一个可用的系统。下面详细记录了ThinkPadT61上安装Debian的全过程，有兴趣的可以看看。至于六牙四皂和某猫小姐就可以跳过了。
首先贝壳调整了复制后的硬盘上的分区。由于分区表是按照120G的时候计算的，因此新硬盘上的分区使用不足。启动gparted调整大小后，sda6占用了全部新增空间，暴增到200G。而后贝壳开始查看pci设备和驱动。
# lspci -nn 00:00.0 Host bridge [0600]: Intel Corporation Mobile PM965/GM965/GL960 Memory Controller Hub [8086:2a00] (rev 0c) 00:02.0 VGA compatible controller [0300]: Intel Corporation Mobile GM965/GL960 Integrated Graphics Controller [8086:2a02] (rev 0c) 00:02.1 Display controller [0380]: Intel Corporation Mobile GM965/GL960 Integrated Graphics Controller [8086:2a03] (rev 0c) 00:19.0 Ethernet controller [0200]: Intel Corporation 82566MM Gigabit Network Connection [8086:1049] (rev 03) 00:1a.</description>
    </item>
    
    <item>
      <title>论同时的双系统－－准虚拟对双系统的进一步扩充</title>
      <link>http://shell909090.org/blog/archives/49/</link>
      <pubDate>Mon, 12 Jan 2009 01:04:00 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/49/</guid>
      <description>熟悉贝壳的人都知道，贝壳是个linux爱用者，不过因为工作关系，经常要使用windows。贝壳在自己的笔记本上使用了linux/windows混合双系统，并通过共用磁盘的方式共享数据，解决这个问题。但是长期的使用表明，这种解决方案存在几个巨大的瑕疵。首先是系统切换时间常，因此长期在一个系统中工作，而很少触及另外一个系统。其次是稳定性差，windows下一旦崩溃，进入linux后就需要检测数据盘，80G的数据慢慢扫描，感觉晕到死。那么是否有一种方案，能够同时使用两个工作级系统（注意，不是实验级，贝壳成功的在windows下的vmware里跑了一个oracle，这个可以说是实验级的典范。然而工作级系统的要求和实验级完全不同）。
从系统发展史的角度来说，我们可以预见，将来的系统将是脱离硬件的。首要的原因就是和硬件不相匹配的各个层级的计算能力需求。现在系统发展有两个极端，一个是虚拟机，试图将一个硬件整体分离，运行多个系统。另一个是高性能集群，试图将多个硬件合并，运行一个系统。从根本上说，这是因为高性价比的硬件集中在了一个性能区间，而实际的性能需求却是完全分离的，因此我们才会出现如此两类完全背离的需求。而现在有大量宝贵的人力浪费在了系统和硬件结合，系统稳定性问题上，这无疑是对将来发展的一个巨大瓶颈。虽然无法预知将来的技术发展会以何种方式解决这个问题，然而可以预见的是，解决硬件和性能的背离将是人类计算机发展史上一个重要的里程碑，解决这个问题的人必定会在计算机历史上留下重重的一笔。
同时，更进一步，贝壳揣测，将来的解决方案将是系统硬件调度/驱动和系统软件管理分离。一个软系统拥有一个用户表和一个硬件表，硬件表上写他可能有10个键盘，两个显示器，或者一堆其他设备。系统借助某个可信方案，管理了一系列虚拟抽象设备和真实设备形成的映射。作为系统层以上的软件，我们只要关心如何操作这个虚拟设备即可。而实际上，我们可以通过管理参数和对应关系实现各种需要。例如我们可以将多个机器的硬件管理核心加入一个系统，形成集群。或者我们可以在一个机器的硬件管理核心上加入多个系统，形成虚拟机。这个基本是分布系统的观点。如此一来，系统层软件就无法得知也无需得知自己是在到底运行在什么环境下。只是这个系统设计方案对高性能要求的子系统（主要是显卡）相当不利。
从揣测回到现实，为了实现一个工作级系统（幸好，还不是工业级），我们需要为系统制定一些评判标准，以判别各个方案的优劣。我们首先能想到的评判标准就是速度，一个慢吞吞的系统解决方案是没有任何实用价值的。当然，这个速度是有差异的，可能是linux快一些，windows慢一些，或者相反。我们假定实际的需要是windows快一些，因为linux可以通过定制进行加速。
我们的第二个评判标准就是稳定性，经常会崩溃的系统不比慢吞吞的系统好到哪里去，甚至会更加让人讨厌。虽然工作级系统并没有工业级那样高的要求，然而高负荷稳定，宕机平均频率低于3天/次还是要保证的。而后我们还希望两个系统可以做到数据互通，即两个系统间的数据尽可能的共享，至少要做到文件和邮件的共享。最后，我们希望解决方案简单易用，便于实施和维护。
而后，我们列出了一个原始方案，和以下几个改进解决方案，并给出优劣评价，谨供大家参考借鉴。同时我们在其中还补充了一些无法实际解决问题的虚拟化解决方案，并且说明无法使用的原因，供适合的人自行选用。
原始方案，windows+linux+数据分区。此种方案是最中规中矩的，性能最高的方案。具有对硬件最好的支持，最容易的维护。如果需要运行游戏（尤其是魔兽，WOW），这也是唯一可行的工作级方案。稳定性评价属于尚可，主要由于ntfs在linux的稳定性并不好，ext3在windows需要使用非官方驱动，和某些（就是avast）驱动不兼容。数据互通比较方便，通过数据分区可以轻松的共享文件和邮件。
windows虚拟方案，vmware+虚拟分区。这种方案是改进方案中唯一可以跑游戏的，因为虚拟机随时可以关上。性能上满足windows快 linux慢的要求，虚拟系统显示性能良好，也可以通过文件共享部分的解决数据共享问题（文件共享方便，邮件共享困难）。稳定性很好，基本没有什么不稳定的问题出现，操作和维护都不困难。然而之所以一开始这种方案就被排除在外，主要是因为这种方案无法让linux驱动实体硬件，无法通过机器启动。这样也许对一些跑起来玩玩的人或者是内核工程师/测试员比较有用，然而如果要在linux里面进行大量工作，编译程序，运行服务，这种方案就力有未逮。因此这个方案可以说是一个实验级方案，而非工作级。
windows虚拟方案，vmware+实体硬盘。速度一般，windows快linux慢，基本和上面一个方案一样，唯一的区别就是linux也可以被实际驱动。然而这也成了整个方案的最大败笔，因为linux的驱动灵活性不如windows，因此无法经受这种系统切换的动作。举例来说，真实的机器上，硬盘是sata的，作为sda识别和使用。而虚拟机上则是IDE的，被识别成了hda。于是启动环境一变，就需要修改大量配置来调和这个问题。又例如，在真实机器上，X使用fglrx驱动，而虚拟机下面要用mesa。如果我在/etc/xorg.conf中不指定驱动，那么真实机器的驱动也会变成 mesa，导致性能下降。如果指定驱动，又会导致虚拟机内X无法运行。诸如此类的问题林林总总，需要大量细节修正，因此维护复杂，稳定性差，不建议正式使用。在贝壳机器上更严重的，出现了虚拟机内和虚拟机外争抢数据分区的状况，这种情况下数据分区实质是被当做盘阵用了。使用非专用的磁盘作为底层共享存储，并在上面运行ext3系统，这是及其危险和愚蠢的。
linux虚拟方案，xen。速度超快，但是上来就在贝壳的机器上暴出几个问题，因而没有继续测试。首先是安装xen后x无法启动，出现fglrx驱动无法加载的状况。其次是xen要求使用虚拟盘启动，可贝壳经常需要跑到windows下面打游戏。因此在简单测试后被剔除出局。感觉这种方案的最大问题在于配置管理太过复杂，debian下面已经很轻松了，只需要安装对应内核，使用工具建立虚拟机，但是依旧感觉麻烦到一塌糊涂。相信这种方案在专业级服务器领域应当有不俗表现。
linux虚拟方案，openvz。这种方案压根就不适合贝壳的状况，因为这个虚拟方案要求宿主和客户必须是同一CPU同一系统（不要求同一linux发行）。主要用于希望将一个主机切分成多个独立的同构主机，以达到分离管理的目的（例如业务服务器和数据库服务器分离）。需要做大型网络管理/虚拟主机业务的人可能会对这个虚拟方案感兴趣。
linux虚拟方案，vmware。速度一般，linux快windows慢，视频效果不错。vmware毕竟是商业公司，视频驱动挺齐全的。但是内核驱动的编译麻烦到死，首先是要求编译器版本和主内核编译器版本一致，于是贝壳去搞了个gcc-4.1，然后连接了上去。下面又是内核头定义出现版本差异，搞到现在还没有搞定。谁能搞的定的给个参考，最好是debian上的解决方案。
linux虚拟方案，kvm。这个是贝壳目前使用的方案，基本比较理想。速度很快，和xen基本差不多，显示速度不如vmware（理论上说装好显卡驱动应该会好点，不过贝壳找不到CLDC5446的XP驱动，那是Win32和Win95时代的显卡）。linux快windows慢，但是还在可忍受范围内。稳定性很好，只要测试通过，运行中到目前为止没有死机（当然很多参数是加了之后开机即死机）。数据可以通过samba互通，邮件也同样可以互通。然而使用samba无疑复杂很多，而且性能并不太好。只是从稳定性上说，让linux自己去驱动ext3总比半吊子的windows驱动更好，同时也不会出现争抢的问题。易用性上还算可以，无论是内核编译还是系统使用都不太难，最大的麻烦就是网络配置。根据贝壳的测试，在真实机器上superpi运行100W 位需要45秒，虚拟机内需要54-60秒，尤其在换用kvm-72.2后反而更慢了（54下降到60，折合真实机器83.3％下降到75％）。
总体来说，贝壳更倾向于使用全开源的准-全虚拟解决方案kvm，主要因为他简便易行，对系统影响小，不改变现有系统。同时性能高，稳定性好。主要需要解决显卡效率问题。如果以上问题无法彻底解决，贝壳打算换用linux下的vmware，想办法搞定他的内核模块。</description>
    </item>
    
    <item>
      <title>U盘启动</title>
      <link>http://shell909090.org/blog/archives/479/</link>
      <pubDate>Mon, 15 Dec 2008 16:34:28 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/479/</guid>
      <description>hihi
大家看过血色星期一没有？那里面有个家伙用随身的U盘当系统带来带去，很酷哎。
贝壳也有个U盘系统盘，做过使用/分区隐藏/Linux启动/密码访问控制，但是基本用不上，首先一个原因就是――太慢。
KST的2GU盘读写速度是5/1.5，貌似用来启动个30多M的系统也够了，可是加上各种检测，时间就远远比硬盘长，而且长很多。所以贝壳正在寻思，什么时候弄个高速(起码要10M)U盘来当系统。分个2G给linux，足够他跑X了，连带编译器什么都可以加上去。
不过在这之前，首先要搞定系统启动问题。混蛋的grub在U盘启动的时候不稳定，一会把U盘当hd0，一会把硬盘当hd0。可以想象，系统启动的时候每次都要手工确认，这种东西鬼才高兴用。而且U盘系统有的时候开关机不稳定，半路死机ext3就损坏，又要拿debian来扫。ext3损坏本来没什么，可是hd识别又出现变化――变的像死机一样。TMD这种鬼环境，加上600M的空间，会用才有鬼了。
先解决这个问题，然后弄个8GU盘来装酷，就这么决定了。
另外，血色星期一的设定弄的很不错，系统是linux(估计是定制的)，里面用的是python(就是听说用这个语言才去看的)。不过入侵的时候时间和动作都搞笑了点。真正的入侵往往耗时数天甚至数周，而hack高手也不是拿一堆脚本去淹死服务器的家伙。能够从别人认为完美的地方看出破绽才算入门，而能够从逻辑层面升华到理论的才算是大师。</description>
    </item>
    
    <item>
      <title>一些使用firefox的技巧</title>
      <link>http://shell909090.org/blog/archives/435/</link>
      <pubDate>Mon, 10 Mar 2008 13:33:31 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/435/</guid>
      <description>在linux下和windows下共享同样配置/插件。这个很简单，上面的blog中有篇文章说到thnunderbird在双系统下共享同样邮件的问题，firefox也一样解决。能用linux的人不会查不出配置目录位置吧。
节约内存技巧。
firefox虽然号称小巧，然而很多时候我们发现他的内存消耗也非常惊人。在贝壳的机器上，有的时候会高达150M，基本等于普通编辑器/播放器的10倍。事实上，不是firefox浪费内存，而是默认的内存配置是针对&amp;rdquo;机器上只开firefox&amp;rdquo;设计的。如果你机器内存小，或者需要同时开其他程序，最好自己配置一下firefox。
首先就是fasterfox，关闭其中的&amp;rdquo;增强预读&amp;rdquo;，这东西很消耗内存。然后是内存缓存，调整到32M吧。一般一个网页上所有文件差不多1M-2M，32M够把20个网页的所有内容缓存起来，再多就不大正常了。根据贝壳自己的猜测，渲染动作应当是动态进行的，否则内存根本顶不住长文本的渲染。这样在浏览的时候，从后台抓取内容，动态渲染的速度就非常重要，因此强烈推荐不要小于8M。否则连5个页面的内容都不在内存中命中，还玩个P阿～
还有渲染中的&amp;rdquo;启用快速返回&amp;rdquo;，将内存中的保留页面数调整小，贝壳用的是3。当然，这个只适用于firefox1.5。
其次是session manager，将&amp;rdquo;撤销关闭&amp;rdquo;尽量减小。反正贝壳减小到了1个窗口3个页面。这些页面在关闭后还是继续消耗系统的内存，因此越小越好。当然，小到多少是要看你的具体需要了。
最后，少用插件，少启用插件，除非你真的需要。长期不需要的就禁用，或者干脆卸载。
内存回收技巧。
很简单，觉得不够了，关了再开。反正有session manager，正在浏览的网页根本不会有影响。
同时打开大批网页技巧。
最好使用Tree Style Tab，这样方便。另外，如果需要打开一个页面的所有连接，可以这样做。先察看页面信息，选择&amp;rdquo;链接&amp;rdquo;-&amp;gt;&amp;ldquo;全部选择&amp;rdquo;-&amp;gt;&amp;ldquo;复制&amp;rdquo;，然后开一个文本文件，把内容粘贴进去。可以看到内容其实是一堆的页面链接。当然，如果页面内有js做的链接指向，可以试试用Convert javascript or onclick to normal links这个greasemonkey脚本转换成目标链接。然后，把这个文本文件改名成htm，打开。通常情况下应该是一堆无法点击的文字，不过你可以用Linkify ting来把文字转换成一堆链接。然后……一个个点过去吧。
上面是使用greasemonkey解决的方法，当然，也有更简单的方法。你可以安装flashgot，然后新增一个下载管理器，名字叫做firefox。路径就指向firefox的执行文件路径，参数不用动。平时用你喜欢的管理器，需要打开全部链接的时候，更改为firefox，然后&amp;rdquo;使用flashgot下载全部链接&amp;rdquo;。当然，缺点是对付不了js脚本，除非你加载Convert javascript or onclick to normal。
不过鉴于内存状态考虑，建议不要同时打开大量页面。维持在10-20个上下最好。</description>
    </item>
    
    <item>
      <title>wc、sort介绍</title>
      <link>http://shell909090.org/blog/archives/421/</link>
      <pubDate>Tue, 04 Dec 2007 05:44:52 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/421/</guid>
      <description>首先声明一点，我介绍的小软件系列都是Linux下的，在Windows下可以找Gnuwin32里面提供的移植包。因此多数人都是可以使用的，只是高兴不高兴用的问题而已。
其次我得道歉。本来说好了每周介绍一些小软件的，结果MSN空间不稳定，加上贝壳又忙。所以现在才介绍第二个，大家理解理解吧。
这次介绍的对象是wc，不是厕所，也不是世界杯，而是一个字符统计软件。这个软件的目的是统计出一个文件内的行数，单词数，字符数。行数是按照硬回车来统计的，单词是按照分割符号来统计的，字符么就不说了。这个和Word的字符统计很像，不过用起来并不那么方便。也许有人奇怪，这种软件有什么用呢？主要是在脚本程序内使用来统计一些数据，也有用来统计程序的代码行数的。平时大家一般都是分开统计行数，这次可以wc -l *.cpp *.h。就可以得到所有文件的行数和总行数。
而后我补充介绍一个东西，sort。这东西也很简单，就是把输入的内容按照一定的法则排序输出。一般来说，排序法则是alpha法则，当然也有数字法则等等。这个软件主要是从输出中排除一些重复数据，或者把输出过滤。例如我们可以和上面的联合使用，wc -l *.c *.h | sort。就可以得到当前所有的文件的行数，并且排序。</description>
    </item>
    
    <item>
      <title>Linux和windows共享邮件</title>
      <link>http://shell909090.org/blog/archives/417/</link>
      <pubDate>Sun, 04 Nov 2007 22:59:14 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/417/</guid>
      <description>总算能发正常的文章了，前面发出来的老是不会断行。庆祝一下。
很多人像贝壳一样使用双系统，Linux加windows。贝壳的Linux用的是Debian，最近其中的xfce4出现一些问题。使用的时候老是死机，这日子没法过了。所以贝壳就稍微下了点功夫，先弄个好用的windows凑合一下。
windows下最难办的恐怕就是邮件了，到不是说不能收。只是windows下一个邮件状况，Linux下一个。未免讨厌了点。就算有导入导出可以转换，你想转换多少次呢？
下面贝壳就说一种方法来对付这种状况。
首先你的系统盘应当是ntfs，否则这方法不能用。然后在windows下安装ext2ifs来读取linux的home目录，假定是d:\username.mozilla-thunderbird。windows下安装类似版本的thunderbird，然后看看你的C:\Document and Setting\username\Application Data\Thunderbird下面，是否有一个profile.ini？有就对了。删除这个目录(我没说错)，然后去下一个叫做junction的软件，微软出的。这个软件可以将ntfs的某个目录映射到一个目标上去，对这个目录的访问就等同于对这个目标的访问，就好像linux下面的符号链接一样。下面知道我要做什么了么？
junction &amp;quot;C:\Document and Setting\username\Application Data\Thunderbird&amp;quot; d:\username\.mozilla-thunderbird  然后启动thunderbird，他首先会检查你系统中插件的版本可用性。然后你的Linux下邮件就可以用了。
简单吧？</description>
    </item>
    
    <item>
      <title>wget介绍</title>
      <link>http://shell909090.org/blog/archives/410/</link>
      <pubDate>Tue, 25 Sep 2007 17:53:48 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/410/</guid>
      <description>从今天开始，贝壳每周介绍一些小软件，作为基础的电脑知识普及。软件可能是Windows的，也可能是Linux的，要点是轻巧好用。由于是简介，不会写的太详细。想要看专业介绍的，会给出Reference。
今天介绍的软件就是wget[1]。这个是*nix下的下载软件，也有windows移植[2]。现在可以运行在任何一种POSIX系统上。软件是GPL版权的，属于GNU开源组织的核心代码，也是GNU组织的几大招牌之一(最出名的是GCC)。如果要看详细的资料，请看这里[3]，可惜是英文的。
wget是*nix时代出名的下载软件，以稳定和通用出名。主要针对http和ftp协议的文件下载，拥有很多配置选项和能力。其中比较有名的是链接跟随，这种能力可以跟踪html内的链接。例如将所有链接所需的文件下载到本地，并且修改链接地址，即抓取完整页面文件。跟随链接抓取多重页面(网络蜘蛛)。
wget不支持多线程下载，但是支持断点续传。最常用的用法是wget -c [URL]。如果没有文件就直接下载，有文件就尝试续传。如果没有文件重试次数的指定，几乎就是无限制的下载。下载非常稳定，就算每小时下载10字节都不会断线。
和今天的GUI多线程，甚至带P2P的下载软件相比，wget无疑是非常单薄的。然而由于是基于命令行的，而且非常稳定，因此经常被用于脚本语言中。例如bash或者python，用于下载网络文件后的处理。windows中的很多脚本也可以用这个软件来下载网络文件，非常方便。
Reference:
 GNU Wget: http://www.gnu.org/software/wget/
 Wget for Windows: http://gnuwin32.sourceforge.net/packages/wget.htm
 GNU Wget Manual: http://www.gnu.org/software/wget/manual
  </description>
    </item>
    
    <item>
      <title>活活憋死&amp;最近的状态</title>
      <link>http://shell909090.org/blog/archives/405/</link>
      <pubDate>Thu, 06 Sep 2007 04:49:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/405/</guid>
      <description>今天碰到一个恶心事情，贝壳用的是Debian，相信大家都知道。今天贝壳上上海移动的网站，发现上海移动的网站虽然可以登录，但是在使用过程中过渡是使用Flash的。换句话说，没有装Flash的就死定了。贝壳虽然装了Flash，但是不知道是版本还是什么别的问题，不能用。于是贝壳无奈之下切换到了windows，然后准备去上这个网站。
切到windows下——发现新装的系统没有设定过网络密码。贝壳赶快挂上Debian的根分区，找到网络配置配上。然后完成查询，重启进入Linux——系统死机——
由于这个机器才修过——贝壳一下超级紧张。于是重启进入单用户，照旧死机。贝壳转到windows，好的。于是贝壳再进入一个Linux，总算发现原来机器是死在了ext3文件系统挂载上。
死的是个根分区，压根没法启动系统。贝壳只好找人借启动盘。找到一个RH9的，却无法识别SATA设备。最后没办法，一边找人下载镜像，一边问一个网上的朋友求援。最后运气不错，总算弄到一个启动盘。重启进入启动盘后fsck.ext3 /dev/sda?就可以了。
就这么简单的一件事情，因为没有启动盘搞的贝壳非常狼狈。浪费了一个下午啥都没做到处求援。Linux对于系统的容错和健壮看来也是有问题的。
接下来的几天，贝壳恐怕无法天天上网了。不过估计会几天上一次来收发一下邮件，检查一下blog，还有看看新的小说。诸位有事的话就发邮件好了，别的恐怕是找不到人了。</description>
    </item>
    
    <item>
      <title>Linux下设备可靠性控制</title>
      <link>http://shell909090.org/blog/archives/402/</link>
      <pubDate>Thu, 16 Aug 2007 19:27:04 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/402/</guid>
      <description>上篇文章中提到了一个问题，CPU温度。关于这个问题，就涉及了另外一个问题。Linux下如何获得设备可靠性参数，例如电压，功率，温度，风扇转速，SMART等等。至于获得后要如何做的问题，这还轮不到我关心，相信大家都会使用各种用法。
首先是最主要的组件，lm-sensors包。安装后有一个叫做sensors-detect的程序，运行一下。这个程序会检测你有什么性能控制设备，并且提示你加载相应的驱动模块。在完成加载后(不加载驱动的话就无法查看)，使用sensors查看各个传感器的各个数据。通常有CPU温度和电压等等。贝壳使用的是xfce4，因此还需要一个xfce4-sensors-plugin包。安装后可以在控制面板中添加一个applet，用于检查当前温度。
而后，是硬盘的温度。贝壳不知道是否所有的硬盘都支持温度控制，不过目前本本上的这个Hitachi
HTS541612J9SA00支持硬盘温度测量。贝壳实验过，真的会变化。安装hddtemp包，而后以root身份运行hddtemp就可以了。如果要获得干净的文本，可以使用hddtemp [dev] | cut -d: -f3来取得。唯一可惜的就是这个程序必须以root运行，因而无法运用在applet上进行即时检测。
最后，是SMART信息。包是smartmontools，可以检测硬盘的SMART状态。
基本就上面这些了。</description>
    </item>
    
    <item>
      <title>Linux下的模拟器</title>
      <link>http://shell909090.org/blog/archives/395/</link>
      <pubDate>Wed, 27 Jun 2007 18:25:39 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/395/</guid>
      <description>模拟器是一个很模糊的概念，究竟什么是模拟器？这个问题可能对于诸多玩友并不困难，但是对于程序员却是很难界定。什么是模拟器，bochs算吗？wine算吗？POSIX子系统算吗？OS/360算吗？
下面所定义的模拟器是至少具备以下几个特征的。
1.模拟目标机的CPU。按照这个特征，wine就被剔除出模拟器的范畴。这种东西其实最好规划在模拟子系统中(虚拟机)，这类软件是以本地CPU真实运行为基础特征的。如果这样被算入模拟器，那Windows算不算？
2.模拟目标机的硬件响应。这个特性其实说了和没说一样的。
限于贝壳接触的限制，目前我们的目标系统仅仅涵盖以下几种机器。GB/GBA NES/SNES(FC/SFC) NeoGeo MD 街机
PS。这几种机器相信应该没有人不知道吧。其中FC就是中国风靡一时的红白机。
我们来看看对应的模拟器。注意以下全是Linux系统下的模拟器，FreeBSD之类的需要进一步测试。
gngb
只能用于GB，GBA无法模拟。
gnuboy
和gngb看不出什么区别。
Visual Boy advance
至少从名字上知道能模拟GBA，不过我没有用，下面会说原因。
fceu
FC模拟器，非常好用的东西，有Windows版。除了吞食天地2外还没有模拟不出来的东西(贝壳语：为什么是我喜欢的吞食天地啊～～～)。不过贝壳一样没用，下面有原因。
mednafen
万能的救世主，最全能的模拟器(Linux下)。支持GB/GBA NES NeoGeo涵盖除了MD外的大多数系统，开源而且方便好用，具备Win32版本。不过吞食天地2一样模拟不出来。(贝壳：为什么～～～)
mopher
严格来说这不是Linux模拟器，而是WinCE的。不过鉴于一样是偏门系统，贝壳就顺便介绍以下好了，是GB/GBA
NES/SNES MD的全能模拟器。
dgen
唯一的，也是最好的MD模拟器，可惜在AMD64系统上运行不大正常。
mame
就是Windows下超强模拟器mame的Linux版本，唯一能够模拟街机的模拟器。发布版本超多，支持Windows,
Mac, Linux, Xbox(贝壳：?!), CE(贝壳：??!!),
Nokia9210(贝壳：???!!!)。简直是模拟器族啊——！
pcsx
PS模拟器，其实是PS2啦。支持Windows, Linux,
DreamCast(表问贝壳最后一个是啥东东)。如果你没有超级强劲的CPU就想都别想。
X GL SDL问题
这三者都是图形界面接口。一般来说，Xv是2D最快的，GL是3D最快的。所以能用X的不用SDL，能用SDL的不用GL，跑3D没的商量。
建议大家安装一个mednafen的X版本，一个mame的X版本。不是AMD64的装一个dgen，CPU够劲的装一个pcsx。基本上面的机器都能模拟了</description>
    </item>
    
    <item>
      <title>鸣谢</title>
      <link>http://shell909090.org/blog/archives/394/</link>
      <pubDate>Mon, 18 Jun 2007 21:47:55 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/394/</guid>
      <description>如果是明星获奖后的那种鸣谢的话，我想谢谢自己的父母，谢谢老师们，谢谢所有帮助过我的人们——谢谢你们——
不过好像有点无聊，所以，我还是准备鸣谢这次的对象。一个叫做Krzysztof Burghaedt的可爱家伙，虽然他估计根本看不懂这篇文章。
具体原文请看Install and using Debian GNU/Linux on Acer Aspire 5102WLMi
贝壳最近买的机器是Acer Aspire 5100，这么说大家也许能明白几分。贝壳自行驱动了大部分的设备，除了几个比较妖怪的问题。
一个是USB线路连接手机问题，事后证明A1200不在保用之列。
一个是MMC驱动问题，遗憾，现在还没有解决。
最后一个是声卡问题，音量不能调节。
贝壳曾经问过很多人，还在gg上疯狂找了几天。最后在此人的homepage上找到了正确答案(之所以说正确是因为有人曾经告诉贝壳，需要删除alsa1.0.13，使用1.0.14。当然，结果是无用的)。
首先删除/var/lib/alsa/asound.state，而后重新加载驱动。
#rmmod snd_hda_intel #modprobe snd_hda_intel  而后就可以正常使用了。
所有有类似设备，发现alsamixer: function snd_mixer_load failed: Invalid argument错误的朋友们可以试试。</description>
    </item>
    
    <item>
      <title>查找重复文件</title>
      <link>http://shell909090.org/blog/archives/348/</link>
      <pubDate>Mon, 15 Jan 2007 07:39:52 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/348/</guid>
      <description>算是介绍一个奇淫巧技吧。查找重复的文件，这个应该有很多软件都可以做的。不过在Linux里面，利用系统工具，一句语句查找应该就比较少见了。
$find . -name &amp;quot;*&amp;quot; -type f -size +0 -exec md5sum {} ; | sort | uniq -d -w 32  原理是这样的，先用find查找当前所有文件。我们加上限定类型必须是文件，目录不要。限定大小不为0，空文件不要。然后对所有满足条件的执行md5sum，获得md5和文件的列表。然后排序，再针对md5的部分做唯一限定。就得到了所有md5相同的文件的列表。
问题是，这时候我们得到的还只是一堆重复的文件的md5。我们可以把以上步骤拆开来获得完整的输出。
$find . -name &amp;quot;*&amp;quot; -type f -size +0 -exec md5sum {} ; | sort &amp;gt; file_md5 $cat file_md5 | uniq -d -w 32 $grep &amp;quot;...&amp;quot; file_md5  相信大家都看出是怎么回事情了，就不赘言了。
Windows下以前我总是执行不出，原因在于要这么写。
find . -type f -size +0 -exec md5sum {} ; | sort &amp;gt; report.txt  差一个转义，因为不需要。
总结一下，我们可以用一个脚本来处理这些问题。
--------------------------fine_rep------------------------------ find $1 -type f -size +0 -exec md5sum {} ; | sort &amp;gt; &amp;quot;file_md5&amp;quot; cat &amp;quot;file_md5&amp;quot; | uniq -d -w 32 | cut -d&amp;quot; &amp;quot; -f1 | while read x do grep &amp;quot;$x&amp;quot; file_md5 echo &amp;quot;&amp;quot; done echo &amp;quot;done&amp;quot; rm &amp;quot;file_md5&amp;quot; ------------------------------------------------------------  </description>
    </item>
    
    <item>
      <title>通过LPIC1</title>
      <link>http://shell909090.org/blog/archives/328/</link>
      <pubDate>Sat, 21 Oct 2006 08:04:40 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/328/</guid>
      <description>总算正式通过LPIC1了，搞了半年这个东西，真的差点让我崩溃。通过可以有两种方法，背考古题，或者拥有深厚的功底。
里面最让我觉得不爽的就是很多莫名其妙的参数还需要记忆。例如tracroute -n的n，是阻止R-DNS的意思。这个如果是RHCE，一个man就知道了——可是这里，就需要人自行记忆。除非相当长时间的使用，让你对这些参数了如指掌，否则——考古题。
不过里面对于功底的考察蛮细致的，有的题目会问你一些正常不会细究的东西。我为了通过考试，自行研究了整个Linux引导的详细过程。从开机到initrd，然后从服务到启动X，到自动执行脚本。非常详细的了解了整个Linux的基础，并且可以自行定制一个Live系统。这里面需要非常详细的研究，一般的大路货考试好像还没有这个必要——
不过我要说的是——这些东西——纯粹是自己吓自己。事实上，LPI-101我考了550分，LPI-102我考了640。不是啥高分，不过远远超过通过分数。原因是对于考试评价过高——还特意拖了很久——等很多事情稳定了，而且功底扎实了才去。没想到这么简单，扫兴。
总体来说——考试通过的感觉还不错，不过没有什么好惊讶的。意料中的事情——除了多出来的1300块钞票——我的钱阿——</description>
    </item>
    
    <item>
      <title>LPI的表述问题</title>
      <link>http://shell909090.org/blog/archives/327/</link>
      <pubDate>Tue, 17 Oct 2006 19:42:02 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/327/</guid>
      <description>+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ | {width=&amp;ldquo;181&amp;rdquo; height=&amp;ldquo;80&amp;rdquo;} | | 在您准备接受LPI认证考试前,必须在 LPI | | 官方网站上进行注册登记,注册后系统会发送一个LPI | | | | ID到您的邮箱中，同时登陆会员区也可查看 LPI | | ID。 | | | | 如果您在注册中遇到困难,请致电: 010-62670579,或发邮件到 | | candy@lpi-china.org 或 bai@lpi-china.org, | | 我们有考试官员为您服务，所有注册都是免费的。 | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ | {width=&amp;ldquo;183&amp;rdquo; height=&amp;ldquo;80&amp;rdquo;} | | 拿到您的LPI | | ID后，您可持本人身份证到LPI中国办公室、LPI授权培训中心及Prometric考试中心报名，同时一次性交纳考试费￥1300元，然后您会得到一个准考证，持准考证及身份证到指定的考场去参加考试。 | | | | | | 注：考生在报名时，请选择对应的考试级别和中、英文试题：LPIC-1 | | | | 和 LPIC-2。 | | | | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- | | &amp;ndash; | | LPIC-1 | | 101 | | | | 102 | | | | LPIC-2 | | 201 | | | | 202 | | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- | | &amp;ndash; | | | | 以任何顺序通过 101 和 102,可以获得 LPIC-1 证书,只有获得了 LPIC-1 | | 证书,又获得 201 和 202 考试的专业人士才能获得 LPIC-2 证书。 | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+ | {width=&amp;ldquo;181&amp;rdquo; height=&amp;ldquo;80&amp;rdquo;} | | 在附近的 Prometric | | 考试中心预定考试时间,接受考试,成绩会立即出来,证书要等 7 | | 个工作日,从加 | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+</description>
    </item>
    
    <item>
      <title>Windows和Linux之争</title>
      <link>http://shell909090.org/blog/archives/326/</link>
      <pubDate>Fri, 06 Oct 2006 22:56:15 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/326/</guid>
      <description>在网络上大家经常能看到争论Linux和Windows哪个更实用的帖子。两者无非抱持两种论点，Linux胜在价格和灵活性，Windows胜在简便和可用。一般来说都是说，不论怎么说，Linux可以如何如何而Windows不行。或者是，Windows可以什么什么而Linux不行。
总体来说，Windows擅长于桌面应用而Linux擅长于服务系统。Windows最大的资本在于品牌和延伸。Windows的品牌和可乐的不同在于，可乐的品牌仅仅是牌子，是虚拟价值。一旦可乐公司全部烧毁，那么能否靠可乐的牌子重新站起还是一个问题。但是Windows的牌子还附带了用户对于UI操作方式的粘滞。一旦M$烧了，别人也是很难抢这个蛋糕的。Linux长处在于免费，就单机成本来说，Linux远远要低于Windows。但是这是不完全的运营模式。一个不赚钱的项目？如何吸引别人？
我不考虑Windows和Linux哪个更好，而是考虑另外两个问题。他们是否有存在的必要，以及他们谁更适合我。
大家想必知道，POSIX标准下还有Linux，BSD，Solaris的分别。如果今天不是WL之争，是否会出现UL之争呢？我不知道，历史无法假设。不过我相信，多个公司多种模式的混合竞争，会造成好的效应。很多Windows项目，都潜在的为Linux项目提供了资金(至少M$养活了很多程序员)。而很多Linux项目，又为Windows项目提供了技术和支持。最重要的是，没有Linux的追赶，windows就会无限制的膨胀，垄断，守旧，出现问题。而没有挑战Windows的需要，Linux也不会不断进步。
很多人往往把Windows和Linux等同到开源软件和商业软件。其实这是不严格的。软件往往分为商业软件，试用软件，共享软件和免费软件。商业软件是指代码封闭，作为公司的一个资产。可以转让，可以有条件开放。软件收取使用费用，并且出品公司对于功能提供保证。这样的一类软件。试用软件是商业软件的特殊版本，指限制或者取消了部分或全部功能，准许用户合法免费有限使用的一种特例。代码可以封闭也可以开放(但即使开放也往往是部分代码，甚至是理论代码)，通常是全部软件的一个部分，或者是修改版。往往可以通过缴费来变成商业软件。共享软件指软件作者保留软件的所有权，但是免费的发行软件，不收取费用或者仅仅收取手续费。源码可以封闭也可以开放。免费软件指作者按照源码形式发布软件，并且放弃源码所有权力。一般有有条件发布和无条件发布。GPL就是一种发布条件，虽然作者不继续拥有代码所有权力，但是这些代码不得进入商业领域。而无条件的免费软件，所有者放弃所有权力，任何人可以合法的运用其中的代码。
由此来看的话，大致是商业软件和试用软件一个阵营，共享软件和免费软件一个阵营。然后，Windows上有大量的共享软件，例如Winamp，这已经是Windows得以生存的一个基础了。Linux上面也有很多的商业软件，例如MAYA。往往是属于免费阵营的共享软件稳固了Windows的存在基础，给Windows系统提供了大量的功能和定制。而属于商业阵营的MAYA等为开发4Linux的软件，而为Linux提供了大量的资金。
至于哪个更适合我(注意，这里的我，可不是贝壳本人)，则要看系统的功能，成本，特性而定了。首先是成本问题，M$曾经提出所谓总体拥有成本。即，Windows通过一次购买就可以低成本的运行，而Linux一般都是要为机器配备高水准的管理员。所以管理员水平的上涨引发的费用应当被计入成本中。而且Windows系统对于操作者是基本不用培训的，而Linux需要培训操作者，因此也会产生成本。
问题在于，Windows一次购买1000台机器的时候，大约40W是的纯软件成本。如果原来是需要配置3个网管，现在要配置5个高水准的。那么原来大约需要12W一年，现在需要25W一年。如果3年内需要购买升级产品，则会导致Windows的成本反而高。问题在于，Windows也是会购买升级的，所以软件的成本也会平摊在每年上。当运行的机器多了，就会导致网管的工资上升不算啥的状况。而且注意，其中还不包括因为要在Windows上工作而需要购买的其他软件，例如Office。如此计算下来，单纯从配置的平均拥有成本讲，Windows不占有优势。
不过在雇员培训上，Windows就非常有优势了。现在会Office的雇员满天飞，不会才奇怪。因此可以说是无成本的。然后不会的人找起来反而困难，加上培训，每人成本就要高出100-200。而且非Windows环境和Windows环境交互上比较麻烦，所以这个成本还要更高。从这点来说，一般企业都不适合用Linux。什么企业适合呢？1000台以上机器，雇员学历偏高，在和他人交互上需要他人配合的企业。其实去了企业就可以明白说是政府了。
特性上说，Linux奉行的是专业分工合作的模式。由一个软件完成一个非常专的部分，例如排序，或者下载。然后通过交互通道来协调各个软件，达到一个复杂软件的构成。例如一个邮件软件，可以在里面加入HTML，加入加密，加入VIM编辑。定制性非常强，对于和某些常见任务接近但是细节上有区别，又强调细节必须实现的特殊任务。往往可以非常简单快速的完成。例如同样一个从Internel上面抓专利信息形成数据库的工作，Windows下要专门写程序，而Linux下面可以通过连接lynx|sed&amp;gt;来完成。
然而这对于使用者水平要求非常高，如果不熟悉系统，根本无法做到。对于学校，专家来说，使用Linux是非常方便的。而对于正常用户来说，Linux可就是鸡肋了。
windows的特性是大而全，思考是基于用户傻瓜的模式。固然没人愿意说自己是傻瓜，可是做傻瓜考量的软件总不做天才考量的软件好用。简单来说，windows不追求低成本，不追求好用，只追求用户最简单可以用。可见，随着电脑普及，windows这种思路是无法持续的，或者至少是要萎缩的。
最后一个是功能，Linux的功能和windows总体评价来看差不多。不过Linux的软件更多是专业用的，例如免费的符号表达求解。而windows更多是娱乐的，例如游戏。因此要实现有限功能的人可以自由选择，例如办公环境。需要专业的人最好用Linux，需要娱乐的人最好用windows。
综上来说，对于政府，学校，专家，需要专业软件的人，建议选择Linux。而对于中小企业，需要娱乐的个人，最好选择Windows。</description>
    </item>
    
    <item>
      <title>X system 配置文件执行流程分析</title>
      <link>http://shell909090.org/blog/archives/319/</link>
      <pubDate>Mon, 11 Sep 2006 21:47:55 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/319/</guid>
      <description>1.startx启动流程
/usr/bin/startx +-&amp;gt;/etc/X11/xinit/xinitrc |-&amp;gt;/etc/X11/Xsession |-&amp;gt;~/.xinitrc |-&amp;gt;/etc/X11/xinit/xserverrc |-&amp;gt;/usr/bin/X11/X -&amp;gt;~/.xserverrc
startx脚本会分析用户主目录下是否存在特殊配置文件，如果不存在则使用系统默认脚本。默认脚本分两个部份，xinitrc启动客户端部份，xserverrc启动服务器端部份。
xserverrc内容仅为启动X。xinitrc会执行/etc/X11/Xsession，而后进入session分析。
2.Xsession
/etc/X11/Xsession -&amp;gt; /etc/X11/Xsession.d/*
/etc/X11/Xsession和/etc/init.d/rc很类似，是用来循环依次启动其他脚本的控制脚本。他负责启动/etc/X11/Xsession.d/下的所有文件。其中50xfree86-common_determine-startup文件会依次检测以下3个文件，并且设置到STARTUP变量中。x-session-manager;x-window-manager;x-terminal-emulator;最后99xfree86-common_start文件会执行exec $STARTUP;完成整个系统的启动过程。
3.gdm
gdm服务被/etc/init.d/gdm启动，而后读取/etc/gdm/gdm.conf配置自身。后面是基于理论分析，没有加以验证。
|-gdm---gdm-+-Xorg | `-x-session-manag-+-scim | `-ssh-agent  上面是pstree的结果，第1个gdm是/etc/init.d/gdm，第2个gdm是/usr/bin/gdm。gdm先启动一个X作为服务端，否则自身也无法以图形方式显示登录界面。而后gdm成为此X界面的唯一用户，显示登录系统。在用户登录后，gdm启动/etc/gdm/Xsession。这个脚本的内容和/etc/X11/Xsession非常类似，我怀疑为什么他们不用链接的方式(可能是因为包的关系？)。这时整个启动活动就结束了。</description>
    </item>
    
    <item>
      <title>Linux配置文件测序</title>
      <link>http://shell909090.org/blog/archives/318/</link>
      <pubDate>Mon, 11 Sep 2006 06:44:44 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/318/</guid>
      <description>CopyRight:
Written by Shell.E.Xu. Published under GPL.
KeyWord:
Linux bash profile 配置文件。
Abstract:
利用变量声明次序测定多个配置文件是否被调用以及调用的次序。
环境：
Debian/GNU Linux starg 3.1
Kernel:2.6.16-686-2
测定方法，加入变量TEST=XXX。此方法可能被某些变量解除函数解除，因此不予执行的反应未必是真，不过执行次序一般假不了。
1.tty登录时
/etc/environment;/etc/profile;~/.bash_profile-&amp;gt;~/.bashrc-&amp;gt;/etc/bashrc;
/etc/environment;/etc/profile;~/.bash_login
/etc/environment;/etc/profile;~/.profile
当上级启动过程中文件不存在时，才进行下面的过程。
2.GDM登录时
/etc/environment
3.新启动bash时
/etc/bash.bashrc;~/.bashrc-&amp;gt;/etc/bashrc;
4.~/.inputrc
根据文档，这个函数在readline函数初始化时启用。
5.结论
如果需要有效执行命令，需要同时修改/etc/profile和/etc/bash.bashrc。因为GDM登录的时候不执行登录脚本顺序，所以仅仅修改/etc/profile会造成对GUI下面开的term无效。虽然/etc/bashrc在理论上也有效，但是一旦~/.bashrc中没有引用，则无效(例如Debian中的root，由于安装系统的时候没有copy skel，所以缺少很多.XX文件)。如果仅仅是设定变量，可以用/etc/environment。该文件没有找到资料，其中仅可以设定变量(不用export，应当是被某程序作为配置读取而非脚本执行)，据分析是登录时当即起效。</description>
    </item>
    
    <item>
      <title>音乐文件转换技巧和脚本</title>
      <link>http://shell909090.org/blog/archives/316/</link>
      <pubDate>Fri, 08 Sep 2006 01:50:47 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/316/</guid>
      <description>好久没动手写啥东西了，最近在准备LPIC1考试。Will everyone keep finger cross 4 me?嘿嘿——
这个题目是个大家伙，反正每天写一点，也不忙在一时。大家有啥需要了解的，也可以问在下面。我会更新的。
copyright:
本文所提到各种软件版权归各个软件开发者所有。文章内容及所有附属脚本为独创，按照GPL发布。
keyword:
音乐 格式 转换 脚本 标签 bash shell script mp3 midi ape flac cue
toc
directory:
1.文件格式解说
1.1.mp3/ogg
1.2.midi
1.3.ape
1.4.flac
1.5.cue/toc
1.6.wav
1.7.iso
2.文件转换
2.1.wav/mp3
2.2.wav/ape
2.3.wav/flac
2.4.midi2wav
2.5.iso/wav
3.转换细节问题
3.1.按照cue切割
content:
1.1.mp3/ogg
这两个是非常有名的音乐压缩文件，其中MP3是mepg II layer
3。不要以为是mpeg
III。一般来说，MP3都被认为是一种小巧但是音质比较差的格式。不过事实上，要指摘MP3的音质前，你先自己找找是否满足了一定条件。周围是否安静，没有噪音。音源是否高清晰（拿MP3还原出来的CD是没意义的）。声音设备是否足够好（至少也要是高质量的音响或者高档耳机，耳塞或者200－300的所谓音箱根本不用说）。如果没有上述条件，那么MP3的音质也算过的去的。MP3格式的压缩比值大约是10：1，和wav相比。另外，如果有CD的话，最好使用lame进行适当压缩。而不要为了方便随便使用一个压缩工具。压缩最好使用VBR格式。这种格式本质上没有什么变化，只是在信息流高的地方使用高的编码格式，以获得最高的质量/空间比值。ogg具体情况没有研究，不过使用上和MP3没有区别。
1.2.midi
midi是所有格式中唯一不记录音频数据的音乐格式。midi记录的实质上是发声事件，简单来说就是什么时候鼓响了一下，什么时候钢琴的哪个键被按下了。因此midi也是没有立体声效果的。除非你使用特殊的软件指定某个乐器演奏时候的位置，然后根据环境生成出相应的音乐文件。midi文件在当前主要是两个用途。一个是midi记录了乐手演奏时候的指法细节，也记录了曲子的曲谱。midi本质上就是谱子。另外一个是midi的超小体积使得在某些嵌入系统（例如手机）上面可以作为背景音乐。
1.3.ape
ape是一种无损压缩格式，你可以把ape看成是一种只能对wav作用的zip文件。压缩比一般是2:1。
1.4.flac
flac和ape基本差不多。
1.5.cue/toc
cue/toc不是音乐文件，他们是用于flac/ape等光盘的音轨定义。一个CD可以有多个音轨，iso会记录下音轨的切分方式。但是ape就不行了。于是eac等抓轨软件生成cue来切分音乐文件。往往看到ape的发行方式是一个ape和一个cue，直接打开ape往往是一首非常长的歌曲。其实切分信息在cue里面。虚拟光驱使用的bin文件也是一样，会有配套的cue文件。两者可以用cuetools和mkcue互相转换。
1.6.wav
wav文件又叫做PCM编码格式。这是一切音乐的基础。无论你是哪种格式，最后都会被还原成wav的某种格式或者变形，才能够从声卡中播放出去。当然，midi的情况特殊，不在此列。
1.7.iso
iso也不是音乐文件，但是和音乐的关系非常密切。大家都知道iso是光盘的镜像，其实说的还不确切。iso本身就是光盘内容严格1字节比1字节复制的结果。至于有的为什么有其他格式。那就涉及光驱设备工作和数据流／加解密的问题了。
另外说一个iso的问题，大家知道linux下面挂载iso的指令是
# mount -t iso9660 -o loop file /mnt  这其实是两个步骤，一个是</description>
    </item>
    
    <item>
      <title>Helix关键提示</title>
      <link>http://shell909090.org/blog/archives/314/</link>
      <pubDate>Mon, 07 Aug 2006 04:56:28 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/314/</guid>
      <description>今天被整死了，好久不用Helix，结果细节忘记光了。
开启Helix后的测试是http://localhost:port/admin/index.html，其中port是安装时候指定的管理端口。然后要输入安装时候指定的用户和密码。开的开吧——那就用不着它了。
在HelixProducer中的设置是Push, user &amp;amp; pass，然后用户和密码就填写管理员的（要么刚刚的管理界面里面自己新建一个去）。端口改安装时候设置的http端口，千万别搞错了。path可以不写，传输方式UDP。最后要记得流名字。
然后我们的点播URL就是rtsp://ip:port/path/filename。port是你指定的rtsp端口，path是HelixProducer指定的，不写就没有，filename是流名字。
希望大家顺利吧。</description>
    </item>
    
    <item>
      <title>论linux引导过程</title>
      <link>http://shell909090.org/blog/archives/308/</link>
      <pubDate>Thu, 13 Jul 2006 23:36:57 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/308/</guid>
      <description>keywords
引导过程, initrd, init, rc
copyright
Shell.E.Xu撰写，按GPL发布。
abstract
简要介绍了引导流程的流转。
main
1.grub&amp;amp;lilo
引导的第一步，是启动引导管理器。这个种类非常复杂，从最早的MBR+专用引导扇区到现在的NTLDR,LILO,GRUB，大小和功能都有非常大的变化。但是主要来讲目的都是一样的。当今引导程序一般都分两个部分，引导扇区和主引导模块。NTLDR来说，C:NTLDR文件即是主引导模块。GRUB的主引导模块在/boot/grub/stage2，至于引导扇区，不用太过关心的。
主引导模块在加载后都会读取引导配置文件，当代流行引导管理器其实都有命令交互功能，可是你总不能指望每次启动都先敲堆命令吧。GRUB来说，配置文件是/boot/grub/menu.lst。注意，GRUB是在启动的时候读取配置的，但是LILO是根据配置来安装的。所以LILO在改变配置的时候需要重新安装。
2.vmlinuz&amp;amp;initrd
引导管理器会自动的将vmlinuz安置在内存中，然后寻找initrd传给vmlinuz。在没有initrd的情况下也可以引导，不过当下的趋势是将引导过程用脚本管理，放置在initrd中。这样引导参数解析，模块加载，设备管理都纳入了脚本的范围内。用linux哪能不会脚本，因此linux引导就有非常强的可以定制特性。
initrd分两种，cpio-initrd和ramfs。这里主要介绍
cpio-initrd。cpio-initrd的建立方法很简单，我上篇文章中有介绍。大致来说，就是把一些内容打包备份而已。vmlinuz会启动根下面的init脚本，我下篇文章会专门解析debian中配置的initrd.img的init脚本。现在大致说下。
init首先建立两个目录，建立/dev系统，并且建立null和console文件，否则udev的运做会出错。然后解析引导参数，解析到每个变量。而后依次运作init-top,init-premount,init-bottom（这些目录内的文件）。在init-bottom运行前会运行包含指定的脚本，这个脚本由BOOT参数指定，并且内部包含mount函数。这样可以通过指定BOOT参数定制mountroot的过程。最后是迁移大部分的系统过去（主要是/sys和/proc），最后通过run-init直接chroot和init。
3.init&amp;amp;rc
init运行的开始，会寻找inittab。其中指定了系统的很多特性，最主要的是runlevel。首先是寻找/etc/init.d/rc并且运行，并且把运行级别作为第一参数传递。然后rc会寻找/etc/init.d/rcS和/etc/default/rcS，如果有的话则包含或者运行。然后rc会以参数S运行自身，过程和正常启动一样。这个作为基础启动参数，无论你以何种级别运行都会运行rcS.d里面的脚本。
4.service
service启动的时候，是用rc?.d的脚本启动的。多数会用start-stop-daemon作为另外一个身份启动成守护进程。
5.bash&amp;amp;gdm
6.conf files
reference:
[1].</description>
    </item>
    
    <item>
      <title>debian live</title>
      <link>http://shell909090.org/blog/archives/307/</link>
      <pubDate>Tue, 11 Jul 2006 09:10:46 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/307/</guid>
      <description>准备做debian
live了，期间有什么东西都会写在这里。大致来说就是打算实践一个项目。
copyright
Shell.E.Xu撰写，按GPL发布。
abstract
用debian3.1testing为基础建立live cd。128M以内，无X系统，无交换区和/tmp，使用内存盘。
target
用于挂载ext3 ntfs vfat文件系统，实施文件系统管理和修复，访问文件系统内容并修改。
注：准备特别针对3721，yahoo助手之类类似rootkit的东西实施扫描清理。
environment
debian 3.1 starg testing（貌似是废话）
grub stage2_eltorito支持光盘启动
linux-kernel-2.6.15-8 直接使用deb包中内容
initrd 在kernel包中包含
step by step
1.建立基础文件系统并且复制所需文件
建立~/syscd/boot/grub/，复制menu.lst stage2_eltorito文件过去。
复制vmlinuz system.map config到~/syscd/boot中，注意ISO9660格式中文件名不能过长（多少记不清了）。
复制/lib到~/syscd/lib，并且调节内容。（我个人在其中添加了我需要的nVIDIA显卡驱动）
2.grub和iso
cd \~ mkdir initrd #关于initrd的原理生成和使用后面讲 mkdir root #这个是用于内存的镜像内容 mkdir cramfs #这个是只读镜像内容 vi \~/testsyscd ------------------我是邪恶的分割线-------------------- #!/bin/bash qemu -no-kqemu -cdrom \~/syscd.iso -boot d &amp;gt;/dev/null ------------------我是邪恶的分割线-------------------- chmod 755 \~/testsyscd vi \~/mksyscd ------------------我是邪恶的分割线-------------------- #!/bin/bash COMPRESS_MODE=-9 cd \~ # block of create initrd.</description>
    </item>
    
    <item>
      <title>linux中文说</title>
      <link>http://shell909090.org/blog/archives/306/</link>
      <pubDate>Sun, 02 Jul 2006 19:18:31 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/306/</guid>
      <description>linux号称可以支持全部语言，其实细节上还是有不少问题的。具体情况大致是这样的，linux的中文支持分三部分，locales，字体，设置。
首先是locale的部分，这个最简单不过，用root运行dpkg-reconfigure locales，然后选择你需要的解码方式，最后再设定系统默认语言（这个是可以修改的），就OK了。
然后是字体，字体的设定比较复杂，不过在debian中安装所有中文桌面的字体就可以了。不用自己去绞尽脑汁。
最后是设定，这个比较复杂。因为可定制性非常好的系统，无法避免要用大量的脚本来定制。如果可定制性差，相信你也不会用了。和中文相关的设置大致有一下几个，针对debian系统。
/etc/default/gdm:LANG=zh_CN.GBK #gdm登录时候的locales
/etc/default/locale:LANG=zh_CN.GBK #这个是系统默认登录的locals，如果你使用命令行登录就是使用这个的
/etc/environment:LANGUAGE=&amp;ldquo;zh_CN:zh:en_US:en&amp;rdquo;
/etc/environment:LANG=zh_CN #这个是登录进入X后的设置，你运行的所有程序基本都是使用这个
dpkg-reconfigure locales的默认语言设定修改的是/etc/default/locale，所以对X登录进去后的程序不一定起作用。一般情况下这zh_CN的设定就通吃了，不过有的时候有点小BUG，例如term下面vi后退出，就变成看不懂的乱马了。这个时候要重设屏幕才可以恢复。而且在输入的时候没有——的，很多东西也看不到。所以我改成了zh_CN.GBK，然后出现了两个问题。
一个是gvim不运行了，这个看了看别人，这么解决。
----------------------\~/.gvimrc----------------------- set encoding=gb2312 set langmenu=zh_CN.GB2312 set imcmdline source $VIMRUNTIME/delmenu.vim source $VIMRUNTIME/menu.vim ---------------------------------------------------------  保证这个文件里面有这些内容就可以了。
然后是gtk1.X的程序都不正常了，主要是xmms和audacity。这个看了人家忽悠半天，最后这么解决的。
-----------------/usr/bin/env_zh_CN--------------- #!/bin/bash LANG=zh_CN exec $@ ----------------------------------------------------------  然后chmod a+x /usr/bin/env_zh_CN
再修改所有运行语句成env_zh_CN xmms
我修改了两处。
世界基本就清静了。</description>
    </item>
    
    <item>
      <title>debian的桌面研究（二）－－完美桌面</title>
      <link>http://shell909090.org/blog/archives/295/</link>
      <pubDate>Fri, 31 Mar 2006 19:46:43 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/295/</guid>
      <description>一个系统好不好，不是看他崩溃频率（除非崩溃得比9X还欢），也不是看精美程度（除非比MAC还夸张比windows还花哨看界面就像在看美国大片），而是看功能，看应用程序的多少。linux下面要流畅的工作，大致需要以下几个软件。
firefox gaim lumaqq azureus xmule xmms office eclipse
下面逐个讲解安装过程：
firefox：著名的浏览器，功能强劲方便安全
1.aptitude里面找，安不上的纯粹RPWT。
2.debian里面firefox的最新版本是1.0.2,不过网络上面出到1.5了，而且还是比较稳定的。如果要自行升级的请看下面流程，当然，首先先下个firefox的包。
tar -zxvf OOXX.tar.gz chmod -R 755 firefox/ mv firefox /usr/share gedit /usr/share/applications/firefox [Desktop Entry] Encoding=UTF-8 Name=firefox Exec=/usr/share/firefox/firefox Icon=/usr/share/firefox/..#你自己看什么合适吧 Terminal=false Type=Application Categories=Application;Network; StartupNotify=true  gaim：聊天程序，要上msn/icq的找他
aptitude里面找，安不上的纯粹RPWT。
lumaqq：聊天程序，上QQ4linux的
安装比较麻烦，首先要安装java4linux。下面我要装eclipse，所以用的是jdk，用jre的也差不多处理。
xmms：音频播放，linux下面的winamp
aptitude里面找，安不上的纯粹RPWT。
PS，gnome的菜单包是menu-xdg，放置位置/usr/share/applications，模版如下
[Desktop Entry] Encoding=UTF-8 Name=程序名称 Exec=执行代码 Icon=图标 Terminal=false Type=Application Categories=Application;Network;Develope; StartupNotify=true  根据需要修改添加就可以了。
PS，其实还有两个，realplay和mplayer，不过这两个程序正常debian用的话有点小问题，所以放到下篇说了。</description>
    </item>
    
    <item>
      <title>debian的桌面研究（一）－－精简安装</title>
      <link>http://shell909090.org/blog/archives/294/</link>
      <pubDate>Fri, 31 Mar 2006 19:18:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/294/</guid>
      <description>debian应该算是一个比较方便的OS，100M的安装盘就可以自动安装。不过最近debian出了点小小的bug，所以安装过程也要有点技巧的好。下面所说的所有系统都指debian3.1sarge，去年五月出品，是目前最新的版本。
问题出在一个系统核心的更新上，如果默认安装的话就全部都会失败。所以应该在安装的时候中断所有安装更新动作，不安装任何桌面和服务，直接完成安装进入系统。然后更改/etc/apt/source.list加入所有你想要的源（这样安装的速度会比原来快很多），然后运行aptitude -o APT::Force-LoopBreak=1。update一下，有什么可以更新的全部更新上，再选中最新的合适使用的内核和源码（对stable和testing来说，debian的最新发布内核已经没有什么瑕疵可能存在了），然后安装。这个过程大约要下载70-100M的东西，端看你什么时候跑的安装。我这里大约是三刻钟就跑完了下载安装。重启下，用最新内核启动，然后卸载旧内核（不重启的话会非常罗嗦，而且不安全）。这样整个可用系统的最小版本就出来了，装机大约是一个钟头。
然后是桌面环境了，在aptitude里面，选择以下包vim gnome mc x-system-core im-switch gaim选中，然后再选择所有中文桌面和环境（不要用的输入法可以去掉点），这样大约有350M上下的文件需要下载，整个过程约会持续三个钟头。其中设置就不具体说了，不过系统还需要做以下更改。
首先在/etc/X11/xorg.conf里面将mouse类型改成ImPS/2，模拟三键去了。然后修改/etc/X11/xinit/xinput.d/default文件，加入以下内容。
GTK_IM_MODULE=SCIM XIM=SCIM XIM_PROGRAM=&amp;quot;/usr/bin/scim&amp;quot; XIM_ARGS=&#39;-d&#39;  这样基本来说系统就ok了。</description>
    </item>
    
    <item>
      <title>linux2.6.14-3内核编译与安装,iptables1.3.4与模块</title>
      <link>http://shell909090.org/blog/archives/273/</link>
      <pubDate>Mon, 12 Dec 2005 19:18:38 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/273/</guid>
      <description>这次讲的是贝壳的一次比较顺利的经历，安装linux2.6.14-3内核。并且在其上使用iptables时出现问题和解决的方法。
cd /usr/src tar -zxvf linux... ln -s linux... linux cd linux make mrproper make menuconfig make dep make bzImage make modules make modules_install mkinitrd initrd-2.6.14-3.img 2.6.14.3 cp initrd-2.6.14-3.img /boot cp System.map /boot/System.map-2.6.14-3 cp arch/i386/boot/bzImage /boot/vmlinuz-2.6.14-3 cp .config /boot/config-2.6.14-3 cd /boot vi grub/menu.lst  以上就完成了内核编译的工作，按照经典流程走的，没有啥问题，问题在后面。
重启，然后运行到iptables的时候报错。所以升级两个东西，iptables-1.3.4和module-init-tools-3.2.2。然后发现还是有问题。然后我打入lsmod。发现什么模块也没有，这样不出错才见鬼了呢。多试验几次，可以发现要加载iptable_filter模块。而他又依赖于ip_tables模块。OK，用modprobe加载。再启动，还是报错。
仔细看看设置，是在REJECT行报错，所以应该是加载REJECT模块，ipt_REJECT。成功，加载的具体方法是在/etc/init.d/iptables里面添加。
/usr/local/sbin/modprobe -a ip_tables iptable_filter ipt_REJECT  很简单吧。</description>
    </item>
    
    <item>
      <title>apache2服务器证书生成过程</title>
      <link>http://shell909090.org/blog/archives/272/</link>
      <pubDate>Tue, 06 Dec 2005 19:42:04 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/272/</guid>
      <description>首先为 CA 创建一个 RSA 私用密钥
openssl genrsa -des3 -out ca.key 1024  利用 CA 的 RSA 密钥创建一个自签署的 CA 证书（X.509结构）
openssl req -new -x509 -days 3650 -key ca.key -out ca.crt  首先为你的 Apache 创建一个 RSA 私用密钥
openssl genrsa -des3 -out server.key 1024  用 server.key 生成证书签署请求 CSR
openssl req -new -key server.key -out server.csr  签署证书
openssl x509 -md5 -days 3560 -req -signkey server.key -CAcreateserial -CAserial ca.crt -in server.csr -out server.crt  最后apache设置，将下面的参数改为</description>
    </item>
    
    <item>
      <title>AS3下安装resin出错</title>
      <link>http://shell909090.org/blog/archives/270/</link>
      <pubDate>Tue, 06 Dec 2005 17:17:59 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/270/</guid>
      <description>make不通过
出错如下
clude/linux -I../common -DCPU=&amp;quot;i386&amp;quot; -DOS= -c -o ssl.o ssl.c In file included from /usr/include/openssl/ssl.h:179, from ssl.c:62: /usr/include/openssl/kssl.h:72:18: krb5.h: No such file or directory In file included from /usr/include/openssl/ssl.h:179, from ssl.c:62:  解决方法：
export LOCALDEFS=&amp;quot;-DOPENSSL_NO_KRB5&amp;quot; export C_INCLUDE_PATH=&amp;quot;/usr/kerberos/include&amp;quot;  引用自http://www.thinkjam.org/meteor/archives/2005/04/as3resin.html</description>
    </item>
    
    <item>
      <title>debian上配置基于apache2的resin</title>
      <link>http://shell909090.org/blog/archives/266/</link>
      <pubDate>Tue, 29 Nov 2005 00:26:52 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/266/</guid>
      <description>别的不说了，先用debian自带的apt安装apache2,记得安装dev部分，还有libapr0,libapr-dev,libapr0-dev。千万别忘记安装后面的部分，否则你在下面编译的时候就要出现问题。
拿到resin，放在目标目录下面，然后tar -jxvf。完成后用ln -s做一个链接上去，使用resin的名字，这样可以方便的替换版本。然后在主目录下面运行./configure，make一下。一般来说，会出不少错误，最后生成一个libresin.so放到libexec下面，并且更新了resin的主执行程序。这个so很具有迷惑性，开始贝壳就被他骗了。这个so貌似是resin在本地平台下的加速程序，而不是嵌入到apache系列服务器中的整合插件。其中最大的差异是没有caucho_module导出符号，在apache加载的时候肯定会失败。
跑到src/c/plugins/apache2下面运行make。可能会报错，可能没有。贝壳这里报了错，不过贝壳运行configure的时候没有加任何参数，也许加了参数就正常了。如果不正常，出错的代码可能分别是httpd.h找不到或者apr_time.h找不到。运行vi Makefile，看到有INCLUDE的目录吗？那里面要包含/usr/include/apache2和/usr/include/apr-0两个目录，没有就肯定出错。好了，修改然后重新make。得到的文件是mod_caucho.so。将它cp到$RESIN_HOME/libexec下面，这个动态库导出了caucho_module符号。
在/etc/apache2/httpd.conf里面编辑一下，添加这个内容。
LoadModule caucho_module /usr/resin/libexec/mod_caucho.so &amp;lt;IfModule mod_caucho.c&amp;gt; CauchoConfigFile ......../resin.conf &amp;lt;Location /caucho-status&amp;gt; SetHandler caucho-status &amp;lt;/Location&amp;gt; &amp;lt;/IfModule&amp;gt;  在/usr/resin/conf/resin.conf里面，添加这些内容。
&amp;lt;doc-dir&amp;gt;/var/www/htdocs&amp;lt;/doc-dir&amp;gt; &amp;lt;war-dir id=&#39;/var/www/htdocs&#39;/&amp;gt;  在/etc/apache2/sites-available/default中可能要修改如下配置。
DocumentRoot /var/www/htdocs/ &amp;lt;Directory /var/www/htdocs/&amp;gt;  然后注销
RedirectMatch ^/$ /apache2-default/  OK，这样就基本完成了整个系统的整合配置。</description>
    </item>
    
    <item>
      <title>Linux内存计数详解</title>
      <link>http://shell909090.org/blog/archives/264/</link>
      <pubDate>Thu, 24 Nov 2005 23:53:35 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/264/</guid>
      <description>又中计了……
近几天用oracle，发现oracle狂用内存，经常内存小到10M的规模。汗一个，赶快让经理买了新的1G内存来装，上去后发现根本认不出来。加班一多小时才发现386内核根本不认高端内存(HIGHMEM)，所以内存极限一直是896M。以前是1G内存，所以看不出来，现在换了1.5G，看出来了。
赶快上了一个2.6.12-1-686的内核，然后重启，认出来了。不过free还是只有32M左右，我们大惊小怪的打电话到oracle那里去咨询，得到的答复是要安装完整的补丁，并且要用oracle认证过的服务器。oracle认证了啥服务器？RedHatEnterpriseAS3/4,那个东西要收费的，而且绝对不便宜。最后无奈，做了一次不启动oracle的测试。出乎我们意料的，mysql吃了多数的内存。具体造成这种状况的原因是啥呢？
偶查阅了linux内存管理资料，发现linux的内存管理计数上讲的东西和windows讲的有很大差异。下面具体列举下几种计数、查看方式和含义。
total mem，可以用top free查看出来。
free mem，可以用top free vmstat查看出来。
used mem，可以用top free查看出来.
buffer mem，可以用top free vmstat查看出来。
shared mem，可以用free查看出来。
swap mem，可以用top查看出来。
swap used，可以用top vmstat查看出来。
cached mem，可以用top free vmstat查看出来。
active mem，可以用free vmstat -a查看出来，即cached used。
inactive mem，可以用free vmstat -a查看出来，即cached free。
其中total mem是除去系统外的可用内存，系统大约占1M多。然后分配给free mem和used mem。used mem又包括了内核表使用（例如GDT），程序使用，buffer，cached。所以
cached mem=active mem+inactive mem
total mem=free mem+used mem
used mem=内核表使用+程序使用物理内存+buffer mem+cached mem
略去内核表使用，这个式子可以变形成这样：
程序使用总内存=swap used+程序使用物理内存
=swap used+used mem-buffer mem-cached mem
=total mem-free mem+swap used-buffer mem-cached mem</description>
    </item>
    
    <item>
      <title>C&#43;&#43;语言跨系统编程</title>
      <link>http://shell909090.org/blog/archives/263/</link>
      <pubDate>Wed, 23 Nov 2005 03:38:06 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/263/</guid>
      <description>首先我们给这个话题增加一个基础，就是您的C++代码没有用到native的部分。具体哪些部分我会列出让你慢慢检查的，不过用到了还想跨平台，你做梦去吧……
我们假定你代码是在windows的VC++下面写的，因为VC++的转换过去有点麻烦，反向的转换基本可以自动生成。
首先请检查你的头文件依赖性，如果是引用了标准的头文件，那么不需要额外的设定。一般g++的设置中都会自动设定标准的头文件和库。如果引用了某个自己写的文件，那么请检查相对路径是否正确。尤其请着重检查大小写。因为windows不会管大小写的，但是却会将大小写带入*nix。
另外VC++中有一个头文件预编译的加速选项，默认是开启的。将stdafx.cpp(which is empty)预编译次，就得到了stdafx.h的编译结果。在*nix里面我目前还不知道怎么支持，所以stdafx.cpp可以不用理会。
然后请检查标准函数，部分VC++声明在STDLIB.H中的函数其实是VC自带的。用这种函数的结果就是编译100%的失败。遇到这种函数可以自己写一个代替，反正一般都不是特别麻烦。
另外一般不需要关心数据类型和端点型，多数库文件中都会自动处理。不过两种情况需要手工干预。一个是程序中使用了windows特有类型例如DWORD或者linux特有类型le32。这样用typedef重新定义就好了。还有就是跨平台的时候连同芯片类别一起跨过去。这样就要手工确定所有库文件会自动处理数据类型，并且人工定义一组会使用的数据类型扩展宏来处理跨平台的问题。最明显的例子就是int在不同平台的大小问题，对此还有一个特殊的建议就是使用char short long来代替，这三者在所有系统上的长度是相同的。
下面是使用sh脚本来编译代码。其实可以使用make文件来做的，不过俺不会。所以用sh来做好了，反正一般跨平台的程序都不会过于复杂，凑合下就过去了。
g++的编译对象一般是cpp文件，如果是一般的可执行文件，那么编译的指令是g++ *.cpp -o oufile。我这次编译的对象是共享库，所以指令是g++ -shared*.cpp -o outfile。
g++处理extren的比较特殊。如果extren在编译成目标文件时还没有指定链接到哪个符号，那么g++就自动将这个定义为从动态库中引入。不过多数情况下，这应该会出错的。所以要多个cpp文件一起编译，或者使用-c编译到.o文件后再ld起来。否则单个cpp的编译结果根本无法使用。
如果需要使用少量native的方法，也可以按下面说的方法跨平台。
在VC++中定义一个win.cpp，其中将native的方法封装成函数。在主程序中使用C++标准函数和这些函数。
在linux中定义一个linux.cpp，然后用linux的native函数实现对应的函数。在编译的时候略过win.cpp。
VC++中工程引入的时候不要加入linux.cpp。
这样可以保证在两个系统下分别对应不同的函数，当然更好的方法是使用平台相关宏。
附录1，windows下的专有编程技巧：
使用了nativeAPI的绝对无法移植，它们有的甚至无法跨越2000/XP的差异。
使用windowsAPI的，一般不可以移植。这类API多数声明在windows.h中。
使用winsock的没有希望啦，要用socket2才可以。winsock的特征是WSAStartup。
使用了__try{的无法移植，而try{可以。前者是SEH的捕获模块，后者是C++异常捕获模块，在windows下异常捕获是用SEH实现的，不过linux下面不是。linux根本没有SEH。
使用了windows或者VC专用宏的无法移植。
使用C++库和std库的可以移植，包括cout。
使用STL可以移植，不过注意平台差异性。
附录2，linux项目在VC++中引入的方法。
新建一个工程，然后copy所有源代码到工程下面。再然后添加文件到工程，然后F7编译。over</description>
    </item>
    
    <item>
      <title>Debian GNU/Linux下安装Oracle 9i</title>
      <link>http://shell909090.org/blog/archives/262/</link>
      <pubDate>Mon, 21 Nov 2005 21:58:01 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/262/</guid>
      <description>最近因为工作需要，在Debian GNU/Linux安装了Oracle 9i。Debian代号sarge，版本号release 3.1，testing发行。Oracle代号9ir2,版本号9.2.0.4。安装文件名称为ship_9204_linux_disk1.cpio.gz ship_9204_linux_disk2.cpio.gz ship_9204_linux_disk3.cpio.gz。需要一个补丁，文件名为p3006854_9204_LINUX.zip。Oracle 9i安装的是Enterprise Datebase。
先执行以下脚本：
#! /bin/bash #变更内核参数 cd /proc/sys/kernel #1G内存状况，按照需要调整 echo 4294967295 &amp;gt; shmmax touch /etc/rac_on #增加一个link，debian需要 apt-get install libstdc++-glibc ; 或者使用aptitude cd /usr/lib ln -s libstdc++-libc6.2-2.so.3 libstdc++-libc6.1-1.so.2 #增加用户 cd /home mkdir oracle groupadd dba useradd -g dba -d /home/oracle -s /bin/bash oracle #注意-s参数，如果不指定下面的初试化脚本不一定跑的起来 passwd -d oracle chown -cR oracle:dba oracle cd /usr mkdir oracle chown -cR oracle:dba oracle cd /var mkdir oracle chown -cR oracle:dba oracle #增加初试化脚本 cd /home/oracle echo &amp;quot;export DISPLAY=&#39;&#39;&amp;quot;&amp;gt;.</description>
    </item>
    
    <item>
      <title>被骗了</title>
      <link>http://shell909090.org/blog/archives/256/</link>
      <pubDate>Tue, 08 Nov 2005 06:20:32 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/256/</guid>
      <description>如果这个代码出现在linux内核里面，你们怎么想？
subtypes[n].parse(state, bdev, START_SECT(p)*sector_size, NR_SECTS(p)*sector_size, slot);  很像是对象数组调用方法吧，很多人可能甚至会猜想这个东西是虚函数。问题是，大家记得吗？linux内核，是C的！
事实上，这是声明。
static struct { unsigned char id; void (*parse)(struct parsed_partitions *, struct block_device*, u32, u32, int); };  怎么想？这个是方法映射。技术上讲，和虚函数属于同种类的应用（dymanic binding）。当然，数据结构有差异。虚函数要先根据n确定对象位置，根据v_ptr确定虚函数表，根据虚函数表定位了函数入口。而这里是根据n定位了对象，然后直接找到了函数入口。
可是，还是被骗了……
PS.谨以此纪念首次在GNU/GPL下引用Linux内核源码用于程序开发，因为分区系统资料该死的不清楚！</description>
    </item>
    
    <item>
      <title>精简debian和服务器</title>
      <link>http://shell909090.org/blog/archives/249/</link>
      <pubDate>Mon, 31 Oct 2005 19:36:26 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/249/</guid>
      <description>最近在用单位的1G电脑跑debian，不开gnome的情况下真是快啊。长期安装debian（其实才几个月），所以对debian的安装有点心得。准备精简打包一个最小debian，用于拯救和安装。然后cache一个pool做移动使用。这样以后用起来应该方便点。
debian上面装别的问题不大，但是装oracle的时候头痛的要死。难怪oracle一般要和solaris一起安装，而DB2一般捆绑在AIX上面。这种东西换个系统简直就是要了命了。</description>
    </item>
    
    <item>
      <title>北京游记三.中关村，MP3和数码相机</title>
      <link>http://shell909090.org/blog/archives/218/</link>
      <pubDate>Fri, 07 Oct 2005 02:44:10 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/218/</guid>
      <description>10月3日星期一，按照别人的逻辑，去了北京不能不去天安门。那么按照我的逻辑，回到北京就不能不到中关村。这种事情如同朝圣者于麦加，就算知道去了只能看到人山人海，但是沾点灵气总是好的。中关村其实我蛮熟悉的，即使高中同学，除去几个家在海淀的，剩下的人考入清华也不过是四年的事情。我第一台电脑就在中关村被黑的，因为这个事情经常跑过去，严格算来已经有七年以上时间了。不过其实去中关村的时间越短，对它越熟悉。因为如果对比七年前的记忆，你恐怕会一路走到园明园。一个四车道乘四车道的十字路口，现在改建成了立交。北四环和中关村大街的交接点，北大和清华的分水岭，海龙旁边，中关村的核心地带。我的旅程就是从这里开始的。
海龙在三四年前就建了，不过现在还是一样火。进去问了几个报价，不知道是节日宰人，我比较像傻瓜，还是北京上海差价。中关村的报价居然比上海还高。顺便问了服务器报价，真TMD不是人，最精简配置需要壹万以上。这个价格我宁可拼两个并行服务器，如果可以的话。虽然开始不准备买东西，不过最后挡不住诱惑，买了一个MP3。自我催眠说数码相机去上海用信用卡买好了。结果老妈给我一个更大的诱惑，直接买一个给我。这么嘛……还是后面再说好了。
海龙逛完去了鼎好，这里最让人爽的就是顶楼的美食。以前去中关村吃饭不方便，这里建好以后我一直来这里吃。嘿嘿，其实也就是两年的事情。这里一般十块一个人就能吃到不错的东西，二十可以吃的翻过来。正好中午，先撮顿攒的。然后去下面乱逛，想起赵一博个家伙让我给带东西。于是上taxi跑双清路，找了半天，等了半天，总算将他要的东西带到手。问问邮寄价格，NND亏大了。我28车钱不算手机，邮寄才20……
最后坐车跑回海龙，逛了下以前的中海电子市场，现在已经关了。很多以前东西现在也找不到了。最后兴趣索然，照了两张就回去了。
10月4日星期二，老妈给了我一个超级的诱惑，直接送我一个数码相机。说实在我希望在上海买，这样一年内保修方便。事实证明我的却有远见，不过远见比不上东西，还是被诱惑了……
老爸先是开车直接到了北航对门的百盛，进去才发现这种地方也能叫卖场？超市差不多！可是我们的消费卡只能这里消费，所以老妈就贴了一块钱（女人的算计是很可怕的，重复让你试衣服更可怕，在此敬告天下王老五三思），买了几件衣服。然后转去亚运村东面的华堂，这里到是东西够多了。可是中关村2300的东西这里买快4000，只有神经病和有毛病才会这么买东西。干脆，老妈再买了点衣服，买点电池回家。最后没有办法，我领父母去中关村鼎好。说起来老爸在北京开车，道路应该比我熟悉很多。可是中关村这里他想停车吃饭买东西绝对只能拜我下风。
我们跑到一家公司去买数码相机，说到这里我就觉得似乎被坑了。毕竟电脑熟悉数码相机不熟悉，之前又没有在网络上查过报价。家里的电脑坏了，磁道损坏。只有2000原版安装盘情况下能装好已经非常厉害了，能驱动上网更难。不过要用小猫当宽带你还是打死我吧。还有一个PDA，不过只能查SD卡速度，而且还没电池了，要买。所以没有带去，造成中招。
话说数码相机是非常好的，可是相机不带SD卡和备用电池。所以配了一对。但是根据回来后测算的结果，卡是四速读取0.1速写入，而我的低速卡也有1.3速读取2.1速写入。不对称嘛！难怪每次照相都要等很久。备用电池更扯淡，压根充不进去。所以干脆和发票留在北京让老妈回头去换了。唉，要是在上海敢玩这手，我弄死他们。
现在数码用的是我的PDA上的SD卡，还要专门由数码相机格式化，否则老出异常。搞的我PDA还需要重装。电池就用的主电池，南浮跟本顶不住。唉……</description>
    </item>
    
    <item>
      <title>Windows系统引论</title>
      <link>http://shell909090.org/blog/archives/190/</link>
      <pubDate>Wed, 13 Jul 2005 23:15:09 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/190/</guid>
      <description>最近在开linux系统，找找发现资料那个叫……哎。到不是说少，linux号称开放源码，想要什么没有阿。问题是精论系统结构和意义的很少，一般都是讨论某个技术点如何如何的。没有大略的瞻观（当然，也有可能是英文，贝壳的E文水平看了等于没看到）。而一般系统中要做某个应用，除了经验，就是根据系统的运作方法、构架、原理等等去模拟。例如了解了file
HANDLE这种东西后，自然会就如何将一个HiddenConsole的Output转Dump到一个windows的text中产生想法。或者了解了[\.]()系列文件后，自然会想到如何制作的ISO。当然，其实还有ATAPI的方法。如果了解了winsock的层实现流程，自然会知道防火墙如何实现。所以了解一个系统，无须了解内核的每句代码（对于windows，根本无法了解。即使是linux，了解了全部也要数年。届时你了解的也该淘汰了。）。系统主要了解其构架和思想，关键部分才了解实现。
现在看linux系统，犹如隔纱而望。当然，系统的命令我了解了不少（其实了解了ls和man已经差不多了）。但是每个命令是哪里的？系统的目录如何设置？什么配置应该看什么地方。linux载入进程是如何实现的。（估计这个是ELF的范畴，不过肯定要先啃过内核在看的懂。否则就如同我当年不知道NativeAPI的时候看NE和PE一样）
所以现在写一个windows系统引论，希望抛砖引玉。毕竟windows的资料全，了解时间长。所以难保还有哪位大大也写过类似文章，大家姑且看之吧。</description>
    </item>
    
    <item>
      <title>debain</title>
      <link>http://shell909090.org/blog/archives/168/</link>
      <pubDate>Tue, 31 May 2005 20:54:40 +0800</pubDate>
      
      <guid>http://shell909090.org/blog/archives/168/</guid>
      <description>根据babylon的结果，没有debian这个词。根据我的拼音加加的结果，debian打出来是“得便”的意思。而事实上……debian是一个linux的版本。
不过我很奇怪了，why所有的linux发行版本都这么大呢？windows2000的发行版本是4in1，四个版本合一张光盘。而RedHat9的发行版本是1in3，一个版本放了三张光盘……这个居然还好意思号称内核精简。windows的内核严格说起来也只有2M而已，smss大约100K，Csrss不知道多大，加上NTDLL.user32.Kernel32.win32k.gdi32也没有多大。不过windows组件模型比较大，搞得整个windows貌似比较庞大而已。一般来说，优化过后服务器上大约需要2-3G的分区空间。而一个正常可以跑的linux桌面大致也需要这么多的空间……界面和通用性上还不及。这厢真是郁闷大了。
不过仔细想想，linux和windows的传奇都貌似到了顶点。windows自从2003后就基本没有了声音，就算现在他出什么新版本我会不会买账还是回事情。（2003现在都没有试过呢……）linux出新版本总比windows落后一步，usb如此，摄像头亦如此。加上PDA或者智能手机一类的嵌入设备中越来越多的使用WinCE（就是PPC啦），ActiveSync和windows捆绑的迹象越发严重。linux的路不好走啊。
下面恐怕就是分布式系统了吧，如同我前面所讲。分布式系统相对正常系统具备极大的优势。例如硬盘空间共享，这样利用效率就会上升。软件的安装和维护集成，节约成本。CPU资源共用，有利于承担突发事件，并且方便利用用户使用不了的CPU时间。（例如一个在看网页的人的空闲CPU可以分配给运行大型程序的）不过最大的问题就是保密性、可维护性和网络速度问题。一般来说只有当网络速度和硬盘读写速度量级相当的时候才可以考虑分布系统。目前的接入普遍都不快，只有内部网络貌似可以达到这个级别。100Mbps=12.8MB/s，硬盘大约是30MB/s-60MB/s。尚可以考虑考虑。
分布系统的话首先应当选择微内核，否则不同的机器跑不同的内核岂不乱套。网络部分可能会编译到内核里面来加速。不过最大的问题就是，进程如何跨越机器？如果进程无法跨越机器，那么分布系统啥意思都没有了，干脆上一个DFS算了。如果进程要跨越机器，那么操作台占有，信号，等待，互斥等等就都成了问题。以前可能不明显的互斥问题在网络上就会产生明显效应，不同的互斥算法造成的效率差异会非常显著。
我设想分布系统可能如此实现。网络和文件系统编译入内核来加速。程序的运行都要在中央服务器上启动才行。每个进程会派生出控制端的概念，控制端对应不同的权限。严格来说，控制端是一个亚进程的概念。因为同样一个程序可能又多个机器要运行，例如IE一类的浏览器。如果放出多个进程恐怕太过浪费，但是如果放出一个进程，那么这个进程的权限又不好控制。考虑中是否可以将界面控制部分和程序分立开，成为控制端。控制端具备独立的变量空间和权限环境，对应不同终端上的用户窗口，可以容纳多个线程。或者进一步说，同样代码在不同机器上运行时候，环境理论上应当相同，除了控制端部分的数据应当不同（替换成本地的数据）。这样输出窗口的时候可以输出到不同的窗口上。
理论上说，每个程序应当只允许运行一个Instance。如果有人运行某个程序，则应当建立程序的私有空间，并且初始化程序，察看是否已经在运行中。如果在运行中则自网络上虚拟映射入整个程序。而后初始化控制端，并且派生出本地线程。由本地线程来运作整个程序。程序对非控制端部分的操作都要进行互斥访问……真麻烦。
如果某个机器具备空CPU，而另外一个机器CPU运行满，则将整个进程映射入空闲机器中，包括控制端部分。这样可以用空闲的CPU，当然前提必须是支持多线程，这样才可以移动一个线程过去。不过问题是保密性，还有如果空闲的机器也要运行这个程序了怎么办？这样恐怕就要将线程移动回去，然后清空控制端重新初始化。但是空闲的CPU就无法利用了。
呃……貌似扯的蛮远了，从linux安装失败一直扯到了分布系统……今天就这样吧，郁闷……</description>
    </item>
    
  </channel>
</rss>