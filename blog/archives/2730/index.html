<!doctype html>
<html lang="en-us">
  <head>
    <title>FIN-WAIT-1的问题一例 // Shell&#39;s Home</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.152.2">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Shell Xu" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.3c3c186cd62e563ad6e2f00a89dbee656ab912d1d46f856b5605dd0232521e2a.css" />

    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-WH8XZZ4WLY"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-WH8XZZ4WLY');
        }
      </script>
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="FIN-WAIT-1的问题一例">
  <meta name="twitter:description" content="这是一个早应该知道的事情。但是还是被整了半天。
引子 tcp关闭时有多少个状态？
当当，别数了，应该是6个，不算CLOSED。分别是FIN-WAIT-1/FIN-WAIT-2,CLOSING, TIME_WAIT, CLOSE_WAIT,LAST_ACK。如果不能瞬间想起一个方块来，说明tcp状态不算熟。
问题 今天的故事来自今天BI同事提出的一个问题。在线上，他发现这么一个现象。在一组系统中，客户端全都FIN-WAIT-1了，但是服务器还是ESTAB。
我的第一反应很简单，这明显差了一个FIN包的距离。而且鉴于两者在同一网络中，而且重复出现。建议他首先排查中间的防火墙设备和防火墙设置。
会找上我的问题，当然没这么简单。中间没有任何防火墙或软件防火墙设定。
分析 下一步呢？有点没方向了。抓包分析。发现FIN端向ESTAB端不停的发起ACK，但是看起来和FIN没什么太大关系。
偶然，同事注意到所有出现现象的链接都有写缓冲区数据。这是一个不常见的现象。写缓冲区一般会有点数据，但是应该很快就被消费，而不会长期堆积，更不会长期维持同样的数字。这是写缓冲区满。结合刚刚的ACK，其实本质是对端停止消费数据。
这是一个TCP的边角。当读缓冲区满的时候，tcp协议栈会声明window=0。当读缓冲区恢复的时候，读方会用ack with window来重新宣告可用缓冲区。但是在tcp里，ack是不重传的。所以这个ack会丢失。因此写方有责任定期请求确认读方window，来确定整个过程不会卡死。这就是刚刚看到的不停ACK的现象。
而这里就有个非常重要的可能性——FIN包的处理方式。为此我阅读了源码。源码告诉我们，FIN包被接收到的时候，并不是即时处理的。实际上，在ESTAB状态收到的FIN，正常path下会进入tcp_data_queue。这个函数会将包堆积到队列中，并根据当前seq来处理包。主要包括三种seq，当前包，过去包，未来包。只有在以下两种情况下，fin包才会被处理：
当前收到一个fin包。 当前收到一个包，完成处理后out of order队列中有数据，因而进入tcp_ofo_queue。而队列中有fin包。 而不幸的是，当前包处理流程第一步就是判断tcp_receive_window。如果没空间了，会进入out_of_window过程。后者会快速的触发一个ack返回，然后就把包给丢了。
我猜对了开头，可是没有猜到结局。
结论 通过python的快速复现，验证了这个结论。建立一对连接，其中一个不接收任何数据，而其中一个发送足够长的数据。当读缓冲区满后，再去close，出现一端FIN-WAIT-1，一端ESTAB的现象。
因此，结论如下：
当写缓冲区满之后，收到的fin包会被丢弃，而发送端并不会重发。而只要写缓冲还有剩余空间，哪怕一个字节，都可以正常处理。 内核参数 根据文档，可能有几个内核参数与此有关。
net.ipv4.tcp_max_orphans net.ipv4.tcp_orphan_retries 测试表明，net.ipv4.tcp_max_orphans可以抑制这个现象。当减低这个数值后，再进入FIN-WAIT-1状态的连接会自动消失。ss -natp不能看到连接。有趣的是，如果进程尚未关闭的话，可以在/proc/[pid]/fd下面看到fd仍然存在，而且还可以读出数据。
抓包表明，连接实际是被一个RST干掉的。阅读源码，在tcp_close的最后部分，可以看到tcp_too_many_orphans被调用了。如果超过限制，就会发出reset，并且关闭连接。
而tcp_orphan_retirs，根据我的理解和测试，和这事没有关系。这主要是指这么一种现象：当对端机器poweroff(而不是shutdown)的情况下，你所发出的报文会丢失。因此理所当然的，写者的写缓冲区会很快充满。此时会发起连接探测，以确定对方是不是掉线了。套在close的这个case上，就是一边是FIN-WAIT-1，另一边死不响应。需要通过多次探测来宣告对方死亡。因此，如果对方机器死机导致不响应你的FIN，才是用tcp_orphan_retirs的场合。">

    <meta property="og:url" content="//blog.shell909090.org/blog/archives/2730/">
  <meta property="og:site_name" content="Shell&#39;s Home">
  <meta property="og:title" content="FIN-WAIT-1的问题一例">
  <meta property="og:description" content="这是一个早应该知道的事情。但是还是被整了半天。
引子 tcp关闭时有多少个状态？
当当，别数了，应该是6个，不算CLOSED。分别是FIN-WAIT-1/FIN-WAIT-2,CLOSING, TIME_WAIT, CLOSE_WAIT,LAST_ACK。如果不能瞬间想起一个方块来，说明tcp状态不算熟。
问题 今天的故事来自今天BI同事提出的一个问题。在线上，他发现这么一个现象。在一组系统中，客户端全都FIN-WAIT-1了，但是服务器还是ESTAB。
我的第一反应很简单，这明显差了一个FIN包的距离。而且鉴于两者在同一网络中，而且重复出现。建议他首先排查中间的防火墙设备和防火墙设置。
会找上我的问题，当然没这么简单。中间没有任何防火墙或软件防火墙设定。
分析 下一步呢？有点没方向了。抓包分析。发现FIN端向ESTAB端不停的发起ACK，但是看起来和FIN没什么太大关系。
偶然，同事注意到所有出现现象的链接都有写缓冲区数据。这是一个不常见的现象。写缓冲区一般会有点数据，但是应该很快就被消费，而不会长期堆积，更不会长期维持同样的数字。这是写缓冲区满。结合刚刚的ACK，其实本质是对端停止消费数据。
这是一个TCP的边角。当读缓冲区满的时候，tcp协议栈会声明window=0。当读缓冲区恢复的时候，读方会用ack with window来重新宣告可用缓冲区。但是在tcp里，ack是不重传的。所以这个ack会丢失。因此写方有责任定期请求确认读方window，来确定整个过程不会卡死。这就是刚刚看到的不停ACK的现象。
而这里就有个非常重要的可能性——FIN包的处理方式。为此我阅读了源码。源码告诉我们，FIN包被接收到的时候，并不是即时处理的。实际上，在ESTAB状态收到的FIN，正常path下会进入tcp_data_queue。这个函数会将包堆积到队列中，并根据当前seq来处理包。主要包括三种seq，当前包，过去包，未来包。只有在以下两种情况下，fin包才会被处理：
当前收到一个fin包。 当前收到一个包，完成处理后out of order队列中有数据，因而进入tcp_ofo_queue。而队列中有fin包。 而不幸的是，当前包处理流程第一步就是判断tcp_receive_window。如果没空间了，会进入out_of_window过程。后者会快速的触发一个ack返回，然后就把包给丢了。
我猜对了开头，可是没有猜到结局。
结论 通过python的快速复现，验证了这个结论。建立一对连接，其中一个不接收任何数据，而其中一个发送足够长的数据。当读缓冲区满后，再去close，出现一端FIN-WAIT-1，一端ESTAB的现象。
因此，结论如下：
当写缓冲区满之后，收到的fin包会被丢弃，而发送端并不会重发。而只要写缓冲还有剩余空间，哪怕一个字节，都可以正常处理。 内核参数 根据文档，可能有几个内核参数与此有关。
net.ipv4.tcp_max_orphans net.ipv4.tcp_orphan_retries 测试表明，net.ipv4.tcp_max_orphans可以抑制这个现象。当减低这个数值后，再进入FIN-WAIT-1状态的连接会自动消失。ss -natp不能看到连接。有趣的是，如果进程尚未关闭的话，可以在/proc/[pid]/fd下面看到fd仍然存在，而且还可以读出数据。
抓包表明，连接实际是被一个RST干掉的。阅读源码，在tcp_close的最后部分，可以看到tcp_too_many_orphans被调用了。如果超过限制，就会发出reset，并且关闭连接。
而tcp_orphan_retirs，根据我的理解和测试，和这事没有关系。这主要是指这么一种现象：当对端机器poweroff(而不是shutdown)的情况下，你所发出的报文会丢失。因此理所当然的，写者的写缓冲区会很快充满。此时会发起连接探测，以确定对方是不是掉线了。套在close的这个case上，就是一边是FIN-WAIT-1，另一边死不响应。需要通过多次探测来宣告对方死亡。因此，如果对方机器死机导致不响应你的FIN，才是用tcp_orphan_retirs的场合。">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2015-02-26T00:00:00+00:00">
    <meta property="article:modified_time" content="2015-02-26T00:00:00+00:00">


  </head>
  <body>
    <header class="app-header">
      <a href="//blog.shell909090.org/"><img class="app-header-avatar" src="/avatar.jpg" alt="Shell Xu" /></a>
      <span class="app-header-title">Shell&#39;s Home</span>
      <p>贝壳的壳</p>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">FIN-WAIT-1的问题一例</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Feb 26, 2015
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div>
      </div>
    </header>
    <div class="post-content">
      <p>这是一个早应该知道的事情。但是还是被整了半天。</p>
<h1 id="引子">引子</h1>
<p>tcp关闭时有多少个状态？</p>
<p>当当，别数了，应该是6个，不算CLOSED。分别是FIN-WAIT-1/FIN-WAIT-2,CLOSING, TIME_WAIT, CLOSE_WAIT,LAST_ACK。如果不能瞬间想起一个方块来，说明tcp状态不算熟。</p>
<h1 id="问题">问题</h1>
<p>今天的故事来自今天BI同事提出的一个问题。在线上，他发现这么一个现象。在一组系统中，客户端全都FIN-WAIT-1了，但是服务器还是ESTAB。</p>
<p>我的第一反应很简单，这明显差了一个FIN包的距离。而且鉴于两者在同一网络中，而且重复出现。建议他首先排查中间的防火墙设备和防火墙设置。</p>
<p>会找上我的问题，当然没这么简单。中间没有任何防火墙或软件防火墙设定。</p>
<h1 id="分析">分析</h1>
<p>下一步呢？有点没方向了。抓包分析。发现FIN端向ESTAB端不停的发起ACK，但是看起来和FIN没什么太大关系。</p>
<p>偶然，同事注意到所有出现现象的链接都有写缓冲区数据。这是一个不常见的现象。写缓冲区一般会有点数据，但是应该很快就被消费，而不会长期堆积，更不会长期维持同样的数字。这是写缓冲区满。结合刚刚的ACK，其实本质是对端停止消费数据。</p>
<p>这是一个TCP的边角。当读缓冲区满的时候，tcp协议栈会声明window=0。当读缓冲区恢复的时候，读方会用ack with window来重新宣告可用缓冲区。但是在tcp里，ack是不重传的。所以这个ack会丢失。因此写方有责任定期请求确认读方window，来确定整个过程不会卡死。这就是刚刚看到的不停ACK的现象。</p>
<p>而这里就有个非常重要的可能性——FIN包的处理方式。为此我阅读了源码。源码告诉我们，FIN包被接收到的时候，并不是即时处理的。实际上，在ESTAB状态收到的FIN，正常path下会进入tcp_data_queue。这个函数会将包堆积到队列中，并根据当前seq来处理包。主要包括三种seq，当前包，过去包，未来包。只有在以下两种情况下，fin包才会被处理：</p>
<ol>
<li>当前收到一个fin包。</li>
<li>当前收到一个包，完成处理后out of order队列中有数据，因而进入tcp_ofo_queue。而队列中有fin包。</li>
</ol>
<p>而不幸的是，当前包处理流程第一步就是判断tcp_receive_window。如果没空间了，会进入out_of_window过程。后者会快速的触发一个ack返回，然后就把包给丢了。</p>
<p>我猜对了开头，可是没有猜到结局。</p>
<h1 id="结论">结论</h1>
<p>通过python的快速复现，验证了这个结论。建立一对连接，其中一个不接收任何数据，而其中一个发送足够长的数据。当读缓冲区满后，再去close，出现一端FIN-WAIT-1，一端ESTAB的现象。</p>
<p>因此，结论如下：</p>
<pre><code>当写缓冲区满之后，收到的fin包会被丢弃，而发送端并不会重发。而只要写缓冲还有剩余空间，哪怕一个字节，都可以正常处理。
</code></pre>
<h1 id="内核参数">内核参数</h1>
<p>根据文档，可能有几个内核参数与此有关。</p>
<ul>
<li>net.ipv4.tcp_max_orphans</li>
<li>net.ipv4.tcp_orphan_retries</li>
</ul>
<p>测试表明，net.ipv4.tcp_max_orphans可以抑制这个现象。当减低这个数值后，再进入FIN-WAIT-1状态的连接会自动消失。ss -natp不能看到连接。有趣的是，如果进程尚未关闭的话，可以在/proc/[pid]/fd下面看到fd仍然存在，而且还可以读出数据。</p>
<p>抓包表明，连接实际是被一个RST干掉的。阅读源码，在tcp_close的最后部分，可以看到tcp_too_many_orphans被调用了。如果超过限制，就会发出reset，并且关闭连接。</p>
<p>而tcp_orphan_retirs，根据我的理解和测试，和这事没有关系。这主要是指这么一种现象：当对端机器poweroff(而不是shutdown)的情况下，你所发出的报文会丢失。因此理所当然的，写者的写缓冲区会很快充满。此时会发起连接探测，以确定对方是不是掉线了。套在close的这个case上，就是一边是FIN-WAIT-1，另一边死不响应。需要通过多次探测来宣告对方死亡。因此，如果对方机器死机导致不响应你的FIN，才是用tcp_orphan_retirs的场合。</p>

    </div>
    <div class="post-footer">
    </div>
  </article>

    </main>
  </body>
</html>
