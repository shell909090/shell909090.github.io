<!doctype html>
<html lang="en-us">
  <head>
    <title>云计算的成本计算 // Shell&#39;s Home</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.58.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Shell Xu" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="//blog.shell909090.org/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-48816091-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="云计算的成本计算"/>
<meta name="twitter:description" content="成本构成和计算基准 一般来说，云计算的综合成本会分为三块。硬件，机房（包括机房内网络设施），运维。当然，其实还有IP费用和流量费用。但是那个在云计算的费用中一般也是分开列的，所以可以和以上三项分开算。我们先算出去掉IP和流量的费用，然后再来独立讨论这两项的效应。
在云计算中，CPU是可以超卖的，但是内存一般不超卖。所以我们计算的基准是内存。准确的说，是“带上其他硬件设备的内存”的单位价格。单位是人民币每G每年，缩写为/Gyr。在整个计算中，硬件费用都是来自dell美国的报价计算器，汇率恒定在6.5，折旧速率是5年。存储系统的折旧速度会比整机更快。存储盘3年折旧，SSD1.5年折旧。
存储是硬件成本中比较特殊的一项，因为每个虚拟机都带有存储，也可以额外配置。所以我们单独为其估价，再在整体费用中将其加回去。这样在估算价格时可以计算光板系统。
硬件成本 在这个计算中，我随意挑了一款2U机器——R530。这是一台最低型号的2U机器，不知道有没有人在实际生产中用他，总之我们就先随便算。这台机器极限能插8条32G的内存，总内存量可以高达256G，还是挺适合虚拟化的。因为机器总体有成本，单机内存数越高，原理上说越省钱。
撇开存储，撇开网络，内存升到极限，其实我们能选的就是一颗CPU。而且一般来说，CPU和内存需要成比例搭配。一般会选择1:4的搭配比，256G内存需要64颗核心。整个CPU搭配表上就没这么牛X的CPU。。。
好吧，退而求其次，看看稍微差一点的CPU如何。由于整机搭配的内存和CPU越高，整体价格越便宜。所以我们搭配一颗最牛X的核心——E5-2695 * 2。整个系统瞬间升到56颗核心。和64核也相差无几，我们就选他了。
相对的，整个机器既然配置了这么牛的系统，那么网卡就不能用默认的千兆网卡了。我选了两个双口光纤万兆模块，再加上一个1&#43;1冗余电源。其他都用默认选配。计算下来，每G成本为56.2/Gyr。这差不多就是一个光板机器的最低价格了，里面不带任何其他费用。
另外，为了参考，我们计算一组CPU配足的机型E5-2670 * 2。这颗CPU是24T的，所以要配合192G内存。平均成本为60.47/Gyr。
IO密度问题 上面假定一台机器尽力往里插内存，但是实际上不能这么做。因为存储模型的问题。
我把虚拟化分为两种——单台机器故障的情况下数据不丢失，可以立刻在其他系统上开始启动系统的。和单台故障的情况下无法立刻恢复系统，甚至数据完整性都不能保证的。前者敢叫云计算，后者只能叫VPS。
为了达到后者，一般我们会把写入存放在多台机器上。而为了效率考虑，EC编码之类的方案几乎不能考虑。所以综合下来，唯一的方法就是将数据写入同步到另外两台机器上（三副本）。如果这个复制动作通过网络进行，那么写入速度就受到网络瓶颈。
例如上面的256G机器。虽然我选了两个双口万兆模块，总吞吐量高达40G。但是实际上你得假定可能有一根线故障，可用速率只有30G（如果是一个模块故障，更会降低到20G，幸好这不常见）。30G速率均分给256G内存，平均分给每G的吞吐只有120Mbps/G。折算出来就是15MB/s每G。这个速率要通过两份数据，分别传输给两台机器。如果用户不幸而选择了1G的内存，搞不好写入速度只有7.5M/s。要达到普通系统60M/s的写入速率，至少需要8G内存。这还没有计算机器到机器间通讯速率。
那么解决方案是什么？其中之一就是降低机器上的内存数。当然增加网卡也是一个方案，但是这会严重影响接入系统的效率——我们本来已经出了4根纤了，你想把服务器搞成八爪鱼不成？
如果内存数降低，那么单位内存上的吞吐速率就能提升。192G的吞吐是160Mbps/G，每G写入可达10M/s。内存降到128G的话，平均吞吐率就会升高到240Mbps/G，每G的写入速率可以提高到15M/s。如果降到64G，每G写入速率还会提升到30M/s。不过IO问题是个峰值问题。如果全系统都有大量写入，例如大部分实例都装了数据库，那么很不妙。不过如果全系统都是纯密集计算，那写入速度其实影响并不很大。为了对比，我同样计算了128G和64G的情况。但是这并不表示在实际搭建集群的时候需要使用低内存的机器。
有趣的是，在其他保持不变的情况下，128G的平均成本为59.44/Gyr，和256G的版本相差无几，比192G的版本还便宜些。64G却快速上升到94.25。这说明在一定内存数量以上，硬件平均成本受到内存密度的影响并不大，但是低于某个限制后，则快速受到影响。
另一个方案则是在服务器上采用40G网卡，4块40G网卡也能解决问题。但是网络会非常难做。因为上手就用了普通汇聚层的速率，所以如果要不大影响收敛比的情况下，汇聚和核心的速率要求会进一步提升。这种模型下，单位价格为62.55/Gyr。
当然，还有另一个方案。我们使用独立存储系统，例如盘柜。这样会带来两个好处。首先盘柜的光纤独立，因此会极大的提升网络系统的效率。其次盘柜的多份复制是自行完成的，因此并不需要在吐出光纤上传送两份数据。当然，我对这种方案不熟，所以下面没做深入计算。哪天可以把这个方案的成本模型算出来再写一篇。
下面我总结一遍上面方案的配比和成本：
 256G &#43; 10G * 4: 56.20/Gyr 192G &#43; 10G * 4: 60.47/Gyr 128G &#43; 10G * 4: 59.44/Gyr 64G &#43; 10G * 4: 94.25/Gyr 256G &#43; 40G * 4: 62.55/Gyr  注1：其实192G的版本用R730还会更便宜一些，低到54.40/Gyr。但是我们的目标是同类对比。为了减少环境变量，所以不讨论这种情况。
注2：其实128G的版本由于CPU比较节能，所以整机大约可以节约100W的电力。这部分在下面并没有被考虑，否则可能涉及机柜里会多或者少一台机器，计算会非常复杂。
机房成本 机房成本包括两块，网络设备费用和柜子费用。
网络费用很容易算，一个柜子一般是42U/10A/20A电力。撑死放5-10台服务器。一个服务器两口，也就是10-20口左右的交换机。选个不大夸张的机器，也就是1W差不多了。就算电力翻倍，机器翻倍，交换机价格差不多也是翻倍的。所以平均成本还是基本不变。
核心那里难算一点，一套核心要上百万，摊给全机房用。而且如果机器太多，可能两层交换量不够，还会用三层交换。那还有汇聚层的钱要算，大概又是上百万。
柜子的价格最难算。视地点不同，每个月从几k到十几k不等。每个柜子能放的机器，随电力状况和CPU功耗，从5台到15台(35A)不等。而且很多时候，公司的体量大小和谈判能力也会严重的影响到价格。
所以，为了简化上述计算，我直接硬把机柜价格指定为60k/yr[1]。300个柜子，每个柜子5台设备，1500台机器。核心加汇聚加接入，总数大约600W，每个柜子20k。至于为什么是这个数？不为什么，就是后面好算。
于是很容易就算出来，每机柜每年成本64k/yr。128G下是100/Gyr，192G下是66.67/Gyr，256G下是50/Gyr。40G光纤比10G光纤原则上要贵，因为起手就要用汇聚交换机，而不是接入级的。但是具体贵多少——很遗憾我根本找不到数据。推测是贵了至少5倍。
实际上，由于机房各种配比不一定能够达到最优状况，所以接入模型配比往往会比预期的高上非常多。而且机房成本也不一定能够控制在60k/yr的水平上。所以如果从业界实际角度考虑，这个费用的精确度大约会有20%的上下浮动。
 参考 这篇文档 ，有的地方能租到这么便宜的柜子，有的地方不行。  运维 一套云计算平台，需要多少个人运维？"/>

    <meta property="og:title" content="云计算的成本计算" />
<meta property="og:description" content="成本构成和计算基准 一般来说，云计算的综合成本会分为三块。硬件，机房（包括机房内网络设施），运维。当然，其实还有IP费用和流量费用。但是那个在云计算的费用中一般也是分开列的，所以可以和以上三项分开算。我们先算出去掉IP和流量的费用，然后再来独立讨论这两项的效应。
在云计算中，CPU是可以超卖的，但是内存一般不超卖。所以我们计算的基准是内存。准确的说，是“带上其他硬件设备的内存”的单位价格。单位是人民币每G每年，缩写为/Gyr。在整个计算中，硬件费用都是来自dell美国的报价计算器，汇率恒定在6.5，折旧速率是5年。存储系统的折旧速度会比整机更快。存储盘3年折旧，SSD1.5年折旧。
存储是硬件成本中比较特殊的一项，因为每个虚拟机都带有存储，也可以额外配置。所以我们单独为其估价，再在整体费用中将其加回去。这样在估算价格时可以计算光板系统。
硬件成本 在这个计算中，我随意挑了一款2U机器——R530。这是一台最低型号的2U机器，不知道有没有人在实际生产中用他，总之我们就先随便算。这台机器极限能插8条32G的内存，总内存量可以高达256G，还是挺适合虚拟化的。因为机器总体有成本，单机内存数越高，原理上说越省钱。
撇开存储，撇开网络，内存升到极限，其实我们能选的就是一颗CPU。而且一般来说，CPU和内存需要成比例搭配。一般会选择1:4的搭配比，256G内存需要64颗核心。整个CPU搭配表上就没这么牛X的CPU。。。
好吧，退而求其次，看看稍微差一点的CPU如何。由于整机搭配的内存和CPU越高，整体价格越便宜。所以我们搭配一颗最牛X的核心——E5-2695 * 2。整个系统瞬间升到56颗核心。和64核也相差无几，我们就选他了。
相对的，整个机器既然配置了这么牛的系统，那么网卡就不能用默认的千兆网卡了。我选了两个双口光纤万兆模块，再加上一个1&#43;1冗余电源。其他都用默认选配。计算下来，每G成本为56.2/Gyr。这差不多就是一个光板机器的最低价格了，里面不带任何其他费用。
另外，为了参考，我们计算一组CPU配足的机型E5-2670 * 2。这颗CPU是24T的，所以要配合192G内存。平均成本为60.47/Gyr。
IO密度问题 上面假定一台机器尽力往里插内存，但是实际上不能这么做。因为存储模型的问题。
我把虚拟化分为两种——单台机器故障的情况下数据不丢失，可以立刻在其他系统上开始启动系统的。和单台故障的情况下无法立刻恢复系统，甚至数据完整性都不能保证的。前者敢叫云计算，后者只能叫VPS。
为了达到后者，一般我们会把写入存放在多台机器上。而为了效率考虑，EC编码之类的方案几乎不能考虑。所以综合下来，唯一的方法就是将数据写入同步到另外两台机器上（三副本）。如果这个复制动作通过网络进行，那么写入速度就受到网络瓶颈。
例如上面的256G机器。虽然我选了两个双口万兆模块，总吞吐量高达40G。但是实际上你得假定可能有一根线故障，可用速率只有30G（如果是一个模块故障，更会降低到20G，幸好这不常见）。30G速率均分给256G内存，平均分给每G的吞吐只有120Mbps/G。折算出来就是15MB/s每G。这个速率要通过两份数据，分别传输给两台机器。如果用户不幸而选择了1G的内存，搞不好写入速度只有7.5M/s。要达到普通系统60M/s的写入速率，至少需要8G内存。这还没有计算机器到机器间通讯速率。
那么解决方案是什么？其中之一就是降低机器上的内存数。当然增加网卡也是一个方案，但是这会严重影响接入系统的效率——我们本来已经出了4根纤了，你想把服务器搞成八爪鱼不成？
如果内存数降低，那么单位内存上的吞吐速率就能提升。192G的吞吐是160Mbps/G，每G写入可达10M/s。内存降到128G的话，平均吞吐率就会升高到240Mbps/G，每G的写入速率可以提高到15M/s。如果降到64G，每G写入速率还会提升到30M/s。不过IO问题是个峰值问题。如果全系统都有大量写入，例如大部分实例都装了数据库，那么很不妙。不过如果全系统都是纯密集计算，那写入速度其实影响并不很大。为了对比，我同样计算了128G和64G的情况。但是这并不表示在实际搭建集群的时候需要使用低内存的机器。
有趣的是，在其他保持不变的情况下，128G的平均成本为59.44/Gyr，和256G的版本相差无几，比192G的版本还便宜些。64G却快速上升到94.25。这说明在一定内存数量以上，硬件平均成本受到内存密度的影响并不大，但是低于某个限制后，则快速受到影响。
另一个方案则是在服务器上采用40G网卡，4块40G网卡也能解决问题。但是网络会非常难做。因为上手就用了普通汇聚层的速率，所以如果要不大影响收敛比的情况下，汇聚和核心的速率要求会进一步提升。这种模型下，单位价格为62.55/Gyr。
当然，还有另一个方案。我们使用独立存储系统，例如盘柜。这样会带来两个好处。首先盘柜的光纤独立，因此会极大的提升网络系统的效率。其次盘柜的多份复制是自行完成的，因此并不需要在吐出光纤上传送两份数据。当然，我对这种方案不熟，所以下面没做深入计算。哪天可以把这个方案的成本模型算出来再写一篇。
下面我总结一遍上面方案的配比和成本：
 256G &#43; 10G * 4: 56.20/Gyr 192G &#43; 10G * 4: 60.47/Gyr 128G &#43; 10G * 4: 59.44/Gyr 64G &#43; 10G * 4: 94.25/Gyr 256G &#43; 40G * 4: 62.55/Gyr  注1：其实192G的版本用R730还会更便宜一些，低到54.40/Gyr。但是我们的目标是同类对比。为了减少环境变量，所以不讨论这种情况。
注2：其实128G的版本由于CPU比较节能，所以整机大约可以节约100W的电力。这部分在下面并没有被考虑，否则可能涉及机柜里会多或者少一台机器，计算会非常复杂。
机房成本 机房成本包括两块，网络设备费用和柜子费用。
网络费用很容易算，一个柜子一般是42U/10A/20A电力。撑死放5-10台服务器。一个服务器两口，也就是10-20口左右的交换机。选个不大夸张的机器，也就是1W差不多了。就算电力翻倍，机器翻倍，交换机价格差不多也是翻倍的。所以平均成本还是基本不变。
核心那里难算一点，一套核心要上百万，摊给全机房用。而且如果机器太多，可能两层交换量不够，还会用三层交换。那还有汇聚层的钱要算，大概又是上百万。
柜子的价格最难算。视地点不同，每个月从几k到十几k不等。每个柜子能放的机器，随电力状况和CPU功耗，从5台到15台(35A)不等。而且很多时候，公司的体量大小和谈判能力也会严重的影响到价格。
所以，为了简化上述计算，我直接硬把机柜价格指定为60k/yr[1]。300个柜子，每个柜子5台设备，1500台机器。核心加汇聚加接入，总数大约600W，每个柜子20k。至于为什么是这个数？不为什么，就是后面好算。
于是很容易就算出来，每机柜每年成本64k/yr。128G下是100/Gyr，192G下是66.67/Gyr，256G下是50/Gyr。40G光纤比10G光纤原则上要贵，因为起手就要用汇聚交换机，而不是接入级的。但是具体贵多少——很遗憾我根本找不到数据。推测是贵了至少5倍。
实际上，由于机房各种配比不一定能够达到最优状况，所以接入模型配比往往会比预期的高上非常多。而且机房成本也不一定能够控制在60k/yr的水平上。所以如果从业界实际角度考虑，这个费用的精确度大约会有20%的上下浮动。
 参考 这篇文档 ，有的地方能租到这么便宜的柜子，有的地方不行。  运维 一套云计算平台，需要多少个人运维？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="//blog.shell909090.org/blog/archives/2813/" />
<meta property="article:published_time" content="2015-12-18T00:00:00+00:00" />
<meta property="article:modified_time" content="2015-12-18T00:00:00+00:00" />

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body);
        });
    </script>

<header>

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow-night-eighties.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <nav>
    <ul>
      
      
      <li class="pull-left ">
        <a href="//blog.shell909090.org/">/home/shell&#39;s home</a>
      </li>
      

      

    </ul>
  </nav>
</header>


  </head>
  <body>
    <header class="app-header">
      <a href="//blog.shell909090.org/"><img class="app-header-avatar" src="/avatar.jpg" alt="Shell Xu" /></a>
      <h1>Shell&#39;s Home</h1>
      <p>贝壳的壳</p>
      <div class="app-header-social">
        
      </div>
      <p>Copyright &copy; 2020 Shell Xu - <a href="//blog.shell909090.org/license/">License</a></p>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">云计算的成本计算</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Dec 18, 2015
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          2 min read
        </div></div>
    </header>
    <div class="post-content">
      

<h1 id="成本构成和计算基准">成本构成和计算基准</h1>

<p>一般来说，云计算的综合成本会分为三块。硬件，机房（包括机房内网络设施），运维。当然，其实还有IP费用和流量费用。但是那个在云计算的费用中一般也是分开列的，所以可以和以上三项分开算。我们先算出去掉IP和流量的费用，然后再来独立讨论这两项的效应。</p>

<p>在云计算中，CPU是可以超卖的，但是内存一般不超卖。所以我们计算的基准是内存。准确的说，是“带上其他硬件设备的内存”的单位价格。单位是人民币每G每年，缩写为/Gyr。在整个计算中，硬件费用都是来自dell美国的报价计算器，汇率恒定在6.5，折旧速率是5年。存储系统的折旧速度会比整机更快。存储盘3年折旧，SSD1.5年折旧。</p>

<p>存储是硬件成本中比较特殊的一项，因为每个虚拟机都带有存储，也可以额外配置。所以我们单独为其估价，再在整体费用中将其加回去。这样在估算价格时可以计算光板系统。</p>

<h1 id="硬件成本">硬件成本</h1>

<p>在这个计算中，我随意挑了一款2U机器——R530。这是一台最低型号的2U机器，不知道有没有人在实际生产中用他，总之我们就先随便算。这台机器极限能插8条32G的内存，总内存量可以高达256G，还是挺适合虚拟化的。因为机器总体有成本，单机内存数越高，原理上说越省钱。</p>

<p>撇开存储，撇开网络，内存升到极限，其实我们能选的就是一颗CPU。而且一般来说，CPU和内存需要成比例搭配。一般会选择1:4的搭配比，256G内存需要64颗核心。整个CPU搭配表上就没这么牛X的CPU。。。</p>

<p>好吧，退而求其次，看看稍微差一点的CPU如何。由于整机搭配的内存和CPU越高，整体价格越便宜。所以我们搭配一颗最牛X的核心——E5-2695 * 2。整个系统瞬间升到56颗核心。和64核也相差无几，我们就选他了。</p>

<p>相对的，整个机器既然配置了这么牛的系统，那么网卡就不能用默认的千兆网卡了。我选了两个双口光纤万兆模块，再加上一个1+1冗余电源。其他都用默认选配。计算下来，每G成本为56.2/Gyr。这差不多就是一个光板机器的最低价格了，里面不带任何其他费用。</p>

<p>另外，为了参考，我们计算一组CPU配足的机型E5-2670 * 2。这颗CPU是24T的，所以要配合192G内存。平均成本为60.47/Gyr。</p>

<h1 id="io密度问题">IO密度问题</h1>

<p>上面假定一台机器尽力往里插内存，但是实际上不能这么做。因为存储模型的问题。</p>

<p>我把虚拟化分为两种——单台机器故障的情况下数据不丢失，可以立刻在其他系统上开始启动系统的。和单台故障的情况下无法立刻恢复系统，甚至数据完整性都不能保证的。前者敢叫云计算，后者只能叫VPS。</p>

<p>为了达到后者，一般我们会把写入存放在多台机器上。而为了效率考虑，EC编码之类的方案几乎不能考虑。所以综合下来，唯一的方法就是将数据写入同步到另外两台机器上（三副本）。如果这个复制动作通过网络进行，那么写入速度就受到网络瓶颈。</p>

<p>例如上面的256G机器。虽然我选了两个双口万兆模块，总吞吐量高达40G。但是实际上你得假定可能有一根线故障，可用速率只有30G（如果是一个模块故障，更会降低到20G，幸好这不常见）。30G速率均分给256G内存，平均分给每G的吞吐只有120Mbps/G。折算出来就是15MB/s每G。这个速率要通过两份数据，分别传输给两台机器。如果用户不幸而选择了1G的内存，搞不好写入速度只有7.5M/s。要达到普通系统60M/s的写入速率，至少需要8G内存。这还没有计算机器到机器间通讯速率。</p>

<p>那么解决方案是什么？其中之一就是降低机器上的内存数。当然增加网卡也是一个方案，但是这会严重影响接入系统的效率——我们本来已经出了4根纤了，你想把服务器搞成八爪鱼不成？</p>

<p>如果内存数降低，那么单位内存上的吞吐速率就能提升。192G的吞吐是160Mbps/G，每G写入可达10M/s。内存降到128G的话，平均吞吐率就会升高到240Mbps/G，每G的写入速率可以提高到15M/s。如果降到64G，每G写入速率还会提升到30M/s。不过IO问题是个峰值问题。如果全系统都有大量写入，例如大部分实例都装了数据库，那么很不妙。不过如果全系统都是纯密集计算，那写入速度其实影响并不很大。为了对比，我同样计算了128G和64G的情况。但是这并不表示在实际搭建集群的时候需要使用低内存的机器。</p>

<p>有趣的是，在其他保持不变的情况下，128G的平均成本为59.44/Gyr，和256G的版本相差无几，比192G的版本还便宜些。64G却快速上升到94.25。这说明在一定内存数量以上，硬件平均成本受到内存密度的影响并不大，但是低于某个限制后，则快速受到影响。</p>

<p>另一个方案则是在服务器上采用40G网卡，4块40G网卡也能解决问题。但是网络会非常难做。因为上手就用了普通汇聚层的速率，所以如果要不大影响收敛比的情况下，汇聚和核心的速率要求会进一步提升。这种模型下，单位价格为62.55/Gyr。</p>

<p>当然，还有另一个方案。我们使用独立存储系统，例如盘柜。这样会带来两个好处。首先盘柜的光纤独立，因此会极大的提升网络系统的效率。其次盘柜的多份复制是自行完成的，因此并不需要在吐出光纤上传送两份数据。当然，我对这种方案不熟，所以下面没做深入计算。哪天可以把这个方案的成本模型算出来再写一篇。</p>

<p>下面我总结一遍上面方案的配比和成本：</p>

<ul>
<li>256G + 10G * 4: 56.20/Gyr</li>
<li>192G + 10G * 4: 60.47/Gyr</li>
<li>128G + 10G * 4: 59.44/Gyr</li>
<li>64G + 10G * 4: 94.25/Gyr</li>
<li>256G + 40G * 4: 62.55/Gyr</li>
</ul>

<p>注1：其实192G的版本用R730还会更便宜一些，低到54.40/Gyr。但是我们的目标是同类对比。为了减少环境变量，所以不讨论这种情况。</p>

<p>注2：其实128G的版本由于CPU比较节能，所以整机大约可以节约100W的电力。这部分在下面并没有被考虑，否则可能涉及机柜里会多或者少一台机器，计算会非常复杂。</p>

<h1 id="机房成本">机房成本</h1>

<p>机房成本包括两块，网络设备费用和柜子费用。</p>

<p>网络费用很容易算，一个柜子一般是42U/10A/20A电力。撑死放5-10台服务器。一个服务器两口，也就是10-20口左右的交换机。选个不大夸张的机器，也就是1W差不多了。就算电力翻倍，机器翻倍，交换机价格差不多也是翻倍的。所以平均成本还是基本不变。</p>

<p>核心那里难算一点，一套核心要上百万，摊给全机房用。而且如果机器太多，可能两层交换量不够，还会用三层交换。那还有汇聚层的钱要算，大概又是上百万。</p>

<p>柜子的价格最难算。视地点不同，每个月从几k到十几k不等。每个柜子能放的机器，随电力状况和CPU功耗，从5台到15台(35A)不等。而且很多时候，公司的体量大小和谈判能力也会严重的影响到价格。</p>

<p>所以，为了简化上述计算，我直接硬把机柜价格指定为60k/yr[1]。300个柜子，每个柜子5台设备，1500台机器。核心加汇聚加接入，总数大约600W，每个柜子20k。至于为什么是这个数？不为什么，就是后面好算。</p>

<p>于是很容易就算出来，每机柜每年成本64k/yr。128G下是100/Gyr，192G下是66.67/Gyr，256G下是50/Gyr。40G光纤比10G光纤原则上要贵，因为起手就要用汇聚交换机，而不是接入级的。但是具体贵多少——很遗憾我根本找不到数据。推测是贵了至少5倍。</p>

<p>实际上，由于机房各种配比不一定能够达到最优状况，所以接入模型配比往往会比预期的高上非常多。而且机房成本也不一定能够控制在60k/yr的水平上。所以如果从业界实际角度考虑，这个费用的精确度大约会有20%的上下浮动。</p>

<ol>
<li>参考
<a href="http://www.7x24.cn/colocation/idc-colocation-centre.htm">这篇文档</a>
，有的地方能租到这么便宜的柜子，有的地方不行。</li>
</ol>

<h1 id="运维">运维</h1>

<p>一套云计算平台，需要多少个人运维？</p>

<p>不知道，这得看是什么平台了。假定不需要研发（openstack出局），不需要license费（vmware出局），纯维护管理。最小单位需要1-2个SA，1-2个网络工程师，一个程序员，一个经理，五六个值班监控。。。大约10人团队。如果再加上研发，那就没底了。</p>

<p>目前每个人的公司侧成本（不计办公费用，计公司税费），至少要30W一年。这批人就是300W一年的开销。如果摊到1500台256G的机器上，那就是7.812/Gyr。如果是192，那就是10.42/Gyr。如果是128G，那就是15.625/Gyr。当然，加上公司运营因素和各种杂项，要翻倍比较合适。</p>

<h1 id="资金成本">资金成本</h1>

<p>大家别忘了，资金也是有成本的呐。不是说1W摊5年，每年摊2k就完事了。如果1W放五年理财，也得有个25%的收益了。从企业运营的角度讲，如果资金收益率小于10%，那还不如让别人来干。省下钱来干点别的更赚钱的业务。</p>

<p>所以以上各项成本，在累加后还要乘以至少1.1。</p>

<h1 id="成本部分结论">成本部分结论</h1>

<p>上面数项，除掉存储，价格总计为：</p>

<ol>
<li>256G + 10G*4: (56.2 + 50 + 15.62) * 1.1 = 134.0/Gyr</li>
<li>192G + 10G*4: (60.47 + 66.67 + 20.83) * 1.1 = 162.77/Gyr</li>
<li>128G + 10G*4: (59.44 + 100 + 31.25) * 1.1 = 209.76/Gyr</li>
<li>64G + 10G*4: (94.25 + 200 + 62.50) * 1.1 = 392.42/Gyr</li>
<li>256G + 40G*4: (62.55 + 62.5 + 15.62) * 1.1 = 154.74/Gyr</li>
</ol>

<p>里面我们可以得到一些结论。</p>

<ol>
<li><p>云计算的成本，基本是硬件和机柜对半分。最贵的不一定是硬件，很可能是机柜，尤其在内存密度不足时。</p></li>

<li><p>大内存最显著的意义并不是降低硬件平均费用，而是增加机柜密度。机柜密度大就节约租金和运维开销，因为一般运维不会因为维护的机器内存更大就更花人工。当然，由于上面并没有反应出高密度机器CPU功率会高的事实，所以更高的机柜密度就意味着更低的成本。如果将这部分纳入，高功率可能导致少放一台机器，从而产生其他影响。</p></li>

<li><p>影响机柜密度的最主要因素不是空间不足，而是电力不足。机柜租金中也有相当大比例来自电费（和制冷电费）。因此电费便宜，环境冷的地方的机房，成本肯定低。</p></li>

<li><p>从硬件侧说，整台机器的主要电力花销和成本都来自CPU。大数额内存的功率花销几乎可以忽略，成本基本都是32G/500\$，合大约20/Gyr。主要电功率开销和浮动成本都来自CPU，所以选择低功耗低成本比CPU可以有效降低成本。而一般来说，核数越多，平均功耗是几乎肯定降低的，平均价格会略有波动。</p></li>

<li><p>但是如上面所说，增加CPU核心密度来提升机柜密度有其缺陷——外部通讯系统瓶颈。是否要解决这个问题，就见仁见智了。</p></li>

<li><p>在这几个模式里，我个人比较喜欢2和5。两个都相对不算贵。2的IO比1好，而且CPU足。5的成本更低，但是CPU不足，而且这个模式下的稳定性如何，网络如何支撑，没有大量实践。</p></li>
</ol>

<h1 id="存储">存储</h1>

<p>我们下面要估算的是裸存储价格，即光板存储的单位价格。在配置RAID，或者做冗余的时候，需要相应的折损。</p>

<p>裸存储价格也分为三类——低速盘，高速盘，SSD。一般来说，速度越低，IOPS越低，越适合做数据仓库。速度越高，成本越高，越适合做高速读写。</p>

<p>低速盘最大8T，单价7k。折算下来，0.289/Gyr。一般能跑100-200IOPS，平均0.025IOPS/G。</p>

<p>高速盘最大600G，单价4k。折算下来，2.254/Gyr。一般能跑500IOPS，平均0.833IOPS/G。</p>

<p>SSD先选最大一块1.92T那块，单价14k，折算下来，4.972/Gyr。这块是读优化的，有数据说能到100k
IOPS，平均52IOPS/G。如果是写入，只有18k
IOPS，平均9.375IOPS/G。阿里云的宣称数据是30IOPS/G，这块是支撑不起来的。要能支持30IOPS/G，需要选用800G那块，写优化的。单价13.04/Gyr，据说写入能达到28k
IOPS，平均35IOPS/G。</p>

<p>可以看到，SSD的成本要比存储盘远高。按照单价而言，甚至远远高于硬件成本。如果我们给一台虚拟机增配20G裸存储SSD的话，每台就要增加280.8/yr的费用。更糟糕的是，虚拟机存储费用是裸存储的3倍（三副本）。一般来说为了节约成本，没有厂家会在这里用SSD来支撑系统镜像，最多高速盘。也就是135.24/yr的成本。</p>

<p>吞吐的成本如此高，也难怪IO是衡量虚拟机性能的重要指标。</p>

<p>注：有些厂家可能在高速盘集群上搭配了SSD的cache，作为读写缓冲，并自动分层管理缓存。这种模式对IO优化很好，成本也很低廉。我们在这里对这种模式不做深入。</p>

<h1 id="计算存储成本">计算存储成本</h1>

<p>如果以4G内存搭配20G高速盘来计算存储附加，成本增加为：</p>

<p>3 * 2.254 * 20 / 4 * 1.1 = 37.19/Gyr</p>

<ol>
<li>256G + 10G*4: 134.0 + 37.19 = 171.19/Gyr</li>
<li>192G + 10G*4: 162.77 + 37.19 = 199.96/Gyr</li>
<li>128G + 10G*4: 209.76 + 37.19 = 246.95/Gyr</li>
<li>64G + 10G*4: 392.42 + 37.19 = 429.61/Gyr</li>
<li>256G + 40G*4: 154.74 + 37.19 = 191.93/Gyr</li>
</ol>

<h1 id="云计算费用">云计算费用</h1>

<p>OK，在经过上面罗哩罗嗦的计算后，我们终于讲到重头戏了——云计算费用。</p>

<p>在配置硬件的时候，在搭配中1T会配4G内存。但是CPU超卖情况下，1T是绝对不会卖4G以上内存的。因为这会让部分CPU永远不被用到。（想不通的朋友可以考虑，如果1T配8G内存，那256G内存最多分配32T，56T里面会空出24T无法分配）因此2核心可以搭配1G-8G内存，却不能搭配以上。如果只搭配2G内存，那么2G/2核心，按平均却只能占有半个核心，却实际能占据两个核心。</p>

<p>这就是虚拟化成本计算模型中最大的问题——CPU超卖。</p>

<p>我们如何计算呢？很简单。取每家最大核心的情况下，内存最大的一个套餐，计算为每G成本。因为这个搭配基本和这家的每个计算单元的物理状况趋向一致。而这家的其他套餐，费用一定会高于这个套餐。多出来的钱就是CPU超卖利润。</p>

<p>当然，超卖比例越高（例如全都是2G内存搭配4核心），虽然利润越高。但是如果这家不约束这种行为，会很快导致计算力不足而被客户骂死。一旦约束这种行为，实际上就需要将内存空着不卖出去。导致每G内存收取费用上升。本质上还是会回归到差不多的价格。</p>

<p>作为用户来说，其实小内存大核心在密集运算的价格上会占点便宜。但是由于一般网站计算的特性，应当合理的搭配核心和内存。也没可能为了多占核心而特意配一个小内存大核心的机器。1:2到1:4的内存比是比较恰当的。</p>

<p>青云：国内665.82/Gyr，亚太节点921.00/Gyr。</p>

<p>阿里云：国内(除青岛)447.0/Gyr，香港节点525.94/Gyr。</p>

<p>腾讯云：375/Gyr。腾讯云的特殊之处在于有1核心超越4G内存的搭配，看来硬件配比应该比较特殊。而且香港机房并没有显著贵。</p>

<p>ucloud：国内454.84/Gyr，亚太节点518.28/Gyr。</p>

<p>GCE：美国531.44/Gyr，亚太节点584.58/Gyr。</p>

<p>AWS(EC2)：美国516.18/Gyr，美国(北加州)711.46/Gyr，日本683.55/Gyr。</p>

<p>linode：780/Gyr。所有节点统一价格，还包了流量费用。简直神奇。</p>

<h1 id="结论">结论</h1>

<ol>
<li><p>别忘了上面的价格可都是零售价格，大客户还能打折。再加上一般机房里不可能全部资源都正好卖光，都会空着部分资源。上面的价格乘以0.7-0.8差不多是实际运营商每G能赚到的钱。</p></li>

<li><p>大部分云计算厂商的价格都在500/Gyr上下波动。linode的特别贵，但是那个包含了很高的流量费用，扣掉之后反而是最便宜的。但是要记得，linode是vps，而不是云。腾讯云的特别便宜，而且香港机房也没有提价，原因不确定。</p></li>

<li><p>机房对总成本的影响非常大，这点非常符合成本预期。下面实际计算出来光成本差就有0(腾讯云)，50/Gyr(GCE/ucloud)，200/Gyr(青云/AWS)，这么几种级别。</p></li>

<li><p>以阿里云，0.8销售比和128G节点来计算的话。阿里云的折算后收益大约是360，节点成本是250。考虑其他费用（包括市场/售前/售后/财务/人事,etc）的情况下，其实match的很不错。</p></li>

<li><p>假设用户有xG的需求，每个都是理想状态，自建服务器和采购云平台哪个更合算？</p></li>
</ol>

<p>我们只计算256G版本，192G版本和128G版本，其他请自己类推。</p>

<p>256G版本：<br />
(56.2 + 50 + 2*3000000/x + 135.<sup>24</sup>&frasl;<sub>4</sub>) * 1.1 = 500 * 0.8<br />
求出来得到x = 26830.5G。</p>

<p>192G版本：<br />
(60.47 + 66.67 + 2*3000000/x + 135.<sup>24</sup>&frasl;<sub>4</sub>) * 1.1 = 500 * 0.8<br />
求出来得到x = 29602.4G。</p>

<p>128G版本：<br />
(59.44 + 100 + 2*3000000/x + 135.<sup>24</sup>&frasl;<sub>4</sub>) * 1.1 = 500 * 0.8<br />
求出来得到x = 35214.1G。</p>

<p>所以，要自建机房，至少得有30T内存需求以上，甚至要到35T。用256G内存来算，这大约是120台。192G下是160台。128G下是300台。</p>

<p>一个基本结论是，所用的内存越大，越容易低成本的自建云存储。这很容易理解，因为大内存机机柜密度高，租金低，用小团队就可以管理。考虑到各种其他开销。如果总内存需求量上了30T，不妨可以考虑一下。当然，你可别忘了上面的假定是“10个人团队能hold住整个系统”。很多IT公司的管理和选型下，这点是做不到的。</p>

<p>考虑到自己开销的波动（例如促销），公有云比自建机房更方便抵消这部分波动。从这里来说，大部分情况下自建机房都不合算。如果基础系统开销已经超过了临界点，不妨考虑将波动部分扔到云上，通过VPN和自建平台对接（例如AWS
Direct Connect）。</p>

<h1 id="带宽价格">带宽价格</h1>

<p>上面我们都在说机房，而没有提到带宽。主要问题是国内带宽情况非常混乱。电信卖给竞争对手的价格高达1000/Mbps，而阿里CDN的价格只有22.8/Mbps（所以才有流量穿透问题啊，同学们，万恶的资本主义。。。）。这说明在阿里的边缘节点上，他们的带宽价格不会比22.8/Mbps更贵，至少不会普遍更贵。</p>

<p>那么带宽价格如何对照？我觉得比较有意义的是各CDN厂商的价格。CDN厂商的主要成本都是来自边缘节点的出向流量费用。由于缓存作用，他们的入向流量应该显著不足。当然，传统CDN厂商也像各大运营商一样，定价非常浮动。不过aliyun之类的厂商定价还是比较透明的。我们可以以他们作为标杆。</p>

<h1 id="说明">说明</h1>

<p>首先特别说明一点。这个计算中不包括任何七牛的线上配置，产品，价格之类的数据。对比中也特意略去了七牛。</p>

<p>对于我来说，这些算是公司机密，因为很多我都接触到了。当然，大家可以自行将上面的算法应用在七牛上。。。那就和我没关系了。</p>

<p>其次要注意，成本那部分并不很准。首先用的是DELL海外官方价格。相信任何一家云计算去采购的时候都会面对不一样的供货价格，然后再谈判一个折扣。那个价格只能参考。其次很多地方也采用了近似估计的方法（例如机房）。只能仅供参考。</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
